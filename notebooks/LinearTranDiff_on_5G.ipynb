{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pollyjuice74/REU-LDPC-Project/blob/main/LinearTranDiff_on_5G.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Decoding on 5G NR LDPC codes using custom made Transformer Diffusion model. Reached loss of:\n",
        "\n",
        "***Training epoch 1, Batch 100/100, Loss=2.18612e-04\n",
        "Epoch 1 Train Time 1836.7272102832794s***"
      ],
      "metadata": {
        "id": "ZBMu-VBcAPNo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rXwLdxMGTjF8"
      },
      "outputs": [],
      "source": [
        "# Source code\n",
        "!git clone https://github.com/pollyjuice74/REU-LDPC-Project\n",
        "!git clone https://github.com/pollyjuice74/DDECC\n",
        "# Sionna stuff\n",
        "!git clone https://github.com/NVlabs/sionna.git\n",
        "!pip install mitsuba\n",
        "!pip install pythreejs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "e-lnoCOdT9LS"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import random\n",
        "import numpy as np\n",
        "import scipy as sp\n",
        "import time\n",
        "import os\n",
        "from scipy.sparse import issparse, csr_matrix, coo_matrix\n",
        "\n",
        "\n",
        "# os.chdir('../..')\n",
        "os.chdir('sionna')\n",
        "from sionna.fec.ldpc.encoding import * # 5g encoder\n",
        "\n",
        "from sionna.utils.metrics import compute_ber, compute_bler\n",
        "from sionna.utils import BitErrorRate, BinarySource, ebnodb2no\n",
        "\n",
        "from sionna.mapping import Constellation, Mapper, Demapper\n",
        "from sionna.channel import AWGN\n",
        "os.chdir('..')\n",
        "\n",
        "if os.path.exists('REU-LDPC-Project'):\n",
        "  os.rename('REU-LDPC-Project', 'REU_LDPC_Project')\n",
        "\n",
        "os.chdir('REU_LDPC_Project/adv_nn')\n",
        "from attention import *\n",
        "from channel import *\n",
        "from transformer import *\n",
        "from dataset import *\n",
        "from args import *\n",
        "from model_functs import *\n",
        "from models import *\n",
        "from decoder5G import * # 5g decoder\n",
        "\n",
        "os.chdir('../..')\n",
        "from DDECC.src.codes import EbN0_to_std\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerDiffusion( Layer ):\n",
        "    def __init__(self, args):\n",
        "        super().__init__()\n",
        "        self.model_type = args.model_type\n",
        "        self.n_steps = args.n_steps\n",
        "\n",
        "        code = args.code\n",
        "        assert issparse(code.H), \"Code's pcm must be sparse.\"\n",
        "        self.pcm = code.H\n",
        "        # shapes\n",
        "        self.m, self.n = self.pcm.shape\n",
        "        self.k = self.n - self.m\n",
        "\n",
        "        self.mask = self.create_mask(self.pcm)\n",
        "        # layers\n",
        "        self.src_embed = tf.Variable( tf.random.uniform([1, self.n + self.m, args.d_model]), trainable=True )\n",
        "        self.decoder = Transformer(args.d_model, args.heads, self.mask, args.t_layers)\n",
        "        self.fc = Dense(1)\n",
        "        self.to_n = Dense(1)\n",
        "        self.to_m = Dense(1)\n",
        "        self.time_embed = Embedding(args.n_steps, args.d_model)\n",
        "\n",
        "        self.betas = tf.constant( tf.linspace(1e-3, 1e-2, args.n_steps)*0 + args.sigma )\n",
        "        self.betas_bar = tf.constant( tf.math.cumsum(self.betas, 0) )\n",
        "\n",
        "        self.split_diff = False#args.split_diff\n",
        "        self.ls_active = args.ls_active\n",
        "\n",
        "        scheduler = tf.keras.optimizers.schedules.CosineDecay( initial_learning_rate=args.lr, decay_steps=args.epochs ) # 1000 is size of trainloader\n",
        "        self.optimizer =  tf.keras.optimizers.Adam(learning_rate=scheduler)\n",
        "\n",
        "    def create_mask(self, H):\n",
        "        m,n = H.shape\n",
        "        mask = tf.eye(n+m, dtype=tf.float32) # (n+m, n+m)\n",
        "        cn_con, vn_con, _ = sp.sparse.find(H)\n",
        "\n",
        "        for cn, vn_i in zip(cn_con, vn_con):\n",
        "            # cn to vn connections in the mask\n",
        "            mask = tf.tensor_scatter_nd_update(mask, [[n+cn, vn_i],[vn_i, n+cn]], [1.0,1.0])\n",
        "\n",
        "            # distance 2 vn neighbors of vn_i\n",
        "            related_vns = vn_con[cn_con==cn]\n",
        "            for vn_j in related_vns:\n",
        "                mask = tf.tensor_scatter_nd_update(mask, [[vn_i, vn_j],[vn_j, vn_i]], [1.0,1.0])\n",
        "\n",
        "        # -infinity where mask is not set\n",
        "        mask = tf.cast( tf.math.logical_not(mask > 0), dtype=tf.float32) # not(mask > 0) for setting non connections to -1e9\n",
        "        return mask\n",
        "\n",
        "    def get_sigma(self, t):\n",
        "        # make sure t is a positive int\n",
        "        t = tf.cast( tf.abs(t), tf.int32 )\n",
        "        # gather betas\n",
        "        betas_t = tf.gather(self.betas, t)\n",
        "        betas_bar_t = tf.gather(self.betas_bar, t)\n",
        "\n",
        "        return betas_bar_t * betas_t / (betas_bar_t + betas_t)\n",
        "\n",
        "    def get_syndrome(self, r_t):\n",
        "        # Calculate syndrome (pcm @ r = 0) if r is correct in binary\n",
        "        r_t = tf.reshape(r_t, (self.n, -1)) # (n,b)\n",
        "        return self.pcm.dot( llr_to_bin( r_t ).numpy() ) % 2 # (m,n)@(n,b)->(m,b)\n",
        "\n",
        "    # Extracts noise estimate z_hat from r\n",
        "    def tran_call(self, r_t, t):\n",
        "        # Make sure r_t and t are compatible\n",
        "        r_t = tf.reshape(r_t, (self.n, -1)) # (n,b)\n",
        "        t = tf.cast(t, dtype=tf.int32)\n",
        "\n",
        "        # Compute synd and magn\n",
        "        syndrome = tf.reshape( self.get_syndrome(llr_to_bin(r_t)), (self.pcm.shape[0], -1) ) # (m,n)@(n,b)->(m,b) check nodes\n",
        "        magnitude = tf.reshape( tf.abs(r_t), (self.n, -1) ) #(n,b) variable nodes\n",
        "        # make sure their the same dtype\n",
        "        magnitude, syndrome = [ tf.cast(tensor, dtype=tf.float32) for tensor in [magnitude, syndrome] ]\n",
        "\n",
        "        # Concatenate synd and magn\n",
        "        nodes = tf.concat([magnitude, syndrome], axis=0) # data for vertices\n",
        "        nodes = tf.reshape(nodes, (1, self.n+self.m, -1)) # (1, n+m, b)\n",
        "        print(nodes.shape)\n",
        "\n",
        "        # Embedding nodes w/ attn and 'time' (sum syn errs) dims\n",
        "        nodes_emb = tf.reshape( self.src_embed * nodes, (self.src_embed.shape[-1], self.pcm.shape[0]+self.n, -1) ) # (d,n+m,b)\n",
        "        time_emb = tf.reshape( self.time_embed(t), (self.src_embed.shape[-1], 1, -1) ) # (d,1,b)\n",
        "\n",
        "        # Applying embeds\n",
        "        emb_t = time_emb * nodes_emb # (d, n+m, b)\n",
        "        logits = self.decoder(emb_t) # (d, n+m, d) # TODO: missing batch dims b\n",
        "        print(emb_t, logits)\n",
        "\n",
        "        # Reduce (d,n+m,d)->(d,n+m)\n",
        "        logits = tf.squeeze( self.fc(logits), axis=-1 )\n",
        "        vn_logits = tf.reshape( logits[:, :self.n], (self.n, -1) ) # (n,d) take the first n logits from the concatenation\n",
        "        cn_logits = tf.reshape( logits[:, self.n:], (self.m, -1) ) # (m,d) take the last m logits from the concatenation\n",
        "        print(vn_logits, cn_logits)\n",
        "\n",
        "        z_hat = self.to_n(vn_logits)# (n,d)->(n,)\n",
        "        synd = self.to_m(cn_logits)# (m,d)->(m,)\n",
        "        print(logits.shape, z_hat.shape)\n",
        "\n",
        "        return z_hat, synd\n",
        "\n",
        "    # optimal lambda l for theoretical and for error prediction\n",
        "    def line_search(self, r_t, sigma, err_hat, lin_splits=20):\n",
        "        l_values =  tf.reshape( tf.linspace(1., 20., lin_splits), (1, 1, lin_splits) )\n",
        "        r_t, sigma, err_hat = [ tf.expand_dims(tensor, axis=-1) for tensor in [r_t, sigma, err_hat] ]# (n,b, 1)\n",
        "        print(f\"sigma: {sigma}, err_hat: {err_hat}\")\n",
        "\n",
        "        # Compute theoretical step size w/ ls splits\n",
        "        z_hat_values = l_values*(sigma*err_hat) # (n,b, l), l is lin_splits\n",
        "        r_values = llr_to_bin(r_t - z_hat_values) # (n,b, l)\n",
        "        # sum of synds (m,n)@(n,b*l)->(m,b*l)->(b*l, 1)\n",
        "        sum_synds = tf.reduce_sum( tf.abs( self.pcm.dot( tf.squeeze(r_values, axis=1) ) % 2 ),\n",
        "                                   axis=0 )[:, tf.newaxis]\n",
        "        print(sum_synds.shape)\n",
        "\n",
        "        # Pick optimal ls value\n",
        "        if self.model_type=='dis':\n",
        "             ixs = tf.math.argmin(sum_synds, axis=0, output_type=tf.int32) # (b,1) w/ ixs of optimal line search for batch b\n",
        "        elif self.model_type=='gen':\n",
        "             ixs = tf.math.argmax(sum_synds, axis=0, output_type=tf.int32) # (b,1)\n",
        "\n",
        "        print(r_values.shape, z_hat_values.shape, ixs.shape)\n",
        "        # (b, l, n) for indexing on l\n",
        "        r_values, z_hat_values = [ tf.transpose(tensor, perm=[1,2,0])\n",
        "                                            for tensor in [r_values, z_hat_values] ]\n",
        "\n",
        "        # concat range of batch ixs [0,...,n-1] and optimal line search ixs in gather_nd\n",
        "        indices = tf.concat( [tf.range(ixs.shape[0]), ixs], axis=-1) # (b,2)\n",
        "\n",
        "        # print(r_values, z_hat_values, indices)\n",
        "        # ix on lin_splits w/ gather_nd st. ix,(b, l, n)->(n,b)\n",
        "        r_t1, z_hat = [ tf.reshape( tf.gather_nd(tensor, indices), (self.n, -1) )\n",
        "                                             for tensor in [r_values, z_hat_values] ]\n",
        "        print(r_t1, z_hat_values)\n",
        "        return r_t1, z_hat # r at t-1\n",
        "\n",
        "    def loss_fn(self, synd):\n",
        "        return tf.reduce_mean(tf.square(synd))\n",
        "\n",
        "    def train_step(self, llr_ch):\n",
        "        with tf.GradientTape() as tape:\n",
        "            _, synd = self.tran_call(llr_ch,\n",
        "                                     tf.reduce_sum( self.get_syndrome(llr_ch) ))\n",
        "            loss = self.loss_fn(synd)\n",
        "        gradients = tape.gradient(loss, self.trainable_variables)\n",
        "        self.optimizer.apply_gradients(zip(gradients, self.trainable_variables))\n",
        "        return loss\n",
        "\n",
        "\n",
        "\n",
        "class Decoder( TransformerDiffusion ):\n",
        "    def __init__(self, args):\n",
        "        super().__init__(args)\n",
        "\n",
        "    # 'test' function\n",
        "    def call(self, r_t):\n",
        "        for i in range(self.m):\n",
        "            print(r_t.shape)\n",
        "            # both (n,)\n",
        "            r_t, z_hat = self.rev_diff_call(r_t) if not self.split_diff else self.split_rdiff_call(r_t)\n",
        "\n",
        "            # Check if synd is 0 return r_t\n",
        "            if tf.reduce_sum( self.get_syndrome(r_t) ) == 0:\n",
        "                return r_t, z_hat, i\n",
        "\n",
        "        return r_t, z_hat, i\n",
        "\n",
        "    # Refines recieved codeword r at time t\n",
        "    def rev_diff_call(self, r_t):\n",
        "        print(\"Rev def call...\")\n",
        "        # Make sure r_t and t are compatible\n",
        "        r_t = tf.reshape(r_t, (self.n, -1)) # (n,b)\n",
        "        # 'time step' of diffusion is really ix of abs(sum synd errors)\n",
        "        t = tf.reduce_sum( self.get_syndrome(llr_to_bin(r_t)), axis=0 ) # (m,n)@(n,b)->(m,b)->(1,b)\n",
        "        t = tf.cast(tf.abs(t), dtype=tf.int32)\n",
        "\n",
        "        # Transformer error prediction\n",
        "        z_hat_crude, synd = self.tran_call(r_t, t) # (n,1), (m,1)\n",
        "        print(\"z_hat_crude: \", z_hat_crude)\n",
        "\n",
        "        # Compute diffusion vars\n",
        "        sigma = self.get_sigma(t) # theoretical step size\n",
        "        print(\"sigma: \", sigma)\n",
        "        err_hat = r_t - tf.sign(z_hat_crude * r_t) # (n,1)\n",
        "\n",
        "        # Refined estimate of the codeword for the ls diffusion step\n",
        "        r_t1, z_hat = self.line_search(r_t, sigma, err_hat) if self.ls_active else 1.\n",
        "        # r_t1[t==0] = r_t[t==0] # if cw has 0 synd. keep as is\n",
        "\n",
        "        return r_t1, z_hat # r at t-1, both (n,1)\n",
        "\n",
        "    def split_rdiff_call(self, r_t):\n",
        "        print(\"Rev diff call with split diffusion...\")\n",
        "        # Ensure r_t is correctly shaped\n",
        "        r_t = tf.reshape(r_t, (self.n, -1))  # (n,b)\n",
        "        t = tf.reduce_sum(self.get_syndrome(llr_to_bin(r_t)), axis=0)  # (m,n)@(n,b)->(m,b)->(1,b)\n",
        "        t = tf.cast(tf.abs(t), dtype=tf.int32)\n",
        "\n",
        "        # First half-step condition subproblem\n",
        "        z_hat_crude, synd = self.tran_call(r_t, t)\n",
        "        r_t_half = r_t - 0.5 * self.fc(z_hat_crude * self.get_sigma(t))\n",
        "\n",
        "        # Full-step diffusion subproblem\n",
        "        r_t1 = r_t_half + tf.random.normal(r_t_half.shape) * tf.sqrt(self.get_sigma(t))\n",
        "\n",
        "        # Second half-step condition subproblem\n",
        "        z_hat_crude_half, synd = self.tran_call(r_t1, t)  # Reuse the second `tran_call`\n",
        "        r_t1 = r_t1 - 0.5 * self.fc(z_hat_crude_half * self.get_sigma(t))\n",
        "\n",
        "        return r_t1, z_hat_crude_half  # r at t-1, both (n,1)\n",
        "\n",
        "\n",
        "\n",
        "args = Args(model_type='dis', code_type='LDPC5G') # args for decoder/discriminator\n",
        "\n",
        "# Define enc/dec layers #\n",
        "enc5G = LDPC5GEncoder(args.k, args.n)\n",
        "dec5G = LDPC5GDecoder(enc5G, args)\n",
        "\n",
        "binary_source = BinarySource()\n",
        "\n",
        "# initialize mapper and demapper for constellation object\n",
        "constellation = Constellation(\"qam\", num_bits_per_symbol=4)\n",
        "mapper = Mapper(constellation=constellation)\n",
        "demapper = Demapper(\"app\", constellation=constellation)\n",
        "\n",
        "channel = AWGN() # replace w/ Generator(args)\n",
        "\n",
        "no = ebnodb2no(1, 11, args.k/args.n) # eb_no=1, bps=4\n",
        "no = tf.expand_dims(tf.cast(no, tf.float32), axis=-1)\n",
        "\n",
        "args.code.H = dec5G.pcm\n",
        "dec = Decoder(args)\n",
        "\n",
        "\n",
        "\n",
        "# Simulate #\n",
        "\n"
      ],
      "metadata": {
        "id": "eYSwka9S8OJa"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dec5G = LDPC5GDecoder(enc5G, args)\n",
        "# dec = Decoder(args)\n",
        "\n",
        "def train_dec_5G(dec5G, epoch, training_len=100):\n",
        "    loss_fn = tf.keras.losses.BinaryCrossentropy()\n",
        "    t = time.time()\n",
        "\n",
        "    for batch_idx in range(training_len):\n",
        "        u = binary_source([1, args.k])\n",
        "        c = enc5G(u) # (1,n)\n",
        "\n",
        "        x = mapper(c) # map c to symbols x\n",
        "        y = channel([x, no]) # transmit over AWGN channel\n",
        "        llr_ch = demapper([y, no]) # demap y to LLRs (1,n)\n",
        "\n",
        "        if dec5G.return_llrs5g:\n",
        "            llr_5g = dec5G(llr_ch)\n",
        "\n",
        "            loss = dec.train_step(llr_5g)\n",
        "\n",
        "        else:\n",
        "            c_hat = dec5G(llr_ch)\n",
        "            print(\"c, c_hat: \", c, c_hat)\n",
        "            loss = loss_fn(c_hat, c)\n",
        "\n",
        "        if (batch_idx + 1) % 1 == 0:\n",
        "            print(f'Training epoch {epoch}, Batch {batch_idx + 1}/{training_len}, Loss={loss.numpy():.5e}')\n",
        "\n",
        "    print(f'Epoch {epoch} Train Time {time.time() - t}s\\n')\n",
        "\n",
        "\n",
        "train_dec_5G(dec5G, epoch=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q2VA1wKMsaP4",
        "outputId": "3c277c68-4366-40a3-b443-eee585284b11"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1, 764, 1)\n",
            "tf.Tensor(\n",
            "[[[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " [[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " [[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " [[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]], shape=(128, 764, 1), dtype=float32) tf.Tensor(\n",
            "[[[0. 0. 0. ... 0. 0. 0.]\n",
            "  [0. 0. 0. ... 0. 0. 0.]\n",
            "  [0. 0. 0. ... 0. 0. 0.]\n",
            "  ...\n",
            "  [0. 0. 0. ... 0. 0. 0.]\n",
            "  [0. 0. 0. ... 0. 0. 0.]\n",
            "  [0. 0. 0. ... 0. 0. 0.]]\n",
            "\n",
            " [[0. 0. 0. ... 0. 0. 0.]\n",
            "  [0. 0. 0. ... 0. 0. 0.]\n",
            "  [0. 0. 0. ... 0. 0. 0.]\n",
            "  ...\n",
            "  [0. 0. 0. ... 0. 0. 0.]\n",
            "  [0. 0. 0. ... 0. 0. 0.]\n",
            "  [0. 0. 0. ... 0. 0. 0.]]\n",
            "\n",
            " [[0. 0. 0. ... 0. 0. 0.]\n",
            "  [0. 0. 0. ... 0. 0. 0.]\n",
            "  [0. 0. 0. ... 0. 0. 0.]\n",
            "  ...\n",
            "  [0. 0. 0. ... 0. 0. 0.]\n",
            "  [0. 0. 0. ... 0. 0. 0.]\n",
            "  [0. 0. 0. ... 0. 0. 0.]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[0. 0. 0. ... 0. 0. 0.]\n",
            "  [0. 0. 0. ... 0. 0. 0.]\n",
            "  [0. 0. 0. ... 0. 0. 0.]\n",
            "  ...\n",
            "  [0. 0. 0. ... 0. 0. 0.]\n",
            "  [0. 0. 0. ... 0. 0. 0.]\n",
            "  [0. 0. 0. ... 0. 0. 0.]]\n",
            "\n",
            " [[0. 0. 0. ... 0. 0. 0.]\n",
            "  [0. 0. 0. ... 0. 0. 0.]\n",
            "  [0. 0. 0. ... 0. 0. 0.]\n",
            "  ...\n",
            "  [0. 0. 0. ... 0. 0. 0.]\n",
            "  [0. 0. 0. ... 0. 0. 0.]\n",
            "  [0. 0. 0. ... 0. 0. 0.]]\n",
            "\n",
            " [[0. 0. 0. ... 0. 0. 0.]\n",
            "  [0. 0. 0. ... 0. 0. 0.]\n",
            "  [0. 0. 0. ... 0. 0. 0.]\n",
            "  ...\n",
            "  [0. 0. 0. ... 0. 0. 0.]\n",
            "  [0. 0. 0. ... 0. 0. 0.]\n",
            "  [0. 0. 0. ... 0. 0. 0.]]], shape=(128, 764, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]], shape=(512, 128), dtype=float32) tf.Tensor(\n",
            "[[0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]], shape=(252, 128), dtype=float32)\n",
            "(128, 764) (512, 1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_15/kernel:0', 'dense_15/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_15/kernel:0', 'dense_15/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch 1, Batch 1/100, Loss=2.85477e+00\n",
            "(1, 764, 1)\n",
            "tf.Tensor(\n",
            "[[[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " [[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " [[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " [[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]], shape=(128, 764, 1), dtype=float32) tf.Tensor(\n",
            "[[[-0.10004186 -0.20162575 -0.14838    ...  0.42604607  0.08091199\n",
            "   -0.03277602]\n",
            "  [-0.10004186 -0.20162575 -0.14838    ...  0.42604607  0.08091199\n",
            "   -0.03277602]\n",
            "  [-0.10004186 -0.20162575 -0.14838    ...  0.42604607  0.08091199\n",
            "   -0.03277602]\n",
            "  ...\n",
            "  [-0.10004186 -0.20162575 -0.14838    ...  0.42604607  0.08091199\n",
            "   -0.03277602]\n",
            "  [-0.10004186 -0.20162575 -0.14838    ...  0.42604607  0.08091199\n",
            "   -0.03277602]\n",
            "  [-0.10004186 -0.20162575 -0.14838    ...  0.42604607  0.08091199\n",
            "   -0.03277602]]\n",
            "\n",
            " [[-0.10004186 -0.20162575 -0.14838    ...  0.42604607  0.08091199\n",
            "   -0.03277602]\n",
            "  [-0.10004186 -0.20162575 -0.14838    ...  0.42604607  0.08091199\n",
            "   -0.03277602]\n",
            "  [-0.10004186 -0.20162575 -0.14838    ...  0.42604607  0.08091199\n",
            "   -0.03277602]\n",
            "  ...\n",
            "  [-0.10004186 -0.20162575 -0.14838    ...  0.42604607  0.08091199\n",
            "   -0.03277602]\n",
            "  [-0.10004186 -0.20162575 -0.14838    ...  0.42604607  0.08091199\n",
            "   -0.03277602]\n",
            "  [-0.10004186 -0.20162575 -0.14838    ...  0.42604607  0.08091199\n",
            "   -0.03277602]]\n",
            "\n",
            " [[-0.10004186 -0.20162575 -0.14838    ...  0.42604607  0.08091199\n",
            "   -0.03277602]\n",
            "  [-0.10004186 -0.20162575 -0.14838    ...  0.42604607  0.08091199\n",
            "   -0.03277602]\n",
            "  [-0.10004186 -0.20162575 -0.14838    ...  0.42604607  0.08091199\n",
            "   -0.03277602]\n",
            "  ...\n",
            "  [-0.10004186 -0.20162575 -0.14838    ...  0.42604607  0.08091199\n",
            "   -0.03277602]\n",
            "  [-0.10004186 -0.20162575 -0.14838    ...  0.42604607  0.08091199\n",
            "   -0.03277602]\n",
            "  [-0.10004186 -0.20162575 -0.14838    ...  0.42604607  0.08091199\n",
            "   -0.03277602]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[-0.10004186 -0.20162575 -0.14838    ...  0.42604607  0.08091199\n",
            "   -0.03277602]\n",
            "  [-0.10004186 -0.20162575 -0.14838    ...  0.42604607  0.08091199\n",
            "   -0.03277602]\n",
            "  [-0.10004186 -0.20162575 -0.14838    ...  0.42604607  0.08091199\n",
            "   -0.03277602]\n",
            "  ...\n",
            "  [-0.10004186 -0.20162575 -0.14838    ...  0.42604607  0.08091199\n",
            "   -0.03277602]\n",
            "  [-0.10004186 -0.20162575 -0.14838    ...  0.42604607  0.08091199\n",
            "   -0.03277602]\n",
            "  [-0.10004186 -0.20162575 -0.14838    ...  0.42604607  0.08091199\n",
            "   -0.03277602]]\n",
            "\n",
            " [[-0.10004186 -0.20162575 -0.14838    ...  0.42604607  0.08091199\n",
            "   -0.03277602]\n",
            "  [-0.10004186 -0.20162575 -0.14838    ...  0.42604607  0.08091199\n",
            "   -0.03277602]\n",
            "  [-0.10004186 -0.20162575 -0.14838    ...  0.42604607  0.08091199\n",
            "   -0.03277602]\n",
            "  ...\n",
            "  [-0.10004186 -0.20162575 -0.14838    ...  0.42604607  0.08091199\n",
            "   -0.03277602]\n",
            "  [-0.10004186 -0.20162575 -0.14838    ...  0.42604607  0.08091199\n",
            "   -0.03277602]\n",
            "  [-0.10004186 -0.20162575 -0.14838    ...  0.42604607  0.08091199\n",
            "   -0.03277602]]\n",
            "\n",
            " [[-0.10004186 -0.20162575 -0.14838    ...  0.42604607  0.08091199\n",
            "   -0.03277602]\n",
            "  [-0.10004186 -0.20162575 -0.14838    ...  0.42604607  0.08091199\n",
            "   -0.03277602]\n",
            "  [-0.10004186 -0.20162575 -0.14838    ...  0.42604607  0.08091199\n",
            "   -0.03277602]\n",
            "  ...\n",
            "  [-0.10004186 -0.20162575 -0.14838    ...  0.42604607  0.08091199\n",
            "   -0.03277602]\n",
            "  [-0.10004186 -0.20162575 -0.14838    ...  0.42604607  0.08091199\n",
            "   -0.03277602]\n",
            "  [-0.10004186 -0.20162575 -0.14838    ...  0.42604607  0.08091199\n",
            "   -0.03277602]]], shape=(128, 764, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-2.8196385 -2.8196385 -2.8196385 ... -2.8196385 -2.8196385 -2.8196385]\n",
            " [-2.8196385 -2.8196385 -2.8196385 ... -2.8196385 -2.8196385 -2.8196385]\n",
            " [-2.8196385 -2.8196385 -2.8196385 ... -2.8196385 -2.8196385 -2.8196385]\n",
            " ...\n",
            " [-2.8196385 -2.8196385 -2.8196385 ... -2.8196385 -2.8196385 -2.8196385]\n",
            " [-2.8196385 -2.8196385 -2.8196385 ... -2.8196385 -2.8196385 -2.8196385]\n",
            " [-2.8196385 -2.8196385 -2.8196385 ... -2.8196385 -2.8196385 -2.8196385]], shape=(512, 128), dtype=float32) tf.Tensor(\n",
            "[[-2.8196385 -2.8196385 -2.8196385 ... -2.8196385 -2.8196385 -2.8196385]\n",
            " [-2.8196385 -2.8196385 -2.8196385 ... -2.8196385 -2.8196385 -2.8196385]\n",
            " [-2.8196385 -2.8196385 -2.8196385 ... -2.8196385 -2.8196385 -2.8196385]\n",
            " ...\n",
            " [-2.8196385 -2.8196385 -2.8196385 ... -2.8196385 -2.8196385 -2.8196385]\n",
            " [-2.8196385 -2.8196385 -2.8196385 ... -2.8196385 -2.8196385 -2.8196385]\n",
            " [-2.8196385 -2.8196385 -2.8196385 ... -2.8196385 -2.8196385 -2.8196385]], shape=(252, 128), dtype=float32)\n",
            "(128, 764) (512, 1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_15/kernel:0', 'dense_15/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_15/kernel:0', 'dense_15/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch 1, Batch 2/100, Loss=3.49990e+01\n",
            "(1, 764, 1)\n",
            "tf.Tensor(\n",
            "[[[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " [[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]], shape=(128, 764, 1), dtype=float32) tf.Tensor(\n",
            "[[[ 0.06061488 -0.03742179 -0.08985044 ...  0.18859294  0.05053362\n",
            "   -0.04918952]\n",
            "  [ 0.06061488 -0.03742179 -0.08985044 ...  0.18859294  0.05053362\n",
            "   -0.04918952]\n",
            "  [ 0.06061488 -0.03742179 -0.08985044 ...  0.18859294  0.05053362\n",
            "   -0.04918952]\n",
            "  ...\n",
            "  [ 0.06061488 -0.03742179 -0.08985044 ...  0.18859294  0.05053362\n",
            "   -0.04918952]\n",
            "  [ 0.06061488 -0.03742179 -0.08985044 ...  0.18859294  0.05053362\n",
            "   -0.04918952]\n",
            "  [ 0.06061488 -0.03742179 -0.08985044 ...  0.18859294  0.05053362\n",
            "   -0.04918952]]\n",
            "\n",
            " [[ 0.06061488 -0.03742179 -0.08985044 ...  0.18859294  0.05053362\n",
            "   -0.04918952]\n",
            "  [ 0.06061488 -0.03742179 -0.08985044 ...  0.18859294  0.05053362\n",
            "   -0.04918952]\n",
            "  [ 0.06061488 -0.03742179 -0.08985044 ...  0.18859294  0.05053362\n",
            "   -0.04918952]\n",
            "  ...\n",
            "  [ 0.06061488 -0.03742179 -0.08985044 ...  0.18859294  0.05053362\n",
            "   -0.04918952]\n",
            "  [ 0.06061488 -0.03742179 -0.08985044 ...  0.18859294  0.05053362\n",
            "   -0.04918952]\n",
            "  [ 0.06061488 -0.03742179 -0.08985044 ...  0.18859294  0.05053362\n",
            "   -0.04918952]]\n",
            "\n",
            " [[ 0.06061488 -0.03742179 -0.08985044 ...  0.18859294  0.05053362\n",
            "   -0.04918952]\n",
            "  [ 0.06061488 -0.03742179 -0.08985044 ...  0.18859294  0.05053362\n",
            "   -0.04918952]\n",
            "  [ 0.06061488 -0.03742179 -0.08985044 ...  0.18859294  0.05053362\n",
            "   -0.04918952]\n",
            "  ...\n",
            "  [ 0.06061488 -0.03742179 -0.08985044 ...  0.18859294  0.05053362\n",
            "   -0.04918952]\n",
            "  [ 0.06061488 -0.03742179 -0.08985044 ...  0.18859294  0.05053362\n",
            "   -0.04918952]\n",
            "  [ 0.06061488 -0.03742179 -0.08985044 ...  0.18859294  0.05053362\n",
            "   -0.04918952]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[ 0.06061488 -0.03742179 -0.08985044 ...  0.18859294  0.05053362\n",
            "   -0.04918952]\n",
            "  [ 0.06061488 -0.03742179 -0.08985044 ...  0.18859294  0.05053362\n",
            "   -0.04918952]\n",
            "  [ 0.06061488 -0.03742179 -0.08985044 ...  0.18859294  0.05053362\n",
            "   -0.04918952]\n",
            "  ...\n",
            "  [ 0.06061488 -0.03742179 -0.08985044 ...  0.18859294  0.05053362\n",
            "   -0.04918952]\n",
            "  [ 0.06061488 -0.03742179 -0.08985044 ...  0.18859294  0.05053362\n",
            "   -0.04918952]\n",
            "  [ 0.06061488 -0.03742179 -0.08985044 ...  0.18859294  0.05053362\n",
            "   -0.04918952]]\n",
            "\n",
            " [[ 0.06061488 -0.03742179 -0.08985044 ...  0.18859294  0.05053362\n",
            "   -0.04918952]\n",
            "  [ 0.06061488 -0.03742179 -0.08985044 ...  0.18859294  0.05053362\n",
            "   -0.04918952]\n",
            "  [ 0.06061488 -0.03742179 -0.08985044 ...  0.18859294  0.05053362\n",
            "   -0.04918952]\n",
            "  ...\n",
            "  [ 0.06061488 -0.03742179 -0.08985044 ...  0.18859294  0.05053362\n",
            "   -0.04918952]\n",
            "  [ 0.06061488 -0.03742179 -0.08985044 ...  0.18859294  0.05053362\n",
            "   -0.04918952]\n",
            "  [ 0.06061488 -0.03742179 -0.08985044 ...  0.18859294  0.05053362\n",
            "   -0.04918952]]\n",
            "\n",
            " [[ 0.06061488 -0.03742179 -0.08985044 ...  0.18859294  0.05053362\n",
            "   -0.04918952]\n",
            "  [ 0.06061488 -0.03742179 -0.08985044 ...  0.18859294  0.05053362\n",
            "   -0.04918952]\n",
            "  [ 0.06061488 -0.03742179 -0.08985044 ...  0.18859294  0.05053362\n",
            "   -0.04918952]\n",
            "  ...\n",
            "  [ 0.06061488 -0.03742179 -0.08985044 ...  0.18859294  0.05053362\n",
            "   -0.04918952]\n",
            "  [ 0.06061488 -0.03742179 -0.08985044 ...  0.18859294  0.05053362\n",
            "   -0.04918952]\n",
            "  [ 0.06061488 -0.03742179 -0.08985044 ...  0.18859294  0.05053362\n",
            "   -0.04918952]]], shape=(128, 764, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.5555505 -0.5555505 -0.5555505 ... -0.5555505 -0.5555505 -0.5555505]\n",
            " [-0.5555505 -0.5555505 -0.5555505 ... -0.5555505 -0.5555505 -0.5555505]\n",
            " [-0.5555505 -0.5555505 -0.5555505 ... -0.5555505 -0.5555505 -0.5555505]\n",
            " ...\n",
            " [-0.5555505 -0.5555505 -0.5555505 ... -0.5555505 -0.5555505 -0.5555505]\n",
            " [-0.5555505 -0.5555505 -0.5555505 ... -0.5555505 -0.5555505 -0.5555505]\n",
            " [-0.5555505 -0.5555505 -0.5555505 ... -0.5555505 -0.5555505 -0.5555505]], shape=(512, 128), dtype=float32) tf.Tensor(\n",
            "[[-0.5555505 -0.5555505 -0.5555505 ... -0.5555505 -0.5555505 -0.5555505]\n",
            " [-0.5555505 -0.5555505 -0.5555505 ... -0.5555505 -0.5555505 -0.5555505]\n",
            " [-0.5555505 -0.5555505 -0.5555505 ... -0.5555505 -0.5555505 -0.5555505]\n",
            " ...\n",
            " [-0.5555505 -0.5555505 -0.5555505 ... -0.5555505 -0.5555505 -0.5555505]\n",
            " [-0.5555505 -0.5555505 -0.5555505 ... -0.5555505 -0.5555505 -0.5555505]\n",
            " [-0.5555505 -0.5555505 -0.5555505 ... -0.5555505 -0.5555505 -0.5555505]], shape=(252, 128), dtype=float32)\n",
            "(128, 764) (512, 1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_15/kernel:0', 'dense_15/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_15/kernel:0', 'dense_15/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch 1, Batch 3/100, Loss=4.82552e+00\n",
            "(1, 764, 1)\n",
            "tf.Tensor(\n",
            "[[[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " [[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " [[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]], shape=(128, 764, 1), dtype=float32) tf.Tensor(\n",
            "[[[ 0.16521327  0.10187042 -0.05762851 ...  0.00711305  0.07028772\n",
            "   -0.07937425]\n",
            "  [ 0.16521327  0.10187042 -0.05762851 ...  0.00711305  0.07028772\n",
            "   -0.07937425]\n",
            "  [ 0.16521327  0.10187042 -0.05762851 ...  0.00711305  0.07028772\n",
            "   -0.07937425]\n",
            "  ...\n",
            "  [ 0.16521327  0.10187042 -0.05762851 ...  0.00711305  0.07028772\n",
            "   -0.07937425]\n",
            "  [ 0.16521327  0.10187042 -0.05762851 ...  0.00711305  0.07028772\n",
            "   -0.07937425]\n",
            "  [ 0.16521327  0.10187042 -0.05762851 ...  0.00711305  0.07028772\n",
            "   -0.07937425]]\n",
            "\n",
            " [[ 0.16521327  0.10187042 -0.05762851 ...  0.00711305  0.07028772\n",
            "   -0.07937425]\n",
            "  [ 0.16521327  0.10187042 -0.05762851 ...  0.00711305  0.07028772\n",
            "   -0.07937425]\n",
            "  [ 0.16521327  0.10187042 -0.05762851 ...  0.00711305  0.07028772\n",
            "   -0.07937425]\n",
            "  ...\n",
            "  [ 0.16521327  0.10187042 -0.05762851 ...  0.00711305  0.07028772\n",
            "   -0.07937425]\n",
            "  [ 0.16521327  0.10187042 -0.05762851 ...  0.00711305  0.07028772\n",
            "   -0.07937425]\n",
            "  [ 0.16521327  0.10187042 -0.05762851 ...  0.00711305  0.07028772\n",
            "   -0.07937425]]\n",
            "\n",
            " [[ 0.16521327  0.10187042 -0.05762851 ...  0.00711305  0.07028772\n",
            "   -0.07937425]\n",
            "  [ 0.16521327  0.10187042 -0.05762851 ...  0.00711305  0.07028772\n",
            "   -0.07937425]\n",
            "  [ 0.16521327  0.10187042 -0.05762851 ...  0.00711305  0.07028772\n",
            "   -0.07937425]\n",
            "  ...\n",
            "  [ 0.16521327  0.10187042 -0.05762851 ...  0.00711305  0.07028772\n",
            "   -0.07937425]\n",
            "  [ 0.16521327  0.10187042 -0.05762851 ...  0.00711305  0.07028772\n",
            "   -0.07937425]\n",
            "  [ 0.16521327  0.10187042 -0.05762851 ...  0.00711305  0.07028772\n",
            "   -0.07937425]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[ 0.16521327  0.10187042 -0.05762851 ...  0.00711305  0.07028772\n",
            "   -0.07937425]\n",
            "  [ 0.16521327  0.10187042 -0.05762851 ...  0.00711305  0.07028772\n",
            "   -0.07937425]\n",
            "  [ 0.16521327  0.10187042 -0.05762851 ...  0.00711305  0.07028772\n",
            "   -0.07937425]\n",
            "  ...\n",
            "  [ 0.16521327  0.10187042 -0.05762851 ...  0.00711305  0.07028772\n",
            "   -0.07937425]\n",
            "  [ 0.16521327  0.10187042 -0.05762851 ...  0.00711305  0.07028772\n",
            "   -0.07937425]\n",
            "  [ 0.16521327  0.10187042 -0.05762851 ...  0.00711305  0.07028772\n",
            "   -0.07937425]]\n",
            "\n",
            " [[ 0.16521327  0.10187042 -0.05762851 ...  0.00711305  0.07028772\n",
            "   -0.07937425]\n",
            "  [ 0.16521327  0.10187042 -0.05762851 ...  0.00711305  0.07028772\n",
            "   -0.07937425]\n",
            "  [ 0.16521327  0.10187042 -0.05762851 ...  0.00711305  0.07028772\n",
            "   -0.07937425]\n",
            "  ...\n",
            "  [ 0.16521327  0.10187042 -0.05762851 ...  0.00711305  0.07028772\n",
            "   -0.07937425]\n",
            "  [ 0.16521327  0.10187042 -0.05762851 ...  0.00711305  0.07028772\n",
            "   -0.07937425]\n",
            "  [ 0.16521327  0.10187042 -0.05762851 ...  0.00711305  0.07028772\n",
            "   -0.07937425]]\n",
            "\n",
            " [[ 0.16521327  0.10187042 -0.05762851 ...  0.00711305  0.07028772\n",
            "   -0.07937425]\n",
            "  [ 0.16521327  0.10187042 -0.05762851 ...  0.00711305  0.07028772\n",
            "   -0.07937425]\n",
            "  [ 0.16521327  0.10187042 -0.05762851 ...  0.00711305  0.07028772\n",
            "   -0.07937425]\n",
            "  ...\n",
            "  [ 0.16521327  0.10187042 -0.05762851 ...  0.00711305  0.07028772\n",
            "   -0.07937425]\n",
            "  [ 0.16521327  0.10187042 -0.05762851 ...  0.00711305  0.07028772\n",
            "   -0.07937425]\n",
            "  [ 0.16521327  0.10187042 -0.05762851 ...  0.00711305  0.07028772\n",
            "   -0.07937425]]], shape=(128, 764, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[0.9905851 0.9905851 0.9905851 ... 0.9905851 0.9905851 0.9905851]\n",
            " [0.9905851 0.9905851 0.9905851 ... 0.9905851 0.9905851 0.9905851]\n",
            " [0.9905851 0.9905851 0.9905851 ... 0.9905851 0.9905851 0.9905851]\n",
            " ...\n",
            " [0.9905851 0.9905851 0.9905851 ... 0.9905851 0.9905851 0.9905851]\n",
            " [0.9905851 0.9905851 0.9905851 ... 0.9905851 0.9905851 0.9905851]\n",
            " [0.9905851 0.9905851 0.9905851 ... 0.9905851 0.9905851 0.9905851]], shape=(512, 128), dtype=float32) tf.Tensor(\n",
            "[[0.9905851 0.9905851 0.9905851 ... 0.9905851 0.9905851 0.9905851]\n",
            " [0.9905851 0.9905851 0.9905851 ... 0.9905851 0.9905851 0.9905851]\n",
            " [0.9905851 0.9905851 0.9905851 ... 0.9905851 0.9905851 0.9905851]\n",
            " ...\n",
            " [0.9905851 0.9905851 0.9905851 ... 0.9905851 0.9905851 0.9905851]\n",
            " [0.9905851 0.9905851 0.9905851 ... 0.9905851 0.9905851 0.9905851]\n",
            " [0.9905851 0.9905851 0.9905851 ... 0.9905851 0.9905851 0.9905851]], shape=(252, 128), dtype=float32)\n",
            "(128, 764) (512, 1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_15/kernel:0', 'dense_15/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_15/kernel:0', 'dense_15/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch 1, Batch 4/100, Loss=5.29308e+00\n",
            "(1, 764, 1)\n",
            "tf.Tensor(\n",
            "[[[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " [[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " [[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " [[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " [[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]], shape=(128, 764, 1), dtype=float32) tf.Tensor(\n",
            "[[[ 0.15200846  0.16585082 -0.07513744 ... -0.08671951  0.09484892\n",
            "   -0.14707254]\n",
            "  [ 0.15200846  0.16585082 -0.07513744 ... -0.08671951  0.09484892\n",
            "   -0.14707254]\n",
            "  [ 0.15200846  0.16585082 -0.07513744 ... -0.08671951  0.09484892\n",
            "   -0.14707254]\n",
            "  ...\n",
            "  [ 0.15200846  0.16585082 -0.07513744 ... -0.08671951  0.09484892\n",
            "   -0.14707254]\n",
            "  [ 0.15200846  0.16585082 -0.07513744 ... -0.08671951  0.09484892\n",
            "   -0.14707254]\n",
            "  [ 0.15200846  0.16585082 -0.07513744 ... -0.08671951  0.09484892\n",
            "   -0.14707254]]\n",
            "\n",
            " [[ 0.15200846  0.16585082 -0.07513744 ... -0.08671951  0.09484892\n",
            "   -0.14707254]\n",
            "  [ 0.15200846  0.16585082 -0.07513744 ... -0.08671951  0.09484892\n",
            "   -0.14707254]\n",
            "  [ 0.15200846  0.16585082 -0.07513744 ... -0.08671951  0.09484892\n",
            "   -0.14707254]\n",
            "  ...\n",
            "  [ 0.15200846  0.16585082 -0.07513744 ... -0.08671951  0.09484892\n",
            "   -0.14707254]\n",
            "  [ 0.15200846  0.16585082 -0.07513744 ... -0.08671951  0.09484892\n",
            "   -0.14707254]\n",
            "  [ 0.15200846  0.16585082 -0.07513744 ... -0.08671951  0.09484892\n",
            "   -0.14707254]]\n",
            "\n",
            " [[ 0.15200846  0.16585082 -0.07513744 ... -0.08671951  0.09484892\n",
            "   -0.14707254]\n",
            "  [ 0.15200846  0.16585082 -0.07513744 ... -0.08671951  0.09484892\n",
            "   -0.14707254]\n",
            "  [ 0.15200846  0.16585082 -0.07513744 ... -0.08671951  0.09484892\n",
            "   -0.14707254]\n",
            "  ...\n",
            "  [ 0.15200846  0.16585082 -0.07513744 ... -0.08671951  0.09484892\n",
            "   -0.14707254]\n",
            "  [ 0.15200846  0.16585082 -0.07513744 ... -0.08671951  0.09484892\n",
            "   -0.14707254]\n",
            "  [ 0.15200846  0.16585082 -0.07513744 ... -0.08671951  0.09484892\n",
            "   -0.14707254]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[ 0.15200846  0.16585082 -0.07513744 ... -0.08671951  0.09484892\n",
            "   -0.14707254]\n",
            "  [ 0.15200846  0.16585082 -0.07513744 ... -0.08671951  0.09484892\n",
            "   -0.14707254]\n",
            "  [ 0.15200846  0.16585082 -0.07513744 ... -0.08671951  0.09484892\n",
            "   -0.14707254]\n",
            "  ...\n",
            "  [ 0.15200846  0.16585082 -0.07513744 ... -0.08671951  0.09484892\n",
            "   -0.14707254]\n",
            "  [ 0.15200846  0.16585082 -0.07513744 ... -0.08671951  0.09484892\n",
            "   -0.14707254]\n",
            "  [ 0.15200846  0.16585082 -0.07513744 ... -0.08671951  0.09484892\n",
            "   -0.14707254]]\n",
            "\n",
            " [[ 0.15200846  0.16585082 -0.07513744 ... -0.08671951  0.09484892\n",
            "   -0.14707254]\n",
            "  [ 0.15200846  0.16585082 -0.07513744 ... -0.08671951  0.09484892\n",
            "   -0.14707254]\n",
            "  [ 0.15200846  0.16585082 -0.07513744 ... -0.08671951  0.09484892\n",
            "   -0.14707254]\n",
            "  ...\n",
            "  [ 0.15200846  0.16585082 -0.07513744 ... -0.08671951  0.09484892\n",
            "   -0.14707254]\n",
            "  [ 0.15200846  0.16585082 -0.07513744 ... -0.08671951  0.09484892\n",
            "   -0.14707254]\n",
            "  [ 0.15200846  0.16585082 -0.07513744 ... -0.08671951  0.09484892\n",
            "   -0.14707254]]\n",
            "\n",
            " [[ 0.15200846  0.16585082 -0.07513744 ... -0.08671951  0.09484892\n",
            "   -0.14707254]\n",
            "  [ 0.15200846  0.16585082 -0.07513744 ... -0.08671951  0.09484892\n",
            "   -0.14707254]\n",
            "  [ 0.15200846  0.16585082 -0.07513744 ... -0.08671951  0.09484892\n",
            "   -0.14707254]\n",
            "  ...\n",
            "  [ 0.15200846  0.16585082 -0.07513744 ... -0.08671951  0.09484892\n",
            "   -0.14707254]\n",
            "  [ 0.15200846  0.16585082 -0.07513744 ... -0.08671951  0.09484892\n",
            "   -0.14707254]\n",
            "  [ 0.15200846  0.16585082 -0.07513744 ... -0.08671951  0.09484892\n",
            "   -0.14707254]]], shape=(128, 764, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[1.3628136 1.3628136 1.3628136 ... 1.3628136 1.3628136 1.3628136]\n",
            " [1.3628136 1.3628136 1.3628136 ... 1.3628136 1.3628136 1.3628136]\n",
            " [1.3628136 1.3628136 1.3628136 ... 1.3628136 1.3628136 1.3628136]\n",
            " ...\n",
            " [1.3628136 1.3628136 1.3628136 ... 1.3628136 1.3628136 1.3628136]\n",
            " [1.3628136 1.3628136 1.3628136 ... 1.3628136 1.3628136 1.3628136]\n",
            " [1.3628136 1.3628136 1.3628136 ... 1.3628136 1.3628136 1.3628136]], shape=(512, 128), dtype=float32) tf.Tensor(\n",
            "[[1.3628136 1.3628136 1.3628136 ... 1.3628136 1.3628136 1.3628136]\n",
            " [1.3628136 1.3628136 1.3628136 ... 1.3628136 1.3628136 1.3628136]\n",
            " [1.3628136 1.3628136 1.3628136 ... 1.3628136 1.3628136 1.3628136]\n",
            " ...\n",
            " [1.3628136 1.3628136 1.3628136 ... 1.3628136 1.3628136 1.3628136]\n",
            " [1.3628136 1.3628136 1.3628136 ... 1.3628136 1.3628136 1.3628136]\n",
            " [1.3628136 1.3628136 1.3628136 ... 1.3628136 1.3628136 1.3628136]], shape=(252, 128), dtype=float32)\n",
            "(128, 764) (512, 1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_15/kernel:0', 'dense_15/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_15/kernel:0', 'dense_15/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch 1, Batch 5/100, Loss=6.90802e+00\n",
            "(1, 764, 1)\n",
            "tf.Tensor(\n",
            "[[[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " [[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " [[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " [[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]], shape=(128, 764, 1), dtype=float32) tf.Tensor(\n",
            "[[[ 0.0890951   0.15324475 -0.12433486 ... -0.13676488  0.14142168\n",
            "   -0.24852586]\n",
            "  [ 0.0890951   0.15324475 -0.12433486 ... -0.13676488  0.14142168\n",
            "   -0.24852586]\n",
            "  [ 0.0890951   0.15324475 -0.12433486 ... -0.13676488  0.14142168\n",
            "   -0.24852586]\n",
            "  ...\n",
            "  [ 0.0890951   0.15324475 -0.12433486 ... -0.13676488  0.14142168\n",
            "   -0.24852586]\n",
            "  [ 0.0890951   0.15324475 -0.12433486 ... -0.13676488  0.14142168\n",
            "   -0.24852586]\n",
            "  [ 0.0890951   0.15324475 -0.12433486 ... -0.13676488  0.14142168\n",
            "   -0.24852586]]\n",
            "\n",
            " [[ 0.0890951   0.15324475 -0.12433486 ... -0.13676488  0.14142168\n",
            "   -0.24852586]\n",
            "  [ 0.0890951   0.15324475 -0.12433486 ... -0.13676488  0.14142168\n",
            "   -0.24852586]\n",
            "  [ 0.0890951   0.15324475 -0.12433486 ... -0.13676488  0.14142168\n",
            "   -0.24852586]\n",
            "  ...\n",
            "  [ 0.0890951   0.15324475 -0.12433486 ... -0.13676488  0.14142168\n",
            "   -0.24852586]\n",
            "  [ 0.0890951   0.15324475 -0.12433486 ... -0.13676488  0.14142168\n",
            "   -0.24852586]\n",
            "  [ 0.0890951   0.15324475 -0.12433486 ... -0.13676488  0.14142168\n",
            "   -0.24852586]]\n",
            "\n",
            " [[ 0.0890951   0.15324475 -0.12433486 ... -0.13676488  0.14142168\n",
            "   -0.24852586]\n",
            "  [ 0.0890951   0.15324475 -0.12433486 ... -0.13676488  0.14142168\n",
            "   -0.24852586]\n",
            "  [ 0.0890951   0.15324475 -0.12433486 ... -0.13676488  0.14142168\n",
            "   -0.24852586]\n",
            "  ...\n",
            "  [ 0.0890951   0.15324475 -0.12433486 ... -0.13676488  0.14142168\n",
            "   -0.24852586]\n",
            "  [ 0.0890951   0.15324475 -0.12433486 ... -0.13676488  0.14142168\n",
            "   -0.24852586]\n",
            "  [ 0.0890951   0.15324475 -0.12433486 ... -0.13676488  0.14142168\n",
            "   -0.24852586]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[ 0.0890951   0.15324475 -0.12433486 ... -0.13676488  0.14142168\n",
            "   -0.24852586]\n",
            "  [ 0.0890951   0.15324475 -0.12433486 ... -0.13676488  0.14142168\n",
            "   -0.24852586]\n",
            "  [ 0.0890951   0.15324475 -0.12433486 ... -0.13676488  0.14142168\n",
            "   -0.24852586]\n",
            "  ...\n",
            "  [ 0.0890951   0.15324475 -0.12433486 ... -0.13676488  0.14142168\n",
            "   -0.24852586]\n",
            "  [ 0.0890951   0.15324475 -0.12433486 ... -0.13676488  0.14142168\n",
            "   -0.24852586]\n",
            "  [ 0.0890951   0.15324475 -0.12433486 ... -0.13676488  0.14142168\n",
            "   -0.24852586]]\n",
            "\n",
            " [[ 0.0890951   0.15324475 -0.12433486 ... -0.13676488  0.14142168\n",
            "   -0.24852586]\n",
            "  [ 0.0890951   0.15324475 -0.12433486 ... -0.13676488  0.14142168\n",
            "   -0.24852586]\n",
            "  [ 0.0890951   0.15324475 -0.12433486 ... -0.13676488  0.14142168\n",
            "   -0.24852586]\n",
            "  ...\n",
            "  [ 0.0890951   0.15324475 -0.12433486 ... -0.13676488  0.14142168\n",
            "   -0.24852586]\n",
            "  [ 0.0890951   0.15324475 -0.12433486 ... -0.13676488  0.14142168\n",
            "   -0.24852586]\n",
            "  [ 0.0890951   0.15324475 -0.12433486 ... -0.13676488  0.14142168\n",
            "   -0.24852586]]\n",
            "\n",
            " [[ 0.0890951   0.15324475 -0.12433486 ... -0.13676488  0.14142168\n",
            "   -0.24852586]\n",
            "  [ 0.0890951   0.15324475 -0.12433486 ... -0.13676488  0.14142168\n",
            "   -0.24852586]\n",
            "  [ 0.0890951   0.15324475 -0.12433486 ... -0.13676488  0.14142168\n",
            "   -0.24852586]\n",
            "  ...\n",
            "  [ 0.0890951   0.15324475 -0.12433486 ... -0.13676488  0.14142168\n",
            "   -0.24852586]\n",
            "  [ 0.0890951   0.15324475 -0.12433486 ... -0.13676488  0.14142168\n",
            "   -0.24852586]\n",
            "  [ 0.0890951   0.15324475 -0.12433486 ... -0.13676488  0.14142168\n",
            "   -0.24852586]]], shape=(128, 764, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[0.96646893 0.96646893 0.96646893 ... 0.96646893 0.96646893 0.96646893]\n",
            " [0.96646893 0.96646893 0.96646893 ... 0.96646893 0.96646893 0.96646893]\n",
            " [0.96646893 0.96646893 0.96646893 ... 0.96646893 0.96646893 0.96646893]\n",
            " ...\n",
            " [0.96646893 0.96646893 0.96646893 ... 0.96646893 0.96646893 0.96646893]\n",
            " [0.96646893 0.96646893 0.96646893 ... 0.96646893 0.96646893 0.96646893]\n",
            " [0.96646893 0.96646893 0.96646893 ... 0.96646893 0.96646893 0.96646893]], shape=(512, 128), dtype=float32) tf.Tensor(\n",
            "[[0.96646893 0.96646893 0.96646893 ... 0.96646893 0.96646893 0.96646893]\n",
            " [0.96646893 0.96646893 0.96646893 ... 0.96646893 0.96646893 0.96646893]\n",
            " [0.96646893 0.96646893 0.96646893 ... 0.96646893 0.96646893 0.96646893]\n",
            " ...\n",
            " [0.96646893 0.96646893 0.96646893 ... 0.96646893 0.96646893 0.96646893]\n",
            " [0.96646893 0.96646893 0.96646893 ... 0.96646893 0.96646893 0.96646893]\n",
            " [0.96646893 0.96646893 0.96646893 ... 0.96646893 0.96646893 0.96646893]], shape=(252, 128), dtype=float32)\n",
            "(128, 764) (512, 1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_15/kernel:0', 'dense_15/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_15/kernel:0', 'dense_15/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch 1, Batch 6/100, Loss=3.46746e+00\n",
            "(1, 764, 1)\n",
            "tf.Tensor(\n",
            "[[[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " [[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " [[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " [[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]], shape=(128, 764, 1), dtype=float32) tf.Tensor(\n",
            "[[[-0.00158221  0.09869464 -0.19373874 ... -0.17195736  0.2127241\n",
            "   -0.36630532]\n",
            "  [-0.00158221  0.09869464 -0.19373874 ... -0.17195736  0.2127241\n",
            "   -0.36630532]\n",
            "  [-0.00158221  0.09869464 -0.19373874 ... -0.17195736  0.2127241\n",
            "   -0.36630532]\n",
            "  ...\n",
            "  [-0.00158221  0.09869464 -0.19373874 ... -0.17195736  0.2127241\n",
            "   -0.36630532]\n",
            "  [-0.00158221  0.09869464 -0.19373874 ... -0.17195736  0.2127241\n",
            "   -0.36630532]\n",
            "  [-0.00158221  0.09869464 -0.19373874 ... -0.17195736  0.2127241\n",
            "   -0.36630532]]\n",
            "\n",
            " [[-0.00158221  0.09869464 -0.19373874 ... -0.17195736  0.2127241\n",
            "   -0.36630532]\n",
            "  [-0.00158221  0.09869464 -0.19373874 ... -0.17195736  0.2127241\n",
            "   -0.36630532]\n",
            "  [-0.00158221  0.09869464 -0.19373874 ... -0.17195736  0.2127241\n",
            "   -0.36630532]\n",
            "  ...\n",
            "  [-0.00158221  0.09869464 -0.19373874 ... -0.17195736  0.2127241\n",
            "   -0.36630532]\n",
            "  [-0.00158221  0.09869464 -0.19373874 ... -0.17195736  0.2127241\n",
            "   -0.36630532]\n",
            "  [-0.00158221  0.09869464 -0.19373874 ... -0.17195736  0.2127241\n",
            "   -0.36630532]]\n",
            "\n",
            " [[-0.00158221  0.09869464 -0.19373874 ... -0.17195736  0.2127241\n",
            "   -0.36630532]\n",
            "  [-0.00158221  0.09869464 -0.19373874 ... -0.17195736  0.2127241\n",
            "   -0.36630532]\n",
            "  [-0.00158221  0.09869464 -0.19373874 ... -0.17195736  0.2127241\n",
            "   -0.36630532]\n",
            "  ...\n",
            "  [-0.00158221  0.09869464 -0.19373874 ... -0.17195736  0.2127241\n",
            "   -0.36630532]\n",
            "  [-0.00158221  0.09869464 -0.19373874 ... -0.17195736  0.2127241\n",
            "   -0.36630532]\n",
            "  [-0.00158221  0.09869464 -0.19373874 ... -0.17195736  0.2127241\n",
            "   -0.36630532]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[-0.00158221  0.09869464 -0.19373874 ... -0.17195736  0.2127241\n",
            "   -0.36630532]\n",
            "  [-0.00158221  0.09869464 -0.19373874 ... -0.17195736  0.2127241\n",
            "   -0.36630532]\n",
            "  [-0.00158221  0.09869464 -0.19373874 ... -0.17195736  0.2127241\n",
            "   -0.36630532]\n",
            "  ...\n",
            "  [-0.00158221  0.09869464 -0.19373874 ... -0.17195736  0.2127241\n",
            "   -0.36630532]\n",
            "  [-0.00158221  0.09869464 -0.19373874 ... -0.17195736  0.2127241\n",
            "   -0.36630532]\n",
            "  [-0.00158221  0.09869464 -0.19373874 ... -0.17195736  0.2127241\n",
            "   -0.36630532]]\n",
            "\n",
            " [[-0.00158221  0.09869464 -0.19373874 ... -0.17195736  0.2127241\n",
            "   -0.36630532]\n",
            "  [-0.00158221  0.09869464 -0.19373874 ... -0.17195736  0.2127241\n",
            "   -0.36630532]\n",
            "  [-0.00158221  0.09869464 -0.19373874 ... -0.17195736  0.2127241\n",
            "   -0.36630532]\n",
            "  ...\n",
            "  [-0.00158221  0.09869464 -0.19373874 ... -0.17195736  0.2127241\n",
            "   -0.36630532]\n",
            "  [-0.00158221  0.09869464 -0.19373874 ... -0.17195736  0.2127241\n",
            "   -0.36630532]\n",
            "  [-0.00158221  0.09869464 -0.19373874 ... -0.17195736  0.2127241\n",
            "   -0.36630532]]\n",
            "\n",
            " [[-0.00158221  0.09869464 -0.19373874 ... -0.17195736  0.2127241\n",
            "   -0.36630532]\n",
            "  [-0.00158221  0.09869464 -0.19373874 ... -0.17195736  0.2127241\n",
            "   -0.36630532]\n",
            "  [-0.00158221  0.09869464 -0.19373874 ... -0.17195736  0.2127241\n",
            "   -0.36630532]\n",
            "  ...\n",
            "  [-0.00158221  0.09869464 -0.19373874 ... -0.17195736  0.2127241\n",
            "   -0.36630532]\n",
            "  [-0.00158221  0.09869464 -0.19373874 ... -0.17195736  0.2127241\n",
            "   -0.36630532]\n",
            "  [-0.00158221  0.09869464 -0.19373874 ... -0.17195736  0.2127241\n",
            "   -0.36630532]]], shape=(128, 764, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[0.17227365 0.17227365 0.17227365 ... 0.17227365 0.17227365 0.17227365]\n",
            " [0.17227365 0.17227365 0.17227365 ... 0.17227365 0.17227365 0.17227365]\n",
            " [0.17227365 0.17227365 0.17227365 ... 0.17227365 0.17227365 0.17227365]\n",
            " ...\n",
            " [0.17227365 0.17227365 0.17227365 ... 0.17227365 0.17227365 0.17227365]\n",
            " [0.17227365 0.17227365 0.17227365 ... 0.17227365 0.17227365 0.17227365]\n",
            " [0.17227365 0.17227365 0.17227365 ... 0.17227365 0.17227365 0.17227365]], shape=(512, 128), dtype=float32) tf.Tensor(\n",
            "[[0.17227365 0.17227365 0.17227365 ... 0.17227365 0.17227365 0.17227365]\n",
            " [0.17227365 0.17227365 0.17227365 ... 0.17227365 0.17227365 0.17227365]\n",
            " [0.17227365 0.17227365 0.17227365 ... 0.17227365 0.17227365 0.17227365]\n",
            " ...\n",
            " [0.17227365 0.17227365 0.17227365 ... 0.17227365 0.17227365 0.17227365]\n",
            " [0.17227365 0.17227365 0.17227365 ... 0.17227365 0.17227365 0.17227365]\n",
            " [0.17227365 0.17227365 0.17227365 ... 0.17227365 0.17227365 0.17227365]], shape=(252, 128), dtype=float32)\n",
            "(128, 764) (512, 1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_15/kernel:0', 'dense_15/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_15/kernel:0', 'dense_15/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch 1, Batch 7/100, Loss=9.66214e-01\n",
            "(1, 764, 1)\n",
            "tf.Tensor(\n",
            "[[[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]], shape=(128, 764, 1), dtype=float32) tf.Tensor(\n",
            "[[[-0.09172302  0.04116556 -0.2620812  ... -0.19684376  0.2875422\n",
            "   -0.4766695 ]\n",
            "  [-0.09172302  0.04116556 -0.2620812  ... -0.19684376  0.2875422\n",
            "   -0.4766695 ]\n",
            "  [-0.09172302  0.04116556 -0.2620812  ... -0.19684376  0.2875422\n",
            "   -0.4766695 ]\n",
            "  ...\n",
            "  [-0.09172302  0.04116556 -0.2620812  ... -0.19684376  0.2875422\n",
            "   -0.4766695 ]\n",
            "  [-0.09172302  0.04116556 -0.2620812  ... -0.19684376  0.2875422\n",
            "   -0.4766695 ]\n",
            "  [-0.09172302  0.04116556 -0.2620812  ... -0.19684376  0.2875422\n",
            "   -0.4766695 ]]\n",
            "\n",
            " [[-0.09172302  0.04116556 -0.2620812  ... -0.19684376  0.2875422\n",
            "   -0.4766695 ]\n",
            "  [-0.09172302  0.04116556 -0.2620812  ... -0.19684376  0.2875422\n",
            "   -0.4766695 ]\n",
            "  [-0.09172302  0.04116556 -0.2620812  ... -0.19684376  0.2875422\n",
            "   -0.4766695 ]\n",
            "  ...\n",
            "  [-0.09172302  0.04116556 -0.2620812  ... -0.19684376  0.2875422\n",
            "   -0.4766695 ]\n",
            "  [-0.09172302  0.04116556 -0.2620812  ... -0.19684376  0.2875422\n",
            "   -0.4766695 ]\n",
            "  [-0.09172302  0.04116556 -0.2620812  ... -0.19684376  0.2875422\n",
            "   -0.4766695 ]]\n",
            "\n",
            " [[-0.09172302  0.04116556 -0.2620812  ... -0.19684376  0.2875422\n",
            "   -0.4766695 ]\n",
            "  [-0.09172302  0.04116556 -0.2620812  ... -0.19684376  0.2875422\n",
            "   -0.4766695 ]\n",
            "  [-0.09172302  0.04116556 -0.2620812  ... -0.19684376  0.2875422\n",
            "   -0.4766695 ]\n",
            "  ...\n",
            "  [-0.09172302  0.04116556 -0.2620812  ... -0.19684376  0.2875422\n",
            "   -0.4766695 ]\n",
            "  [-0.09172302  0.04116556 -0.2620812  ... -0.19684376  0.2875422\n",
            "   -0.4766695 ]\n",
            "  [-0.09172302  0.04116556 -0.2620812  ... -0.19684376  0.2875422\n",
            "   -0.4766695 ]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[-0.09172302  0.04116556 -0.2620812  ... -0.19684376  0.2875422\n",
            "   -0.4766695 ]\n",
            "  [-0.09172302  0.04116556 -0.2620812  ... -0.19684376  0.2875422\n",
            "   -0.4766695 ]\n",
            "  [-0.09172302  0.04116556 -0.2620812  ... -0.19684376  0.2875422\n",
            "   -0.4766695 ]\n",
            "  ...\n",
            "  [-0.09172302  0.04116556 -0.2620812  ... -0.19684376  0.2875422\n",
            "   -0.4766695 ]\n",
            "  [-0.09172302  0.04116556 -0.2620812  ... -0.19684376  0.2875422\n",
            "   -0.4766695 ]\n",
            "  [-0.09172302  0.04116556 -0.2620812  ... -0.19684376  0.2875422\n",
            "   -0.4766695 ]]\n",
            "\n",
            " [[-0.09172302  0.04116556 -0.2620812  ... -0.19684376  0.2875422\n",
            "   -0.4766695 ]\n",
            "  [-0.09172302  0.04116556 -0.2620812  ... -0.19684376  0.2875422\n",
            "   -0.4766695 ]\n",
            "  [-0.09172302  0.04116556 -0.2620812  ... -0.19684376  0.2875422\n",
            "   -0.4766695 ]\n",
            "  ...\n",
            "  [-0.09172302  0.04116556 -0.2620812  ... -0.19684376  0.2875422\n",
            "   -0.4766695 ]\n",
            "  [-0.09172302  0.04116556 -0.2620812  ... -0.19684376  0.2875422\n",
            "   -0.4766695 ]\n",
            "  [-0.09172302  0.04116556 -0.2620812  ... -0.19684376  0.2875422\n",
            "   -0.4766695 ]]\n",
            "\n",
            " [[-0.09172302  0.04116556 -0.2620812  ... -0.19684376  0.2875422\n",
            "   -0.4766695 ]\n",
            "  [-0.09172302  0.04116556 -0.2620812  ... -0.19684376  0.2875422\n",
            "   -0.4766695 ]\n",
            "  [-0.09172302  0.04116556 -0.2620812  ... -0.19684376  0.2875422\n",
            "   -0.4766695 ]\n",
            "  ...\n",
            "  [-0.09172302  0.04116556 -0.2620812  ... -0.19684376  0.2875422\n",
            "   -0.4766695 ]\n",
            "  [-0.09172302  0.04116556 -0.2620812  ... -0.19684376  0.2875422\n",
            "   -0.4766695 ]\n",
            "  [-0.09172302  0.04116556 -0.2620812  ... -0.19684376  0.2875422\n",
            "   -0.4766695 ]]], shape=(128, 764, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.68875027 -0.68875027 -0.68875027 ... -0.68875027 -0.68875027\n",
            "  -0.68875027]\n",
            " [-0.68875027 -0.68875027 -0.68875027 ... -0.68875027 -0.68875027\n",
            "  -0.68875027]\n",
            " [-0.68875027 -0.68875027 -0.68875027 ... -0.68875027 -0.68875027\n",
            "  -0.68875027]\n",
            " ...\n",
            " [-0.68875027 -0.68875027 -0.68875027 ... -0.68875027 -0.68875027\n",
            "  -0.68875027]\n",
            " [-0.68875027 -0.68875027 -0.68875027 ... -0.68875027 -0.68875027\n",
            "  -0.68875027]\n",
            " [-0.68875027 -0.68875027 -0.68875027 ... -0.68875027 -0.68875027\n",
            "  -0.68875027]], shape=(512, 128), dtype=float32) tf.Tensor(\n",
            "[[-0.68875027 -0.68875027 -0.68875027 ... -0.68875027 -0.68875027\n",
            "  -0.68875027]\n",
            " [-0.68875027 -0.68875027 -0.68875027 ... -0.68875027 -0.68875027\n",
            "  -0.68875027]\n",
            " [-0.68875027 -0.68875027 -0.68875027 ... -0.68875027 -0.68875027\n",
            "  -0.68875027]\n",
            " ...\n",
            " [-0.68875027 -0.68875027 -0.68875027 ... -0.68875027 -0.68875027\n",
            "  -0.68875027]\n",
            " [-0.68875027 -0.68875027 -0.68875027 ... -0.68875027 -0.68875027\n",
            "  -0.68875027]\n",
            " [-0.68875027 -0.68875027 -0.68875027 ... -0.68875027 -0.68875027\n",
            "  -0.68875027]], shape=(252, 128), dtype=float32)\n",
            "(128, 764) (512, 1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_15/kernel:0', 'dense_15/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_15/kernel:0', 'dense_15/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch 1, Batch 8/100, Loss=2.75663e+00\n",
            "(1, 764, 1)\n",
            "tf.Tensor(\n",
            "[[[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " [[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " [[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]], shape=(128, 764, 1), dtype=float32) tf.Tensor(\n",
            "[[[-0.17127696  0.02190647 -0.30060238 ... -0.21097656  0.32713982\n",
            "   -0.53121704]\n",
            "  [-0.17127696  0.02190647 -0.30060238 ... -0.21097656  0.32713982\n",
            "   -0.53121704]\n",
            "  [-0.17127696  0.02190647 -0.30060238 ... -0.21097656  0.32713982\n",
            "   -0.53121704]\n",
            "  ...\n",
            "  [-0.17127696  0.02190647 -0.30060238 ... -0.21097656  0.32713982\n",
            "   -0.53121704]\n",
            "  [-0.17127696  0.02190647 -0.30060238 ... -0.21097656  0.32713982\n",
            "   -0.53121704]\n",
            "  [-0.17127696  0.02190647 -0.30060238 ... -0.21097656  0.32713982\n",
            "   -0.53121704]]\n",
            "\n",
            " [[-0.17127696  0.02190647 -0.30060238 ... -0.21097656  0.32713982\n",
            "   -0.53121704]\n",
            "  [-0.17127696  0.02190647 -0.30060238 ... -0.21097656  0.32713982\n",
            "   -0.53121704]\n",
            "  [-0.17127696  0.02190647 -0.30060238 ... -0.21097656  0.32713982\n",
            "   -0.53121704]\n",
            "  ...\n",
            "  [-0.17127696  0.02190647 -0.30060238 ... -0.21097656  0.32713982\n",
            "   -0.53121704]\n",
            "  [-0.17127696  0.02190647 -0.30060238 ... -0.21097656  0.32713982\n",
            "   -0.53121704]\n",
            "  [-0.17127696  0.02190647 -0.30060238 ... -0.21097656  0.32713982\n",
            "   -0.53121704]]\n",
            "\n",
            " [[-0.17127696  0.02190647 -0.30060238 ... -0.21097656  0.32713982\n",
            "   -0.53121704]\n",
            "  [-0.17127696  0.02190647 -0.30060238 ... -0.21097656  0.32713982\n",
            "   -0.53121704]\n",
            "  [-0.17127696  0.02190647 -0.30060238 ... -0.21097656  0.32713982\n",
            "   -0.53121704]\n",
            "  ...\n",
            "  [-0.17127696  0.02190647 -0.30060238 ... -0.21097656  0.32713982\n",
            "   -0.53121704]\n",
            "  [-0.17127696  0.02190647 -0.30060238 ... -0.21097656  0.32713982\n",
            "   -0.53121704]\n",
            "  [-0.17127696  0.02190647 -0.30060238 ... -0.21097656  0.32713982\n",
            "   -0.53121704]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[-0.17127696  0.02190647 -0.30060238 ... -0.21097656  0.32713982\n",
            "   -0.53121704]\n",
            "  [-0.17127696  0.02190647 -0.30060238 ... -0.21097656  0.32713982\n",
            "   -0.53121704]\n",
            "  [-0.17127696  0.02190647 -0.30060238 ... -0.21097656  0.32713982\n",
            "   -0.53121704]\n",
            "  ...\n",
            "  [-0.17127696  0.02190647 -0.30060238 ... -0.21097656  0.32713982\n",
            "   -0.53121704]\n",
            "  [-0.17127696  0.02190647 -0.30060238 ... -0.21097656  0.32713982\n",
            "   -0.53121704]\n",
            "  [-0.17127696  0.02190647 -0.30060238 ... -0.21097656  0.32713982\n",
            "   -0.53121704]]\n",
            "\n",
            " [[-0.17127696  0.02190647 -0.30060238 ... -0.21097656  0.32713982\n",
            "   -0.53121704]\n",
            "  [-0.17127696  0.02190647 -0.30060238 ... -0.21097656  0.32713982\n",
            "   -0.53121704]\n",
            "  [-0.17127696  0.02190647 -0.30060238 ... -0.21097656  0.32713982\n",
            "   -0.53121704]\n",
            "  ...\n",
            "  [-0.17127696  0.02190647 -0.30060238 ... -0.21097656  0.32713982\n",
            "   -0.53121704]\n",
            "  [-0.17127696  0.02190647 -0.30060238 ... -0.21097656  0.32713982\n",
            "   -0.53121704]\n",
            "  [-0.17127696  0.02190647 -0.30060238 ... -0.21097656  0.32713982\n",
            "   -0.53121704]]\n",
            "\n",
            " [[-0.17127696  0.02190647 -0.30060238 ... -0.21097656  0.32713982\n",
            "   -0.53121704]\n",
            "  [-0.17127696  0.02190647 -0.30060238 ... -0.21097656  0.32713982\n",
            "   -0.53121704]\n",
            "  [-0.17127696  0.02190647 -0.30060238 ... -0.21097656  0.32713982\n",
            "   -0.53121704]\n",
            "  ...\n",
            "  [-0.17127696  0.02190647 -0.30060238 ... -0.21097656  0.32713982\n",
            "   -0.53121704]\n",
            "  [-0.17127696  0.02190647 -0.30060238 ... -0.21097656  0.32713982\n",
            "   -0.53121704]\n",
            "  [-0.17127696  0.02190647 -0.30060238 ... -0.21097656  0.32713982\n",
            "   -0.53121704]]], shape=(128, 764, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-1.1598917 -1.1598917 -1.1598917 ... -1.1598917 -1.1598917 -1.1598917]\n",
            " [-1.1598917 -1.1598917 -1.1598917 ... -1.1598917 -1.1598917 -1.1598917]\n",
            " [-1.1598917 -1.1598917 -1.1598917 ... -1.1598917 -1.1598917 -1.1598917]\n",
            " ...\n",
            " [-1.1598917 -1.1598917 -1.1598917 ... -1.1598917 -1.1598917 -1.1598917]\n",
            " [-1.1598917 -1.1598917 -1.1598917 ... -1.1598917 -1.1598917 -1.1598917]\n",
            " [-1.1598917 -1.1598917 -1.1598917 ... -1.1598917 -1.1598917 -1.1598917]], shape=(512, 128), dtype=float32) tf.Tensor(\n",
            "[[-1.1598917 -1.1598917 -1.1598917 ... -1.1598917 -1.1598917 -1.1598917]\n",
            " [-1.1598917 -1.1598917 -1.1598917 ... -1.1598917 -1.1598917 -1.1598917]\n",
            " [-1.1598917 -1.1598917 -1.1598917 ... -1.1598917 -1.1598917 -1.1598917]\n",
            " ...\n",
            " [-1.1598917 -1.1598917 -1.1598917 ... -1.1598917 -1.1598917 -1.1598917]\n",
            " [-1.1598917 -1.1598917 -1.1598917 ... -1.1598917 -1.1598917 -1.1598917]\n",
            " [-1.1598917 -1.1598917 -1.1598917 ... -1.1598917 -1.1598917 -1.1598917]], shape=(252, 128), dtype=float32)\n",
            "(128, 764) (512, 1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_15/kernel:0', 'dense_15/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_15/kernel:0', 'dense_15/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch 1, Batch 9/100, Loss=5.03601e+00\n",
            "(1, 764, 1)\n",
            "tf.Tensor(\n",
            "[[[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " [[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " [[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]], shape=(128, 764, 1), dtype=float32) tf.Tensor(\n",
            "[[[-0.22216998  0.04796818 -0.29433423 ... -0.22362752  0.3178854\n",
            "   -0.5310056 ]\n",
            "  [-0.22216998  0.04796818 -0.29433423 ... -0.22362752  0.3178854\n",
            "   -0.5310056 ]\n",
            "  [-0.22216998  0.04796818 -0.29433423 ... -0.22362752  0.3178854\n",
            "   -0.5310056 ]\n",
            "  ...\n",
            "  [-0.22216998  0.04796818 -0.29433423 ... -0.22362752  0.3178854\n",
            "   -0.5310056 ]\n",
            "  [-0.22216998  0.04796818 -0.29433423 ... -0.22362752  0.3178854\n",
            "   -0.5310056 ]\n",
            "  [-0.22216998  0.04796818 -0.29433423 ... -0.22362752  0.3178854\n",
            "   -0.5310056 ]]\n",
            "\n",
            " [[-0.22216998  0.04796818 -0.29433423 ... -0.22362752  0.3178854\n",
            "   -0.5310056 ]\n",
            "  [-0.22216998  0.04796818 -0.29433423 ... -0.22362752  0.3178854\n",
            "   -0.5310056 ]\n",
            "  [-0.22216998  0.04796818 -0.29433423 ... -0.22362752  0.3178854\n",
            "   -0.5310056 ]\n",
            "  ...\n",
            "  [-0.22216998  0.04796818 -0.29433423 ... -0.22362752  0.3178854\n",
            "   -0.5310056 ]\n",
            "  [-0.22216998  0.04796818 -0.29433423 ... -0.22362752  0.3178854\n",
            "   -0.5310056 ]\n",
            "  [-0.22216998  0.04796818 -0.29433423 ... -0.22362752  0.3178854\n",
            "   -0.5310056 ]]\n",
            "\n",
            " [[-0.22216998  0.04796818 -0.29433423 ... -0.22362752  0.3178854\n",
            "   -0.5310056 ]\n",
            "  [-0.22216998  0.04796818 -0.29433423 ... -0.22362752  0.3178854\n",
            "   -0.5310056 ]\n",
            "  [-0.22216998  0.04796818 -0.29433423 ... -0.22362752  0.3178854\n",
            "   -0.5310056 ]\n",
            "  ...\n",
            "  [-0.22216998  0.04796818 -0.29433423 ... -0.22362752  0.3178854\n",
            "   -0.5310056 ]\n",
            "  [-0.22216998  0.04796818 -0.29433423 ... -0.22362752  0.3178854\n",
            "   -0.5310056 ]\n",
            "  [-0.22216998  0.04796818 -0.29433423 ... -0.22362752  0.3178854\n",
            "   -0.5310056 ]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[-0.22216998  0.04796818 -0.29433423 ... -0.22362752  0.3178854\n",
            "   -0.5310056 ]\n",
            "  [-0.22216998  0.04796818 -0.29433423 ... -0.22362752  0.3178854\n",
            "   -0.5310056 ]\n",
            "  [-0.22216998  0.04796818 -0.29433423 ... -0.22362752  0.3178854\n",
            "   -0.5310056 ]\n",
            "  ...\n",
            "  [-0.22216998  0.04796818 -0.29433423 ... -0.22362752  0.3178854\n",
            "   -0.5310056 ]\n",
            "  [-0.22216998  0.04796818 -0.29433423 ... -0.22362752  0.3178854\n",
            "   -0.5310056 ]\n",
            "  [-0.22216998  0.04796818 -0.29433423 ... -0.22362752  0.3178854\n",
            "   -0.5310056 ]]\n",
            "\n",
            " [[-0.22216998  0.04796818 -0.29433423 ... -0.22362752  0.3178854\n",
            "   -0.5310056 ]\n",
            "  [-0.22216998  0.04796818 -0.29433423 ... -0.22362752  0.3178854\n",
            "   -0.5310056 ]\n",
            "  [-0.22216998  0.04796818 -0.29433423 ... -0.22362752  0.3178854\n",
            "   -0.5310056 ]\n",
            "  ...\n",
            "  [-0.22216998  0.04796818 -0.29433423 ... -0.22362752  0.3178854\n",
            "   -0.5310056 ]\n",
            "  [-0.22216998  0.04796818 -0.29433423 ... -0.22362752  0.3178854\n",
            "   -0.5310056 ]\n",
            "  [-0.22216998  0.04796818 -0.29433423 ... -0.22362752  0.3178854\n",
            "   -0.5310056 ]]\n",
            "\n",
            " [[-0.22216998  0.04796818 -0.29433423 ... -0.22362752  0.3178854\n",
            "   -0.5310056 ]\n",
            "  [-0.22216998  0.04796818 -0.29433423 ... -0.22362752  0.3178854\n",
            "   -0.5310056 ]\n",
            "  [-0.22216998  0.04796818 -0.29433423 ... -0.22362752  0.3178854\n",
            "   -0.5310056 ]\n",
            "  ...\n",
            "  [-0.22216998  0.04796818 -0.29433423 ... -0.22362752  0.3178854\n",
            "   -0.5310056 ]\n",
            "  [-0.22216998  0.04796818 -0.29433423 ... -0.22362752  0.3178854\n",
            "   -0.5310056 ]\n",
            "  [-0.22216998  0.04796818 -0.29433423 ... -0.22362752  0.3178854\n",
            "   -0.5310056 ]]], shape=(128, 764, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-1.1159688 -1.1159688 -1.1159688 ... -1.1159688 -1.1159688 -1.1159688]\n",
            " [-1.1159688 -1.1159688 -1.1159688 ... -1.1159688 -1.1159688 -1.1159688]\n",
            " [-1.1159688 -1.1159688 -1.1159688 ... -1.1159688 -1.1159688 -1.1159688]\n",
            " ...\n",
            " [-1.1159688 -1.1159688 -1.1159688 ... -1.1159688 -1.1159688 -1.1159688]\n",
            " [-1.1159688 -1.1159688 -1.1159688 ... -1.1159688 -1.1159688 -1.1159688]\n",
            " [-1.1159688 -1.1159688 -1.1159688 ... -1.1159688 -1.1159688 -1.1159688]], shape=(512, 128), dtype=float32) tf.Tensor(\n",
            "[[-1.1159688 -1.1159688 -1.1159688 ... -1.1159688 -1.1159688 -1.1159688]\n",
            " [-1.1159688 -1.1159688 -1.1159688 ... -1.1159688 -1.1159688 -1.1159688]\n",
            " [-1.1159688 -1.1159688 -1.1159688 ... -1.1159688 -1.1159688 -1.1159688]\n",
            " ...\n",
            " [-1.1159688 -1.1159688 -1.1159688 ... -1.1159688 -1.1159688 -1.1159688]\n",
            " [-1.1159688 -1.1159688 -1.1159688 ... -1.1159688 -1.1159688 -1.1159688]\n",
            " [-1.1159688 -1.1159688 -1.1159688 ... -1.1159688 -1.1159688 -1.1159688]], shape=(252, 128), dtype=float32)\n",
            "(128, 764) (512, 1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_15/kernel:0', 'dense_15/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_15/kernel:0', 'dense_15/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch 1, Batch 10/100, Loss=4.57727e+00\n",
            "(1, 764, 1)\n",
            "tf.Tensor(\n",
            "[[[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " [[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " [[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]], shape=(128, 764, 1), dtype=float32) tf.Tensor(\n",
            "[[[-0.255192    0.10387804 -0.2576554  ... -0.23809342  0.27210826\n",
            "   -0.49316314]\n",
            "  [-0.255192    0.10387804 -0.2576554  ... -0.23809342  0.27210826\n",
            "   -0.49316314]\n",
            "  [-0.255192    0.10387804 -0.2576554  ... -0.23809342  0.27210826\n",
            "   -0.49316314]\n",
            "  ...\n",
            "  [-0.255192    0.10387804 -0.2576554  ... -0.23809342  0.27210826\n",
            "   -0.49316314]\n",
            "  [-0.255192    0.10387804 -0.2576554  ... -0.23809342  0.27210826\n",
            "   -0.49316314]\n",
            "  [-0.255192    0.10387804 -0.2576554  ... -0.23809342  0.27210826\n",
            "   -0.49316314]]\n",
            "\n",
            " [[-0.255192    0.10387804 -0.2576554  ... -0.23809342  0.27210826\n",
            "   -0.49316314]\n",
            "  [-0.255192    0.10387804 -0.2576554  ... -0.23809342  0.27210826\n",
            "   -0.49316314]\n",
            "  [-0.255192    0.10387804 -0.2576554  ... -0.23809342  0.27210826\n",
            "   -0.49316314]\n",
            "  ...\n",
            "  [-0.255192    0.10387804 -0.2576554  ... -0.23809342  0.27210826\n",
            "   -0.49316314]\n",
            "  [-0.255192    0.10387804 -0.2576554  ... -0.23809342  0.27210826\n",
            "   -0.49316314]\n",
            "  [-0.255192    0.10387804 -0.2576554  ... -0.23809342  0.27210826\n",
            "   -0.49316314]]\n",
            "\n",
            " [[-0.255192    0.10387804 -0.2576554  ... -0.23809342  0.27210826\n",
            "   -0.49316314]\n",
            "  [-0.255192    0.10387804 -0.2576554  ... -0.23809342  0.27210826\n",
            "   -0.49316314]\n",
            "  [-0.255192    0.10387804 -0.2576554  ... -0.23809342  0.27210826\n",
            "   -0.49316314]\n",
            "  ...\n",
            "  [-0.255192    0.10387804 -0.2576554  ... -0.23809342  0.27210826\n",
            "   -0.49316314]\n",
            "  [-0.255192    0.10387804 -0.2576554  ... -0.23809342  0.27210826\n",
            "   -0.49316314]\n",
            "  [-0.255192    0.10387804 -0.2576554  ... -0.23809342  0.27210826\n",
            "   -0.49316314]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[-0.255192    0.10387804 -0.2576554  ... -0.23809342  0.27210826\n",
            "   -0.49316314]\n",
            "  [-0.255192    0.10387804 -0.2576554  ... -0.23809342  0.27210826\n",
            "   -0.49316314]\n",
            "  [-0.255192    0.10387804 -0.2576554  ... -0.23809342  0.27210826\n",
            "   -0.49316314]\n",
            "  ...\n",
            "  [-0.255192    0.10387804 -0.2576554  ... -0.23809342  0.27210826\n",
            "   -0.49316314]\n",
            "  [-0.255192    0.10387804 -0.2576554  ... -0.23809342  0.27210826\n",
            "   -0.49316314]\n",
            "  [-0.255192    0.10387804 -0.2576554  ... -0.23809342  0.27210826\n",
            "   -0.49316314]]\n",
            "\n",
            " [[-0.255192    0.10387804 -0.2576554  ... -0.23809342  0.27210826\n",
            "   -0.49316314]\n",
            "  [-0.255192    0.10387804 -0.2576554  ... -0.23809342  0.27210826\n",
            "   -0.49316314]\n",
            "  [-0.255192    0.10387804 -0.2576554  ... -0.23809342  0.27210826\n",
            "   -0.49316314]\n",
            "  ...\n",
            "  [-0.255192    0.10387804 -0.2576554  ... -0.23809342  0.27210826\n",
            "   -0.49316314]\n",
            "  [-0.255192    0.10387804 -0.2576554  ... -0.23809342  0.27210826\n",
            "   -0.49316314]\n",
            "  [-0.255192    0.10387804 -0.2576554  ... -0.23809342  0.27210826\n",
            "   -0.49316314]]\n",
            "\n",
            " [[-0.255192    0.10387804 -0.2576554  ... -0.23809342  0.27210826\n",
            "   -0.49316314]\n",
            "  [-0.255192    0.10387804 -0.2576554  ... -0.23809342  0.27210826\n",
            "   -0.49316314]\n",
            "  [-0.255192    0.10387804 -0.2576554  ... -0.23809342  0.27210826\n",
            "   -0.49316314]\n",
            "  ...\n",
            "  [-0.255192    0.10387804 -0.2576554  ... -0.23809342  0.27210826\n",
            "   -0.49316314]\n",
            "  [-0.255192    0.10387804 -0.2576554  ... -0.23809342  0.27210826\n",
            "   -0.49316314]\n",
            "  [-0.255192    0.10387804 -0.2576554  ... -0.23809342  0.27210826\n",
            "   -0.49316314]]], shape=(128, 764, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.72241527 -0.72241527 -0.72241527 ... -0.72241527 -0.72241527\n",
            "  -0.72241527]\n",
            " [-0.72241527 -0.72241527 -0.72241527 ... -0.72241527 -0.72241527\n",
            "  -0.72241527]\n",
            " [-0.72241527 -0.72241527 -0.72241527 ... -0.72241527 -0.72241527\n",
            "  -0.72241527]\n",
            " ...\n",
            " [-0.72241527 -0.72241527 -0.72241527 ... -0.72241527 -0.72241527\n",
            "  -0.72241527]\n",
            " [-0.72241527 -0.72241527 -0.72241527 ... -0.72241527 -0.72241527\n",
            "  -0.72241527]\n",
            " [-0.72241527 -0.72241527 -0.72241527 ... -0.72241527 -0.72241527\n",
            "  -0.72241527]], shape=(512, 128), dtype=float32) tf.Tensor(\n",
            "[[-0.72241527 -0.72241527 -0.72241527 ... -0.72241527 -0.72241527\n",
            "  -0.72241527]\n",
            " [-0.72241527 -0.72241527 -0.72241527 ... -0.72241527 -0.72241527\n",
            "  -0.72241527]\n",
            " [-0.72241527 -0.72241527 -0.72241527 ... -0.72241527 -0.72241527\n",
            "  -0.72241527]\n",
            " ...\n",
            " [-0.72241527 -0.72241527 -0.72241527 ... -0.72241527 -0.72241527\n",
            "  -0.72241527]\n",
            " [-0.72241527 -0.72241527 -0.72241527 ... -0.72241527 -0.72241527\n",
            "  -0.72241527]\n",
            " [-0.72241527 -0.72241527 -0.72241527 ... -0.72241527 -0.72241527\n",
            "  -0.72241527]], shape=(252, 128), dtype=float32)\n",
            "(128, 764) (512, 1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_15/kernel:0', 'dense_15/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_15/kernel:0', 'dense_15/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch 1, Batch 11/100, Loss=1.86300e+00\n",
            "(1, 764, 1)\n",
            "tf.Tensor(\n",
            "[[[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " [[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " [[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]], shape=(128, 764, 1), dtype=float32) tf.Tensor(\n",
            "[[[-0.28499576  0.17062554 -0.20962018 ... -0.25071156  0.20961624\n",
            "   -0.43706498]\n",
            "  [-0.28499576  0.17062554 -0.20962018 ... -0.25071156  0.20961624\n",
            "   -0.43706498]\n",
            "  [-0.28499576  0.17062554 -0.20962018 ... -0.25071156  0.20961624\n",
            "   -0.43706498]\n",
            "  ...\n",
            "  [-0.28499576  0.17062554 -0.20962018 ... -0.25071156  0.20961624\n",
            "   -0.43706498]\n",
            "  [-0.28499576  0.17062554 -0.20962018 ... -0.25071156  0.20961624\n",
            "   -0.43706498]\n",
            "  [-0.28499576  0.17062554 -0.20962018 ... -0.25071156  0.20961624\n",
            "   -0.43706498]]\n",
            "\n",
            " [[-0.28499576  0.17062554 -0.20962018 ... -0.25071156  0.20961624\n",
            "   -0.43706498]\n",
            "  [-0.28499576  0.17062554 -0.20962018 ... -0.25071156  0.20961624\n",
            "   -0.43706498]\n",
            "  [-0.28499576  0.17062554 -0.20962018 ... -0.25071156  0.20961624\n",
            "   -0.43706498]\n",
            "  ...\n",
            "  [-0.28499576  0.17062554 -0.20962018 ... -0.25071156  0.20961624\n",
            "   -0.43706498]\n",
            "  [-0.28499576  0.17062554 -0.20962018 ... -0.25071156  0.20961624\n",
            "   -0.43706498]\n",
            "  [-0.28499576  0.17062554 -0.20962018 ... -0.25071156  0.20961624\n",
            "   -0.43706498]]\n",
            "\n",
            " [[-0.28499576  0.17062554 -0.20962018 ... -0.25071156  0.20961624\n",
            "   -0.43706498]\n",
            "  [-0.28499576  0.17062554 -0.20962018 ... -0.25071156  0.20961624\n",
            "   -0.43706498]\n",
            "  [-0.28499576  0.17062554 -0.20962018 ... -0.25071156  0.20961624\n",
            "   -0.43706498]\n",
            "  ...\n",
            "  [-0.28499576  0.17062554 -0.20962018 ... -0.25071156  0.20961624\n",
            "   -0.43706498]\n",
            "  [-0.28499576  0.17062554 -0.20962018 ... -0.25071156  0.20961624\n",
            "   -0.43706498]\n",
            "  [-0.28499576  0.17062554 -0.20962018 ... -0.25071156  0.20961624\n",
            "   -0.43706498]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[-0.28499576  0.17062554 -0.20962018 ... -0.25071156  0.20961624\n",
            "   -0.43706498]\n",
            "  [-0.28499576  0.17062554 -0.20962018 ... -0.25071156  0.20961624\n",
            "   -0.43706498]\n",
            "  [-0.28499576  0.17062554 -0.20962018 ... -0.25071156  0.20961624\n",
            "   -0.43706498]\n",
            "  ...\n",
            "  [-0.28499576  0.17062554 -0.20962018 ... -0.25071156  0.20961624\n",
            "   -0.43706498]\n",
            "  [-0.28499576  0.17062554 -0.20962018 ... -0.25071156  0.20961624\n",
            "   -0.43706498]\n",
            "  [-0.28499576  0.17062554 -0.20962018 ... -0.25071156  0.20961624\n",
            "   -0.43706498]]\n",
            "\n",
            " [[-0.28499576  0.17062554 -0.20962018 ... -0.25071156  0.20961624\n",
            "   -0.43706498]\n",
            "  [-0.28499576  0.17062554 -0.20962018 ... -0.25071156  0.20961624\n",
            "   -0.43706498]\n",
            "  [-0.28499576  0.17062554 -0.20962018 ... -0.25071156  0.20961624\n",
            "   -0.43706498]\n",
            "  ...\n",
            "  [-0.28499576  0.17062554 -0.20962018 ... -0.25071156  0.20961624\n",
            "   -0.43706498]\n",
            "  [-0.28499576  0.17062554 -0.20962018 ... -0.25071156  0.20961624\n",
            "   -0.43706498]\n",
            "  [-0.28499576  0.17062554 -0.20962018 ... -0.25071156  0.20961624\n",
            "   -0.43706498]]\n",
            "\n",
            " [[-0.28499576  0.17062554 -0.20962018 ... -0.25071156  0.20961624\n",
            "   -0.43706498]\n",
            "  [-0.28499576  0.17062554 -0.20962018 ... -0.25071156  0.20961624\n",
            "   -0.43706498]\n",
            "  [-0.28499576  0.17062554 -0.20962018 ... -0.25071156  0.20961624\n",
            "   -0.43706498]\n",
            "  ...\n",
            "  [-0.28499576  0.17062554 -0.20962018 ... -0.25071156  0.20961624\n",
            "   -0.43706498]\n",
            "  [-0.28499576  0.17062554 -0.20962018 ... -0.25071156  0.20961624\n",
            "   -0.43706498]\n",
            "  [-0.28499576  0.17062554 -0.20962018 ... -0.25071156  0.20961624\n",
            "   -0.43706498]]], shape=(128, 764, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.195801 -0.195801 -0.195801 ... -0.195801 -0.195801 -0.195801]\n",
            " [-0.195801 -0.195801 -0.195801 ... -0.195801 -0.195801 -0.195801]\n",
            " [-0.195801 -0.195801 -0.195801 ... -0.195801 -0.195801 -0.195801]\n",
            " ...\n",
            " [-0.195801 -0.195801 -0.195801 ... -0.195801 -0.195801 -0.195801]\n",
            " [-0.195801 -0.195801 -0.195801 ... -0.195801 -0.195801 -0.195801]\n",
            " [-0.195801 -0.195801 -0.195801 ... -0.195801 -0.195801 -0.195801]], shape=(512, 128), dtype=float32) tf.Tensor(\n",
            "[[-0.195801 -0.195801 -0.195801 ... -0.195801 -0.195801 -0.195801]\n",
            " [-0.195801 -0.195801 -0.195801 ... -0.195801 -0.195801 -0.195801]\n",
            " [-0.195801 -0.195801 -0.195801 ... -0.195801 -0.195801 -0.195801]\n",
            " ...\n",
            " [-0.195801 -0.195801 -0.195801 ... -0.195801 -0.195801 -0.195801]\n",
            " [-0.195801 -0.195801 -0.195801 ... -0.195801 -0.195801 -0.195801]\n",
            " [-0.195801 -0.195801 -0.195801 ... -0.195801 -0.195801 -0.195801]], shape=(252, 128), dtype=float32)\n",
            "(128, 764) (512, 1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_15/kernel:0', 'dense_15/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_15/kernel:0', 'dense_15/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch 1, Batch 12/100, Loss=3.09370e-01\n",
            "(1, 764, 1)\n",
            "tf.Tensor(\n",
            "[[[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " [[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " [[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]], shape=(128, 764, 1), dtype=float32) tf.Tensor(\n",
            "[[[-0.31571662  0.23366718 -0.16419278 ... -0.25864     0.14790587\n",
            "   -0.38076407]\n",
            "  [-0.31571662  0.23366718 -0.16419278 ... -0.25864     0.14790587\n",
            "   -0.38076407]\n",
            "  [-0.31571662  0.23366718 -0.16419278 ... -0.25864     0.14790587\n",
            "   -0.38076407]\n",
            "  ...\n",
            "  [-0.31571662  0.23366718 -0.16419278 ... -0.25864     0.14790587\n",
            "   -0.38076407]\n",
            "  [-0.31571662  0.23366718 -0.16419278 ... -0.25864     0.14790587\n",
            "   -0.38076407]\n",
            "  [-0.31571662  0.23366718 -0.16419278 ... -0.25864     0.14790587\n",
            "   -0.38076407]]\n",
            "\n",
            " [[-0.31571662  0.23366718 -0.16419278 ... -0.25864     0.14790587\n",
            "   -0.38076407]\n",
            "  [-0.31571662  0.23366718 -0.16419278 ... -0.25864     0.14790587\n",
            "   -0.38076407]\n",
            "  [-0.31571662  0.23366718 -0.16419278 ... -0.25864     0.14790587\n",
            "   -0.38076407]\n",
            "  ...\n",
            "  [-0.31571662  0.23366718 -0.16419278 ... -0.25864     0.14790587\n",
            "   -0.38076407]\n",
            "  [-0.31571662  0.23366718 -0.16419278 ... -0.25864     0.14790587\n",
            "   -0.38076407]\n",
            "  [-0.31571662  0.23366718 -0.16419278 ... -0.25864     0.14790587\n",
            "   -0.38076407]]\n",
            "\n",
            " [[-0.31571662  0.23366718 -0.16419278 ... -0.25864     0.14790587\n",
            "   -0.38076407]\n",
            "  [-0.31571662  0.23366718 -0.16419278 ... -0.25864     0.14790587\n",
            "   -0.38076407]\n",
            "  [-0.31571662  0.23366718 -0.16419278 ... -0.25864     0.14790587\n",
            "   -0.38076407]\n",
            "  ...\n",
            "  [-0.31571662  0.23366718 -0.16419278 ... -0.25864     0.14790587\n",
            "   -0.38076407]\n",
            "  [-0.31571662  0.23366718 -0.16419278 ... -0.25864     0.14790587\n",
            "   -0.38076407]\n",
            "  [-0.31571662  0.23366718 -0.16419278 ... -0.25864     0.14790587\n",
            "   -0.38076407]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[-0.31571662  0.23366718 -0.16419278 ... -0.25864     0.14790587\n",
            "   -0.38076407]\n",
            "  [-0.31571662  0.23366718 -0.16419278 ... -0.25864     0.14790587\n",
            "   -0.38076407]\n",
            "  [-0.31571662  0.23366718 -0.16419278 ... -0.25864     0.14790587\n",
            "   -0.38076407]\n",
            "  ...\n",
            "  [-0.31571662  0.23366718 -0.16419278 ... -0.25864     0.14790587\n",
            "   -0.38076407]\n",
            "  [-0.31571662  0.23366718 -0.16419278 ... -0.25864     0.14790587\n",
            "   -0.38076407]\n",
            "  [-0.31571662  0.23366718 -0.16419278 ... -0.25864     0.14790587\n",
            "   -0.38076407]]\n",
            "\n",
            " [[-0.31571662  0.23366718 -0.16419278 ... -0.25864     0.14790587\n",
            "   -0.38076407]\n",
            "  [-0.31571662  0.23366718 -0.16419278 ... -0.25864     0.14790587\n",
            "   -0.38076407]\n",
            "  [-0.31571662  0.23366718 -0.16419278 ... -0.25864     0.14790587\n",
            "   -0.38076407]\n",
            "  ...\n",
            "  [-0.31571662  0.23366718 -0.16419278 ... -0.25864     0.14790587\n",
            "   -0.38076407]\n",
            "  [-0.31571662  0.23366718 -0.16419278 ... -0.25864     0.14790587\n",
            "   -0.38076407]\n",
            "  [-0.31571662  0.23366718 -0.16419278 ... -0.25864     0.14790587\n",
            "   -0.38076407]]\n",
            "\n",
            " [[-0.31571662  0.23366718 -0.16419278 ... -0.25864     0.14790587\n",
            "   -0.38076407]\n",
            "  [-0.31571662  0.23366718 -0.16419278 ... -0.25864     0.14790587\n",
            "   -0.38076407]\n",
            "  [-0.31571662  0.23366718 -0.16419278 ... -0.25864     0.14790587\n",
            "   -0.38076407]\n",
            "  ...\n",
            "  [-0.31571662  0.23366718 -0.16419278 ... -0.25864     0.14790587\n",
            "   -0.38076407]\n",
            "  [-0.31571662  0.23366718 -0.16419278 ... -0.25864     0.14790587\n",
            "   -0.38076407]\n",
            "  [-0.31571662  0.23366718 -0.16419278 ... -0.25864     0.14790587\n",
            "   -0.38076407]]], shape=(128, 764, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[0.30115023 0.30115023 0.30115023 ... 0.30115023 0.30115023 0.30115023]\n",
            " [0.30115023 0.30115023 0.30115023 ... 0.30115023 0.30115023 0.30115023]\n",
            " [0.30115023 0.30115023 0.30115023 ... 0.30115023 0.30115023 0.30115023]\n",
            " ...\n",
            " [0.30115023 0.30115023 0.30115023 ... 0.30115023 0.30115023 0.30115023]\n",
            " [0.30115023 0.30115023 0.30115023 ... 0.30115023 0.30115023 0.30115023]\n",
            " [0.30115023 0.30115023 0.30115023 ... 0.30115023 0.30115023 0.30115023]], shape=(512, 128), dtype=float32) tf.Tensor(\n",
            "[[0.30115023 0.30115023 0.30115023 ... 0.30115023 0.30115023 0.30115023]\n",
            " [0.30115023 0.30115023 0.30115023 ... 0.30115023 0.30115023 0.30115023]\n",
            " [0.30115023 0.30115023 0.30115023 ... 0.30115023 0.30115023 0.30115023]\n",
            " ...\n",
            " [0.30115023 0.30115023 0.30115023 ... 0.30115023 0.30115023 0.30115023]\n",
            " [0.30115023 0.30115023 0.30115023 ... 0.30115023 0.30115023 0.30115023]\n",
            " [0.30115023 0.30115023 0.30115023 ... 0.30115023 0.30115023 0.30115023]], shape=(252, 128), dtype=float32)\n",
            "(128, 764) (512, 1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_15/kernel:0', 'dense_15/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_15/kernel:0', 'dense_15/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch 1, Batch 13/100, Loss=2.64717e-01\n",
            "(1, 764, 1)\n",
            "tf.Tensor(\n",
            "[[[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]], shape=(128, 764, 1), dtype=float32) tf.Tensor(\n",
            "[[[-0.34031862  0.2819536  -0.12986307 ... -0.26000115  0.10194446\n",
            "   -0.33917305]\n",
            "  [-0.34031862  0.2819536  -0.12986307 ... -0.26000115  0.10194446\n",
            "   -0.33917305]\n",
            "  [-0.34031862  0.2819536  -0.12986307 ... -0.26000115  0.10194446\n",
            "   -0.33917305]\n",
            "  ...\n",
            "  [-0.34031862  0.2819536  -0.12986307 ... -0.26000115  0.10194446\n",
            "   -0.33917305]\n",
            "  [-0.34031862  0.2819536  -0.12986307 ... -0.26000115  0.10194446\n",
            "   -0.33917305]\n",
            "  [-0.34031862  0.2819536  -0.12986307 ... -0.26000115  0.10194446\n",
            "   -0.33917305]]\n",
            "\n",
            " [[-0.34031862  0.2819536  -0.12986307 ... -0.26000115  0.10194446\n",
            "   -0.33917305]\n",
            "  [-0.34031862  0.2819536  -0.12986307 ... -0.26000115  0.10194446\n",
            "   -0.33917305]\n",
            "  [-0.34031862  0.2819536  -0.12986307 ... -0.26000115  0.10194446\n",
            "   -0.33917305]\n",
            "  ...\n",
            "  [-0.34031862  0.2819536  -0.12986307 ... -0.26000115  0.10194446\n",
            "   -0.33917305]\n",
            "  [-0.34031862  0.2819536  -0.12986307 ... -0.26000115  0.10194446\n",
            "   -0.33917305]\n",
            "  [-0.34031862  0.2819536  -0.12986307 ... -0.26000115  0.10194446\n",
            "   -0.33917305]]\n",
            "\n",
            " [[-0.34031862  0.2819536  -0.12986307 ... -0.26000115  0.10194446\n",
            "   -0.33917305]\n",
            "  [-0.34031862  0.2819536  -0.12986307 ... -0.26000115  0.10194446\n",
            "   -0.33917305]\n",
            "  [-0.34031862  0.2819536  -0.12986307 ... -0.26000115  0.10194446\n",
            "   -0.33917305]\n",
            "  ...\n",
            "  [-0.34031862  0.2819536  -0.12986307 ... -0.26000115  0.10194446\n",
            "   -0.33917305]\n",
            "  [-0.34031862  0.2819536  -0.12986307 ... -0.26000115  0.10194446\n",
            "   -0.33917305]\n",
            "  [-0.34031862  0.2819536  -0.12986307 ... -0.26000115  0.10194446\n",
            "   -0.33917305]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[-0.34031862  0.2819536  -0.12986307 ... -0.26000115  0.10194446\n",
            "   -0.33917305]\n",
            "  [-0.34031862  0.2819536  -0.12986307 ... -0.26000115  0.10194446\n",
            "   -0.33917305]\n",
            "  [-0.34031862  0.2819536  -0.12986307 ... -0.26000115  0.10194446\n",
            "   -0.33917305]\n",
            "  ...\n",
            "  [-0.34031862  0.2819536  -0.12986307 ... -0.26000115  0.10194446\n",
            "   -0.33917305]\n",
            "  [-0.34031862  0.2819536  -0.12986307 ... -0.26000115  0.10194446\n",
            "   -0.33917305]\n",
            "  [-0.34031862  0.2819536  -0.12986307 ... -0.26000115  0.10194446\n",
            "   -0.33917305]]\n",
            "\n",
            " [[-0.34031862  0.2819536  -0.12986307 ... -0.26000115  0.10194446\n",
            "   -0.33917305]\n",
            "  [-0.34031862  0.2819536  -0.12986307 ... -0.26000115  0.10194446\n",
            "   -0.33917305]\n",
            "  [-0.34031862  0.2819536  -0.12986307 ... -0.26000115  0.10194446\n",
            "   -0.33917305]\n",
            "  ...\n",
            "  [-0.34031862  0.2819536  -0.12986307 ... -0.26000115  0.10194446\n",
            "   -0.33917305]\n",
            "  [-0.34031862  0.2819536  -0.12986307 ... -0.26000115  0.10194446\n",
            "   -0.33917305]\n",
            "  [-0.34031862  0.2819536  -0.12986307 ... -0.26000115  0.10194446\n",
            "   -0.33917305]]\n",
            "\n",
            " [[-0.34031862  0.2819536  -0.12986307 ... -0.26000115  0.10194446\n",
            "   -0.33917305]\n",
            "  [-0.34031862  0.2819536  -0.12986307 ... -0.26000115  0.10194446\n",
            "   -0.33917305]\n",
            "  [-0.34031862  0.2819536  -0.12986307 ... -0.26000115  0.10194446\n",
            "   -0.33917305]\n",
            "  ...\n",
            "  [-0.34031862  0.2819536  -0.12986307 ... -0.26000115  0.10194446\n",
            "   -0.33917305]\n",
            "  [-0.34031862  0.2819536  -0.12986307 ... -0.26000115  0.10194446\n",
            "   -0.33917305]\n",
            "  [-0.34031862  0.2819536  -0.12986307 ... -0.26000115  0.10194446\n",
            "   -0.33917305]]], shape=(128, 764, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[0.6550937 0.6550937 0.6550937 ... 0.6550937 0.6550937 0.6550937]\n",
            " [0.6550937 0.6550937 0.6550937 ... 0.6550937 0.6550937 0.6550937]\n",
            " [0.6550937 0.6550937 0.6550937 ... 0.6550937 0.6550937 0.6550937]\n",
            " ...\n",
            " [0.6550937 0.6550937 0.6550937 ... 0.6550937 0.6550937 0.6550937]\n",
            " [0.6550937 0.6550937 0.6550937 ... 0.6550937 0.6550937 0.6550937]\n",
            " [0.6550937 0.6550937 0.6550937 ... 0.6550937 0.6550937 0.6550937]], shape=(512, 128), dtype=float32) tf.Tensor(\n",
            "[[0.6550937 0.6550937 0.6550937 ... 0.6550937 0.6550937 0.6550937]\n",
            " [0.6550937 0.6550937 0.6550937 ... 0.6550937 0.6550937 0.6550937]\n",
            " [0.6550937 0.6550937 0.6550937 ... 0.6550937 0.6550937 0.6550937]\n",
            " ...\n",
            " [0.6550937 0.6550937 0.6550937 ... 0.6550937 0.6550937 0.6550937]\n",
            " [0.6550937 0.6550937 0.6550937 ... 0.6550937 0.6550937 0.6550937]\n",
            " [0.6550937 0.6550937 0.6550937 ... 0.6550937 0.6550937 0.6550937]], shape=(252, 128), dtype=float32)\n",
            "(128, 764) (512, 1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_15/kernel:0', 'dense_15/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_15/kernel:0', 'dense_15/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch 1, Batch 14/100, Loss=1.00235e+00\n",
            "(1, 764, 1)\n",
            "tf.Tensor(\n",
            "[[[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]], shape=(128, 764, 1), dtype=float32) tf.Tensor(\n",
            "[[[-0.3505724   0.31061915 -0.11035129 ... -0.25145566  0.07940809\n",
            "   -0.32113132]\n",
            "  [-0.3505724   0.31061915 -0.11035129 ... -0.25145566  0.07940809\n",
            "   -0.32113132]\n",
            "  [-0.3505724   0.31061915 -0.11035129 ... -0.25145566  0.07940809\n",
            "   -0.32113132]\n",
            "  ...\n",
            "  [-0.3505724   0.31061915 -0.11035129 ... -0.25145566  0.07940809\n",
            "   -0.32113132]\n",
            "  [-0.3505724   0.31061915 -0.11035129 ... -0.25145566  0.07940809\n",
            "   -0.32113132]\n",
            "  [-0.3505724   0.31061915 -0.11035129 ... -0.25145566  0.07940809\n",
            "   -0.32113132]]\n",
            "\n",
            " [[-0.3505724   0.31061915 -0.11035129 ... -0.25145566  0.07940809\n",
            "   -0.32113132]\n",
            "  [-0.3505724   0.31061915 -0.11035129 ... -0.25145566  0.07940809\n",
            "   -0.32113132]\n",
            "  [-0.3505724   0.31061915 -0.11035129 ... -0.25145566  0.07940809\n",
            "   -0.32113132]\n",
            "  ...\n",
            "  [-0.3505724   0.31061915 -0.11035129 ... -0.25145566  0.07940809\n",
            "   -0.32113132]\n",
            "  [-0.3505724   0.31061915 -0.11035129 ... -0.25145566  0.07940809\n",
            "   -0.32113132]\n",
            "  [-0.3505724   0.31061915 -0.11035129 ... -0.25145566  0.07940809\n",
            "   -0.32113132]]\n",
            "\n",
            " [[-0.3505724   0.31061915 -0.11035129 ... -0.25145566  0.07940809\n",
            "   -0.32113132]\n",
            "  [-0.3505724   0.31061915 -0.11035129 ... -0.25145566  0.07940809\n",
            "   -0.32113132]\n",
            "  [-0.3505724   0.31061915 -0.11035129 ... -0.25145566  0.07940809\n",
            "   -0.32113132]\n",
            "  ...\n",
            "  [-0.3505724   0.31061915 -0.11035129 ... -0.25145566  0.07940809\n",
            "   -0.32113132]\n",
            "  [-0.3505724   0.31061915 -0.11035129 ... -0.25145566  0.07940809\n",
            "   -0.32113132]\n",
            "  [-0.3505724   0.31061915 -0.11035129 ... -0.25145566  0.07940809\n",
            "   -0.32113132]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[-0.3505724   0.31061915 -0.11035129 ... -0.25145566  0.07940809\n",
            "   -0.32113132]\n",
            "  [-0.3505724   0.31061915 -0.11035129 ... -0.25145566  0.07940809\n",
            "   -0.32113132]\n",
            "  [-0.3505724   0.31061915 -0.11035129 ... -0.25145566  0.07940809\n",
            "   -0.32113132]\n",
            "  ...\n",
            "  [-0.3505724   0.31061915 -0.11035129 ... -0.25145566  0.07940809\n",
            "   -0.32113132]\n",
            "  [-0.3505724   0.31061915 -0.11035129 ... -0.25145566  0.07940809\n",
            "   -0.32113132]\n",
            "  [-0.3505724   0.31061915 -0.11035129 ... -0.25145566  0.07940809\n",
            "   -0.32113132]]\n",
            "\n",
            " [[-0.3505724   0.31061915 -0.11035129 ... -0.25145566  0.07940809\n",
            "   -0.32113132]\n",
            "  [-0.3505724   0.31061915 -0.11035129 ... -0.25145566  0.07940809\n",
            "   -0.32113132]\n",
            "  [-0.3505724   0.31061915 -0.11035129 ... -0.25145566  0.07940809\n",
            "   -0.32113132]\n",
            "  ...\n",
            "  [-0.3505724   0.31061915 -0.11035129 ... -0.25145566  0.07940809\n",
            "   -0.32113132]\n",
            "  [-0.3505724   0.31061915 -0.11035129 ... -0.25145566  0.07940809\n",
            "   -0.32113132]\n",
            "  [-0.3505724   0.31061915 -0.11035129 ... -0.25145566  0.07940809\n",
            "   -0.32113132]]\n",
            "\n",
            " [[-0.3505724   0.31061915 -0.11035129 ... -0.25145566  0.07940809\n",
            "   -0.32113132]\n",
            "  [-0.3505724   0.31061915 -0.11035129 ... -0.25145566  0.07940809\n",
            "   -0.32113132]\n",
            "  [-0.3505724   0.31061915 -0.11035129 ... -0.25145566  0.07940809\n",
            "   -0.32113132]\n",
            "  ...\n",
            "  [-0.3505724   0.31061915 -0.11035129 ... -0.25145566  0.07940809\n",
            "   -0.32113132]\n",
            "  [-0.3505724   0.31061915 -0.11035129 ... -0.25145566  0.07940809\n",
            "   -0.32113132]\n",
            "  [-0.3505724   0.31061915 -0.11035129 ... -0.25145566  0.07940809\n",
            "   -0.32113132]]], shape=(128, 764, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[0.8103632 0.8103632 0.8103632 ... 0.8103632 0.8103632 0.8103632]\n",
            " [0.8103632 0.8103632 0.8103632 ... 0.8103632 0.8103632 0.8103632]\n",
            " [0.8103632 0.8103632 0.8103632 ... 0.8103632 0.8103632 0.8103632]\n",
            " ...\n",
            " [0.8103632 0.8103632 0.8103632 ... 0.8103632 0.8103632 0.8103632]\n",
            " [0.8103632 0.8103632 0.8103632 ... 0.8103632 0.8103632 0.8103632]\n",
            " [0.8103632 0.8103632 0.8103632 ... 0.8103632 0.8103632 0.8103632]], shape=(512, 128), dtype=float32) tf.Tensor(\n",
            "[[0.8103632 0.8103632 0.8103632 ... 0.8103632 0.8103632 0.8103632]\n",
            " [0.8103632 0.8103632 0.8103632 ... 0.8103632 0.8103632 0.8103632]\n",
            " [0.8103632 0.8103632 0.8103632 ... 0.8103632 0.8103632 0.8103632]\n",
            " ...\n",
            " [0.8103632 0.8103632 0.8103632 ... 0.8103632 0.8103632 0.8103632]\n",
            " [0.8103632 0.8103632 0.8103632 ... 0.8103632 0.8103632 0.8103632]\n",
            " [0.8103632 0.8103632 0.8103632 ... 0.8103632 0.8103632 0.8103632]], shape=(252, 128), dtype=float32)\n",
            "(128, 764) (512, 1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_15/kernel:0', 'dense_15/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_15/kernel:0', 'dense_15/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch 1, Batch 15/100, Loss=1.57489e+00\n",
            "(1, 764, 1)\n",
            "tf.Tensor(\n",
            "[[[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " [[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " [[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " [[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " [[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]], shape=(128, 764, 1), dtype=float32) tf.Tensor(\n",
            "[[[-0.34624156  0.3220424  -0.10687612 ... -0.22744852  0.0779999\n",
            "   -0.33064407]\n",
            "  [-0.34624156  0.3220424  -0.10687612 ... -0.22744852  0.0779999\n",
            "   -0.33064407]\n",
            "  [-0.34624156  0.3220424  -0.10687612 ... -0.22744852  0.0779999\n",
            "   -0.33064407]\n",
            "  ...\n",
            "  [-0.34624156  0.3220424  -0.10687612 ... -0.22744852  0.0779999\n",
            "   -0.33064407]\n",
            "  [-0.34624156  0.3220424  -0.10687612 ... -0.22744852  0.0779999\n",
            "   -0.33064407]\n",
            "  [-0.34624156  0.3220424  -0.10687612 ... -0.22744852  0.0779999\n",
            "   -0.33064407]]\n",
            "\n",
            " [[-0.34624156  0.3220424  -0.10687612 ... -0.22744852  0.0779999\n",
            "   -0.33064407]\n",
            "  [-0.34624156  0.3220424  -0.10687612 ... -0.22744852  0.0779999\n",
            "   -0.33064407]\n",
            "  [-0.34624156  0.3220424  -0.10687612 ... -0.22744852  0.0779999\n",
            "   -0.33064407]\n",
            "  ...\n",
            "  [-0.34624156  0.3220424  -0.10687612 ... -0.22744852  0.0779999\n",
            "   -0.33064407]\n",
            "  [-0.34624156  0.3220424  -0.10687612 ... -0.22744852  0.0779999\n",
            "   -0.33064407]\n",
            "  [-0.34624156  0.3220424  -0.10687612 ... -0.22744852  0.0779999\n",
            "   -0.33064407]]\n",
            "\n",
            " [[-0.34624156  0.3220424  -0.10687612 ... -0.22744852  0.0779999\n",
            "   -0.33064407]\n",
            "  [-0.34624156  0.3220424  -0.10687612 ... -0.22744852  0.0779999\n",
            "   -0.33064407]\n",
            "  [-0.34624156  0.3220424  -0.10687612 ... -0.22744852  0.0779999\n",
            "   -0.33064407]\n",
            "  ...\n",
            "  [-0.34624156  0.3220424  -0.10687612 ... -0.22744852  0.0779999\n",
            "   -0.33064407]\n",
            "  [-0.34624156  0.3220424  -0.10687612 ... -0.22744852  0.0779999\n",
            "   -0.33064407]\n",
            "  [-0.34624156  0.3220424  -0.10687612 ... -0.22744852  0.0779999\n",
            "   -0.33064407]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[-0.34624156  0.3220424  -0.10687612 ... -0.22744852  0.0779999\n",
            "   -0.33064407]\n",
            "  [-0.34624156  0.3220424  -0.10687612 ... -0.22744852  0.0779999\n",
            "   -0.33064407]\n",
            "  [-0.34624156  0.3220424  -0.10687612 ... -0.22744852  0.0779999\n",
            "   -0.33064407]\n",
            "  ...\n",
            "  [-0.34624156  0.3220424  -0.10687612 ... -0.22744852  0.0779999\n",
            "   -0.33064407]\n",
            "  [-0.34624156  0.3220424  -0.10687612 ... -0.22744852  0.0779999\n",
            "   -0.33064407]\n",
            "  [-0.34624156  0.3220424  -0.10687612 ... -0.22744852  0.0779999\n",
            "   -0.33064407]]\n",
            "\n",
            " [[-0.34624156  0.3220424  -0.10687612 ... -0.22744852  0.0779999\n",
            "   -0.33064407]\n",
            "  [-0.34624156  0.3220424  -0.10687612 ... -0.22744852  0.0779999\n",
            "   -0.33064407]\n",
            "  [-0.34624156  0.3220424  -0.10687612 ... -0.22744852  0.0779999\n",
            "   -0.33064407]\n",
            "  ...\n",
            "  [-0.34624156  0.3220424  -0.10687612 ... -0.22744852  0.0779999\n",
            "   -0.33064407]\n",
            "  [-0.34624156  0.3220424  -0.10687612 ... -0.22744852  0.0779999\n",
            "   -0.33064407]\n",
            "  [-0.34624156  0.3220424  -0.10687612 ... -0.22744852  0.0779999\n",
            "   -0.33064407]]\n",
            "\n",
            " [[-0.34624156  0.3220424  -0.10687612 ... -0.22744852  0.0779999\n",
            "   -0.33064407]\n",
            "  [-0.34624156  0.3220424  -0.10687612 ... -0.22744852  0.0779999\n",
            "   -0.33064407]\n",
            "  [-0.34624156  0.3220424  -0.10687612 ... -0.22744852  0.0779999\n",
            "   -0.33064407]\n",
            "  ...\n",
            "  [-0.34624156  0.3220424  -0.10687612 ... -0.22744852  0.0779999\n",
            "   -0.33064407]\n",
            "  [-0.34624156  0.3220424  -0.10687612 ... -0.22744852  0.0779999\n",
            "   -0.33064407]\n",
            "  [-0.34624156  0.3220424  -0.10687612 ... -0.22744852  0.0779999\n",
            "   -0.33064407]]], shape=(128, 764, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[0.76797825 0.76797825 0.76797825 ... 0.76797825 0.76797825 0.76797825]\n",
            " [0.76797825 0.76797825 0.76797825 ... 0.76797825 0.76797825 0.76797825]\n",
            " [0.76797825 0.76797825 0.76797825 ... 0.76797825 0.76797825 0.76797825]\n",
            " ...\n",
            " [0.76797825 0.76797825 0.76797825 ... 0.76797825 0.76797825 0.76797825]\n",
            " [0.76797825 0.76797825 0.76797825 ... 0.76797825 0.76797825 0.76797825]\n",
            " [0.76797825 0.76797825 0.76797825 ... 0.76797825 0.76797825 0.76797825]], shape=(512, 128), dtype=float32) tf.Tensor(\n",
            "[[0.76797825 0.76797825 0.76797825 ... 0.76797825 0.76797825 0.76797825]\n",
            " [0.76797825 0.76797825 0.76797825 ... 0.76797825 0.76797825 0.76797825]\n",
            " [0.76797825 0.76797825 0.76797825 ... 0.76797825 0.76797825 0.76797825]\n",
            " ...\n",
            " [0.76797825 0.76797825 0.76797825 ... 0.76797825 0.76797825 0.76797825]\n",
            " [0.76797825 0.76797825 0.76797825 ... 0.76797825 0.76797825 0.76797825]\n",
            " [0.76797825 0.76797825 0.76797825 ... 0.76797825 0.76797825 0.76797825]], shape=(252, 128), dtype=float32)\n",
            "(128, 764) (512, 1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_15/kernel:0', 'dense_15/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_15/kernel:0', 'dense_15/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch 1, Batch 16/100, Loss=1.35484e+00\n",
            "(1, 764, 1)\n",
            "tf.Tensor(\n",
            "[[[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " [[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " [[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " [[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " [[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]], shape=(128, 764, 1), dtype=float32) tf.Tensor(\n",
            "[[[-0.33145347  0.32214677 -0.11680703 ... -0.18744205  0.08976471\n",
            "   -0.36362308]\n",
            "  [-0.33145347  0.32214677 -0.11680703 ... -0.18744205  0.08976471\n",
            "   -0.36362308]\n",
            "  [-0.33145347  0.32214677 -0.11680703 ... -0.18744205  0.08976471\n",
            "   -0.36362308]\n",
            "  ...\n",
            "  [-0.33145347  0.32214677 -0.11680703 ... -0.18744205  0.08976471\n",
            "   -0.36362308]\n",
            "  [-0.33145347  0.32214677 -0.11680703 ... -0.18744205  0.08976471\n",
            "   -0.36362308]\n",
            "  [-0.33145347  0.32214677 -0.11680703 ... -0.18744205  0.08976471\n",
            "   -0.36362308]]\n",
            "\n",
            " [[-0.33145347  0.32214677 -0.11680703 ... -0.18744205  0.08976471\n",
            "   -0.36362308]\n",
            "  [-0.33145347  0.32214677 -0.11680703 ... -0.18744205  0.08976471\n",
            "   -0.36362308]\n",
            "  [-0.33145347  0.32214677 -0.11680703 ... -0.18744205  0.08976471\n",
            "   -0.36362308]\n",
            "  ...\n",
            "  [-0.33145347  0.32214677 -0.11680703 ... -0.18744205  0.08976471\n",
            "   -0.36362308]\n",
            "  [-0.33145347  0.32214677 -0.11680703 ... -0.18744205  0.08976471\n",
            "   -0.36362308]\n",
            "  [-0.33145347  0.32214677 -0.11680703 ... -0.18744205  0.08976471\n",
            "   -0.36362308]]\n",
            "\n",
            " [[-0.33145347  0.32214677 -0.11680703 ... -0.18744205  0.08976471\n",
            "   -0.36362308]\n",
            "  [-0.33145347  0.32214677 -0.11680703 ... -0.18744205  0.08976471\n",
            "   -0.36362308]\n",
            "  [-0.33145347  0.32214677 -0.11680703 ... -0.18744205  0.08976471\n",
            "   -0.36362308]\n",
            "  ...\n",
            "  [-0.33145347  0.32214677 -0.11680703 ... -0.18744205  0.08976471\n",
            "   -0.36362308]\n",
            "  [-0.33145347  0.32214677 -0.11680703 ... -0.18744205  0.08976471\n",
            "   -0.36362308]\n",
            "  [-0.33145347  0.32214677 -0.11680703 ... -0.18744205  0.08976471\n",
            "   -0.36362308]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[-0.33145347  0.32214677 -0.11680703 ... -0.18744205  0.08976471\n",
            "   -0.36362308]\n",
            "  [-0.33145347  0.32214677 -0.11680703 ... -0.18744205  0.08976471\n",
            "   -0.36362308]\n",
            "  [-0.33145347  0.32214677 -0.11680703 ... -0.18744205  0.08976471\n",
            "   -0.36362308]\n",
            "  ...\n",
            "  [-0.33145347  0.32214677 -0.11680703 ... -0.18744205  0.08976471\n",
            "   -0.36362308]\n",
            "  [-0.33145347  0.32214677 -0.11680703 ... -0.18744205  0.08976471\n",
            "   -0.36362308]\n",
            "  [-0.33145347  0.32214677 -0.11680703 ... -0.18744205  0.08976471\n",
            "   -0.36362308]]\n",
            "\n",
            " [[-0.33145347  0.32214677 -0.11680703 ... -0.18744205  0.08976471\n",
            "   -0.36362308]\n",
            "  [-0.33145347  0.32214677 -0.11680703 ... -0.18744205  0.08976471\n",
            "   -0.36362308]\n",
            "  [-0.33145347  0.32214677 -0.11680703 ... -0.18744205  0.08976471\n",
            "   -0.36362308]\n",
            "  ...\n",
            "  [-0.33145347  0.32214677 -0.11680703 ... -0.18744205  0.08976471\n",
            "   -0.36362308]\n",
            "  [-0.33145347  0.32214677 -0.11680703 ... -0.18744205  0.08976471\n",
            "   -0.36362308]\n",
            "  [-0.33145347  0.32214677 -0.11680703 ... -0.18744205  0.08976471\n",
            "   -0.36362308]]\n",
            "\n",
            " [[-0.33145347  0.32214677 -0.11680703 ... -0.18744205  0.08976471\n",
            "   -0.36362308]\n",
            "  [-0.33145347  0.32214677 -0.11680703 ... -0.18744205  0.08976471\n",
            "   -0.36362308]\n",
            "  [-0.33145347  0.32214677 -0.11680703 ... -0.18744205  0.08976471\n",
            "   -0.36362308]\n",
            "  ...\n",
            "  [-0.33145347  0.32214677 -0.11680703 ... -0.18744205  0.08976471\n",
            "   -0.36362308]\n",
            "  [-0.33145347  0.32214677 -0.11680703 ... -0.18744205  0.08976471\n",
            "   -0.36362308]\n",
            "  [-0.33145347  0.32214677 -0.11680703 ... -0.18744205  0.08976471\n",
            "   -0.36362308]]], shape=(128, 764, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[0.5810918 0.5810918 0.5810918 ... 0.5810918 0.5810918 0.5810918]\n",
            " [0.5810918 0.5810918 0.5810918 ... 0.5810918 0.5810918 0.5810918]\n",
            " [0.5810918 0.5810918 0.5810918 ... 0.5810918 0.5810918 0.5810918]\n",
            " ...\n",
            " [0.5810918 0.5810918 0.5810918 ... 0.5810918 0.5810918 0.5810918]\n",
            " [0.5810918 0.5810918 0.5810918 ... 0.5810918 0.5810918 0.5810918]\n",
            " [0.5810918 0.5810918 0.5810918 ... 0.5810918 0.5810918 0.5810918]], shape=(512, 128), dtype=float32) tf.Tensor(\n",
            "[[0.5810918 0.5810918 0.5810918 ... 0.5810918 0.5810918 0.5810918]\n",
            " [0.5810918 0.5810918 0.5810918 ... 0.5810918 0.5810918 0.5810918]\n",
            " [0.5810918 0.5810918 0.5810918 ... 0.5810918 0.5810918 0.5810918]\n",
            " ...\n",
            " [0.5810918 0.5810918 0.5810918 ... 0.5810918 0.5810918 0.5810918]\n",
            " [0.5810918 0.5810918 0.5810918 ... 0.5810918 0.5810918 0.5810918]\n",
            " [0.5810918 0.5810918 0.5810918 ... 0.5810918 0.5810918 0.5810918]], shape=(252, 128), dtype=float32)\n",
            "(128, 764) (512, 1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_15/kernel:0', 'dense_15/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_15/kernel:0', 'dense_15/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch 1, Batch 17/100, Loss=9.62159e-01\n",
            "(1, 764, 1)\n",
            "tf.Tensor(\n",
            "[[[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " [[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " [[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " [[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]], shape=(128, 764, 1), dtype=float32) tf.Tensor(\n",
            "[[[-0.3093486   0.31517476 -0.13651732 ... -0.13459153  0.10890739\n",
            "   -0.4133707 ]\n",
            "  [-0.3093486   0.31517476 -0.13651732 ... -0.13459153  0.10890739\n",
            "   -0.4133707 ]\n",
            "  [-0.3093486   0.31517476 -0.13651732 ... -0.13459153  0.10890739\n",
            "   -0.4133707 ]\n",
            "  ...\n",
            "  [-0.3093486   0.31517476 -0.13651732 ... -0.13459153  0.10890739\n",
            "   -0.4133707 ]\n",
            "  [-0.3093486   0.31517476 -0.13651732 ... -0.13459153  0.10890739\n",
            "   -0.4133707 ]\n",
            "  [-0.3093486   0.31517476 -0.13651732 ... -0.13459153  0.10890739\n",
            "   -0.4133707 ]]\n",
            "\n",
            " [[-0.3093486   0.31517476 -0.13651732 ... -0.13459153  0.10890739\n",
            "   -0.4133707 ]\n",
            "  [-0.3093486   0.31517476 -0.13651732 ... -0.13459153  0.10890739\n",
            "   -0.4133707 ]\n",
            "  [-0.3093486   0.31517476 -0.13651732 ... -0.13459153  0.10890739\n",
            "   -0.4133707 ]\n",
            "  ...\n",
            "  [-0.3093486   0.31517476 -0.13651732 ... -0.13459153  0.10890739\n",
            "   -0.4133707 ]\n",
            "  [-0.3093486   0.31517476 -0.13651732 ... -0.13459153  0.10890739\n",
            "   -0.4133707 ]\n",
            "  [-0.3093486   0.31517476 -0.13651732 ... -0.13459153  0.10890739\n",
            "   -0.4133707 ]]\n",
            "\n",
            " [[-0.3093486   0.31517476 -0.13651732 ... -0.13459153  0.10890739\n",
            "   -0.4133707 ]\n",
            "  [-0.3093486   0.31517476 -0.13651732 ... -0.13459153  0.10890739\n",
            "   -0.4133707 ]\n",
            "  [-0.3093486   0.31517476 -0.13651732 ... -0.13459153  0.10890739\n",
            "   -0.4133707 ]\n",
            "  ...\n",
            "  [-0.3093486   0.31517476 -0.13651732 ... -0.13459153  0.10890739\n",
            "   -0.4133707 ]\n",
            "  [-0.3093486   0.31517476 -0.13651732 ... -0.13459153  0.10890739\n",
            "   -0.4133707 ]\n",
            "  [-0.3093486   0.31517476 -0.13651732 ... -0.13459153  0.10890739\n",
            "   -0.4133707 ]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[-0.3093486   0.31517476 -0.13651732 ... -0.13459153  0.10890739\n",
            "   -0.4133707 ]\n",
            "  [-0.3093486   0.31517476 -0.13651732 ... -0.13459153  0.10890739\n",
            "   -0.4133707 ]\n",
            "  [-0.3093486   0.31517476 -0.13651732 ... -0.13459153  0.10890739\n",
            "   -0.4133707 ]\n",
            "  ...\n",
            "  [-0.3093486   0.31517476 -0.13651732 ... -0.13459153  0.10890739\n",
            "   -0.4133707 ]\n",
            "  [-0.3093486   0.31517476 -0.13651732 ... -0.13459153  0.10890739\n",
            "   -0.4133707 ]\n",
            "  [-0.3093486   0.31517476 -0.13651732 ... -0.13459153  0.10890739\n",
            "   -0.4133707 ]]\n",
            "\n",
            " [[-0.3093486   0.31517476 -0.13651732 ... -0.13459153  0.10890739\n",
            "   -0.4133707 ]\n",
            "  [-0.3093486   0.31517476 -0.13651732 ... -0.13459153  0.10890739\n",
            "   -0.4133707 ]\n",
            "  [-0.3093486   0.31517476 -0.13651732 ... -0.13459153  0.10890739\n",
            "   -0.4133707 ]\n",
            "  ...\n",
            "  [-0.3093486   0.31517476 -0.13651732 ... -0.13459153  0.10890739\n",
            "   -0.4133707 ]\n",
            "  [-0.3093486   0.31517476 -0.13651732 ... -0.13459153  0.10890739\n",
            "   -0.4133707 ]\n",
            "  [-0.3093486   0.31517476 -0.13651732 ... -0.13459153  0.10890739\n",
            "   -0.4133707 ]]\n",
            "\n",
            " [[-0.3093486   0.31517476 -0.13651732 ... -0.13459153  0.10890739\n",
            "   -0.4133707 ]\n",
            "  [-0.3093486   0.31517476 -0.13651732 ... -0.13459153  0.10890739\n",
            "   -0.4133707 ]\n",
            "  [-0.3093486   0.31517476 -0.13651732 ... -0.13459153  0.10890739\n",
            "   -0.4133707 ]\n",
            "  ...\n",
            "  [-0.3093486   0.31517476 -0.13651732 ... -0.13459153  0.10890739\n",
            "   -0.4133707 ]\n",
            "  [-0.3093486   0.31517476 -0.13651732 ... -0.13459153  0.10890739\n",
            "   -0.4133707 ]\n",
            "  [-0.3093486   0.31517476 -0.13651732 ... -0.13459153  0.10890739\n",
            "   -0.4133707 ]]], shape=(128, 764, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[0.3013146 0.3013146 0.3013146 ... 0.3013146 0.3013146 0.3013146]\n",
            " [0.3013146 0.3013146 0.3013146 ... 0.3013146 0.3013146 0.3013146]\n",
            " [0.3013146 0.3013146 0.3013146 ... 0.3013146 0.3013146 0.3013146]\n",
            " ...\n",
            " [0.3013146 0.3013146 0.3013146 ... 0.3013146 0.3013146 0.3013146]\n",
            " [0.3013146 0.3013146 0.3013146 ... 0.3013146 0.3013146 0.3013146]\n",
            " [0.3013146 0.3013146 0.3013146 ... 0.3013146 0.3013146 0.3013146]], shape=(512, 128), dtype=float32) tf.Tensor(\n",
            "[[0.3013146 0.3013146 0.3013146 ... 0.3013146 0.3013146 0.3013146]\n",
            " [0.3013146 0.3013146 0.3013146 ... 0.3013146 0.3013146 0.3013146]\n",
            " [0.3013146 0.3013146 0.3013146 ... 0.3013146 0.3013146 0.3013146]\n",
            " ...\n",
            " [0.3013146 0.3013146 0.3013146 ... 0.3013146 0.3013146 0.3013146]\n",
            " [0.3013146 0.3013146 0.3013146 ... 0.3013146 0.3013146 0.3013146]\n",
            " [0.3013146 0.3013146 0.3013146 ... 0.3013146 0.3013146 0.3013146]], shape=(252, 128), dtype=float32)\n",
            "(128, 764) (512, 1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_15/kernel:0', 'dense_15/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_15/kernel:0', 'dense_15/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch 1, Batch 18/100, Loss=4.57361e-01\n",
            "(1, 764, 1)\n",
            "tf.Tensor(\n",
            "[[[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]], shape=(128, 764, 1), dtype=float32) tf.Tensor(\n",
            "[[[-0.28427675  0.305017   -0.16079982 ... -0.07610866  0.13026492\n",
            "   -0.46983764]\n",
            "  [-0.28427675  0.305017   -0.16079982 ... -0.07610866  0.13026492\n",
            "   -0.46983764]\n",
            "  [-0.28427675  0.305017   -0.16079982 ... -0.07610866  0.13026492\n",
            "   -0.46983764]\n",
            "  ...\n",
            "  [-0.28427675  0.305017   -0.16079982 ... -0.07610866  0.13026492\n",
            "   -0.46983764]\n",
            "  [-0.28427675  0.305017   -0.16079982 ... -0.07610866  0.13026492\n",
            "   -0.46983764]\n",
            "  [-0.28427675  0.305017   -0.16079982 ... -0.07610866  0.13026492\n",
            "   -0.46983764]]\n",
            "\n",
            " [[-0.28427675  0.305017   -0.16079982 ... -0.07610866  0.13026492\n",
            "   -0.46983764]\n",
            "  [-0.28427675  0.305017   -0.16079982 ... -0.07610866  0.13026492\n",
            "   -0.46983764]\n",
            "  [-0.28427675  0.305017   -0.16079982 ... -0.07610866  0.13026492\n",
            "   -0.46983764]\n",
            "  ...\n",
            "  [-0.28427675  0.305017   -0.16079982 ... -0.07610866  0.13026492\n",
            "   -0.46983764]\n",
            "  [-0.28427675  0.305017   -0.16079982 ... -0.07610866  0.13026492\n",
            "   -0.46983764]\n",
            "  [-0.28427675  0.305017   -0.16079982 ... -0.07610866  0.13026492\n",
            "   -0.46983764]]\n",
            "\n",
            " [[-0.28427675  0.305017   -0.16079982 ... -0.07610866  0.13026492\n",
            "   -0.46983764]\n",
            "  [-0.28427675  0.305017   -0.16079982 ... -0.07610866  0.13026492\n",
            "   -0.46983764]\n",
            "  [-0.28427675  0.305017   -0.16079982 ... -0.07610866  0.13026492\n",
            "   -0.46983764]\n",
            "  ...\n",
            "  [-0.28427675  0.305017   -0.16079982 ... -0.07610866  0.13026492\n",
            "   -0.46983764]\n",
            "  [-0.28427675  0.305017   -0.16079982 ... -0.07610866  0.13026492\n",
            "   -0.46983764]\n",
            "  [-0.28427675  0.305017   -0.16079982 ... -0.07610866  0.13026492\n",
            "   -0.46983764]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[-0.28427675  0.305017   -0.16079982 ... -0.07610866  0.13026492\n",
            "   -0.46983764]\n",
            "  [-0.28427675  0.305017   -0.16079982 ... -0.07610866  0.13026492\n",
            "   -0.46983764]\n",
            "  [-0.28427675  0.305017   -0.16079982 ... -0.07610866  0.13026492\n",
            "   -0.46983764]\n",
            "  ...\n",
            "  [-0.28427675  0.305017   -0.16079982 ... -0.07610866  0.13026492\n",
            "   -0.46983764]\n",
            "  [-0.28427675  0.305017   -0.16079982 ... -0.07610866  0.13026492\n",
            "   -0.46983764]\n",
            "  [-0.28427675  0.305017   -0.16079982 ... -0.07610866  0.13026492\n",
            "   -0.46983764]]\n",
            "\n",
            " [[-0.28427675  0.305017   -0.16079982 ... -0.07610866  0.13026492\n",
            "   -0.46983764]\n",
            "  [-0.28427675  0.305017   -0.16079982 ... -0.07610866  0.13026492\n",
            "   -0.46983764]\n",
            "  [-0.28427675  0.305017   -0.16079982 ... -0.07610866  0.13026492\n",
            "   -0.46983764]\n",
            "  ...\n",
            "  [-0.28427675  0.305017   -0.16079982 ... -0.07610866  0.13026492\n",
            "   -0.46983764]\n",
            "  [-0.28427675  0.305017   -0.16079982 ... -0.07610866  0.13026492\n",
            "   -0.46983764]\n",
            "  [-0.28427675  0.305017   -0.16079982 ... -0.07610866  0.13026492\n",
            "   -0.46983764]]\n",
            "\n",
            " [[-0.28427675  0.305017   -0.16079982 ... -0.07610866  0.13026492\n",
            "   -0.46983764]\n",
            "  [-0.28427675  0.305017   -0.16079982 ... -0.07610866  0.13026492\n",
            "   -0.46983764]\n",
            "  [-0.28427675  0.305017   -0.16079982 ... -0.07610866  0.13026492\n",
            "   -0.46983764]\n",
            "  ...\n",
            "  [-0.28427675  0.305017   -0.16079982 ... -0.07610866  0.13026492\n",
            "   -0.46983764]\n",
            "  [-0.28427675  0.305017   -0.16079982 ... -0.07610866  0.13026492\n",
            "   -0.46983764]\n",
            "  [-0.28427675  0.305017   -0.16079982 ... -0.07610866  0.13026492\n",
            "   -0.46983764]]], shape=(128, 764, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.01317184 -0.01317184 -0.01317184 ... -0.01317184 -0.01317184\n",
            "  -0.01317184]\n",
            " [-0.01317184 -0.01317184 -0.01317184 ... -0.01317184 -0.01317184\n",
            "  -0.01317184]\n",
            " [-0.01317184 -0.01317184 -0.01317184 ... -0.01317184 -0.01317184\n",
            "  -0.01317184]\n",
            " ...\n",
            " [-0.01317184 -0.01317184 -0.01317184 ... -0.01317184 -0.01317184\n",
            "  -0.01317184]\n",
            " [-0.01317184 -0.01317184 -0.01317184 ... -0.01317184 -0.01317184\n",
            "  -0.01317184]\n",
            " [-0.01317184 -0.01317184 -0.01317184 ... -0.01317184 -0.01317184\n",
            "  -0.01317184]], shape=(512, 128), dtype=float32) tf.Tensor(\n",
            "[[-0.01317184 -0.01317184 -0.01317184 ... -0.01317184 -0.01317184\n",
            "  -0.01317184]\n",
            " [-0.01317184 -0.01317184 -0.01317184 ... -0.01317184 -0.01317184\n",
            "  -0.01317184]\n",
            " [-0.01317184 -0.01317184 -0.01317184 ... -0.01317184 -0.01317184\n",
            "  -0.01317184]\n",
            " ...\n",
            " [-0.01317184 -0.01317184 -0.01317184 ... -0.01317184 -0.01317184\n",
            "  -0.01317184]\n",
            " [-0.01317184 -0.01317184 -0.01317184 ... -0.01317184 -0.01317184\n",
            "  -0.01317184]\n",
            " [-0.01317184 -0.01317184 -0.01317184 ... -0.01317184 -0.01317184\n",
            "  -0.01317184]], shape=(252, 128), dtype=float32)\n",
            "(128, 764) (512, 1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_15/kernel:0', 'dense_15/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_15/kernel:0', 'dense_15/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch 1, Batch 19/100, Loss=2.76470e-01\n",
            "(1, 764, 1)\n",
            "tf.Tensor(\n",
            "[[[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " [[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " [[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]], shape=(128, 764, 1), dtype=float32) tf.Tensor(\n",
            "[[[-0.26134172  0.29541707 -0.18292974 ... -0.02335597  0.14891227\n",
            "   -0.5197125 ]\n",
            "  [-0.26134172  0.29541707 -0.18292974 ... -0.02335597  0.14891227\n",
            "   -0.5197125 ]\n",
            "  [-0.26134172  0.29541707 -0.18292974 ... -0.02335597  0.14891227\n",
            "   -0.5197125 ]\n",
            "  ...\n",
            "  [-0.26134172  0.29541707 -0.18292974 ... -0.02335597  0.14891227\n",
            "   -0.5197125 ]\n",
            "  [-0.26134172  0.29541707 -0.18292974 ... -0.02335597  0.14891227\n",
            "   -0.5197125 ]\n",
            "  [-0.26134172  0.29541707 -0.18292974 ... -0.02335597  0.14891227\n",
            "   -0.5197125 ]]\n",
            "\n",
            " [[-0.26134172  0.29541707 -0.18292974 ... -0.02335597  0.14891227\n",
            "   -0.5197125 ]\n",
            "  [-0.26134172  0.29541707 -0.18292974 ... -0.02335597  0.14891227\n",
            "   -0.5197125 ]\n",
            "  [-0.26134172  0.29541707 -0.18292974 ... -0.02335597  0.14891227\n",
            "   -0.5197125 ]\n",
            "  ...\n",
            "  [-0.26134172  0.29541707 -0.18292974 ... -0.02335597  0.14891227\n",
            "   -0.5197125 ]\n",
            "  [-0.26134172  0.29541707 -0.18292974 ... -0.02335597  0.14891227\n",
            "   -0.5197125 ]\n",
            "  [-0.26134172  0.29541707 -0.18292974 ... -0.02335597  0.14891227\n",
            "   -0.5197125 ]]\n",
            "\n",
            " [[-0.26134172  0.29541707 -0.18292974 ... -0.02335597  0.14891227\n",
            "   -0.5197125 ]\n",
            "  [-0.26134172  0.29541707 -0.18292974 ... -0.02335597  0.14891227\n",
            "   -0.5197125 ]\n",
            "  [-0.26134172  0.29541707 -0.18292974 ... -0.02335597  0.14891227\n",
            "   -0.5197125 ]\n",
            "  ...\n",
            "  [-0.26134172  0.29541707 -0.18292974 ... -0.02335597  0.14891227\n",
            "   -0.5197125 ]\n",
            "  [-0.26134172  0.29541707 -0.18292974 ... -0.02335597  0.14891227\n",
            "   -0.5197125 ]\n",
            "  [-0.26134172  0.29541707 -0.18292974 ... -0.02335597  0.14891227\n",
            "   -0.5197125 ]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[-0.26134172  0.29541707 -0.18292974 ... -0.02335597  0.14891227\n",
            "   -0.5197125 ]\n",
            "  [-0.26134172  0.29541707 -0.18292974 ... -0.02335597  0.14891227\n",
            "   -0.5197125 ]\n",
            "  [-0.26134172  0.29541707 -0.18292974 ... -0.02335597  0.14891227\n",
            "   -0.5197125 ]\n",
            "  ...\n",
            "  [-0.26134172  0.29541707 -0.18292974 ... -0.02335597  0.14891227\n",
            "   -0.5197125 ]\n",
            "  [-0.26134172  0.29541707 -0.18292974 ... -0.02335597  0.14891227\n",
            "   -0.5197125 ]\n",
            "  [-0.26134172  0.29541707 -0.18292974 ... -0.02335597  0.14891227\n",
            "   -0.5197125 ]]\n",
            "\n",
            " [[-0.26134172  0.29541707 -0.18292974 ... -0.02335597  0.14891227\n",
            "   -0.5197125 ]\n",
            "  [-0.26134172  0.29541707 -0.18292974 ... -0.02335597  0.14891227\n",
            "   -0.5197125 ]\n",
            "  [-0.26134172  0.29541707 -0.18292974 ... -0.02335597  0.14891227\n",
            "   -0.5197125 ]\n",
            "  ...\n",
            "  [-0.26134172  0.29541707 -0.18292974 ... -0.02335597  0.14891227\n",
            "   -0.5197125 ]\n",
            "  [-0.26134172  0.29541707 -0.18292974 ... -0.02335597  0.14891227\n",
            "   -0.5197125 ]\n",
            "  [-0.26134172  0.29541707 -0.18292974 ... -0.02335597  0.14891227\n",
            "   -0.5197125 ]]\n",
            "\n",
            " [[-0.26134172  0.29541707 -0.18292974 ... -0.02335597  0.14891227\n",
            "   -0.5197125 ]\n",
            "  [-0.26134172  0.29541707 -0.18292974 ... -0.02335597  0.14891227\n",
            "   -0.5197125 ]\n",
            "  [-0.26134172  0.29541707 -0.18292974 ... -0.02335597  0.14891227\n",
            "   -0.5197125 ]\n",
            "  ...\n",
            "  [-0.26134172  0.29541707 -0.18292974 ... -0.02335597  0.14891227\n",
            "   -0.5197125 ]\n",
            "  [-0.26134172  0.29541707 -0.18292974 ... -0.02335597  0.14891227\n",
            "   -0.5197125 ]\n",
            "  [-0.26134172  0.29541707 -0.18292974 ... -0.02335597  0.14891227\n",
            "   -0.5197125 ]]], shape=(128, 764, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.29400396 -0.29400396 -0.29400396 ... -0.29400396 -0.29400396\n",
            "  -0.29400396]\n",
            " [-0.29400396 -0.29400396 -0.29400396 ... -0.29400396 -0.29400396\n",
            "  -0.29400396]\n",
            " [-0.29400396 -0.29400396 -0.29400396 ... -0.29400396 -0.29400396\n",
            "  -0.29400396]\n",
            " ...\n",
            " [-0.29400396 -0.29400396 -0.29400396 ... -0.29400396 -0.29400396\n",
            "  -0.29400396]\n",
            " [-0.29400396 -0.29400396 -0.29400396 ... -0.29400396 -0.29400396\n",
            "  -0.29400396]\n",
            " [-0.29400396 -0.29400396 -0.29400396 ... -0.29400396 -0.29400396\n",
            "  -0.29400396]], shape=(512, 128), dtype=float32) tf.Tensor(\n",
            "[[-0.29400396 -0.29400396 -0.29400396 ... -0.29400396 -0.29400396\n",
            "  -0.29400396]\n",
            " [-0.29400396 -0.29400396 -0.29400396 ... -0.29400396 -0.29400396\n",
            "  -0.29400396]\n",
            " [-0.29400396 -0.29400396 -0.29400396 ... -0.29400396 -0.29400396\n",
            "  -0.29400396]\n",
            " ...\n",
            " [-0.29400396 -0.29400396 -0.29400396 ... -0.29400396 -0.29400396\n",
            "  -0.29400396]\n",
            " [-0.29400396 -0.29400396 -0.29400396 ... -0.29400396 -0.29400396\n",
            "  -0.29400396]\n",
            " [-0.29400396 -0.29400396 -0.29400396 ... -0.29400396 -0.29400396\n",
            "  -0.29400396]], shape=(252, 128), dtype=float32)\n",
            "(128, 764) (512, 1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_15/kernel:0', 'dense_15/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_15/kernel:0', 'dense_15/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch 1, Batch 20/100, Loss=4.61569e-01\n",
            "(1, 764, 1)\n",
            "tf.Tensor(\n",
            "[[[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " [[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " [[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]], shape=(128, 764, 1), dtype=float32) tf.Tensor(\n",
            "[[[-0.24381539  0.28898016 -0.197253   ...  0.01246506  0.16105413\n",
            "   -0.5515465 ]\n",
            "  [-0.24381539  0.28898016 -0.197253   ...  0.01246506  0.16105413\n",
            "   -0.5515465 ]\n",
            "  [-0.24381539  0.28898016 -0.197253   ...  0.01246506  0.16105413\n",
            "   -0.5515465 ]\n",
            "  ...\n",
            "  [-0.24381539  0.28898016 -0.197253   ...  0.01246506  0.16105413\n",
            "   -0.5515465 ]\n",
            "  [-0.24381539  0.28898016 -0.197253   ...  0.01246506  0.16105413\n",
            "   -0.5515465 ]\n",
            "  [-0.24381539  0.28898016 -0.197253   ...  0.01246506  0.16105413\n",
            "   -0.5515465 ]]\n",
            "\n",
            " [[-0.24381539  0.28898016 -0.197253   ...  0.01246506  0.16105413\n",
            "   -0.5515465 ]\n",
            "  [-0.24381539  0.28898016 -0.197253   ...  0.01246506  0.16105413\n",
            "   -0.5515465 ]\n",
            "  [-0.24381539  0.28898016 -0.197253   ...  0.01246506  0.16105413\n",
            "   -0.5515465 ]\n",
            "  ...\n",
            "  [-0.24381539  0.28898016 -0.197253   ...  0.01246506  0.16105413\n",
            "   -0.5515465 ]\n",
            "  [-0.24381539  0.28898016 -0.197253   ...  0.01246506  0.16105413\n",
            "   -0.5515465 ]\n",
            "  [-0.24381539  0.28898016 -0.197253   ...  0.01246506  0.16105413\n",
            "   -0.5515465 ]]\n",
            "\n",
            " [[-0.24381539  0.28898016 -0.197253   ...  0.01246506  0.16105413\n",
            "   -0.5515465 ]\n",
            "  [-0.24381539  0.28898016 -0.197253   ...  0.01246506  0.16105413\n",
            "   -0.5515465 ]\n",
            "  [-0.24381539  0.28898016 -0.197253   ...  0.01246506  0.16105413\n",
            "   -0.5515465 ]\n",
            "  ...\n",
            "  [-0.24381539  0.28898016 -0.197253   ...  0.01246506  0.16105413\n",
            "   -0.5515465 ]\n",
            "  [-0.24381539  0.28898016 -0.197253   ...  0.01246506  0.16105413\n",
            "   -0.5515465 ]\n",
            "  [-0.24381539  0.28898016 -0.197253   ...  0.01246506  0.16105413\n",
            "   -0.5515465 ]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[-0.24381539  0.28898016 -0.197253   ...  0.01246506  0.16105413\n",
            "   -0.5515465 ]\n",
            "  [-0.24381539  0.28898016 -0.197253   ...  0.01246506  0.16105413\n",
            "   -0.5515465 ]\n",
            "  [-0.24381539  0.28898016 -0.197253   ...  0.01246506  0.16105413\n",
            "   -0.5515465 ]\n",
            "  ...\n",
            "  [-0.24381539  0.28898016 -0.197253   ...  0.01246506  0.16105413\n",
            "   -0.5515465 ]\n",
            "  [-0.24381539  0.28898016 -0.197253   ...  0.01246506  0.16105413\n",
            "   -0.5515465 ]\n",
            "  [-0.24381539  0.28898016 -0.197253   ...  0.01246506  0.16105413\n",
            "   -0.5515465 ]]\n",
            "\n",
            " [[-0.24381539  0.28898016 -0.197253   ...  0.01246506  0.16105413\n",
            "   -0.5515465 ]\n",
            "  [-0.24381539  0.28898016 -0.197253   ...  0.01246506  0.16105413\n",
            "   -0.5515465 ]\n",
            "  [-0.24381539  0.28898016 -0.197253   ...  0.01246506  0.16105413\n",
            "   -0.5515465 ]\n",
            "  ...\n",
            "  [-0.24381539  0.28898016 -0.197253   ...  0.01246506  0.16105413\n",
            "   -0.5515465 ]\n",
            "  [-0.24381539  0.28898016 -0.197253   ...  0.01246506  0.16105413\n",
            "   -0.5515465 ]\n",
            "  [-0.24381539  0.28898016 -0.197253   ...  0.01246506  0.16105413\n",
            "   -0.5515465 ]]\n",
            "\n",
            " [[-0.24381539  0.28898016 -0.197253   ...  0.01246506  0.16105413\n",
            "   -0.5515465 ]\n",
            "  [-0.24381539  0.28898016 -0.197253   ...  0.01246506  0.16105413\n",
            "   -0.5515465 ]\n",
            "  [-0.24381539  0.28898016 -0.197253   ...  0.01246506  0.16105413\n",
            "   -0.5515465 ]\n",
            "  ...\n",
            "  [-0.24381539  0.28898016 -0.197253   ...  0.01246506  0.16105413\n",
            "   -0.5515465 ]\n",
            "  [-0.24381539  0.28898016 -0.197253   ...  0.01246506  0.16105413\n",
            "   -0.5515465 ]\n",
            "  [-0.24381539  0.28898016 -0.197253   ...  0.01246506  0.16105413\n",
            "   -0.5515465 ]]], shape=(128, 764, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.4827478 -0.4827478 -0.4827478 ... -0.4827478 -0.4827478 -0.4827478]\n",
            " [-0.4827478 -0.4827478 -0.4827478 ... -0.4827478 -0.4827478 -0.4827478]\n",
            " [-0.4827478 -0.4827478 -0.4827478 ... -0.4827478 -0.4827478 -0.4827478]\n",
            " ...\n",
            " [-0.4827478 -0.4827478 -0.4827478 ... -0.4827478 -0.4827478 -0.4827478]\n",
            " [-0.4827478 -0.4827478 -0.4827478 ... -0.4827478 -0.4827478 -0.4827478]\n",
            " [-0.4827478 -0.4827478 -0.4827478 ... -0.4827478 -0.4827478 -0.4827478]], shape=(512, 128), dtype=float32) tf.Tensor(\n",
            "[[-0.4827478 -0.4827478 -0.4827478 ... -0.4827478 -0.4827478 -0.4827478]\n",
            " [-0.4827478 -0.4827478 -0.4827478 ... -0.4827478 -0.4827478 -0.4827478]\n",
            " [-0.4827478 -0.4827478 -0.4827478 ... -0.4827478 -0.4827478 -0.4827478]\n",
            " ...\n",
            " [-0.4827478 -0.4827478 -0.4827478 ... -0.4827478 -0.4827478 -0.4827478]\n",
            " [-0.4827478 -0.4827478 -0.4827478 ... -0.4827478 -0.4827478 -0.4827478]\n",
            " [-0.4827478 -0.4827478 -0.4827478 ... -0.4827478 -0.4827478 -0.4827478]], shape=(252, 128), dtype=float32)\n",
            "(128, 764) (512, 1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_15/kernel:0', 'dense_15/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_15/kernel:0', 'dense_15/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch 1, Batch 21/100, Loss=6.74045e-01\n",
            "(1, 764, 1)\n",
            "tf.Tensor(\n",
            "[[[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]], shape=(128, 764, 1), dtype=float32) tf.Tensor(\n",
            "[[[-0.2319205   0.2864754  -0.2013859  ...  0.0262132   0.16505998\n",
            "   -0.5611095 ]\n",
            "  [-0.2319205   0.2864754  -0.2013859  ...  0.0262132   0.16505998\n",
            "   -0.5611095 ]\n",
            "  [-0.2319205   0.2864754  -0.2013859  ...  0.0262132   0.16505998\n",
            "   -0.5611095 ]\n",
            "  ...\n",
            "  [-0.2319205   0.2864754  -0.2013859  ...  0.0262132   0.16505998\n",
            "   -0.5611095 ]\n",
            "  [-0.2319205   0.2864754  -0.2013859  ...  0.0262132   0.16505998\n",
            "   -0.5611095 ]\n",
            "  [-0.2319205   0.2864754  -0.2013859  ...  0.0262132   0.16505998\n",
            "   -0.5611095 ]]\n",
            "\n",
            " [[-0.2319205   0.2864754  -0.2013859  ...  0.0262132   0.16505998\n",
            "   -0.5611095 ]\n",
            "  [-0.2319205   0.2864754  -0.2013859  ...  0.0262132   0.16505998\n",
            "   -0.5611095 ]\n",
            "  [-0.2319205   0.2864754  -0.2013859  ...  0.0262132   0.16505998\n",
            "   -0.5611095 ]\n",
            "  ...\n",
            "  [-0.2319205   0.2864754  -0.2013859  ...  0.0262132   0.16505998\n",
            "   -0.5611095 ]\n",
            "  [-0.2319205   0.2864754  -0.2013859  ...  0.0262132   0.16505998\n",
            "   -0.5611095 ]\n",
            "  [-0.2319205   0.2864754  -0.2013859  ...  0.0262132   0.16505998\n",
            "   -0.5611095 ]]\n",
            "\n",
            " [[-0.2319205   0.2864754  -0.2013859  ...  0.0262132   0.16505998\n",
            "   -0.5611095 ]\n",
            "  [-0.2319205   0.2864754  -0.2013859  ...  0.0262132   0.16505998\n",
            "   -0.5611095 ]\n",
            "  [-0.2319205   0.2864754  -0.2013859  ...  0.0262132   0.16505998\n",
            "   -0.5611095 ]\n",
            "  ...\n",
            "  [-0.2319205   0.2864754  -0.2013859  ...  0.0262132   0.16505998\n",
            "   -0.5611095 ]\n",
            "  [-0.2319205   0.2864754  -0.2013859  ...  0.0262132   0.16505998\n",
            "   -0.5611095 ]\n",
            "  [-0.2319205   0.2864754  -0.2013859  ...  0.0262132   0.16505998\n",
            "   -0.5611095 ]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[-0.2319205   0.2864754  -0.2013859  ...  0.0262132   0.16505998\n",
            "   -0.5611095 ]\n",
            "  [-0.2319205   0.2864754  -0.2013859  ...  0.0262132   0.16505998\n",
            "   -0.5611095 ]\n",
            "  [-0.2319205   0.2864754  -0.2013859  ...  0.0262132   0.16505998\n",
            "   -0.5611095 ]\n",
            "  ...\n",
            "  [-0.2319205   0.2864754  -0.2013859  ...  0.0262132   0.16505998\n",
            "   -0.5611095 ]\n",
            "  [-0.2319205   0.2864754  -0.2013859  ...  0.0262132   0.16505998\n",
            "   -0.5611095 ]\n",
            "  [-0.2319205   0.2864754  -0.2013859  ...  0.0262132   0.16505998\n",
            "   -0.5611095 ]]\n",
            "\n",
            " [[-0.2319205   0.2864754  -0.2013859  ...  0.0262132   0.16505998\n",
            "   -0.5611095 ]\n",
            "  [-0.2319205   0.2864754  -0.2013859  ...  0.0262132   0.16505998\n",
            "   -0.5611095 ]\n",
            "  [-0.2319205   0.2864754  -0.2013859  ...  0.0262132   0.16505998\n",
            "   -0.5611095 ]\n",
            "  ...\n",
            "  [-0.2319205   0.2864754  -0.2013859  ...  0.0262132   0.16505998\n",
            "   -0.5611095 ]\n",
            "  [-0.2319205   0.2864754  -0.2013859  ...  0.0262132   0.16505998\n",
            "   -0.5611095 ]\n",
            "  [-0.2319205   0.2864754  -0.2013859  ...  0.0262132   0.16505998\n",
            "   -0.5611095 ]]\n",
            "\n",
            " [[-0.2319205   0.2864754  -0.2013859  ...  0.0262132   0.16505998\n",
            "   -0.5611095 ]\n",
            "  [-0.2319205   0.2864754  -0.2013859  ...  0.0262132   0.16505998\n",
            "   -0.5611095 ]\n",
            "  [-0.2319205   0.2864754  -0.2013859  ...  0.0262132   0.16505998\n",
            "   -0.5611095 ]\n",
            "  ...\n",
            "  [-0.2319205   0.2864754  -0.2013859  ...  0.0262132   0.16505998\n",
            "   -0.5611095 ]\n",
            "  [-0.2319205   0.2864754  -0.2013859  ...  0.0262132   0.16505998\n",
            "   -0.5611095 ]\n",
            "  [-0.2319205   0.2864754  -0.2013859  ...  0.0262132   0.16505998\n",
            "   -0.5611095 ]]], shape=(128, 764, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.5564576 -0.5564576 -0.5564576 ... -0.5564576 -0.5564576 -0.5564576]\n",
            " [-0.5564576 -0.5564576 -0.5564576 ... -0.5564576 -0.5564576 -0.5564576]\n",
            " [-0.5564576 -0.5564576 -0.5564576 ... -0.5564576 -0.5564576 -0.5564576]\n",
            " ...\n",
            " [-0.5564576 -0.5564576 -0.5564576 ... -0.5564576 -0.5564576 -0.5564576]\n",
            " [-0.5564576 -0.5564576 -0.5564576 ... -0.5564576 -0.5564576 -0.5564576]\n",
            " [-0.5564576 -0.5564576 -0.5564576 ... -0.5564576 -0.5564576 -0.5564576]], shape=(512, 128), dtype=float32) tf.Tensor(\n",
            "[[-0.5564576 -0.5564576 -0.5564576 ... -0.5564576 -0.5564576 -0.5564576]\n",
            " [-0.5564576 -0.5564576 -0.5564576 ... -0.5564576 -0.5564576 -0.5564576]\n",
            " [-0.5564576 -0.5564576 -0.5564576 ... -0.5564576 -0.5564576 -0.5564576]\n",
            " ...\n",
            " [-0.5564576 -0.5564576 -0.5564576 ... -0.5564576 -0.5564576 -0.5564576]\n",
            " [-0.5564576 -0.5564576 -0.5564576 ... -0.5564576 -0.5564576 -0.5564576]\n",
            " [-0.5564576 -0.5564576 -0.5564576 ... -0.5564576 -0.5564576 -0.5564576]], shape=(252, 128), dtype=float32)\n",
            "(128, 764) (512, 1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_15/kernel:0', 'dense_15/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_15/kernel:0', 'dense_15/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch 1, Batch 22/100, Loss=7.91480e-01\n",
            "(1, 764, 1)\n",
            "tf.Tensor(\n",
            "[[[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]], shape=(128, 764, 1), dtype=float32) tf.Tensor(\n",
            "[[[-0.22435395  0.28766954 -0.19471537 ...  0.01636281  0.15980837\n",
            "   -0.5476995 ]\n",
            "  [-0.22435395  0.28766954 -0.19471537 ...  0.01636281  0.15980837\n",
            "   -0.5476995 ]\n",
            "  [-0.22435395  0.28766954 -0.19471537 ...  0.01636281  0.15980837\n",
            "   -0.5476995 ]\n",
            "  ...\n",
            "  [-0.22435395  0.28766954 -0.19471537 ...  0.01636281  0.15980837\n",
            "   -0.5476995 ]\n",
            "  [-0.22435395  0.28766954 -0.19471537 ...  0.01636281  0.15980837\n",
            "   -0.5476995 ]\n",
            "  [-0.22435395  0.28766954 -0.19471537 ...  0.01636281  0.15980837\n",
            "   -0.5476995 ]]\n",
            "\n",
            " [[-0.22435395  0.28766954 -0.19471537 ...  0.01636281  0.15980837\n",
            "   -0.5476995 ]\n",
            "  [-0.22435395  0.28766954 -0.19471537 ...  0.01636281  0.15980837\n",
            "   -0.5476995 ]\n",
            "  [-0.22435395  0.28766954 -0.19471537 ...  0.01636281  0.15980837\n",
            "   -0.5476995 ]\n",
            "  ...\n",
            "  [-0.22435395  0.28766954 -0.19471537 ...  0.01636281  0.15980837\n",
            "   -0.5476995 ]\n",
            "  [-0.22435395  0.28766954 -0.19471537 ...  0.01636281  0.15980837\n",
            "   -0.5476995 ]\n",
            "  [-0.22435395  0.28766954 -0.19471537 ...  0.01636281  0.15980837\n",
            "   -0.5476995 ]]\n",
            "\n",
            " [[-0.22435395  0.28766954 -0.19471537 ...  0.01636281  0.15980837\n",
            "   -0.5476995 ]\n",
            "  [-0.22435395  0.28766954 -0.19471537 ...  0.01636281  0.15980837\n",
            "   -0.5476995 ]\n",
            "  [-0.22435395  0.28766954 -0.19471537 ...  0.01636281  0.15980837\n",
            "   -0.5476995 ]\n",
            "  ...\n",
            "  [-0.22435395  0.28766954 -0.19471537 ...  0.01636281  0.15980837\n",
            "   -0.5476995 ]\n",
            "  [-0.22435395  0.28766954 -0.19471537 ...  0.01636281  0.15980837\n",
            "   -0.5476995 ]\n",
            "  [-0.22435395  0.28766954 -0.19471537 ...  0.01636281  0.15980837\n",
            "   -0.5476995 ]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[-0.22435395  0.28766954 -0.19471537 ...  0.01636281  0.15980837\n",
            "   -0.5476995 ]\n",
            "  [-0.22435395  0.28766954 -0.19471537 ...  0.01636281  0.15980837\n",
            "   -0.5476995 ]\n",
            "  [-0.22435395  0.28766954 -0.19471537 ...  0.01636281  0.15980837\n",
            "   -0.5476995 ]\n",
            "  ...\n",
            "  [-0.22435395  0.28766954 -0.19471537 ...  0.01636281  0.15980837\n",
            "   -0.5476995 ]\n",
            "  [-0.22435395  0.28766954 -0.19471537 ...  0.01636281  0.15980837\n",
            "   -0.5476995 ]\n",
            "  [-0.22435395  0.28766954 -0.19471537 ...  0.01636281  0.15980837\n",
            "   -0.5476995 ]]\n",
            "\n",
            " [[-0.22435395  0.28766954 -0.19471537 ...  0.01636281  0.15980837\n",
            "   -0.5476995 ]\n",
            "  [-0.22435395  0.28766954 -0.19471537 ...  0.01636281  0.15980837\n",
            "   -0.5476995 ]\n",
            "  [-0.22435395  0.28766954 -0.19471537 ...  0.01636281  0.15980837\n",
            "   -0.5476995 ]\n",
            "  ...\n",
            "  [-0.22435395  0.28766954 -0.19471537 ...  0.01636281  0.15980837\n",
            "   -0.5476995 ]\n",
            "  [-0.22435395  0.28766954 -0.19471537 ...  0.01636281  0.15980837\n",
            "   -0.5476995 ]\n",
            "  [-0.22435395  0.28766954 -0.19471537 ...  0.01636281  0.15980837\n",
            "   -0.5476995 ]]\n",
            "\n",
            " [[-0.22435395  0.28766954 -0.19471537 ...  0.01636281  0.15980837\n",
            "   -0.5476995 ]\n",
            "  [-0.22435395  0.28766954 -0.19471537 ...  0.01636281  0.15980837\n",
            "   -0.5476995 ]\n",
            "  [-0.22435395  0.28766954 -0.19471537 ...  0.01636281  0.15980837\n",
            "   -0.5476995 ]\n",
            "  ...\n",
            "  [-0.22435395  0.28766954 -0.19471537 ...  0.01636281  0.15980837\n",
            "   -0.5476995 ]\n",
            "  [-0.22435395  0.28766954 -0.19471537 ...  0.01636281  0.15980837\n",
            "   -0.5476995 ]\n",
            "  [-0.22435395  0.28766954 -0.19471537 ...  0.01636281  0.15980837\n",
            "   -0.5476995 ]]], shape=(128, 764, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.5102227 -0.5102227 -0.5102227 ... -0.5102227 -0.5102227 -0.5102227]\n",
            " [-0.5102227 -0.5102227 -0.5102227 ... -0.5102227 -0.5102227 -0.5102227]\n",
            " [-0.5102227 -0.5102227 -0.5102227 ... -0.5102227 -0.5102227 -0.5102227]\n",
            " ...\n",
            " [-0.5102227 -0.5102227 -0.5102227 ... -0.5102227 -0.5102227 -0.5102227]\n",
            " [-0.5102227 -0.5102227 -0.5102227 ... -0.5102227 -0.5102227 -0.5102227]\n",
            " [-0.5102227 -0.5102227 -0.5102227 ... -0.5102227 -0.5102227 -0.5102227]], shape=(512, 128), dtype=float32) tf.Tensor(\n",
            "[[-0.5102227 -0.5102227 -0.5102227 ... -0.5102227 -0.5102227 -0.5102227]\n",
            " [-0.5102227 -0.5102227 -0.5102227 ... -0.5102227 -0.5102227 -0.5102227]\n",
            " [-0.5102227 -0.5102227 -0.5102227 ... -0.5102227 -0.5102227 -0.5102227]\n",
            " ...\n",
            " [-0.5102227 -0.5102227 -0.5102227 ... -0.5102227 -0.5102227 -0.5102227]\n",
            " [-0.5102227 -0.5102227 -0.5102227 ... -0.5102227 -0.5102227 -0.5102227]\n",
            " [-0.5102227 -0.5102227 -0.5102227 ... -0.5102227 -0.5102227 -0.5102227]], shape=(252, 128), dtype=float32)\n",
            "(128, 764) (512, 1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_15/kernel:0', 'dense_15/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_15/kernel:0', 'dense_15/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch 1, Batch 23/100, Loss=5.66848e-01\n",
            "(1, 764, 1)\n",
            "tf.Tensor(\n",
            "[[[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " [[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " [[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]], shape=(128, 764, 1), dtype=float32) tf.Tensor(\n",
            "[[[-0.21865806  0.29090524 -0.18036889 ... -0.01058715  0.1468462\n",
            "   -0.5180583 ]\n",
            "  [-0.21865806  0.29090524 -0.18036889 ... -0.01058715  0.1468462\n",
            "   -0.5180583 ]\n",
            "  [-0.21865806  0.29090524 -0.18036889 ... -0.01058715  0.1468462\n",
            "   -0.5180583 ]\n",
            "  ...\n",
            "  [-0.21865806  0.29090524 -0.18036889 ... -0.01058715  0.1468462\n",
            "   -0.5180583 ]\n",
            "  [-0.21865806  0.29090524 -0.18036889 ... -0.01058715  0.1468462\n",
            "   -0.5180583 ]\n",
            "  [-0.21865806  0.29090524 -0.18036889 ... -0.01058715  0.1468462\n",
            "   -0.5180583 ]]\n",
            "\n",
            " [[-0.21865806  0.29090524 -0.18036889 ... -0.01058715  0.1468462\n",
            "   -0.5180583 ]\n",
            "  [-0.21865806  0.29090524 -0.18036889 ... -0.01058715  0.1468462\n",
            "   -0.5180583 ]\n",
            "  [-0.21865806  0.29090524 -0.18036889 ... -0.01058715  0.1468462\n",
            "   -0.5180583 ]\n",
            "  ...\n",
            "  [-0.21865806  0.29090524 -0.18036889 ... -0.01058715  0.1468462\n",
            "   -0.5180583 ]\n",
            "  [-0.21865806  0.29090524 -0.18036889 ... -0.01058715  0.1468462\n",
            "   -0.5180583 ]\n",
            "  [-0.21865806  0.29090524 -0.18036889 ... -0.01058715  0.1468462\n",
            "   -0.5180583 ]]\n",
            "\n",
            " [[-0.21865806  0.29090524 -0.18036889 ... -0.01058715  0.1468462\n",
            "   -0.5180583 ]\n",
            "  [-0.21865806  0.29090524 -0.18036889 ... -0.01058715  0.1468462\n",
            "   -0.5180583 ]\n",
            "  [-0.21865806  0.29090524 -0.18036889 ... -0.01058715  0.1468462\n",
            "   -0.5180583 ]\n",
            "  ...\n",
            "  [-0.21865806  0.29090524 -0.18036889 ... -0.01058715  0.1468462\n",
            "   -0.5180583 ]\n",
            "  [-0.21865806  0.29090524 -0.18036889 ... -0.01058715  0.1468462\n",
            "   -0.5180583 ]\n",
            "  [-0.21865806  0.29090524 -0.18036889 ... -0.01058715  0.1468462\n",
            "   -0.5180583 ]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[-0.21865806  0.29090524 -0.18036889 ... -0.01058715  0.1468462\n",
            "   -0.5180583 ]\n",
            "  [-0.21865806  0.29090524 -0.18036889 ... -0.01058715  0.1468462\n",
            "   -0.5180583 ]\n",
            "  [-0.21865806  0.29090524 -0.18036889 ... -0.01058715  0.1468462\n",
            "   -0.5180583 ]\n",
            "  ...\n",
            "  [-0.21865806  0.29090524 -0.18036889 ... -0.01058715  0.1468462\n",
            "   -0.5180583 ]\n",
            "  [-0.21865806  0.29090524 -0.18036889 ... -0.01058715  0.1468462\n",
            "   -0.5180583 ]\n",
            "  [-0.21865806  0.29090524 -0.18036889 ... -0.01058715  0.1468462\n",
            "   -0.5180583 ]]\n",
            "\n",
            " [[-0.21865806  0.29090524 -0.18036889 ... -0.01058715  0.1468462\n",
            "   -0.5180583 ]\n",
            "  [-0.21865806  0.29090524 -0.18036889 ... -0.01058715  0.1468462\n",
            "   -0.5180583 ]\n",
            "  [-0.21865806  0.29090524 -0.18036889 ... -0.01058715  0.1468462\n",
            "   -0.5180583 ]\n",
            "  ...\n",
            "  [-0.21865806  0.29090524 -0.18036889 ... -0.01058715  0.1468462\n",
            "   -0.5180583 ]\n",
            "  [-0.21865806  0.29090524 -0.18036889 ... -0.01058715  0.1468462\n",
            "   -0.5180583 ]\n",
            "  [-0.21865806  0.29090524 -0.18036889 ... -0.01058715  0.1468462\n",
            "   -0.5180583 ]]\n",
            "\n",
            " [[-0.21865806  0.29090524 -0.18036889 ... -0.01058715  0.1468462\n",
            "   -0.5180583 ]\n",
            "  [-0.21865806  0.29090524 -0.18036889 ... -0.01058715  0.1468462\n",
            "   -0.5180583 ]\n",
            "  [-0.21865806  0.29090524 -0.18036889 ... -0.01058715  0.1468462\n",
            "   -0.5180583 ]\n",
            "  ...\n",
            "  [-0.21865806  0.29090524 -0.18036889 ... -0.01058715  0.1468462\n",
            "   -0.5180583 ]\n",
            "  [-0.21865806  0.29090524 -0.18036889 ... -0.01058715  0.1468462\n",
            "   -0.5180583 ]\n",
            "  [-0.21865806  0.29090524 -0.18036889 ... -0.01058715  0.1468462\n",
            "   -0.5180583 ]]], shape=(128, 764, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.378068 -0.378068 -0.378068 ... -0.378068 -0.378068 -0.378068]\n",
            " [-0.378068 -0.378068 -0.378068 ... -0.378068 -0.378068 -0.378068]\n",
            " [-0.378068 -0.378068 -0.378068 ... -0.378068 -0.378068 -0.378068]\n",
            " ...\n",
            " [-0.378068 -0.378068 -0.378068 ... -0.378068 -0.378068 -0.378068]\n",
            " [-0.378068 -0.378068 -0.378068 ... -0.378068 -0.378068 -0.378068]\n",
            " [-0.378068 -0.378068 -0.378068 ... -0.378068 -0.378068 -0.378068]], shape=(512, 128), dtype=float32) tf.Tensor(\n",
            "[[-0.378068 -0.378068 -0.378068 ... -0.378068 -0.378068 -0.378068]\n",
            " [-0.378068 -0.378068 -0.378068 ... -0.378068 -0.378068 -0.378068]\n",
            " [-0.378068 -0.378068 -0.378068 ... -0.378068 -0.378068 -0.378068]\n",
            " ...\n",
            " [-0.378068 -0.378068 -0.378068 ... -0.378068 -0.378068 -0.378068]\n",
            " [-0.378068 -0.378068 -0.378068 ... -0.378068 -0.378068 -0.378068]\n",
            " [-0.378068 -0.378068 -0.378068 ... -0.378068 -0.378068 -0.378068]], shape=(252, 128), dtype=float32)\n",
            "(128, 764) (512, 1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_15/kernel:0', 'dense_15/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_15/kernel:0', 'dense_15/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch 1, Batch 24/100, Loss=2.94117e-01\n",
            "(1, 764, 1)\n",
            "tf.Tensor(\n",
            "[[[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " [[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " [[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]], shape=(128, 764, 1), dtype=float32) tf.Tensor(\n",
            "[[[-0.21325496  0.29467082 -0.16197322 ... -0.04692832  0.12882417\n",
            "   -0.47971672]\n",
            "  [-0.21325496  0.29467082 -0.16197322 ... -0.04692832  0.12882417\n",
            "   -0.47971672]\n",
            "  [-0.21325496  0.29467082 -0.16197322 ... -0.04692832  0.12882417\n",
            "   -0.47971672]\n",
            "  ...\n",
            "  [-0.21325496  0.29467082 -0.16197322 ... -0.04692832  0.12882417\n",
            "   -0.47971672]\n",
            "  [-0.21325496  0.29467082 -0.16197322 ... -0.04692832  0.12882417\n",
            "   -0.47971672]\n",
            "  [-0.21325496  0.29467082 -0.16197322 ... -0.04692832  0.12882417\n",
            "   -0.47971672]]\n",
            "\n",
            " [[-0.21325496  0.29467082 -0.16197322 ... -0.04692832  0.12882417\n",
            "   -0.47971672]\n",
            "  [-0.21325496  0.29467082 -0.16197322 ... -0.04692832  0.12882417\n",
            "   -0.47971672]\n",
            "  [-0.21325496  0.29467082 -0.16197322 ... -0.04692832  0.12882417\n",
            "   -0.47971672]\n",
            "  ...\n",
            "  [-0.21325496  0.29467082 -0.16197322 ... -0.04692832  0.12882417\n",
            "   -0.47971672]\n",
            "  [-0.21325496  0.29467082 -0.16197322 ... -0.04692832  0.12882417\n",
            "   -0.47971672]\n",
            "  [-0.21325496  0.29467082 -0.16197322 ... -0.04692832  0.12882417\n",
            "   -0.47971672]]\n",
            "\n",
            " [[-0.21325496  0.29467082 -0.16197322 ... -0.04692832  0.12882417\n",
            "   -0.47971672]\n",
            "  [-0.21325496  0.29467082 -0.16197322 ... -0.04692832  0.12882417\n",
            "   -0.47971672]\n",
            "  [-0.21325496  0.29467082 -0.16197322 ... -0.04692832  0.12882417\n",
            "   -0.47971672]\n",
            "  ...\n",
            "  [-0.21325496  0.29467082 -0.16197322 ... -0.04692832  0.12882417\n",
            "   -0.47971672]\n",
            "  [-0.21325496  0.29467082 -0.16197322 ... -0.04692832  0.12882417\n",
            "   -0.47971672]\n",
            "  [-0.21325496  0.29467082 -0.16197322 ... -0.04692832  0.12882417\n",
            "   -0.47971672]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[-0.21325496  0.29467082 -0.16197322 ... -0.04692832  0.12882417\n",
            "   -0.47971672]\n",
            "  [-0.21325496  0.29467082 -0.16197322 ... -0.04692832  0.12882417\n",
            "   -0.47971672]\n",
            "  [-0.21325496  0.29467082 -0.16197322 ... -0.04692832  0.12882417\n",
            "   -0.47971672]\n",
            "  ...\n",
            "  [-0.21325496  0.29467082 -0.16197322 ... -0.04692832  0.12882417\n",
            "   -0.47971672]\n",
            "  [-0.21325496  0.29467082 -0.16197322 ... -0.04692832  0.12882417\n",
            "   -0.47971672]\n",
            "  [-0.21325496  0.29467082 -0.16197322 ... -0.04692832  0.12882417\n",
            "   -0.47971672]]\n",
            "\n",
            " [[-0.21325496  0.29467082 -0.16197322 ... -0.04692832  0.12882417\n",
            "   -0.47971672]\n",
            "  [-0.21325496  0.29467082 -0.16197322 ... -0.04692832  0.12882417\n",
            "   -0.47971672]\n",
            "  [-0.21325496  0.29467082 -0.16197322 ... -0.04692832  0.12882417\n",
            "   -0.47971672]\n",
            "  ...\n",
            "  [-0.21325496  0.29467082 -0.16197322 ... -0.04692832  0.12882417\n",
            "   -0.47971672]\n",
            "  [-0.21325496  0.29467082 -0.16197322 ... -0.04692832  0.12882417\n",
            "   -0.47971672]\n",
            "  [-0.21325496  0.29467082 -0.16197322 ... -0.04692832  0.12882417\n",
            "   -0.47971672]]\n",
            "\n",
            " [[-0.21325496  0.29467082 -0.16197322 ... -0.04692832  0.12882417\n",
            "   -0.47971672]\n",
            "  [-0.21325496  0.29467082 -0.16197322 ... -0.04692832  0.12882417\n",
            "   -0.47971672]\n",
            "  [-0.21325496  0.29467082 -0.16197322 ... -0.04692832  0.12882417\n",
            "   -0.47971672]\n",
            "  ...\n",
            "  [-0.21325496  0.29467082 -0.16197322 ... -0.04692832  0.12882417\n",
            "   -0.47971672]\n",
            "  [-0.21325496  0.29467082 -0.16197322 ... -0.04692832  0.12882417\n",
            "   -0.47971672]\n",
            "  [-0.21325496  0.29467082 -0.16197322 ... -0.04692832  0.12882417\n",
            "   -0.47971672]]], shape=(128, 764, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.19938204 -0.19938204 -0.19938204 ... -0.19938204 -0.19938204\n",
            "  -0.19938204]\n",
            " [-0.19938204 -0.19938204 -0.19938204 ... -0.19938204 -0.19938204\n",
            "  -0.19938204]\n",
            " [-0.19938204 -0.19938204 -0.19938204 ... -0.19938204 -0.19938204\n",
            "  -0.19938204]\n",
            " ...\n",
            " [-0.19938204 -0.19938204 -0.19938204 ... -0.19938204 -0.19938204\n",
            "  -0.19938204]\n",
            " [-0.19938204 -0.19938204 -0.19938204 ... -0.19938204 -0.19938204\n",
            "  -0.19938204]\n",
            " [-0.19938204 -0.19938204 -0.19938204 ... -0.19938204 -0.19938204\n",
            "  -0.19938204]], shape=(512, 128), dtype=float32) tf.Tensor(\n",
            "[[-0.19938204 -0.19938204 -0.19938204 ... -0.19938204 -0.19938204\n",
            "  -0.19938204]\n",
            " [-0.19938204 -0.19938204 -0.19938204 ... -0.19938204 -0.19938204\n",
            "  -0.19938204]\n",
            " [-0.19938204 -0.19938204 -0.19938204 ... -0.19938204 -0.19938204\n",
            "  -0.19938204]\n",
            " ...\n",
            " [-0.19938204 -0.19938204 -0.19938204 ... -0.19938204 -0.19938204\n",
            "  -0.19938204]\n",
            " [-0.19938204 -0.19938204 -0.19938204 ... -0.19938204 -0.19938204\n",
            "  -0.19938204]\n",
            " [-0.19938204 -0.19938204 -0.19938204 ... -0.19938204 -0.19938204\n",
            "  -0.19938204]], shape=(252, 128), dtype=float32)\n",
            "(128, 764) (512, 1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_15/kernel:0', 'dense_15/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_15/kernel:0', 'dense_15/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch 1, Batch 25/100, Loss=9.21997e-02\n",
            "(1, 764, 1)\n",
            "tf.Tensor(\n",
            "[[[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " [[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " [[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]], shape=(128, 764, 1), dtype=float32) tf.Tensor(\n",
            "[[[-0.2077668   0.29804504 -0.14272028 ... -0.08576747  0.10881291\n",
            "   -0.43921298]\n",
            "  [-0.2077668   0.29804504 -0.14272028 ... -0.08576747  0.10881291\n",
            "   -0.43921298]\n",
            "  [-0.2077668   0.29804504 -0.14272028 ... -0.08576747  0.10881291\n",
            "   -0.43921298]\n",
            "  ...\n",
            "  [-0.2077668   0.29804504 -0.14272028 ... -0.08576747  0.10881291\n",
            "   -0.43921298]\n",
            "  [-0.2077668   0.29804504 -0.14272028 ... -0.08576747  0.10881291\n",
            "   -0.43921298]\n",
            "  [-0.2077668   0.29804504 -0.14272028 ... -0.08576747  0.10881291\n",
            "   -0.43921298]]\n",
            "\n",
            " [[-0.2077668   0.29804504 -0.14272028 ... -0.08576747  0.10881291\n",
            "   -0.43921298]\n",
            "  [-0.2077668   0.29804504 -0.14272028 ... -0.08576747  0.10881291\n",
            "   -0.43921298]\n",
            "  [-0.2077668   0.29804504 -0.14272028 ... -0.08576747  0.10881291\n",
            "   -0.43921298]\n",
            "  ...\n",
            "  [-0.2077668   0.29804504 -0.14272028 ... -0.08576747  0.10881291\n",
            "   -0.43921298]\n",
            "  [-0.2077668   0.29804504 -0.14272028 ... -0.08576747  0.10881291\n",
            "   -0.43921298]\n",
            "  [-0.2077668   0.29804504 -0.14272028 ... -0.08576747  0.10881291\n",
            "   -0.43921298]]\n",
            "\n",
            " [[-0.2077668   0.29804504 -0.14272028 ... -0.08576747  0.10881291\n",
            "   -0.43921298]\n",
            "  [-0.2077668   0.29804504 -0.14272028 ... -0.08576747  0.10881291\n",
            "   -0.43921298]\n",
            "  [-0.2077668   0.29804504 -0.14272028 ... -0.08576747  0.10881291\n",
            "   -0.43921298]\n",
            "  ...\n",
            "  [-0.2077668   0.29804504 -0.14272028 ... -0.08576747  0.10881291\n",
            "   -0.43921298]\n",
            "  [-0.2077668   0.29804504 -0.14272028 ... -0.08576747  0.10881291\n",
            "   -0.43921298]\n",
            "  [-0.2077668   0.29804504 -0.14272028 ... -0.08576747  0.10881291\n",
            "   -0.43921298]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[-0.2077668   0.29804504 -0.14272028 ... -0.08576747  0.10881291\n",
            "   -0.43921298]\n",
            "  [-0.2077668   0.29804504 -0.14272028 ... -0.08576747  0.10881291\n",
            "   -0.43921298]\n",
            "  [-0.2077668   0.29804504 -0.14272028 ... -0.08576747  0.10881291\n",
            "   -0.43921298]\n",
            "  ...\n",
            "  [-0.2077668   0.29804504 -0.14272028 ... -0.08576747  0.10881291\n",
            "   -0.43921298]\n",
            "  [-0.2077668   0.29804504 -0.14272028 ... -0.08576747  0.10881291\n",
            "   -0.43921298]\n",
            "  [-0.2077668   0.29804504 -0.14272028 ... -0.08576747  0.10881291\n",
            "   -0.43921298]]\n",
            "\n",
            " [[-0.2077668   0.29804504 -0.14272028 ... -0.08576747  0.10881291\n",
            "   -0.43921298]\n",
            "  [-0.2077668   0.29804504 -0.14272028 ... -0.08576747  0.10881291\n",
            "   -0.43921298]\n",
            "  [-0.2077668   0.29804504 -0.14272028 ... -0.08576747  0.10881291\n",
            "   -0.43921298]\n",
            "  ...\n",
            "  [-0.2077668   0.29804504 -0.14272028 ... -0.08576747  0.10881291\n",
            "   -0.43921298]\n",
            "  [-0.2077668   0.29804504 -0.14272028 ... -0.08576747  0.10881291\n",
            "   -0.43921298]\n",
            "  [-0.2077668   0.29804504 -0.14272028 ... -0.08576747  0.10881291\n",
            "   -0.43921298]]\n",
            "\n",
            " [[-0.2077668   0.29804504 -0.14272028 ... -0.08576747  0.10881291\n",
            "   -0.43921298]\n",
            "  [-0.2077668   0.29804504 -0.14272028 ... -0.08576747  0.10881291\n",
            "   -0.43921298]\n",
            "  [-0.2077668   0.29804504 -0.14272028 ... -0.08576747  0.10881291\n",
            "   -0.43921298]\n",
            "  ...\n",
            "  [-0.2077668   0.29804504 -0.14272028 ... -0.08576747  0.10881291\n",
            "   -0.43921298]\n",
            "  [-0.2077668   0.29804504 -0.14272028 ... -0.08576747  0.10881291\n",
            "   -0.43921298]\n",
            "  [-0.2077668   0.29804504 -0.14272028 ... -0.08576747  0.10881291\n",
            "   -0.43921298]]], shape=(128, 764, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.00945211 -0.00945211 -0.00945211 ... -0.00945211 -0.00945211\n",
            "  -0.00945211]\n",
            " [-0.00945211 -0.00945211 -0.00945211 ... -0.00945211 -0.00945211\n",
            "  -0.00945211]\n",
            " [-0.00945211 -0.00945211 -0.00945211 ... -0.00945211 -0.00945211\n",
            "  -0.00945211]\n",
            " ...\n",
            " [-0.00945211 -0.00945211 -0.00945211 ... -0.00945211 -0.00945211\n",
            "  -0.00945211]\n",
            " [-0.00945211 -0.00945211 -0.00945211 ... -0.00945211 -0.00945211\n",
            "  -0.00945211]\n",
            " [-0.00945211 -0.00945211 -0.00945211 ... -0.00945211 -0.00945211\n",
            "  -0.00945211]], shape=(512, 128), dtype=float32) tf.Tensor(\n",
            "[[-0.00945211 -0.00945211 -0.00945211 ... -0.00945211 -0.00945211\n",
            "  -0.00945211]\n",
            " [-0.00945211 -0.00945211 -0.00945211 ... -0.00945211 -0.00945211\n",
            "  -0.00945211]\n",
            " [-0.00945211 -0.00945211 -0.00945211 ... -0.00945211 -0.00945211\n",
            "  -0.00945211]\n",
            " ...\n",
            " [-0.00945211 -0.00945211 -0.00945211 ... -0.00945211 -0.00945211\n",
            "  -0.00945211]\n",
            " [-0.00945211 -0.00945211 -0.00945211 ... -0.00945211 -0.00945211\n",
            "  -0.00945211]\n",
            " [-0.00945211 -0.00945211 -0.00945211 ... -0.00945211 -0.00945211\n",
            "  -0.00945211]], shape=(252, 128), dtype=float32)\n",
            "(128, 764) (512, 1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_15/kernel:0', 'dense_15/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_15/kernel:0', 'dense_15/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch 1, Batch 26/100, Loss=3.25564e-02\n",
            "(1, 764, 1)\n",
            "tf.Tensor(\n",
            "[[[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " [[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]], shape=(128, 764, 1), dtype=float32) tf.Tensor(\n",
            "[[[-0.20338772  0.30079117 -0.1256405  ... -0.12039559  0.09102369\n",
            "   -0.40266004]\n",
            "  [-0.20338772  0.30079117 -0.1256405  ... -0.12039559  0.09102369\n",
            "   -0.40266004]\n",
            "  [-0.20338772  0.30079117 -0.1256405  ... -0.12039559  0.09102369\n",
            "   -0.40266004]\n",
            "  ...\n",
            "  [-0.20338772  0.30079117 -0.1256405  ... -0.12039559  0.09102369\n",
            "   -0.40266004]\n",
            "  [-0.20338772  0.30079117 -0.1256405  ... -0.12039559  0.09102369\n",
            "   -0.40266004]\n",
            "  [-0.20338772  0.30079117 -0.1256405  ... -0.12039559  0.09102369\n",
            "   -0.40266004]]\n",
            "\n",
            " [[-0.20338772  0.30079117 -0.1256405  ... -0.12039559  0.09102369\n",
            "   -0.40266004]\n",
            "  [-0.20338772  0.30079117 -0.1256405  ... -0.12039559  0.09102369\n",
            "   -0.40266004]\n",
            "  [-0.20338772  0.30079117 -0.1256405  ... -0.12039559  0.09102369\n",
            "   -0.40266004]\n",
            "  ...\n",
            "  [-0.20338772  0.30079117 -0.1256405  ... -0.12039559  0.09102369\n",
            "   -0.40266004]\n",
            "  [-0.20338772  0.30079117 -0.1256405  ... -0.12039559  0.09102369\n",
            "   -0.40266004]\n",
            "  [-0.20338772  0.30079117 -0.1256405  ... -0.12039559  0.09102369\n",
            "   -0.40266004]]\n",
            "\n",
            " [[-0.20338772  0.30079117 -0.1256405  ... -0.12039559  0.09102369\n",
            "   -0.40266004]\n",
            "  [-0.20338772  0.30079117 -0.1256405  ... -0.12039559  0.09102369\n",
            "   -0.40266004]\n",
            "  [-0.20338772  0.30079117 -0.1256405  ... -0.12039559  0.09102369\n",
            "   -0.40266004]\n",
            "  ...\n",
            "  [-0.20338772  0.30079117 -0.1256405  ... -0.12039559  0.09102369\n",
            "   -0.40266004]\n",
            "  [-0.20338772  0.30079117 -0.1256405  ... -0.12039559  0.09102369\n",
            "   -0.40266004]\n",
            "  [-0.20338772  0.30079117 -0.1256405  ... -0.12039559  0.09102369\n",
            "   -0.40266004]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[-0.20338772  0.30079117 -0.1256405  ... -0.12039559  0.09102369\n",
            "   -0.40266004]\n",
            "  [-0.20338772  0.30079117 -0.1256405  ... -0.12039559  0.09102369\n",
            "   -0.40266004]\n",
            "  [-0.20338772  0.30079117 -0.1256405  ... -0.12039559  0.09102369\n",
            "   -0.40266004]\n",
            "  ...\n",
            "  [-0.20338772  0.30079117 -0.1256405  ... -0.12039559  0.09102369\n",
            "   -0.40266004]\n",
            "  [-0.20338772  0.30079117 -0.1256405  ... -0.12039559  0.09102369\n",
            "   -0.40266004]\n",
            "  [-0.20338772  0.30079117 -0.1256405  ... -0.12039559  0.09102369\n",
            "   -0.40266004]]\n",
            "\n",
            " [[-0.20338772  0.30079117 -0.1256405  ... -0.12039559  0.09102369\n",
            "   -0.40266004]\n",
            "  [-0.20338772  0.30079117 -0.1256405  ... -0.12039559  0.09102369\n",
            "   -0.40266004]\n",
            "  [-0.20338772  0.30079117 -0.1256405  ... -0.12039559  0.09102369\n",
            "   -0.40266004]\n",
            "  ...\n",
            "  [-0.20338772  0.30079117 -0.1256405  ... -0.12039559  0.09102369\n",
            "   -0.40266004]\n",
            "  [-0.20338772  0.30079117 -0.1256405  ... -0.12039559  0.09102369\n",
            "   -0.40266004]\n",
            "  [-0.20338772  0.30079117 -0.1256405  ... -0.12039559  0.09102369\n",
            "   -0.40266004]]\n",
            "\n",
            " [[-0.20338772  0.30079117 -0.1256405  ... -0.12039559  0.09102369\n",
            "   -0.40266004]\n",
            "  [-0.20338772  0.30079117 -0.1256405  ... -0.12039559  0.09102369\n",
            "   -0.40266004]\n",
            "  [-0.20338772  0.30079117 -0.1256405  ... -0.12039559  0.09102369\n",
            "   -0.40266004]\n",
            "  ...\n",
            "  [-0.20338772  0.30079117 -0.1256405  ... -0.12039559  0.09102369\n",
            "   -0.40266004]\n",
            "  [-0.20338772  0.30079117 -0.1256405  ... -0.12039559  0.09102369\n",
            "   -0.40266004]\n",
            "  [-0.20338772  0.30079117 -0.1256405  ... -0.12039559  0.09102369\n",
            "   -0.40266004]]], shape=(128, 764, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[0.15639228 0.15639228 0.15639228 ... 0.15639228 0.15639228 0.15639228]\n",
            " [0.15639228 0.15639228 0.15639228 ... 0.15639228 0.15639228 0.15639228]\n",
            " [0.15639228 0.15639228 0.15639228 ... 0.15639228 0.15639228 0.15639228]\n",
            " ...\n",
            " [0.15639228 0.15639228 0.15639228 ... 0.15639228 0.15639228 0.15639228]\n",
            " [0.15639228 0.15639228 0.15639228 ... 0.15639228 0.15639228 0.15639228]\n",
            " [0.15639228 0.15639228 0.15639228 ... 0.15639228 0.15639228 0.15639228]], shape=(512, 128), dtype=float32) tf.Tensor(\n",
            "[[0.15639228 0.15639228 0.15639228 ... 0.15639228 0.15639228 0.15639228]\n",
            " [0.15639228 0.15639228 0.15639228 ... 0.15639228 0.15639228 0.15639228]\n",
            " [0.15639228 0.15639228 0.15639228 ... 0.15639228 0.15639228 0.15639228]\n",
            " ...\n",
            " [0.15639228 0.15639228 0.15639228 ... 0.15639228 0.15639228 0.15639228]\n",
            " [0.15639228 0.15639228 0.15639228 ... 0.15639228 0.15639228 0.15639228]\n",
            " [0.15639228 0.15639228 0.15639228 ... 0.15639228 0.15639228 0.15639228]], shape=(252, 128), dtype=float32)\n",
            "(128, 764) (512, 1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_15/kernel:0', 'dense_15/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_15/kernel:0', 'dense_15/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch 1, Batch 27/100, Loss=1.00765e-01\n",
            "(1, 764, 1)\n",
            "tf.Tensor(\n",
            "[[[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " [[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " [[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]], shape=(128, 764, 1), dtype=float32) tf.Tensor(\n",
            "[[[-0.20219702  0.3032452  -0.11248704 ... -0.14693677  0.07902131\n",
            "   -0.37339848]\n",
            "  [-0.20219702  0.3032452  -0.11248704 ... -0.14693677  0.07902131\n",
            "   -0.37339848]\n",
            "  [-0.20219702  0.3032452  -0.11248704 ... -0.14693677  0.07902131\n",
            "   -0.37339848]\n",
            "  ...\n",
            "  [-0.20219702  0.3032452  -0.11248704 ... -0.14693677  0.07902131\n",
            "   -0.37339848]\n",
            "  [-0.20219702  0.3032452  -0.11248704 ... -0.14693677  0.07902131\n",
            "   -0.37339848]\n",
            "  [-0.20219702  0.3032452  -0.11248704 ... -0.14693677  0.07902131\n",
            "   -0.37339848]]\n",
            "\n",
            " [[-0.20219702  0.3032452  -0.11248704 ... -0.14693677  0.07902131\n",
            "   -0.37339848]\n",
            "  [-0.20219702  0.3032452  -0.11248704 ... -0.14693677  0.07902131\n",
            "   -0.37339848]\n",
            "  [-0.20219702  0.3032452  -0.11248704 ... -0.14693677  0.07902131\n",
            "   -0.37339848]\n",
            "  ...\n",
            "  [-0.20219702  0.3032452  -0.11248704 ... -0.14693677  0.07902131\n",
            "   -0.37339848]\n",
            "  [-0.20219702  0.3032452  -0.11248704 ... -0.14693677  0.07902131\n",
            "   -0.37339848]\n",
            "  [-0.20219702  0.3032452  -0.11248704 ... -0.14693677  0.07902131\n",
            "   -0.37339848]]\n",
            "\n",
            " [[-0.20219702  0.3032452  -0.11248704 ... -0.14693677  0.07902131\n",
            "   -0.37339848]\n",
            "  [-0.20219702  0.3032452  -0.11248704 ... -0.14693677  0.07902131\n",
            "   -0.37339848]\n",
            "  [-0.20219702  0.3032452  -0.11248704 ... -0.14693677  0.07902131\n",
            "   -0.37339848]\n",
            "  ...\n",
            "  [-0.20219702  0.3032452  -0.11248704 ... -0.14693677  0.07902131\n",
            "   -0.37339848]\n",
            "  [-0.20219702  0.3032452  -0.11248704 ... -0.14693677  0.07902131\n",
            "   -0.37339848]\n",
            "  [-0.20219702  0.3032452  -0.11248704 ... -0.14693677  0.07902131\n",
            "   -0.37339848]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[-0.20219702  0.3032452  -0.11248704 ... -0.14693677  0.07902131\n",
            "   -0.37339848]\n",
            "  [-0.20219702  0.3032452  -0.11248704 ... -0.14693677  0.07902131\n",
            "   -0.37339848]\n",
            "  [-0.20219702  0.3032452  -0.11248704 ... -0.14693677  0.07902131\n",
            "   -0.37339848]\n",
            "  ...\n",
            "  [-0.20219702  0.3032452  -0.11248704 ... -0.14693677  0.07902131\n",
            "   -0.37339848]\n",
            "  [-0.20219702  0.3032452  -0.11248704 ... -0.14693677  0.07902131\n",
            "   -0.37339848]\n",
            "  [-0.20219702  0.3032452  -0.11248704 ... -0.14693677  0.07902131\n",
            "   -0.37339848]]\n",
            "\n",
            " [[-0.20219702  0.3032452  -0.11248704 ... -0.14693677  0.07902131\n",
            "   -0.37339848]\n",
            "  [-0.20219702  0.3032452  -0.11248704 ... -0.14693677  0.07902131\n",
            "   -0.37339848]\n",
            "  [-0.20219702  0.3032452  -0.11248704 ... -0.14693677  0.07902131\n",
            "   -0.37339848]\n",
            "  ...\n",
            "  [-0.20219702  0.3032452  -0.11248704 ... -0.14693677  0.07902131\n",
            "   -0.37339848]\n",
            "  [-0.20219702  0.3032452  -0.11248704 ... -0.14693677  0.07902131\n",
            "   -0.37339848]\n",
            "  [-0.20219702  0.3032452  -0.11248704 ... -0.14693677  0.07902131\n",
            "   -0.37339848]]\n",
            "\n",
            " [[-0.20219702  0.3032452  -0.11248704 ... -0.14693677  0.07902131\n",
            "   -0.37339848]\n",
            "  [-0.20219702  0.3032452  -0.11248704 ... -0.14693677  0.07902131\n",
            "   -0.37339848]\n",
            "  [-0.20219702  0.3032452  -0.11248704 ... -0.14693677  0.07902131\n",
            "   -0.37339848]\n",
            "  ...\n",
            "  [-0.20219702  0.3032452  -0.11248704 ... -0.14693677  0.07902131\n",
            "   -0.37339848]\n",
            "  [-0.20219702  0.3032452  -0.11248704 ... -0.14693677  0.07902131\n",
            "   -0.37339848]\n",
            "  [-0.20219702  0.3032452  -0.11248704 ... -0.14693677  0.07902131\n",
            "   -0.37339848]]], shape=(128, 764, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[0.27562544 0.27562544 0.27562544 ... 0.27562544 0.27562544 0.27562544]\n",
            " [0.27562544 0.27562544 0.27562544 ... 0.27562544 0.27562544 0.27562544]\n",
            " [0.27562544 0.27562544 0.27562544 ... 0.27562544 0.27562544 0.27562544]\n",
            " ...\n",
            " [0.27562544 0.27562544 0.27562544 ... 0.27562544 0.27562544 0.27562544]\n",
            " [0.27562544 0.27562544 0.27562544 ... 0.27562544 0.27562544 0.27562544]\n",
            " [0.27562544 0.27562544 0.27562544 ... 0.27562544 0.27562544 0.27562544]], shape=(512, 128), dtype=float32) tf.Tensor(\n",
            "[[0.27562544 0.27562544 0.27562544 ... 0.27562544 0.27562544 0.27562544]\n",
            " [0.27562544 0.27562544 0.27562544 ... 0.27562544 0.27562544 0.27562544]\n",
            " [0.27562544 0.27562544 0.27562544 ... 0.27562544 0.27562544 0.27562544]\n",
            " ...\n",
            " [0.27562544 0.27562544 0.27562544 ... 0.27562544 0.27562544 0.27562544]\n",
            " [0.27562544 0.27562544 0.27562544 ... 0.27562544 0.27562544 0.27562544]\n",
            " [0.27562544 0.27562544 0.27562544 ... 0.27562544 0.27562544 0.27562544]], shape=(252, 128), dtype=float32)\n",
            "(128, 764) (512, 1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_15/kernel:0', 'dense_15/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_15/kernel:0', 'dense_15/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch 1, Batch 28/100, Loss=2.40964e-01\n",
            "(1, 764, 1)\n",
            "tf.Tensor(\n",
            "[[[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " [[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " [[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]], shape=(128, 764, 1), dtype=float32) tf.Tensor(\n",
            "[[[-0.20670329  0.30598557 -0.10427205 ... -0.16329327  0.07579257\n",
            "   -0.3530129 ]\n",
            "  [-0.20670329  0.30598557 -0.10427205 ... -0.16329327  0.07579257\n",
            "   -0.3530129 ]\n",
            "  [-0.20670329  0.30598557 -0.10427205 ... -0.16329327  0.07579257\n",
            "   -0.3530129 ]\n",
            "  ...\n",
            "  [-0.20670329  0.30598557 -0.10427205 ... -0.16329327  0.07579257\n",
            "   -0.3530129 ]\n",
            "  [-0.20670329  0.30598557 -0.10427205 ... -0.16329327  0.07579257\n",
            "   -0.3530129 ]\n",
            "  [-0.20670329  0.30598557 -0.10427205 ... -0.16329327  0.07579257\n",
            "   -0.3530129 ]]\n",
            "\n",
            " [[-0.20670329  0.30598557 -0.10427205 ... -0.16329327  0.07579257\n",
            "   -0.3530129 ]\n",
            "  [-0.20670329  0.30598557 -0.10427205 ... -0.16329327  0.07579257\n",
            "   -0.3530129 ]\n",
            "  [-0.20670329  0.30598557 -0.10427205 ... -0.16329327  0.07579257\n",
            "   -0.3530129 ]\n",
            "  ...\n",
            "  [-0.20670329  0.30598557 -0.10427205 ... -0.16329327  0.07579257\n",
            "   -0.3530129 ]\n",
            "  [-0.20670329  0.30598557 -0.10427205 ... -0.16329327  0.07579257\n",
            "   -0.3530129 ]\n",
            "  [-0.20670329  0.30598557 -0.10427205 ... -0.16329327  0.07579257\n",
            "   -0.3530129 ]]\n",
            "\n",
            " [[-0.20670329  0.30598557 -0.10427205 ... -0.16329327  0.07579257\n",
            "   -0.3530129 ]\n",
            "  [-0.20670329  0.30598557 -0.10427205 ... -0.16329327  0.07579257\n",
            "   -0.3530129 ]\n",
            "  [-0.20670329  0.30598557 -0.10427205 ... -0.16329327  0.07579257\n",
            "   -0.3530129 ]\n",
            "  ...\n",
            "  [-0.20670329  0.30598557 -0.10427205 ... -0.16329327  0.07579257\n",
            "   -0.3530129 ]\n",
            "  [-0.20670329  0.30598557 -0.10427205 ... -0.16329327  0.07579257\n",
            "   -0.3530129 ]\n",
            "  [-0.20670329  0.30598557 -0.10427205 ... -0.16329327  0.07579257\n",
            "   -0.3530129 ]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[-0.20670329  0.30598557 -0.10427205 ... -0.16329327  0.07579257\n",
            "   -0.3530129 ]\n",
            "  [-0.20670329  0.30598557 -0.10427205 ... -0.16329327  0.07579257\n",
            "   -0.3530129 ]\n",
            "  [-0.20670329  0.30598557 -0.10427205 ... -0.16329327  0.07579257\n",
            "   -0.3530129 ]\n",
            "  ...\n",
            "  [-0.20670329  0.30598557 -0.10427205 ... -0.16329327  0.07579257\n",
            "   -0.3530129 ]\n",
            "  [-0.20670329  0.30598557 -0.10427205 ... -0.16329327  0.07579257\n",
            "   -0.3530129 ]\n",
            "  [-0.20670329  0.30598557 -0.10427205 ... -0.16329327  0.07579257\n",
            "   -0.3530129 ]]\n",
            "\n",
            " [[-0.20670329  0.30598557 -0.10427205 ... -0.16329327  0.07579257\n",
            "   -0.3530129 ]\n",
            "  [-0.20670329  0.30598557 -0.10427205 ... -0.16329327  0.07579257\n",
            "   -0.3530129 ]\n",
            "  [-0.20670329  0.30598557 -0.10427205 ... -0.16329327  0.07579257\n",
            "   -0.3530129 ]\n",
            "  ...\n",
            "  [-0.20670329  0.30598557 -0.10427205 ... -0.16329327  0.07579257\n",
            "   -0.3530129 ]\n",
            "  [-0.20670329  0.30598557 -0.10427205 ... -0.16329327  0.07579257\n",
            "   -0.3530129 ]\n",
            "  [-0.20670329  0.30598557 -0.10427205 ... -0.16329327  0.07579257\n",
            "   -0.3530129 ]]\n",
            "\n",
            " [[-0.20670329  0.30598557 -0.10427205 ... -0.16329327  0.07579257\n",
            "   -0.3530129 ]\n",
            "  [-0.20670329  0.30598557 -0.10427205 ... -0.16329327  0.07579257\n",
            "   -0.3530129 ]\n",
            "  [-0.20670329  0.30598557 -0.10427205 ... -0.16329327  0.07579257\n",
            "   -0.3530129 ]\n",
            "  ...\n",
            "  [-0.20670329  0.30598557 -0.10427205 ... -0.16329327  0.07579257\n",
            "   -0.3530129 ]\n",
            "  [-0.20670329  0.30598557 -0.10427205 ... -0.16329327  0.07579257\n",
            "   -0.3530129 ]\n",
            "  [-0.20670329  0.30598557 -0.10427205 ... -0.16329327  0.07579257\n",
            "   -0.3530129 ]]], shape=(128, 764, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[0.33329722 0.33329722 0.33329722 ... 0.33329722 0.33329722 0.33329722]\n",
            " [0.33329722 0.33329722 0.33329722 ... 0.33329722 0.33329722 0.33329722]\n",
            " [0.33329722 0.33329722 0.33329722 ... 0.33329722 0.33329722 0.33329722]\n",
            " ...\n",
            " [0.33329722 0.33329722 0.33329722 ... 0.33329722 0.33329722 0.33329722]\n",
            " [0.33329722 0.33329722 0.33329722 ... 0.33329722 0.33329722 0.33329722]\n",
            " [0.33329722 0.33329722 0.33329722 ... 0.33329722 0.33329722 0.33329722]], shape=(512, 128), dtype=float32) tf.Tensor(\n",
            "[[0.33329722 0.33329722 0.33329722 ... 0.33329722 0.33329722 0.33329722]\n",
            " [0.33329722 0.33329722 0.33329722 ... 0.33329722 0.33329722 0.33329722]\n",
            " [0.33329722 0.33329722 0.33329722 ... 0.33329722 0.33329722 0.33329722]\n",
            " ...\n",
            " [0.33329722 0.33329722 0.33329722 ... 0.33329722 0.33329722 0.33329722]\n",
            " [0.33329722 0.33329722 0.33329722 ... 0.33329722 0.33329722 0.33329722]\n",
            " [0.33329722 0.33329722 0.33329722 ... 0.33329722 0.33329722 0.33329722]], shape=(252, 128), dtype=float32)\n",
            "(128, 764) (512, 1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_15/kernel:0', 'dense_15/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_15/kernel:0', 'dense_15/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch 1, Batch 29/100, Loss=3.11222e-01\n",
            "(1, 764, 1)\n",
            "tf.Tensor(\n",
            "[[[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " [[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]], shape=(128, 764, 1), dtype=float32) tf.Tensor(\n",
            "[[[-0.21780255  0.30937073 -0.10069223 ... -0.17024218  0.08171638\n",
            "   -0.3406837 ]\n",
            "  [-0.21780255  0.30937073 -0.10069223 ... -0.17024218  0.08171638\n",
            "   -0.3406837 ]\n",
            "  [-0.21780255  0.30937073 -0.10069223 ... -0.17024218  0.08171638\n",
            "   -0.3406837 ]\n",
            "  ...\n",
            "  [-0.21780255  0.30937073 -0.10069223 ... -0.17024218  0.08171638\n",
            "   -0.3406837 ]\n",
            "  [-0.21780255  0.30937073 -0.10069223 ... -0.17024218  0.08171638\n",
            "   -0.3406837 ]\n",
            "  [-0.21780255  0.30937073 -0.10069223 ... -0.17024218  0.08171638\n",
            "   -0.3406837 ]]\n",
            "\n",
            " [[-0.21780255  0.30937073 -0.10069223 ... -0.17024218  0.08171638\n",
            "   -0.3406837 ]\n",
            "  [-0.21780255  0.30937073 -0.10069223 ... -0.17024218  0.08171638\n",
            "   -0.3406837 ]\n",
            "  [-0.21780255  0.30937073 -0.10069223 ... -0.17024218  0.08171638\n",
            "   -0.3406837 ]\n",
            "  ...\n",
            "  [-0.21780255  0.30937073 -0.10069223 ... -0.17024218  0.08171638\n",
            "   -0.3406837 ]\n",
            "  [-0.21780255  0.30937073 -0.10069223 ... -0.17024218  0.08171638\n",
            "   -0.3406837 ]\n",
            "  [-0.21780255  0.30937073 -0.10069223 ... -0.17024218  0.08171638\n",
            "   -0.3406837 ]]\n",
            "\n",
            " [[-0.21780255  0.30937073 -0.10069223 ... -0.17024218  0.08171638\n",
            "   -0.3406837 ]\n",
            "  [-0.21780255  0.30937073 -0.10069223 ... -0.17024218  0.08171638\n",
            "   -0.3406837 ]\n",
            "  [-0.21780255  0.30937073 -0.10069223 ... -0.17024218  0.08171638\n",
            "   -0.3406837 ]\n",
            "  ...\n",
            "  [-0.21780255  0.30937073 -0.10069223 ... -0.17024218  0.08171638\n",
            "   -0.3406837 ]\n",
            "  [-0.21780255  0.30937073 -0.10069223 ... -0.17024218  0.08171638\n",
            "   -0.3406837 ]\n",
            "  [-0.21780255  0.30937073 -0.10069223 ... -0.17024218  0.08171638\n",
            "   -0.3406837 ]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[-0.21780255  0.30937073 -0.10069223 ... -0.17024218  0.08171638\n",
            "   -0.3406837 ]\n",
            "  [-0.21780255  0.30937073 -0.10069223 ... -0.17024218  0.08171638\n",
            "   -0.3406837 ]\n",
            "  [-0.21780255  0.30937073 -0.10069223 ... -0.17024218  0.08171638\n",
            "   -0.3406837 ]\n",
            "  ...\n",
            "  [-0.21780255  0.30937073 -0.10069223 ... -0.17024218  0.08171638\n",
            "   -0.3406837 ]\n",
            "  [-0.21780255  0.30937073 -0.10069223 ... -0.17024218  0.08171638\n",
            "   -0.3406837 ]\n",
            "  [-0.21780255  0.30937073 -0.10069223 ... -0.17024218  0.08171638\n",
            "   -0.3406837 ]]\n",
            "\n",
            " [[-0.21780255  0.30937073 -0.10069223 ... -0.17024218  0.08171638\n",
            "   -0.3406837 ]\n",
            "  [-0.21780255  0.30937073 -0.10069223 ... -0.17024218  0.08171638\n",
            "   -0.3406837 ]\n",
            "  [-0.21780255  0.30937073 -0.10069223 ... -0.17024218  0.08171638\n",
            "   -0.3406837 ]\n",
            "  ...\n",
            "  [-0.21780255  0.30937073 -0.10069223 ... -0.17024218  0.08171638\n",
            "   -0.3406837 ]\n",
            "  [-0.21780255  0.30937073 -0.10069223 ... -0.17024218  0.08171638\n",
            "   -0.3406837 ]\n",
            "  [-0.21780255  0.30937073 -0.10069223 ... -0.17024218  0.08171638\n",
            "   -0.3406837 ]]\n",
            "\n",
            " [[-0.21780255  0.30937073 -0.10069223 ... -0.17024218  0.08171638\n",
            "   -0.3406837 ]\n",
            "  [-0.21780255  0.30937073 -0.10069223 ... -0.17024218  0.08171638\n",
            "   -0.3406837 ]\n",
            "  [-0.21780255  0.30937073 -0.10069223 ... -0.17024218  0.08171638\n",
            "   -0.3406837 ]\n",
            "  ...\n",
            "  [-0.21780255  0.30937073 -0.10069223 ... -0.17024218  0.08171638\n",
            "   -0.3406837 ]\n",
            "  [-0.21780255  0.30937073 -0.10069223 ... -0.17024218  0.08171638\n",
            "   -0.3406837 ]\n",
            "  [-0.21780255  0.30937073 -0.10069223 ... -0.17024218  0.08171638\n",
            "   -0.3406837 ]]], shape=(128, 764, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[0.3314019 0.3314019 0.3314019 ... 0.3314019 0.3314019 0.3314019]\n",
            " [0.3314019 0.3314019 0.3314019 ... 0.3314019 0.3314019 0.3314019]\n",
            " [0.3314019 0.3314019 0.3314019 ... 0.3314019 0.3314019 0.3314019]\n",
            " ...\n",
            " [0.3314019 0.3314019 0.3314019 ... 0.3314019 0.3314019 0.3314019]\n",
            " [0.3314019 0.3314019 0.3314019 ... 0.3314019 0.3314019 0.3314019]\n",
            " [0.3314019 0.3314019 0.3314019 ... 0.3314019 0.3314019 0.3314019]], shape=(512, 128), dtype=float32) tf.Tensor(\n",
            "[[0.3314019 0.3314019 0.3314019 ... 0.3314019 0.3314019 0.3314019]\n",
            " [0.3314019 0.3314019 0.3314019 ... 0.3314019 0.3314019 0.3314019]\n",
            " [0.3314019 0.3314019 0.3314019 ... 0.3314019 0.3314019 0.3314019]\n",
            " ...\n",
            " [0.3314019 0.3314019 0.3314019 ... 0.3314019 0.3314019 0.3314019]\n",
            " [0.3314019 0.3314019 0.3314019 ... 0.3314019 0.3314019 0.3314019]\n",
            " [0.3314019 0.3314019 0.3314019 ... 0.3314019 0.3314019 0.3314019]], shape=(252, 128), dtype=float32)\n",
            "(128, 764) (512, 1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_15/kernel:0', 'dense_15/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_15/kernel:0', 'dense_15/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch 1, Batch 30/100, Loss=3.17454e-01\n",
            "(1, 764, 1)\n",
            "tf.Tensor(\n",
            "[[[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " [[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " [[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]], shape=(128, 764, 1), dtype=float32) tf.Tensor(\n",
            "[[[-0.23571369  0.31358874 -0.10131413 ... -0.1688592   0.09648909\n",
            "   -0.33539066]\n",
            "  [-0.23571369  0.31358874 -0.10131413 ... -0.1688592   0.09648909\n",
            "   -0.33539066]\n",
            "  [-0.23571369  0.31358874 -0.10131413 ... -0.1688592   0.09648909\n",
            "   -0.33539066]\n",
            "  ...\n",
            "  [-0.23571369  0.31358874 -0.10131413 ... -0.1688592   0.09648909\n",
            "   -0.33539066]\n",
            "  [-0.23571369  0.31358874 -0.10131413 ... -0.1688592   0.09648909\n",
            "   -0.33539066]\n",
            "  [-0.23571369  0.31358874 -0.10131413 ... -0.1688592   0.09648909\n",
            "   -0.33539066]]\n",
            "\n",
            " [[-0.23571369  0.31358874 -0.10131413 ... -0.1688592   0.09648909\n",
            "   -0.33539066]\n",
            "  [-0.23571369  0.31358874 -0.10131413 ... -0.1688592   0.09648909\n",
            "   -0.33539066]\n",
            "  [-0.23571369  0.31358874 -0.10131413 ... -0.1688592   0.09648909\n",
            "   -0.33539066]\n",
            "  ...\n",
            "  [-0.23571369  0.31358874 -0.10131413 ... -0.1688592   0.09648909\n",
            "   -0.33539066]\n",
            "  [-0.23571369  0.31358874 -0.10131413 ... -0.1688592   0.09648909\n",
            "   -0.33539066]\n",
            "  [-0.23571369  0.31358874 -0.10131413 ... -0.1688592   0.09648909\n",
            "   -0.33539066]]\n",
            "\n",
            " [[-0.23571369  0.31358874 -0.10131413 ... -0.1688592   0.09648909\n",
            "   -0.33539066]\n",
            "  [-0.23571369  0.31358874 -0.10131413 ... -0.1688592   0.09648909\n",
            "   -0.33539066]\n",
            "  [-0.23571369  0.31358874 -0.10131413 ... -0.1688592   0.09648909\n",
            "   -0.33539066]\n",
            "  ...\n",
            "  [-0.23571369  0.31358874 -0.10131413 ... -0.1688592   0.09648909\n",
            "   -0.33539066]\n",
            "  [-0.23571369  0.31358874 -0.10131413 ... -0.1688592   0.09648909\n",
            "   -0.33539066]\n",
            "  [-0.23571369  0.31358874 -0.10131413 ... -0.1688592   0.09648909\n",
            "   -0.33539066]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[-0.23571369  0.31358874 -0.10131413 ... -0.1688592   0.09648909\n",
            "   -0.33539066]\n",
            "  [-0.23571369  0.31358874 -0.10131413 ... -0.1688592   0.09648909\n",
            "   -0.33539066]\n",
            "  [-0.23571369  0.31358874 -0.10131413 ... -0.1688592   0.09648909\n",
            "   -0.33539066]\n",
            "  ...\n",
            "  [-0.23571369  0.31358874 -0.10131413 ... -0.1688592   0.09648909\n",
            "   -0.33539066]\n",
            "  [-0.23571369  0.31358874 -0.10131413 ... -0.1688592   0.09648909\n",
            "   -0.33539066]\n",
            "  [-0.23571369  0.31358874 -0.10131413 ... -0.1688592   0.09648909\n",
            "   -0.33539066]]\n",
            "\n",
            " [[-0.23571369  0.31358874 -0.10131413 ... -0.1688592   0.09648909\n",
            "   -0.33539066]\n",
            "  [-0.23571369  0.31358874 -0.10131413 ... -0.1688592   0.09648909\n",
            "   -0.33539066]\n",
            "  [-0.23571369  0.31358874 -0.10131413 ... -0.1688592   0.09648909\n",
            "   -0.33539066]\n",
            "  ...\n",
            "  [-0.23571369  0.31358874 -0.10131413 ... -0.1688592   0.09648909\n",
            "   -0.33539066]\n",
            "  [-0.23571369  0.31358874 -0.10131413 ... -0.1688592   0.09648909\n",
            "   -0.33539066]\n",
            "  [-0.23571369  0.31358874 -0.10131413 ... -0.1688592   0.09648909\n",
            "   -0.33539066]]\n",
            "\n",
            " [[-0.23571369  0.31358874 -0.10131413 ... -0.1688592   0.09648909\n",
            "   -0.33539066]\n",
            "  [-0.23571369  0.31358874 -0.10131413 ... -0.1688592   0.09648909\n",
            "   -0.33539066]\n",
            "  [-0.23571369  0.31358874 -0.10131413 ... -0.1688592   0.09648909\n",
            "   -0.33539066]\n",
            "  ...\n",
            "  [-0.23571369  0.31358874 -0.10131413 ... -0.1688592   0.09648909\n",
            "   -0.33539066]\n",
            "  [-0.23571369  0.31358874 -0.10131413 ... -0.1688592   0.09648909\n",
            "   -0.33539066]\n",
            "  [-0.23571369  0.31358874 -0.10131413 ... -0.1688592   0.09648909\n",
            "   -0.33539066]]], shape=(128, 764, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[0.27481934 0.27481934 0.27481934 ... 0.27481934 0.27481934 0.27481934]\n",
            " [0.27481934 0.27481934 0.27481934 ... 0.27481934 0.27481934 0.27481934]\n",
            " [0.27481934 0.27481934 0.27481934 ... 0.27481934 0.27481934 0.27481934]\n",
            " ...\n",
            " [0.27481934 0.27481934 0.27481934 ... 0.27481934 0.27481934 0.27481934]\n",
            " [0.27481934 0.27481934 0.27481934 ... 0.27481934 0.27481934 0.27481934]\n",
            " [0.27481934 0.27481934 0.27481934 ... 0.27481934 0.27481934 0.27481934]], shape=(512, 128), dtype=float32) tf.Tensor(\n",
            "[[0.27481934 0.27481934 0.27481934 ... 0.27481934 0.27481934 0.27481934]\n",
            " [0.27481934 0.27481934 0.27481934 ... 0.27481934 0.27481934 0.27481934]\n",
            " [0.27481934 0.27481934 0.27481934 ... 0.27481934 0.27481934 0.27481934]\n",
            " ...\n",
            " [0.27481934 0.27481934 0.27481934 ... 0.27481934 0.27481934 0.27481934]\n",
            " [0.27481934 0.27481934 0.27481934 ... 0.27481934 0.27481934 0.27481934]\n",
            " [0.27481934 0.27481934 0.27481934 ... 0.27481934 0.27481934 0.27481934]], shape=(252, 128), dtype=float32)\n",
            "(128, 764) (512, 1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_15/kernel:0', 'dense_15/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_15/kernel:0', 'dense_15/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch 1, Batch 31/100, Loss=2.35861e-01\n",
            "(1, 764, 1)\n",
            "tf.Tensor(\n",
            "[[[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " [[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " [[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " [[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " [[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]], shape=(128, 764, 1), dtype=float32) tf.Tensor(\n",
            "[[[-0.25813282  0.31834355 -0.10466422 ... -0.16217646  0.11695198\n",
            "   -0.33470204]\n",
            "  [-0.25813282  0.31834355 -0.10466422 ... -0.16217646  0.11695198\n",
            "   -0.33470204]\n",
            "  [-0.25813282  0.31834355 -0.10466422 ... -0.16217646  0.11695198\n",
            "   -0.33470204]\n",
            "  ...\n",
            "  [-0.25813282  0.31834355 -0.10466422 ... -0.16217646  0.11695198\n",
            "   -0.33470204]\n",
            "  [-0.25813282  0.31834355 -0.10466422 ... -0.16217646  0.11695198\n",
            "   -0.33470204]\n",
            "  [-0.25813282  0.31834355 -0.10466422 ... -0.16217646  0.11695198\n",
            "   -0.33470204]]\n",
            "\n",
            " [[-0.25813282  0.31834355 -0.10466422 ... -0.16217646  0.11695198\n",
            "   -0.33470204]\n",
            "  [-0.25813282  0.31834355 -0.10466422 ... -0.16217646  0.11695198\n",
            "   -0.33470204]\n",
            "  [-0.25813282  0.31834355 -0.10466422 ... -0.16217646  0.11695198\n",
            "   -0.33470204]\n",
            "  ...\n",
            "  [-0.25813282  0.31834355 -0.10466422 ... -0.16217646  0.11695198\n",
            "   -0.33470204]\n",
            "  [-0.25813282  0.31834355 -0.10466422 ... -0.16217646  0.11695198\n",
            "   -0.33470204]\n",
            "  [-0.25813282  0.31834355 -0.10466422 ... -0.16217646  0.11695198\n",
            "   -0.33470204]]\n",
            "\n",
            " [[-0.25813282  0.31834355 -0.10466422 ... -0.16217646  0.11695198\n",
            "   -0.33470204]\n",
            "  [-0.25813282  0.31834355 -0.10466422 ... -0.16217646  0.11695198\n",
            "   -0.33470204]\n",
            "  [-0.25813282  0.31834355 -0.10466422 ... -0.16217646  0.11695198\n",
            "   -0.33470204]\n",
            "  ...\n",
            "  [-0.25813282  0.31834355 -0.10466422 ... -0.16217646  0.11695198\n",
            "   -0.33470204]\n",
            "  [-0.25813282  0.31834355 -0.10466422 ... -0.16217646  0.11695198\n",
            "   -0.33470204]\n",
            "  [-0.25813282  0.31834355 -0.10466422 ... -0.16217646  0.11695198\n",
            "   -0.33470204]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[-0.25813282  0.31834355 -0.10466422 ... -0.16217646  0.11695198\n",
            "   -0.33470204]\n",
            "  [-0.25813282  0.31834355 -0.10466422 ... -0.16217646  0.11695198\n",
            "   -0.33470204]\n",
            "  [-0.25813282  0.31834355 -0.10466422 ... -0.16217646  0.11695198\n",
            "   -0.33470204]\n",
            "  ...\n",
            "  [-0.25813282  0.31834355 -0.10466422 ... -0.16217646  0.11695198\n",
            "   -0.33470204]\n",
            "  [-0.25813282  0.31834355 -0.10466422 ... -0.16217646  0.11695198\n",
            "   -0.33470204]\n",
            "  [-0.25813282  0.31834355 -0.10466422 ... -0.16217646  0.11695198\n",
            "   -0.33470204]]\n",
            "\n",
            " [[-0.25813282  0.31834355 -0.10466422 ... -0.16217646  0.11695198\n",
            "   -0.33470204]\n",
            "  [-0.25813282  0.31834355 -0.10466422 ... -0.16217646  0.11695198\n",
            "   -0.33470204]\n",
            "  [-0.25813282  0.31834355 -0.10466422 ... -0.16217646  0.11695198\n",
            "   -0.33470204]\n",
            "  ...\n",
            "  [-0.25813282  0.31834355 -0.10466422 ... -0.16217646  0.11695198\n",
            "   -0.33470204]\n",
            "  [-0.25813282  0.31834355 -0.10466422 ... -0.16217646  0.11695198\n",
            "   -0.33470204]\n",
            "  [-0.25813282  0.31834355 -0.10466422 ... -0.16217646  0.11695198\n",
            "   -0.33470204]]\n",
            "\n",
            " [[-0.25813282  0.31834355 -0.10466422 ... -0.16217646  0.11695198\n",
            "   -0.33470204]\n",
            "  [-0.25813282  0.31834355 -0.10466422 ... -0.16217646  0.11695198\n",
            "   -0.33470204]\n",
            "  [-0.25813282  0.31834355 -0.10466422 ... -0.16217646  0.11695198\n",
            "   -0.33470204]\n",
            "  ...\n",
            "  [-0.25813282  0.31834355 -0.10466422 ... -0.16217646  0.11695198\n",
            "   -0.33470204]\n",
            "  [-0.25813282  0.31834355 -0.10466422 ... -0.16217646  0.11695198\n",
            "   -0.33470204]\n",
            "  [-0.25813282  0.31834355 -0.10466422 ... -0.16217646  0.11695198\n",
            "   -0.33470204]]], shape=(128, 764, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[0.1830689 0.1830689 0.1830689 ... 0.1830689 0.1830689 0.1830689]\n",
            " [0.1830689 0.1830689 0.1830689 ... 0.1830689 0.1830689 0.1830689]\n",
            " [0.1830689 0.1830689 0.1830689 ... 0.1830689 0.1830689 0.1830689]\n",
            " ...\n",
            " [0.1830689 0.1830689 0.1830689 ... 0.1830689 0.1830689 0.1830689]\n",
            " [0.1830689 0.1830689 0.1830689 ... 0.1830689 0.1830689 0.1830689]\n",
            " [0.1830689 0.1830689 0.1830689 ... 0.1830689 0.1830689 0.1830689]], shape=(512, 128), dtype=float32) tf.Tensor(\n",
            "[[0.1830689 0.1830689 0.1830689 ... 0.1830689 0.1830689 0.1830689]\n",
            " [0.1830689 0.1830689 0.1830689 ... 0.1830689 0.1830689 0.1830689]\n",
            " [0.1830689 0.1830689 0.1830689 ... 0.1830689 0.1830689 0.1830689]\n",
            " ...\n",
            " [0.1830689 0.1830689 0.1830689 ... 0.1830689 0.1830689 0.1830689]\n",
            " [0.1830689 0.1830689 0.1830689 ... 0.1830689 0.1830689 0.1830689]\n",
            " [0.1830689 0.1830689 0.1830689 ... 0.1830689 0.1830689 0.1830689]], shape=(252, 128), dtype=float32)\n",
            "(128, 764) (512, 1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_15/kernel:0', 'dense_15/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_15/kernel:0', 'dense_15/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch 1, Batch 32/100, Loss=1.65188e-01\n",
            "(1, 764, 1)\n",
            "tf.Tensor(\n",
            "[[[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " [[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " [[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " [[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]], shape=(128, 764, 1), dtype=float32) tf.Tensor(\n",
            "[[[-0.28310505  0.32334623 -0.10986935 ... -0.15208407  0.14067808\n",
            "   -0.3371864 ]\n",
            "  [-0.28310505  0.32334623 -0.10986935 ... -0.15208407  0.14067808\n",
            "   -0.3371864 ]\n",
            "  [-0.28310505  0.32334623 -0.10986935 ... -0.15208407  0.14067808\n",
            "   -0.3371864 ]\n",
            "  ...\n",
            "  [-0.28310505  0.32334623 -0.10986935 ... -0.15208407  0.14067808\n",
            "   -0.3371864 ]\n",
            "  [-0.28310505  0.32334623 -0.10986935 ... -0.15208407  0.14067808\n",
            "   -0.3371864 ]\n",
            "  [-0.28310505  0.32334623 -0.10986935 ... -0.15208407  0.14067808\n",
            "   -0.3371864 ]]\n",
            "\n",
            " [[-0.28310505  0.32334623 -0.10986935 ... -0.15208407  0.14067808\n",
            "   -0.3371864 ]\n",
            "  [-0.28310505  0.32334623 -0.10986935 ... -0.15208407  0.14067808\n",
            "   -0.3371864 ]\n",
            "  [-0.28310505  0.32334623 -0.10986935 ... -0.15208407  0.14067808\n",
            "   -0.3371864 ]\n",
            "  ...\n",
            "  [-0.28310505  0.32334623 -0.10986935 ... -0.15208407  0.14067808\n",
            "   -0.3371864 ]\n",
            "  [-0.28310505  0.32334623 -0.10986935 ... -0.15208407  0.14067808\n",
            "   -0.3371864 ]\n",
            "  [-0.28310505  0.32334623 -0.10986935 ... -0.15208407  0.14067808\n",
            "   -0.3371864 ]]\n",
            "\n",
            " [[-0.28310505  0.32334623 -0.10986935 ... -0.15208407  0.14067808\n",
            "   -0.3371864 ]\n",
            "  [-0.28310505  0.32334623 -0.10986935 ... -0.15208407  0.14067808\n",
            "   -0.3371864 ]\n",
            "  [-0.28310505  0.32334623 -0.10986935 ... -0.15208407  0.14067808\n",
            "   -0.3371864 ]\n",
            "  ...\n",
            "  [-0.28310505  0.32334623 -0.10986935 ... -0.15208407  0.14067808\n",
            "   -0.3371864 ]\n",
            "  [-0.28310505  0.32334623 -0.10986935 ... -0.15208407  0.14067808\n",
            "   -0.3371864 ]\n",
            "  [-0.28310505  0.32334623 -0.10986935 ... -0.15208407  0.14067808\n",
            "   -0.3371864 ]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[-0.28310505  0.32334623 -0.10986935 ... -0.15208407  0.14067808\n",
            "   -0.3371864 ]\n",
            "  [-0.28310505  0.32334623 -0.10986935 ... -0.15208407  0.14067808\n",
            "   -0.3371864 ]\n",
            "  [-0.28310505  0.32334623 -0.10986935 ... -0.15208407  0.14067808\n",
            "   -0.3371864 ]\n",
            "  ...\n",
            "  [-0.28310505  0.32334623 -0.10986935 ... -0.15208407  0.14067808\n",
            "   -0.3371864 ]\n",
            "  [-0.28310505  0.32334623 -0.10986935 ... -0.15208407  0.14067808\n",
            "   -0.3371864 ]\n",
            "  [-0.28310505  0.32334623 -0.10986935 ... -0.15208407  0.14067808\n",
            "   -0.3371864 ]]\n",
            "\n",
            " [[-0.28310505  0.32334623 -0.10986935 ... -0.15208407  0.14067808\n",
            "   -0.3371864 ]\n",
            "  [-0.28310505  0.32334623 -0.10986935 ... -0.15208407  0.14067808\n",
            "   -0.3371864 ]\n",
            "  [-0.28310505  0.32334623 -0.10986935 ... -0.15208407  0.14067808\n",
            "   -0.3371864 ]\n",
            "  ...\n",
            "  [-0.28310505  0.32334623 -0.10986935 ... -0.15208407  0.14067808\n",
            "   -0.3371864 ]\n",
            "  [-0.28310505  0.32334623 -0.10986935 ... -0.15208407  0.14067808\n",
            "   -0.3371864 ]\n",
            "  [-0.28310505  0.32334623 -0.10986935 ... -0.15208407  0.14067808\n",
            "   -0.3371864 ]]\n",
            "\n",
            " [[-0.28310505  0.32334623 -0.10986935 ... -0.15208407  0.14067808\n",
            "   -0.3371864 ]\n",
            "  [-0.28310505  0.32334623 -0.10986935 ... -0.15208407  0.14067808\n",
            "   -0.3371864 ]\n",
            "  [-0.28310505  0.32334623 -0.10986935 ... -0.15208407  0.14067808\n",
            "   -0.3371864 ]\n",
            "  ...\n",
            "  [-0.28310505  0.32334623 -0.10986935 ... -0.15208407  0.14067808\n",
            "   -0.3371864 ]\n",
            "  [-0.28310505  0.32334623 -0.10986935 ... -0.15208407  0.14067808\n",
            "   -0.3371864 ]\n",
            "  [-0.28310505  0.32334623 -0.10986935 ... -0.15208407  0.14067808\n",
            "   -0.3371864 ]]], shape=(128, 764, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[0.06971166 0.06971166 0.06971166 ... 0.06971166 0.06971166 0.06971166]\n",
            " [0.06971166 0.06971166 0.06971166 ... 0.06971166 0.06971166 0.06971166]\n",
            " [0.06971166 0.06971166 0.06971166 ... 0.06971166 0.06971166 0.06971166]\n",
            " ...\n",
            " [0.06971166 0.06971166 0.06971166 ... 0.06971166 0.06971166 0.06971166]\n",
            " [0.06971166 0.06971166 0.06971166 ... 0.06971166 0.06971166 0.06971166]\n",
            " [0.06971166 0.06971166 0.06971166 ... 0.06971166 0.06971166 0.06971166]], shape=(512, 128), dtype=float32) tf.Tensor(\n",
            "[[0.06971166 0.06971166 0.06971166 ... 0.06971166 0.06971166 0.06971166]\n",
            " [0.06971166 0.06971166 0.06971166 ... 0.06971166 0.06971166 0.06971166]\n",
            " [0.06971166 0.06971166 0.06971166 ... 0.06971166 0.06971166 0.06971166]\n",
            " ...\n",
            " [0.06971166 0.06971166 0.06971166 ... 0.06971166 0.06971166 0.06971166]\n",
            " [0.06971166 0.06971166 0.06971166 ... 0.06971166 0.06971166 0.06971166]\n",
            " [0.06971166 0.06971166 0.06971166 ... 0.06971166 0.06971166 0.06971166]], shape=(252, 128), dtype=float32)\n",
            "(128, 764) (512, 1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_15/kernel:0', 'dense_15/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_15/kernel:0', 'dense_15/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch 1, Batch 33/100, Loss=6.61596e-02\n",
            "(1, 764, 1)\n",
            "tf.Tensor(\n",
            "[[[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " [[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]], shape=(128, 764, 1), dtype=float32) tf.Tensor(\n",
            "[[[-0.30733484  0.32808182 -0.11518873 ... -0.14176814  0.16390885\n",
            "   -0.34030765]\n",
            "  [-0.30733484  0.32808182 -0.11518873 ... -0.14176814  0.16390885\n",
            "   -0.34030765]\n",
            "  [-0.30733484  0.32808182 -0.11518873 ... -0.14176814  0.16390885\n",
            "   -0.34030765]\n",
            "  ...\n",
            "  [-0.30733484  0.32808182 -0.11518873 ... -0.14176814  0.16390885\n",
            "   -0.34030765]\n",
            "  [-0.30733484  0.32808182 -0.11518873 ... -0.14176814  0.16390885\n",
            "   -0.34030765]\n",
            "  [-0.30733484  0.32808182 -0.11518873 ... -0.14176814  0.16390885\n",
            "   -0.34030765]]\n",
            "\n",
            " [[-0.30733484  0.32808182 -0.11518873 ... -0.14176814  0.16390885\n",
            "   -0.34030765]\n",
            "  [-0.30733484  0.32808182 -0.11518873 ... -0.14176814  0.16390885\n",
            "   -0.34030765]\n",
            "  [-0.30733484  0.32808182 -0.11518873 ... -0.14176814  0.16390885\n",
            "   -0.34030765]\n",
            "  ...\n",
            "  [-0.30733484  0.32808182 -0.11518873 ... -0.14176814  0.16390885\n",
            "   -0.34030765]\n",
            "  [-0.30733484  0.32808182 -0.11518873 ... -0.14176814  0.16390885\n",
            "   -0.34030765]\n",
            "  [-0.30733484  0.32808182 -0.11518873 ... -0.14176814  0.16390885\n",
            "   -0.34030765]]\n",
            "\n",
            " [[-0.30733484  0.32808182 -0.11518873 ... -0.14176814  0.16390885\n",
            "   -0.34030765]\n",
            "  [-0.30733484  0.32808182 -0.11518873 ... -0.14176814  0.16390885\n",
            "   -0.34030765]\n",
            "  [-0.30733484  0.32808182 -0.11518873 ... -0.14176814  0.16390885\n",
            "   -0.34030765]\n",
            "  ...\n",
            "  [-0.30733484  0.32808182 -0.11518873 ... -0.14176814  0.16390885\n",
            "   -0.34030765]\n",
            "  [-0.30733484  0.32808182 -0.11518873 ... -0.14176814  0.16390885\n",
            "   -0.34030765]\n",
            "  [-0.30733484  0.32808182 -0.11518873 ... -0.14176814  0.16390885\n",
            "   -0.34030765]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[-0.30733484  0.32808182 -0.11518873 ... -0.14176814  0.16390885\n",
            "   -0.34030765]\n",
            "  [-0.30733484  0.32808182 -0.11518873 ... -0.14176814  0.16390885\n",
            "   -0.34030765]\n",
            "  [-0.30733484  0.32808182 -0.11518873 ... -0.14176814  0.16390885\n",
            "   -0.34030765]\n",
            "  ...\n",
            "  [-0.30733484  0.32808182 -0.11518873 ... -0.14176814  0.16390885\n",
            "   -0.34030765]\n",
            "  [-0.30733484  0.32808182 -0.11518873 ... -0.14176814  0.16390885\n",
            "   -0.34030765]\n",
            "  [-0.30733484  0.32808182 -0.11518873 ... -0.14176814  0.16390885\n",
            "   -0.34030765]]\n",
            "\n",
            " [[-0.30733484  0.32808182 -0.11518873 ... -0.14176814  0.16390885\n",
            "   -0.34030765]\n",
            "  [-0.30733484  0.32808182 -0.11518873 ... -0.14176814  0.16390885\n",
            "   -0.34030765]\n",
            "  [-0.30733484  0.32808182 -0.11518873 ... -0.14176814  0.16390885\n",
            "   -0.34030765]\n",
            "  ...\n",
            "  [-0.30733484  0.32808182 -0.11518873 ... -0.14176814  0.16390885\n",
            "   -0.34030765]\n",
            "  [-0.30733484  0.32808182 -0.11518873 ... -0.14176814  0.16390885\n",
            "   -0.34030765]\n",
            "  [-0.30733484  0.32808182 -0.11518873 ... -0.14176814  0.16390885\n",
            "   -0.34030765]]\n",
            "\n",
            " [[-0.30733484  0.32808182 -0.11518873 ... -0.14176814  0.16390885\n",
            "   -0.34030765]\n",
            "  [-0.30733484  0.32808182 -0.11518873 ... -0.14176814  0.16390885\n",
            "   -0.34030765]\n",
            "  [-0.30733484  0.32808182 -0.11518873 ... -0.14176814  0.16390885\n",
            "   -0.34030765]\n",
            "  ...\n",
            "  [-0.30733484  0.32808182 -0.11518873 ... -0.14176814  0.16390885\n",
            "   -0.34030765]\n",
            "  [-0.30733484  0.32808182 -0.11518873 ... -0.14176814  0.16390885\n",
            "   -0.34030765]\n",
            "  [-0.30733484  0.32808182 -0.11518873 ... -0.14176814  0.16390885\n",
            "   -0.34030765]]], shape=(128, 764, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.04286791 -0.04286791 -0.04286791 ... -0.04286791 -0.04286791\n",
            "  -0.04286791]\n",
            " [-0.04286791 -0.04286791 -0.04286791 ... -0.04286791 -0.04286791\n",
            "  -0.04286791]\n",
            " [-0.04286791 -0.04286791 -0.04286791 ... -0.04286791 -0.04286791\n",
            "  -0.04286791]\n",
            " ...\n",
            " [-0.04286791 -0.04286791 -0.04286791 ... -0.04286791 -0.04286791\n",
            "  -0.04286791]\n",
            " [-0.04286791 -0.04286791 -0.04286791 ... -0.04286791 -0.04286791\n",
            "  -0.04286791]\n",
            " [-0.04286791 -0.04286791 -0.04286791 ... -0.04286791 -0.04286791\n",
            "  -0.04286791]], shape=(512, 128), dtype=float32) tf.Tensor(\n",
            "[[-0.04286791 -0.04286791 -0.04286791 ... -0.04286791 -0.04286791\n",
            "  -0.04286791]\n",
            " [-0.04286791 -0.04286791 -0.04286791 ... -0.04286791 -0.04286791\n",
            "  -0.04286791]\n",
            " [-0.04286791 -0.04286791 -0.04286791 ... -0.04286791 -0.04286791\n",
            "  -0.04286791]\n",
            " ...\n",
            " [-0.04286791 -0.04286791 -0.04286791 ... -0.04286791 -0.04286791\n",
            "  -0.04286791]\n",
            " [-0.04286791 -0.04286791 -0.04286791 ... -0.04286791 -0.04286791\n",
            "  -0.04286791]\n",
            " [-0.04286791 -0.04286791 -0.04286791 ... -0.04286791 -0.04286791\n",
            "  -0.04286791]], shape=(252, 128), dtype=float32)\n",
            "(128, 764) (512, 1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_15/kernel:0', 'dense_15/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_15/kernel:0', 'dense_15/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch 1, Batch 34/100, Loss=4.98950e-02\n",
            "(1, 764, 1)\n",
            "tf.Tensor(\n",
            "[[[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " [[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " [[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]], shape=(128, 764, 1), dtype=float32) tf.Tensor(\n",
            "[[[-0.3287173   0.33222517 -0.11958167 ... -0.13306586  0.1842907\n",
            "   -0.34262207]\n",
            "  [-0.3287173   0.33222517 -0.11958167 ... -0.13306586  0.1842907\n",
            "   -0.34262207]\n",
            "  [-0.3287173   0.33222517 -0.11958167 ... -0.13306586  0.1842907\n",
            "   -0.34262207]\n",
            "  ...\n",
            "  [-0.3287173   0.33222517 -0.11958167 ... -0.13306586  0.1842907\n",
            "   -0.34262207]\n",
            "  [-0.3287173   0.33222517 -0.11958167 ... -0.13306586  0.1842907\n",
            "   -0.34262207]\n",
            "  [-0.3287173   0.33222517 -0.11958167 ... -0.13306586  0.1842907\n",
            "   -0.34262207]]\n",
            "\n",
            " [[-0.3287173   0.33222517 -0.11958167 ... -0.13306586  0.1842907\n",
            "   -0.34262207]\n",
            "  [-0.3287173   0.33222517 -0.11958167 ... -0.13306586  0.1842907\n",
            "   -0.34262207]\n",
            "  [-0.3287173   0.33222517 -0.11958167 ... -0.13306586  0.1842907\n",
            "   -0.34262207]\n",
            "  ...\n",
            "  [-0.3287173   0.33222517 -0.11958167 ... -0.13306586  0.1842907\n",
            "   -0.34262207]\n",
            "  [-0.3287173   0.33222517 -0.11958167 ... -0.13306586  0.1842907\n",
            "   -0.34262207]\n",
            "  [-0.3287173   0.33222517 -0.11958167 ... -0.13306586  0.1842907\n",
            "   -0.34262207]]\n",
            "\n",
            " [[-0.3287173   0.33222517 -0.11958167 ... -0.13306586  0.1842907\n",
            "   -0.34262207]\n",
            "  [-0.3287173   0.33222517 -0.11958167 ... -0.13306586  0.1842907\n",
            "   -0.34262207]\n",
            "  [-0.3287173   0.33222517 -0.11958167 ... -0.13306586  0.1842907\n",
            "   -0.34262207]\n",
            "  ...\n",
            "  [-0.3287173   0.33222517 -0.11958167 ... -0.13306586  0.1842907\n",
            "   -0.34262207]\n",
            "  [-0.3287173   0.33222517 -0.11958167 ... -0.13306586  0.1842907\n",
            "   -0.34262207]\n",
            "  [-0.3287173   0.33222517 -0.11958167 ... -0.13306586  0.1842907\n",
            "   -0.34262207]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[-0.3287173   0.33222517 -0.11958167 ... -0.13306586  0.1842907\n",
            "   -0.34262207]\n",
            "  [-0.3287173   0.33222517 -0.11958167 ... -0.13306586  0.1842907\n",
            "   -0.34262207]\n",
            "  [-0.3287173   0.33222517 -0.11958167 ... -0.13306586  0.1842907\n",
            "   -0.34262207]\n",
            "  ...\n",
            "  [-0.3287173   0.33222517 -0.11958167 ... -0.13306586  0.1842907\n",
            "   -0.34262207]\n",
            "  [-0.3287173   0.33222517 -0.11958167 ... -0.13306586  0.1842907\n",
            "   -0.34262207]\n",
            "  [-0.3287173   0.33222517 -0.11958167 ... -0.13306586  0.1842907\n",
            "   -0.34262207]]\n",
            "\n",
            " [[-0.3287173   0.33222517 -0.11958167 ... -0.13306586  0.1842907\n",
            "   -0.34262207]\n",
            "  [-0.3287173   0.33222517 -0.11958167 ... -0.13306586  0.1842907\n",
            "   -0.34262207]\n",
            "  [-0.3287173   0.33222517 -0.11958167 ... -0.13306586  0.1842907\n",
            "   -0.34262207]\n",
            "  ...\n",
            "  [-0.3287173   0.33222517 -0.11958167 ... -0.13306586  0.1842907\n",
            "   -0.34262207]\n",
            "  [-0.3287173   0.33222517 -0.11958167 ... -0.13306586  0.1842907\n",
            "   -0.34262207]\n",
            "  [-0.3287173   0.33222517 -0.11958167 ... -0.13306586  0.1842907\n",
            "   -0.34262207]]\n",
            "\n",
            " [[-0.3287173   0.33222517 -0.11958167 ... -0.13306586  0.1842907\n",
            "   -0.34262207]\n",
            "  [-0.3287173   0.33222517 -0.11958167 ... -0.13306586  0.1842907\n",
            "   -0.34262207]\n",
            "  [-0.3287173   0.33222517 -0.11958167 ... -0.13306586  0.1842907\n",
            "   -0.34262207]\n",
            "  ...\n",
            "  [-0.3287173   0.33222517 -0.11958167 ... -0.13306586  0.1842907\n",
            "   -0.34262207]\n",
            "  [-0.3287173   0.33222517 -0.11958167 ... -0.13306586  0.1842907\n",
            "   -0.34262207]\n",
            "  [-0.3287173   0.33222517 -0.11958167 ... -0.13306586  0.1842907\n",
            "   -0.34262207]]], shape=(128, 764, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.14126183 -0.14126183 -0.14126183 ... -0.14126183 -0.14126183\n",
            "  -0.14126183]\n",
            " [-0.14126183 -0.14126183 -0.14126183 ... -0.14126183 -0.14126183\n",
            "  -0.14126183]\n",
            " [-0.14126183 -0.14126183 -0.14126183 ... -0.14126183 -0.14126183\n",
            "  -0.14126183]\n",
            " ...\n",
            " [-0.14126183 -0.14126183 -0.14126183 ... -0.14126183 -0.14126183\n",
            "  -0.14126183]\n",
            " [-0.14126183 -0.14126183 -0.14126183 ... -0.14126183 -0.14126183\n",
            "  -0.14126183]\n",
            " [-0.14126183 -0.14126183 -0.14126183 ... -0.14126183 -0.14126183\n",
            "  -0.14126183]], shape=(512, 128), dtype=float32) tf.Tensor(\n",
            "[[-0.14126183 -0.14126183 -0.14126183 ... -0.14126183 -0.14126183\n",
            "  -0.14126183]\n",
            " [-0.14126183 -0.14126183 -0.14126183 ... -0.14126183 -0.14126183\n",
            "  -0.14126183]\n",
            " [-0.14126183 -0.14126183 -0.14126183 ... -0.14126183 -0.14126183\n",
            "  -0.14126183]\n",
            " ...\n",
            " [-0.14126183 -0.14126183 -0.14126183 ... -0.14126183 -0.14126183\n",
            "  -0.14126183]\n",
            " [-0.14126183 -0.14126183 -0.14126183 ... -0.14126183 -0.14126183\n",
            "  -0.14126183]\n",
            " [-0.14126183 -0.14126183 -0.14126183 ... -0.14126183 -0.14126183\n",
            "  -0.14126183]], shape=(252, 128), dtype=float32)\n",
            "(128, 764) (512, 1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_15/kernel:0', 'dense_15/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_15/kernel:0', 'dense_15/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch 1, Batch 35/100, Loss=6.24966e-02\n",
            "(1, 764, 1)\n",
            "tf.Tensor(\n",
            "[[[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]], shape=(128, 764, 1), dtype=float32) tf.Tensor(\n",
            "[[[-0.34514722  0.33548245 -0.12168847 ... -0.12804498  0.19953994\n",
            "   -0.34237507]\n",
            "  [-0.34514722  0.33548245 -0.12168847 ... -0.12804498  0.19953994\n",
            "   -0.34237507]\n",
            "  [-0.34514722  0.33548245 -0.12168847 ... -0.12804498  0.19953994\n",
            "   -0.34237507]\n",
            "  ...\n",
            "  [-0.34514722  0.33548245 -0.12168847 ... -0.12804498  0.19953994\n",
            "   -0.34237507]\n",
            "  [-0.34514722  0.33548245 -0.12168847 ... -0.12804498  0.19953994\n",
            "   -0.34237507]\n",
            "  [-0.34514722  0.33548245 -0.12168847 ... -0.12804498  0.19953994\n",
            "   -0.34237507]]\n",
            "\n",
            " [[-0.34514722  0.33548245 -0.12168847 ... -0.12804498  0.19953994\n",
            "   -0.34237507]\n",
            "  [-0.34514722  0.33548245 -0.12168847 ... -0.12804498  0.19953994\n",
            "   -0.34237507]\n",
            "  [-0.34514722  0.33548245 -0.12168847 ... -0.12804498  0.19953994\n",
            "   -0.34237507]\n",
            "  ...\n",
            "  [-0.34514722  0.33548245 -0.12168847 ... -0.12804498  0.19953994\n",
            "   -0.34237507]\n",
            "  [-0.34514722  0.33548245 -0.12168847 ... -0.12804498  0.19953994\n",
            "   -0.34237507]\n",
            "  [-0.34514722  0.33548245 -0.12168847 ... -0.12804498  0.19953994\n",
            "   -0.34237507]]\n",
            "\n",
            " [[-0.34514722  0.33548245 -0.12168847 ... -0.12804498  0.19953994\n",
            "   -0.34237507]\n",
            "  [-0.34514722  0.33548245 -0.12168847 ... -0.12804498  0.19953994\n",
            "   -0.34237507]\n",
            "  [-0.34514722  0.33548245 -0.12168847 ... -0.12804498  0.19953994\n",
            "   -0.34237507]\n",
            "  ...\n",
            "  [-0.34514722  0.33548245 -0.12168847 ... -0.12804498  0.19953994\n",
            "   -0.34237507]\n",
            "  [-0.34514722  0.33548245 -0.12168847 ... -0.12804498  0.19953994\n",
            "   -0.34237507]\n",
            "  [-0.34514722  0.33548245 -0.12168847 ... -0.12804498  0.19953994\n",
            "   -0.34237507]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[-0.34514722  0.33548245 -0.12168847 ... -0.12804498  0.19953994\n",
            "   -0.34237507]\n",
            "  [-0.34514722  0.33548245 -0.12168847 ... -0.12804498  0.19953994\n",
            "   -0.34237507]\n",
            "  [-0.34514722  0.33548245 -0.12168847 ... -0.12804498  0.19953994\n",
            "   -0.34237507]\n",
            "  ...\n",
            "  [-0.34514722  0.33548245 -0.12168847 ... -0.12804498  0.19953994\n",
            "   -0.34237507]\n",
            "  [-0.34514722  0.33548245 -0.12168847 ... -0.12804498  0.19953994\n",
            "   -0.34237507]\n",
            "  [-0.34514722  0.33548245 -0.12168847 ... -0.12804498  0.19953994\n",
            "   -0.34237507]]\n",
            "\n",
            " [[-0.34514722  0.33548245 -0.12168847 ... -0.12804498  0.19953994\n",
            "   -0.34237507]\n",
            "  [-0.34514722  0.33548245 -0.12168847 ... -0.12804498  0.19953994\n",
            "   -0.34237507]\n",
            "  [-0.34514722  0.33548245 -0.12168847 ... -0.12804498  0.19953994\n",
            "   -0.34237507]\n",
            "  ...\n",
            "  [-0.34514722  0.33548245 -0.12168847 ... -0.12804498  0.19953994\n",
            "   -0.34237507]\n",
            "  [-0.34514722  0.33548245 -0.12168847 ... -0.12804498  0.19953994\n",
            "   -0.34237507]\n",
            "  [-0.34514722  0.33548245 -0.12168847 ... -0.12804498  0.19953994\n",
            "   -0.34237507]]\n",
            "\n",
            " [[-0.34514722  0.33548245 -0.12168847 ... -0.12804498  0.19953994\n",
            "   -0.34237507]\n",
            "  [-0.34514722  0.33548245 -0.12168847 ... -0.12804498  0.19953994\n",
            "   -0.34237507]\n",
            "  [-0.34514722  0.33548245 -0.12168847 ... -0.12804498  0.19953994\n",
            "   -0.34237507]\n",
            "  ...\n",
            "  [-0.34514722  0.33548245 -0.12168847 ... -0.12804498  0.19953994\n",
            "   -0.34237507]\n",
            "  [-0.34514722  0.33548245 -0.12168847 ... -0.12804498  0.19953994\n",
            "   -0.34237507]\n",
            "  [-0.34514722  0.33548245 -0.12168847 ... -0.12804498  0.19953994\n",
            "   -0.34237507]]], shape=(128, 764, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.21101639 -0.21101639 -0.21101639 ... -0.21101639 -0.21101639\n",
            "  -0.21101639]\n",
            " [-0.21101639 -0.21101639 -0.21101639 ... -0.21101639 -0.21101639\n",
            "  -0.21101639]\n",
            " [-0.21101639 -0.21101639 -0.21101639 ... -0.21101639 -0.21101639\n",
            "  -0.21101639]\n",
            " ...\n",
            " [-0.21101639 -0.21101639 -0.21101639 ... -0.21101639 -0.21101639\n",
            "  -0.21101639]\n",
            " [-0.21101639 -0.21101639 -0.21101639 ... -0.21101639 -0.21101639\n",
            "  -0.21101639]\n",
            " [-0.21101639 -0.21101639 -0.21101639 ... -0.21101639 -0.21101639\n",
            "  -0.21101639]], shape=(512, 128), dtype=float32) tf.Tensor(\n",
            "[[-0.21101639 -0.21101639 -0.21101639 ... -0.21101639 -0.21101639\n",
            "  -0.21101639]\n",
            " [-0.21101639 -0.21101639 -0.21101639 ... -0.21101639 -0.21101639\n",
            "  -0.21101639]\n",
            " [-0.21101639 -0.21101639 -0.21101639 ... -0.21101639 -0.21101639\n",
            "  -0.21101639]\n",
            " ...\n",
            " [-0.21101639 -0.21101639 -0.21101639 ... -0.21101639 -0.21101639\n",
            "  -0.21101639]\n",
            " [-0.21101639 -0.21101639 -0.21101639 ... -0.21101639 -0.21101639\n",
            "  -0.21101639]\n",
            " [-0.21101639 -0.21101639 -0.21101639 ... -0.21101639 -0.21101639\n",
            "  -0.21101639]], shape=(252, 128), dtype=float32)\n",
            "(128, 764) (512, 1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_15/kernel:0', 'dense_15/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_15/kernel:0', 'dense_15/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch 1, Batch 36/100, Loss=9.19699e-02\n",
            "(1, 764, 1)\n",
            "tf.Tensor(\n",
            "[[[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " [[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " [[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]], shape=(128, 764, 1), dtype=float32) tf.Tensor(\n",
            "[[[-0.35552552  0.33773586 -0.12053119 ... -0.12790504  0.20851947\n",
            "   -0.3384166 ]\n",
            "  [-0.35552552  0.33773586 -0.12053119 ... -0.12790504  0.20851947\n",
            "   -0.3384166 ]\n",
            "  [-0.35552552  0.33773586 -0.12053119 ... -0.12790504  0.20851947\n",
            "   -0.3384166 ]\n",
            "  ...\n",
            "  [-0.35552552  0.33773586 -0.12053119 ... -0.12790504  0.20851947\n",
            "   -0.3384166 ]\n",
            "  [-0.35552552  0.33773586 -0.12053119 ... -0.12790504  0.20851947\n",
            "   -0.3384166 ]\n",
            "  [-0.35552552  0.33773586 -0.12053119 ... -0.12790504  0.20851947\n",
            "   -0.3384166 ]]\n",
            "\n",
            " [[-0.35552552  0.33773586 -0.12053119 ... -0.12790504  0.20851947\n",
            "   -0.3384166 ]\n",
            "  [-0.35552552  0.33773586 -0.12053119 ... -0.12790504  0.20851947\n",
            "   -0.3384166 ]\n",
            "  [-0.35552552  0.33773586 -0.12053119 ... -0.12790504  0.20851947\n",
            "   -0.3384166 ]\n",
            "  ...\n",
            "  [-0.35552552  0.33773586 -0.12053119 ... -0.12790504  0.20851947\n",
            "   -0.3384166 ]\n",
            "  [-0.35552552  0.33773586 -0.12053119 ... -0.12790504  0.20851947\n",
            "   -0.3384166 ]\n",
            "  [-0.35552552  0.33773586 -0.12053119 ... -0.12790504  0.20851947\n",
            "   -0.3384166 ]]\n",
            "\n",
            " [[-0.35552552  0.33773586 -0.12053119 ... -0.12790504  0.20851947\n",
            "   -0.3384166 ]\n",
            "  [-0.35552552  0.33773586 -0.12053119 ... -0.12790504  0.20851947\n",
            "   -0.3384166 ]\n",
            "  [-0.35552552  0.33773586 -0.12053119 ... -0.12790504  0.20851947\n",
            "   -0.3384166 ]\n",
            "  ...\n",
            "  [-0.35552552  0.33773586 -0.12053119 ... -0.12790504  0.20851947\n",
            "   -0.3384166 ]\n",
            "  [-0.35552552  0.33773586 -0.12053119 ... -0.12790504  0.20851947\n",
            "   -0.3384166 ]\n",
            "  [-0.35552552  0.33773586 -0.12053119 ... -0.12790504  0.20851947\n",
            "   -0.3384166 ]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[-0.35552552  0.33773586 -0.12053119 ... -0.12790504  0.20851947\n",
            "   -0.3384166 ]\n",
            "  [-0.35552552  0.33773586 -0.12053119 ... -0.12790504  0.20851947\n",
            "   -0.3384166 ]\n",
            "  [-0.35552552  0.33773586 -0.12053119 ... -0.12790504  0.20851947\n",
            "   -0.3384166 ]\n",
            "  ...\n",
            "  [-0.35552552  0.33773586 -0.12053119 ... -0.12790504  0.20851947\n",
            "   -0.3384166 ]\n",
            "  [-0.35552552  0.33773586 -0.12053119 ... -0.12790504  0.20851947\n",
            "   -0.3384166 ]\n",
            "  [-0.35552552  0.33773586 -0.12053119 ... -0.12790504  0.20851947\n",
            "   -0.3384166 ]]\n",
            "\n",
            " [[-0.35552552  0.33773586 -0.12053119 ... -0.12790504  0.20851947\n",
            "   -0.3384166 ]\n",
            "  [-0.35552552  0.33773586 -0.12053119 ... -0.12790504  0.20851947\n",
            "   -0.3384166 ]\n",
            "  [-0.35552552  0.33773586 -0.12053119 ... -0.12790504  0.20851947\n",
            "   -0.3384166 ]\n",
            "  ...\n",
            "  [-0.35552552  0.33773586 -0.12053119 ... -0.12790504  0.20851947\n",
            "   -0.3384166 ]\n",
            "  [-0.35552552  0.33773586 -0.12053119 ... -0.12790504  0.20851947\n",
            "   -0.3384166 ]\n",
            "  [-0.35552552  0.33773586 -0.12053119 ... -0.12790504  0.20851947\n",
            "   -0.3384166 ]]\n",
            "\n",
            " [[-0.35552552  0.33773586 -0.12053119 ... -0.12790504  0.20851947\n",
            "   -0.3384166 ]\n",
            "  [-0.35552552  0.33773586 -0.12053119 ... -0.12790504  0.20851947\n",
            "   -0.3384166 ]\n",
            "  [-0.35552552  0.33773586 -0.12053119 ... -0.12790504  0.20851947\n",
            "   -0.3384166 ]\n",
            "  ...\n",
            "  [-0.35552552  0.33773586 -0.12053119 ... -0.12790504  0.20851947\n",
            "   -0.3384166 ]\n",
            "  [-0.35552552  0.33773586 -0.12053119 ... -0.12790504  0.20851947\n",
            "   -0.3384166 ]\n",
            "  [-0.35552552  0.33773586 -0.12053119 ... -0.12790504  0.20851947\n",
            "   -0.3384166 ]]], shape=(128, 764, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.24387203 -0.24387203 -0.24387203 ... -0.24387203 -0.24387203\n",
            "  -0.24387203]\n",
            " [-0.24387203 -0.24387203 -0.24387203 ... -0.24387203 -0.24387203\n",
            "  -0.24387203]\n",
            " [-0.24387203 -0.24387203 -0.24387203 ... -0.24387203 -0.24387203\n",
            "  -0.24387203]\n",
            " ...\n",
            " [-0.24387203 -0.24387203 -0.24387203 ... -0.24387203 -0.24387203\n",
            "  -0.24387203]\n",
            " [-0.24387203 -0.24387203 -0.24387203 ... -0.24387203 -0.24387203\n",
            "  -0.24387203]\n",
            " [-0.24387203 -0.24387203 -0.24387203 ... -0.24387203 -0.24387203\n",
            "  -0.24387203]], shape=(512, 128), dtype=float32) tf.Tensor(\n",
            "[[-0.24387203 -0.24387203 -0.24387203 ... -0.24387203 -0.24387203\n",
            "  -0.24387203]\n",
            " [-0.24387203 -0.24387203 -0.24387203 ... -0.24387203 -0.24387203\n",
            "  -0.24387203]\n",
            " [-0.24387203 -0.24387203 -0.24387203 ... -0.24387203 -0.24387203\n",
            "  -0.24387203]\n",
            " ...\n",
            " [-0.24387203 -0.24387203 -0.24387203 ... -0.24387203 -0.24387203\n",
            "  -0.24387203]\n",
            " [-0.24387203 -0.24387203 -0.24387203 ... -0.24387203 -0.24387203\n",
            "  -0.24387203]\n",
            " [-0.24387203 -0.24387203 -0.24387203 ... -0.24387203 -0.24387203\n",
            "  -0.24387203]], shape=(252, 128), dtype=float32)\n",
            "(128, 764) (512, 1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_15/kernel:0', 'dense_15/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_15/kernel:0', 'dense_15/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch 1, Batch 37/100, Loss=1.11011e-01\n",
            "(1, 764, 1)\n",
            "tf.Tensor(\n",
            "[[[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " [[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " [[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]], shape=(128, 764, 1), dtype=float32) tf.Tensor(\n",
            "[[[-0.3595831   0.33899304 -0.11554202 ... -0.13303031  0.21101986\n",
            "   -0.3301917 ]\n",
            "  [-0.3595831   0.33899304 -0.11554202 ... -0.13303031  0.21101986\n",
            "   -0.3301917 ]\n",
            "  [-0.3595831   0.33899304 -0.11554202 ... -0.13303031  0.21101986\n",
            "   -0.3301917 ]\n",
            "  ...\n",
            "  [-0.3595831   0.33899304 -0.11554202 ... -0.13303031  0.21101986\n",
            "   -0.3301917 ]\n",
            "  [-0.3595831   0.33899304 -0.11554202 ... -0.13303031  0.21101986\n",
            "   -0.3301917 ]\n",
            "  [-0.3595831   0.33899304 -0.11554202 ... -0.13303031  0.21101986\n",
            "   -0.3301917 ]]\n",
            "\n",
            " [[-0.3595831   0.33899304 -0.11554202 ... -0.13303031  0.21101986\n",
            "   -0.3301917 ]\n",
            "  [-0.3595831   0.33899304 -0.11554202 ... -0.13303031  0.21101986\n",
            "   -0.3301917 ]\n",
            "  [-0.3595831   0.33899304 -0.11554202 ... -0.13303031  0.21101986\n",
            "   -0.3301917 ]\n",
            "  ...\n",
            "  [-0.3595831   0.33899304 -0.11554202 ... -0.13303031  0.21101986\n",
            "   -0.3301917 ]\n",
            "  [-0.3595831   0.33899304 -0.11554202 ... -0.13303031  0.21101986\n",
            "   -0.3301917 ]\n",
            "  [-0.3595831   0.33899304 -0.11554202 ... -0.13303031  0.21101986\n",
            "   -0.3301917 ]]\n",
            "\n",
            " [[-0.3595831   0.33899304 -0.11554202 ... -0.13303031  0.21101986\n",
            "   -0.3301917 ]\n",
            "  [-0.3595831   0.33899304 -0.11554202 ... -0.13303031  0.21101986\n",
            "   -0.3301917 ]\n",
            "  [-0.3595831   0.33899304 -0.11554202 ... -0.13303031  0.21101986\n",
            "   -0.3301917 ]\n",
            "  ...\n",
            "  [-0.3595831   0.33899304 -0.11554202 ... -0.13303031  0.21101986\n",
            "   -0.3301917 ]\n",
            "  [-0.3595831   0.33899304 -0.11554202 ... -0.13303031  0.21101986\n",
            "   -0.3301917 ]\n",
            "  [-0.3595831   0.33899304 -0.11554202 ... -0.13303031  0.21101986\n",
            "   -0.3301917 ]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[-0.3595831   0.33899304 -0.11554202 ... -0.13303031  0.21101986\n",
            "   -0.3301917 ]\n",
            "  [-0.3595831   0.33899304 -0.11554202 ... -0.13303031  0.21101986\n",
            "   -0.3301917 ]\n",
            "  [-0.3595831   0.33899304 -0.11554202 ... -0.13303031  0.21101986\n",
            "   -0.3301917 ]\n",
            "  ...\n",
            "  [-0.3595831   0.33899304 -0.11554202 ... -0.13303031  0.21101986\n",
            "   -0.3301917 ]\n",
            "  [-0.3595831   0.33899304 -0.11554202 ... -0.13303031  0.21101986\n",
            "   -0.3301917 ]\n",
            "  [-0.3595831   0.33899304 -0.11554202 ... -0.13303031  0.21101986\n",
            "   -0.3301917 ]]\n",
            "\n",
            " [[-0.3595831   0.33899304 -0.11554202 ... -0.13303031  0.21101986\n",
            "   -0.3301917 ]\n",
            "  [-0.3595831   0.33899304 -0.11554202 ... -0.13303031  0.21101986\n",
            "   -0.3301917 ]\n",
            "  [-0.3595831   0.33899304 -0.11554202 ... -0.13303031  0.21101986\n",
            "   -0.3301917 ]\n",
            "  ...\n",
            "  [-0.3595831   0.33899304 -0.11554202 ... -0.13303031  0.21101986\n",
            "   -0.3301917 ]\n",
            "  [-0.3595831   0.33899304 -0.11554202 ... -0.13303031  0.21101986\n",
            "   -0.3301917 ]\n",
            "  [-0.3595831   0.33899304 -0.11554202 ... -0.13303031  0.21101986\n",
            "   -0.3301917 ]]\n",
            "\n",
            " [[-0.3595831   0.33899304 -0.11554202 ... -0.13303031  0.21101986\n",
            "   -0.3301917 ]\n",
            "  [-0.3595831   0.33899304 -0.11554202 ... -0.13303031  0.21101986\n",
            "   -0.3301917 ]\n",
            "  [-0.3595831   0.33899304 -0.11554202 ... -0.13303031  0.21101986\n",
            "   -0.3301917 ]\n",
            "  ...\n",
            "  [-0.3595831   0.33899304 -0.11554202 ... -0.13303031  0.21101986\n",
            "   -0.3301917 ]\n",
            "  [-0.3595831   0.33899304 -0.11554202 ... -0.13303031  0.21101986\n",
            "   -0.3301917 ]\n",
            "  [-0.3595831   0.33899304 -0.11554202 ... -0.13303031  0.21101986\n",
            "   -0.3301917 ]]], shape=(128, 764, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.2371008 -0.2371008 -0.2371008 ... -0.2371008 -0.2371008 -0.2371008]\n",
            " [-0.2371008 -0.2371008 -0.2371008 ... -0.2371008 -0.2371008 -0.2371008]\n",
            " [-0.2371008 -0.2371008 -0.2371008 ... -0.2371008 -0.2371008 -0.2371008]\n",
            " ...\n",
            " [-0.2371008 -0.2371008 -0.2371008 ... -0.2371008 -0.2371008 -0.2371008]\n",
            " [-0.2371008 -0.2371008 -0.2371008 ... -0.2371008 -0.2371008 -0.2371008]\n",
            " [-0.2371008 -0.2371008 -0.2371008 ... -0.2371008 -0.2371008 -0.2371008]], shape=(512, 128), dtype=float32) tf.Tensor(\n",
            "[[-0.2371008 -0.2371008 -0.2371008 ... -0.2371008 -0.2371008 -0.2371008]\n",
            " [-0.2371008 -0.2371008 -0.2371008 ... -0.2371008 -0.2371008 -0.2371008]\n",
            " [-0.2371008 -0.2371008 -0.2371008 ... -0.2371008 -0.2371008 -0.2371008]\n",
            " ...\n",
            " [-0.2371008 -0.2371008 -0.2371008 ... -0.2371008 -0.2371008 -0.2371008]\n",
            " [-0.2371008 -0.2371008 -0.2371008 ... -0.2371008 -0.2371008 -0.2371008]\n",
            " [-0.2371008 -0.2371008 -0.2371008 ... -0.2371008 -0.2371008 -0.2371008]], shape=(252, 128), dtype=float32)\n",
            "(128, 764) (512, 1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_15/kernel:0', 'dense_15/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_15/kernel:0', 'dense_15/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch 1, Batch 38/100, Loss=1.00004e-01\n",
            "(1, 764, 1)\n",
            "tf.Tensor(\n",
            "[[[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " [[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " [[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " [[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " [[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]], shape=(128, 764, 1), dtype=float32) tf.Tensor(\n",
            "[[[-0.35827282  0.33940583 -0.10700778 ... -0.14257729  0.20812412\n",
            "   -0.3182018 ]\n",
            "  [-0.35827282  0.33940583 -0.10700778 ... -0.14257729  0.20812412\n",
            "   -0.3182018 ]\n",
            "  [-0.35827282  0.33940583 -0.10700778 ... -0.14257729  0.20812412\n",
            "   -0.3182018 ]\n",
            "  ...\n",
            "  [-0.35827282  0.33940583 -0.10700778 ... -0.14257729  0.20812412\n",
            "   -0.3182018 ]\n",
            "  [-0.35827282  0.33940583 -0.10700778 ... -0.14257729  0.20812412\n",
            "   -0.3182018 ]\n",
            "  [-0.35827282  0.33940583 -0.10700778 ... -0.14257729  0.20812412\n",
            "   -0.3182018 ]]\n",
            "\n",
            " [[-0.35827282  0.33940583 -0.10700778 ... -0.14257729  0.20812412\n",
            "   -0.3182018 ]\n",
            "  [-0.35827282  0.33940583 -0.10700778 ... -0.14257729  0.20812412\n",
            "   -0.3182018 ]\n",
            "  [-0.35827282  0.33940583 -0.10700778 ... -0.14257729  0.20812412\n",
            "   -0.3182018 ]\n",
            "  ...\n",
            "  [-0.35827282  0.33940583 -0.10700778 ... -0.14257729  0.20812412\n",
            "   -0.3182018 ]\n",
            "  [-0.35827282  0.33940583 -0.10700778 ... -0.14257729  0.20812412\n",
            "   -0.3182018 ]\n",
            "  [-0.35827282  0.33940583 -0.10700778 ... -0.14257729  0.20812412\n",
            "   -0.3182018 ]]\n",
            "\n",
            " [[-0.35827282  0.33940583 -0.10700778 ... -0.14257729  0.20812412\n",
            "   -0.3182018 ]\n",
            "  [-0.35827282  0.33940583 -0.10700778 ... -0.14257729  0.20812412\n",
            "   -0.3182018 ]\n",
            "  [-0.35827282  0.33940583 -0.10700778 ... -0.14257729  0.20812412\n",
            "   -0.3182018 ]\n",
            "  ...\n",
            "  [-0.35827282  0.33940583 -0.10700778 ... -0.14257729  0.20812412\n",
            "   -0.3182018 ]\n",
            "  [-0.35827282  0.33940583 -0.10700778 ... -0.14257729  0.20812412\n",
            "   -0.3182018 ]\n",
            "  [-0.35827282  0.33940583 -0.10700778 ... -0.14257729  0.20812412\n",
            "   -0.3182018 ]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[-0.35827282  0.33940583 -0.10700778 ... -0.14257729  0.20812412\n",
            "   -0.3182018 ]\n",
            "  [-0.35827282  0.33940583 -0.10700778 ... -0.14257729  0.20812412\n",
            "   -0.3182018 ]\n",
            "  [-0.35827282  0.33940583 -0.10700778 ... -0.14257729  0.20812412\n",
            "   -0.3182018 ]\n",
            "  ...\n",
            "  [-0.35827282  0.33940583 -0.10700778 ... -0.14257729  0.20812412\n",
            "   -0.3182018 ]\n",
            "  [-0.35827282  0.33940583 -0.10700778 ... -0.14257729  0.20812412\n",
            "   -0.3182018 ]\n",
            "  [-0.35827282  0.33940583 -0.10700778 ... -0.14257729  0.20812412\n",
            "   -0.3182018 ]]\n",
            "\n",
            " [[-0.35827282  0.33940583 -0.10700778 ... -0.14257729  0.20812412\n",
            "   -0.3182018 ]\n",
            "  [-0.35827282  0.33940583 -0.10700778 ... -0.14257729  0.20812412\n",
            "   -0.3182018 ]\n",
            "  [-0.35827282  0.33940583 -0.10700778 ... -0.14257729  0.20812412\n",
            "   -0.3182018 ]\n",
            "  ...\n",
            "  [-0.35827282  0.33940583 -0.10700778 ... -0.14257729  0.20812412\n",
            "   -0.3182018 ]\n",
            "  [-0.35827282  0.33940583 -0.10700778 ... -0.14257729  0.20812412\n",
            "   -0.3182018 ]\n",
            "  [-0.35827282  0.33940583 -0.10700778 ... -0.14257729  0.20812412\n",
            "   -0.3182018 ]]\n",
            "\n",
            " [[-0.35827282  0.33940583 -0.10700778 ... -0.14257729  0.20812412\n",
            "   -0.3182018 ]\n",
            "  [-0.35827282  0.33940583 -0.10700778 ... -0.14257729  0.20812412\n",
            "   -0.3182018 ]\n",
            "  [-0.35827282  0.33940583 -0.10700778 ... -0.14257729  0.20812412\n",
            "   -0.3182018 ]\n",
            "  ...\n",
            "  [-0.35827282  0.33940583 -0.10700778 ... -0.14257729  0.20812412\n",
            "   -0.3182018 ]\n",
            "  [-0.35827282  0.33940583 -0.10700778 ... -0.14257729  0.20812412\n",
            "   -0.3182018 ]\n",
            "  [-0.35827282  0.33940583 -0.10700778 ... -0.14257729  0.20812412\n",
            "   -0.3182018 ]]], shape=(128, 764, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.19664055 -0.19664055 -0.19664055 ... -0.19664055 -0.19664055\n",
            "  -0.19664055]\n",
            " [-0.19664055 -0.19664055 -0.19664055 ... -0.19664055 -0.19664055\n",
            "  -0.19664055]\n",
            " [-0.19664055 -0.19664055 -0.19664055 ... -0.19664055 -0.19664055\n",
            "  -0.19664055]\n",
            " ...\n",
            " [-0.19664055 -0.19664055 -0.19664055 ... -0.19664055 -0.19664055\n",
            "  -0.19664055]\n",
            " [-0.19664055 -0.19664055 -0.19664055 ... -0.19664055 -0.19664055\n",
            "  -0.19664055]\n",
            " [-0.19664055 -0.19664055 -0.19664055 ... -0.19664055 -0.19664055\n",
            "  -0.19664055]], shape=(512, 128), dtype=float32) tf.Tensor(\n",
            "[[-0.19664055 -0.19664055 -0.19664055 ... -0.19664055 -0.19664055\n",
            "  -0.19664055]\n",
            " [-0.19664055 -0.19664055 -0.19664055 ... -0.19664055 -0.19664055\n",
            "  -0.19664055]\n",
            " [-0.19664055 -0.19664055 -0.19664055 ... -0.19664055 -0.19664055\n",
            "  -0.19664055]\n",
            " ...\n",
            " [-0.19664055 -0.19664055 -0.19664055 ... -0.19664055 -0.19664055\n",
            "  -0.19664055]\n",
            " [-0.19664055 -0.19664055 -0.19664055 ... -0.19664055 -0.19664055\n",
            "  -0.19664055]\n",
            " [-0.19664055 -0.19664055 -0.19664055 ... -0.19664055 -0.19664055\n",
            "  -0.19664055]], shape=(252, 128), dtype=float32)\n",
            "(128, 764) (512, 1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_15/kernel:0', 'dense_15/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_15/kernel:0', 'dense_15/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch 1, Batch 39/100, Loss=7.01803e-02\n",
            "(1, 764, 1)\n",
            "tf.Tensor(\n",
            "[[[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " [[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " [[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]], shape=(128, 764, 1), dtype=float32) tf.Tensor(\n",
            "[[[-0.3532002   0.33918577 -0.09591661 ... -0.15497418  0.20158371\n",
            "   -0.30369684]\n",
            "  [-0.3532002   0.33918577 -0.09591661 ... -0.15497418  0.20158371\n",
            "   -0.30369684]\n",
            "  [-0.3532002   0.33918577 -0.09591661 ... -0.15497418  0.20158371\n",
            "   -0.30369684]\n",
            "  ...\n",
            "  [-0.3532002   0.33918577 -0.09591661 ... -0.15497418  0.20158371\n",
            "   -0.30369684]\n",
            "  [-0.3532002   0.33918577 -0.09591661 ... -0.15497418  0.20158371\n",
            "   -0.30369684]\n",
            "  [-0.3532002   0.33918577 -0.09591661 ... -0.15497418  0.20158371\n",
            "   -0.30369684]]\n",
            "\n",
            " [[-0.3532002   0.33918577 -0.09591661 ... -0.15497418  0.20158371\n",
            "   -0.30369684]\n",
            "  [-0.3532002   0.33918577 -0.09591661 ... -0.15497418  0.20158371\n",
            "   -0.30369684]\n",
            "  [-0.3532002   0.33918577 -0.09591661 ... -0.15497418  0.20158371\n",
            "   -0.30369684]\n",
            "  ...\n",
            "  [-0.3532002   0.33918577 -0.09591661 ... -0.15497418  0.20158371\n",
            "   -0.30369684]\n",
            "  [-0.3532002   0.33918577 -0.09591661 ... -0.15497418  0.20158371\n",
            "   -0.30369684]\n",
            "  [-0.3532002   0.33918577 -0.09591661 ... -0.15497418  0.20158371\n",
            "   -0.30369684]]\n",
            "\n",
            " [[-0.3532002   0.33918577 -0.09591661 ... -0.15497418  0.20158371\n",
            "   -0.30369684]\n",
            "  [-0.3532002   0.33918577 -0.09591661 ... -0.15497418  0.20158371\n",
            "   -0.30369684]\n",
            "  [-0.3532002   0.33918577 -0.09591661 ... -0.15497418  0.20158371\n",
            "   -0.30369684]\n",
            "  ...\n",
            "  [-0.3532002   0.33918577 -0.09591661 ... -0.15497418  0.20158371\n",
            "   -0.30369684]\n",
            "  [-0.3532002   0.33918577 -0.09591661 ... -0.15497418  0.20158371\n",
            "   -0.30369684]\n",
            "  [-0.3532002   0.33918577 -0.09591661 ... -0.15497418  0.20158371\n",
            "   -0.30369684]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[-0.3532002   0.33918577 -0.09591661 ... -0.15497418  0.20158371\n",
            "   -0.30369684]\n",
            "  [-0.3532002   0.33918577 -0.09591661 ... -0.15497418  0.20158371\n",
            "   -0.30369684]\n",
            "  [-0.3532002   0.33918577 -0.09591661 ... -0.15497418  0.20158371\n",
            "   -0.30369684]\n",
            "  ...\n",
            "  [-0.3532002   0.33918577 -0.09591661 ... -0.15497418  0.20158371\n",
            "   -0.30369684]\n",
            "  [-0.3532002   0.33918577 -0.09591661 ... -0.15497418  0.20158371\n",
            "   -0.30369684]\n",
            "  [-0.3532002   0.33918577 -0.09591661 ... -0.15497418  0.20158371\n",
            "   -0.30369684]]\n",
            "\n",
            " [[-0.3532002   0.33918577 -0.09591661 ... -0.15497418  0.20158371\n",
            "   -0.30369684]\n",
            "  [-0.3532002   0.33918577 -0.09591661 ... -0.15497418  0.20158371\n",
            "   -0.30369684]\n",
            "  [-0.3532002   0.33918577 -0.09591661 ... -0.15497418  0.20158371\n",
            "   -0.30369684]\n",
            "  ...\n",
            "  [-0.3532002   0.33918577 -0.09591661 ... -0.15497418  0.20158371\n",
            "   -0.30369684]\n",
            "  [-0.3532002   0.33918577 -0.09591661 ... -0.15497418  0.20158371\n",
            "   -0.30369684]\n",
            "  [-0.3532002   0.33918577 -0.09591661 ... -0.15497418  0.20158371\n",
            "   -0.30369684]]\n",
            "\n",
            " [[-0.3532002   0.33918577 -0.09591661 ... -0.15497418  0.20158371\n",
            "   -0.30369684]\n",
            "  [-0.3532002   0.33918577 -0.09591661 ... -0.15497418  0.20158371\n",
            "   -0.30369684]\n",
            "  [-0.3532002   0.33918577 -0.09591661 ... -0.15497418  0.20158371\n",
            "   -0.30369684]\n",
            "  ...\n",
            "  [-0.3532002   0.33918577 -0.09591661 ... -0.15497418  0.20158371\n",
            "   -0.30369684]\n",
            "  [-0.3532002   0.33918577 -0.09591661 ... -0.15497418  0.20158371\n",
            "   -0.30369684]\n",
            "  [-0.3532002   0.33918577 -0.09591661 ... -0.15497418  0.20158371\n",
            "   -0.30369684]]], shape=(128, 764, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.13348258 -0.13348258 -0.13348258 ... -0.13348258 -0.13348258\n",
            "  -0.13348258]\n",
            " [-0.13348258 -0.13348258 -0.13348258 ... -0.13348258 -0.13348258\n",
            "  -0.13348258]\n",
            " [-0.13348258 -0.13348258 -0.13348258 ... -0.13348258 -0.13348258\n",
            "  -0.13348258]\n",
            " ...\n",
            " [-0.13348258 -0.13348258 -0.13348258 ... -0.13348258 -0.13348258\n",
            "  -0.13348258]\n",
            " [-0.13348258 -0.13348258 -0.13348258 ... -0.13348258 -0.13348258\n",
            "  -0.13348258]\n",
            " [-0.13348258 -0.13348258 -0.13348258 ... -0.13348258 -0.13348258\n",
            "  -0.13348258]], shape=(512, 128), dtype=float32) tf.Tensor(\n",
            "[[-0.13348258 -0.13348258 -0.13348258 ... -0.13348258 -0.13348258\n",
            "  -0.13348258]\n",
            " [-0.13348258 -0.13348258 -0.13348258 ... -0.13348258 -0.13348258\n",
            "  -0.13348258]\n",
            " [-0.13348258 -0.13348258 -0.13348258 ... -0.13348258 -0.13348258\n",
            "  -0.13348258]\n",
            " ...\n",
            " [-0.13348258 -0.13348258 -0.13348258 ... -0.13348258 -0.13348258\n",
            "  -0.13348258]\n",
            " [-0.13348258 -0.13348258 -0.13348258 ... -0.13348258 -0.13348258\n",
            "  -0.13348258]\n",
            " [-0.13348258 -0.13348258 -0.13348258 ... -0.13348258 -0.13348258\n",
            "  -0.13348258]], shape=(252, 128), dtype=float32)\n",
            "(128, 764) (512, 1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_15/kernel:0', 'dense_15/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_15/kernel:0', 'dense_15/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch 1, Batch 40/100, Loss=3.77191e-02\n",
            "(1, 764, 1)\n",
            "tf.Tensor(\n",
            "[[[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]], shape=(128, 764, 1), dtype=float32) tf.Tensor(\n",
            "[[[-0.3459748   0.33854833 -0.08344026 ... -0.16866331  0.19307953\n",
            "   -0.28802884]\n",
            "  [-0.3459748   0.33854833 -0.08344026 ... -0.16866331  0.19307953\n",
            "   -0.28802884]\n",
            "  [-0.3459748   0.33854833 -0.08344026 ... -0.16866331  0.19307953\n",
            "   -0.28802884]\n",
            "  ...\n",
            "  [-0.3459748   0.33854833 -0.08344026 ... -0.16866331  0.19307953\n",
            "   -0.28802884]\n",
            "  [-0.3459748   0.33854833 -0.08344026 ... -0.16866331  0.19307953\n",
            "   -0.28802884]\n",
            "  [-0.3459748   0.33854833 -0.08344026 ... -0.16866331  0.19307953\n",
            "   -0.28802884]]\n",
            "\n",
            " [[-0.3459748   0.33854833 -0.08344026 ... -0.16866331  0.19307953\n",
            "   -0.28802884]\n",
            "  [-0.3459748   0.33854833 -0.08344026 ... -0.16866331  0.19307953\n",
            "   -0.28802884]\n",
            "  [-0.3459748   0.33854833 -0.08344026 ... -0.16866331  0.19307953\n",
            "   -0.28802884]\n",
            "  ...\n",
            "  [-0.3459748   0.33854833 -0.08344026 ... -0.16866331  0.19307953\n",
            "   -0.28802884]\n",
            "  [-0.3459748   0.33854833 -0.08344026 ... -0.16866331  0.19307953\n",
            "   -0.28802884]\n",
            "  [-0.3459748   0.33854833 -0.08344026 ... -0.16866331  0.19307953\n",
            "   -0.28802884]]\n",
            "\n",
            " [[-0.3459748   0.33854833 -0.08344026 ... -0.16866331  0.19307953\n",
            "   -0.28802884]\n",
            "  [-0.3459748   0.33854833 -0.08344026 ... -0.16866331  0.19307953\n",
            "   -0.28802884]\n",
            "  [-0.3459748   0.33854833 -0.08344026 ... -0.16866331  0.19307953\n",
            "   -0.28802884]\n",
            "  ...\n",
            "  [-0.3459748   0.33854833 -0.08344026 ... -0.16866331  0.19307953\n",
            "   -0.28802884]\n",
            "  [-0.3459748   0.33854833 -0.08344026 ... -0.16866331  0.19307953\n",
            "   -0.28802884]\n",
            "  [-0.3459748   0.33854833 -0.08344026 ... -0.16866331  0.19307953\n",
            "   -0.28802884]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[-0.3459748   0.33854833 -0.08344026 ... -0.16866331  0.19307953\n",
            "   -0.28802884]\n",
            "  [-0.3459748   0.33854833 -0.08344026 ... -0.16866331  0.19307953\n",
            "   -0.28802884]\n",
            "  [-0.3459748   0.33854833 -0.08344026 ... -0.16866331  0.19307953\n",
            "   -0.28802884]\n",
            "  ...\n",
            "  [-0.3459748   0.33854833 -0.08344026 ... -0.16866331  0.19307953\n",
            "   -0.28802884]\n",
            "  [-0.3459748   0.33854833 -0.08344026 ... -0.16866331  0.19307953\n",
            "   -0.28802884]\n",
            "  [-0.3459748   0.33854833 -0.08344026 ... -0.16866331  0.19307953\n",
            "   -0.28802884]]\n",
            "\n",
            " [[-0.3459748   0.33854833 -0.08344026 ... -0.16866331  0.19307953\n",
            "   -0.28802884]\n",
            "  [-0.3459748   0.33854833 -0.08344026 ... -0.16866331  0.19307953\n",
            "   -0.28802884]\n",
            "  [-0.3459748   0.33854833 -0.08344026 ... -0.16866331  0.19307953\n",
            "   -0.28802884]\n",
            "  ...\n",
            "  [-0.3459748   0.33854833 -0.08344026 ... -0.16866331  0.19307953\n",
            "   -0.28802884]\n",
            "  [-0.3459748   0.33854833 -0.08344026 ... -0.16866331  0.19307953\n",
            "   -0.28802884]\n",
            "  [-0.3459748   0.33854833 -0.08344026 ... -0.16866331  0.19307953\n",
            "   -0.28802884]]\n",
            "\n",
            " [[-0.3459748   0.33854833 -0.08344026 ... -0.16866331  0.19307953\n",
            "   -0.28802884]\n",
            "  [-0.3459748   0.33854833 -0.08344026 ... -0.16866331  0.19307953\n",
            "   -0.28802884]\n",
            "  [-0.3459748   0.33854833 -0.08344026 ... -0.16866331  0.19307953\n",
            "   -0.28802884]\n",
            "  ...\n",
            "  [-0.3459748   0.33854833 -0.08344026 ... -0.16866331  0.19307953\n",
            "   -0.28802884]\n",
            "  [-0.3459748   0.33854833 -0.08344026 ... -0.16866331  0.19307953\n",
            "   -0.28802884]\n",
            "  [-0.3459748   0.33854833 -0.08344026 ... -0.16866331  0.19307953\n",
            "   -0.28802884]]], shape=(128, 764, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.05870475 -0.05870475 -0.05870475 ... -0.05870475 -0.05870475\n",
            "  -0.05870475]\n",
            " [-0.05870475 -0.05870475 -0.05870475 ... -0.05870475 -0.05870475\n",
            "  -0.05870475]\n",
            " [-0.05870475 -0.05870475 -0.05870475 ... -0.05870475 -0.05870475\n",
            "  -0.05870475]\n",
            " ...\n",
            " [-0.05870475 -0.05870475 -0.05870475 ... -0.05870475 -0.05870475\n",
            "  -0.05870475]\n",
            " [-0.05870475 -0.05870475 -0.05870475 ... -0.05870475 -0.05870475\n",
            "  -0.05870475]\n",
            " [-0.05870475 -0.05870475 -0.05870475 ... -0.05870475 -0.05870475\n",
            "  -0.05870475]], shape=(512, 128), dtype=float32) tf.Tensor(\n",
            "[[-0.05870475 -0.05870475 -0.05870475 ... -0.05870475 -0.05870475\n",
            "  -0.05870475]\n",
            " [-0.05870475 -0.05870475 -0.05870475 ... -0.05870475 -0.05870475\n",
            "  -0.05870475]\n",
            " [-0.05870475 -0.05870475 -0.05870475 ... -0.05870475 -0.05870475\n",
            "  -0.05870475]\n",
            " ...\n",
            " [-0.05870475 -0.05870475 -0.05870475 ... -0.05870475 -0.05870475\n",
            "  -0.05870475]\n",
            " [-0.05870475 -0.05870475 -0.05870475 ... -0.05870475 -0.05870475\n",
            "  -0.05870475]\n",
            " [-0.05870475 -0.05870475 -0.05870475 ... -0.05870475 -0.05870475\n",
            "  -0.05870475]], shape=(252, 128), dtype=float32)\n",
            "(128, 764) (512, 1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_15/kernel:0', 'dense_15/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_15/kernel:0', 'dense_15/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch 1, Batch 41/100, Loss=1.64276e-02\n",
            "(1, 764, 1)\n",
            "tf.Tensor(\n",
            "[[[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " [[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " [[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]], shape=(128, 764, 1), dtype=float32) tf.Tensor(\n",
            "[[[-0.33821994  0.33771917 -0.07099431 ... -0.18212038  0.184241\n",
            "   -0.27265906]\n",
            "  [-0.33821994  0.33771917 -0.07099431 ... -0.18212038  0.184241\n",
            "   -0.27265906]\n",
            "  [-0.33821994  0.33771917 -0.07099431 ... -0.18212038  0.184241\n",
            "   -0.27265906]\n",
            "  ...\n",
            "  [-0.33821994  0.33771917 -0.07099431 ... -0.18212038  0.184241\n",
            "   -0.27265906]\n",
            "  [-0.33821994  0.33771917 -0.07099431 ... -0.18212038  0.184241\n",
            "   -0.27265906]\n",
            "  [-0.33821994  0.33771917 -0.07099431 ... -0.18212038  0.184241\n",
            "   -0.27265906]]\n",
            "\n",
            " [[-0.33821994  0.33771917 -0.07099431 ... -0.18212038  0.184241\n",
            "   -0.27265906]\n",
            "  [-0.33821994  0.33771917 -0.07099431 ... -0.18212038  0.184241\n",
            "   -0.27265906]\n",
            "  [-0.33821994  0.33771917 -0.07099431 ... -0.18212038  0.184241\n",
            "   -0.27265906]\n",
            "  ...\n",
            "  [-0.33821994  0.33771917 -0.07099431 ... -0.18212038  0.184241\n",
            "   -0.27265906]\n",
            "  [-0.33821994  0.33771917 -0.07099431 ... -0.18212038  0.184241\n",
            "   -0.27265906]\n",
            "  [-0.33821994  0.33771917 -0.07099431 ... -0.18212038  0.184241\n",
            "   -0.27265906]]\n",
            "\n",
            " [[-0.33821994  0.33771917 -0.07099431 ... -0.18212038  0.184241\n",
            "   -0.27265906]\n",
            "  [-0.33821994  0.33771917 -0.07099431 ... -0.18212038  0.184241\n",
            "   -0.27265906]\n",
            "  [-0.33821994  0.33771917 -0.07099431 ... -0.18212038  0.184241\n",
            "   -0.27265906]\n",
            "  ...\n",
            "  [-0.33821994  0.33771917 -0.07099431 ... -0.18212038  0.184241\n",
            "   -0.27265906]\n",
            "  [-0.33821994  0.33771917 -0.07099431 ... -0.18212038  0.184241\n",
            "   -0.27265906]\n",
            "  [-0.33821994  0.33771917 -0.07099431 ... -0.18212038  0.184241\n",
            "   -0.27265906]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[-0.33821994  0.33771917 -0.07099431 ... -0.18212038  0.184241\n",
            "   -0.27265906]\n",
            "  [-0.33821994  0.33771917 -0.07099431 ... -0.18212038  0.184241\n",
            "   -0.27265906]\n",
            "  [-0.33821994  0.33771917 -0.07099431 ... -0.18212038  0.184241\n",
            "   -0.27265906]\n",
            "  ...\n",
            "  [-0.33821994  0.33771917 -0.07099431 ... -0.18212038  0.184241\n",
            "   -0.27265906]\n",
            "  [-0.33821994  0.33771917 -0.07099431 ... -0.18212038  0.184241\n",
            "   -0.27265906]\n",
            "  [-0.33821994  0.33771917 -0.07099431 ... -0.18212038  0.184241\n",
            "   -0.27265906]]\n",
            "\n",
            " [[-0.33821994  0.33771917 -0.07099431 ... -0.18212038  0.184241\n",
            "   -0.27265906]\n",
            "  [-0.33821994  0.33771917 -0.07099431 ... -0.18212038  0.184241\n",
            "   -0.27265906]\n",
            "  [-0.33821994  0.33771917 -0.07099431 ... -0.18212038  0.184241\n",
            "   -0.27265906]\n",
            "  ...\n",
            "  [-0.33821994  0.33771917 -0.07099431 ... -0.18212038  0.184241\n",
            "   -0.27265906]\n",
            "  [-0.33821994  0.33771917 -0.07099431 ... -0.18212038  0.184241\n",
            "   -0.27265906]\n",
            "  [-0.33821994  0.33771917 -0.07099431 ... -0.18212038  0.184241\n",
            "   -0.27265906]]\n",
            "\n",
            " [[-0.33821994  0.33771917 -0.07099431 ... -0.18212038  0.184241\n",
            "   -0.27265906]\n",
            "  [-0.33821994  0.33771917 -0.07099431 ... -0.18212038  0.184241\n",
            "   -0.27265906]\n",
            "  [-0.33821994  0.33771917 -0.07099431 ... -0.18212038  0.184241\n",
            "   -0.27265906]\n",
            "  ...\n",
            "  [-0.33821994  0.33771917 -0.07099431 ... -0.18212038  0.184241\n",
            "   -0.27265906]\n",
            "  [-0.33821994  0.33771917 -0.07099431 ... -0.18212038  0.184241\n",
            "   -0.27265906]\n",
            "  [-0.33821994  0.33771917 -0.07099431 ... -0.18212038  0.184241\n",
            "   -0.27265906]]], shape=(128, 764, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[0.01661334 0.01661334 0.01661334 ... 0.01661334 0.01661334 0.01661334]\n",
            " [0.01661334 0.01661334 0.01661334 ... 0.01661334 0.01661334 0.01661334]\n",
            " [0.01661334 0.01661334 0.01661334 ... 0.01661334 0.01661334 0.01661334]\n",
            " ...\n",
            " [0.01661334 0.01661334 0.01661334 ... 0.01661334 0.01661334 0.01661334]\n",
            " [0.01661334 0.01661334 0.01661334 ... 0.01661334 0.01661334 0.01661334]\n",
            " [0.01661334 0.01661334 0.01661334 ... 0.01661334 0.01661334 0.01661334]], shape=(512, 128), dtype=float32) tf.Tensor(\n",
            "[[0.01661334 0.01661334 0.01661334 ... 0.01661334 0.01661334 0.01661334]\n",
            " [0.01661334 0.01661334 0.01661334 ... 0.01661334 0.01661334 0.01661334]\n",
            " [0.01661334 0.01661334 0.01661334 ... 0.01661334 0.01661334 0.01661334]\n",
            " ...\n",
            " [0.01661334 0.01661334 0.01661334 ... 0.01661334 0.01661334 0.01661334]\n",
            " [0.01661334 0.01661334 0.01661334 ... 0.01661334 0.01661334 0.01661334]\n",
            " [0.01661334 0.01661334 0.01661334 ... 0.01661334 0.01661334 0.01661334]], shape=(252, 128), dtype=float32)\n",
            "(128, 764) (512, 1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_15/kernel:0', 'dense_15/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_15/kernel:0', 'dense_15/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch 1, Batch 42/100, Loss=1.01927e-02\n",
            "(1, 764, 1)\n",
            "tf.Tensor(\n",
            "[[[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " [[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " [[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " [[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " [[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]], shape=(128, 764, 1), dtype=float32) tf.Tensor(\n",
            "[[[-0.33131137  0.33690533 -0.05991433 ... -0.1941502   0.1763676\n",
            "   -0.25884926]\n",
            "  [-0.33131137  0.33690533 -0.05991433 ... -0.1941502   0.1763676\n",
            "   -0.25884926]\n",
            "  [-0.33131137  0.33690533 -0.05991433 ... -0.1941502   0.1763676\n",
            "   -0.25884926]\n",
            "  ...\n",
            "  [-0.33131137  0.33690533 -0.05991433 ... -0.1941502   0.1763676\n",
            "   -0.25884926]\n",
            "  [-0.33131137  0.33690533 -0.05991433 ... -0.1941502   0.1763676\n",
            "   -0.25884926]\n",
            "  [-0.33131137  0.33690533 -0.05991433 ... -0.1941502   0.1763676\n",
            "   -0.25884926]]\n",
            "\n",
            " [[-0.33131137  0.33690533 -0.05991433 ... -0.1941502   0.1763676\n",
            "   -0.25884926]\n",
            "  [-0.33131137  0.33690533 -0.05991433 ... -0.1941502   0.1763676\n",
            "   -0.25884926]\n",
            "  [-0.33131137  0.33690533 -0.05991433 ... -0.1941502   0.1763676\n",
            "   -0.25884926]\n",
            "  ...\n",
            "  [-0.33131137  0.33690533 -0.05991433 ... -0.1941502   0.1763676\n",
            "   -0.25884926]\n",
            "  [-0.33131137  0.33690533 -0.05991433 ... -0.1941502   0.1763676\n",
            "   -0.25884926]\n",
            "  [-0.33131137  0.33690533 -0.05991433 ... -0.1941502   0.1763676\n",
            "   -0.25884926]]\n",
            "\n",
            " [[-0.33131137  0.33690533 -0.05991433 ... -0.1941502   0.1763676\n",
            "   -0.25884926]\n",
            "  [-0.33131137  0.33690533 -0.05991433 ... -0.1941502   0.1763676\n",
            "   -0.25884926]\n",
            "  [-0.33131137  0.33690533 -0.05991433 ... -0.1941502   0.1763676\n",
            "   -0.25884926]\n",
            "  ...\n",
            "  [-0.33131137  0.33690533 -0.05991433 ... -0.1941502   0.1763676\n",
            "   -0.25884926]\n",
            "  [-0.33131137  0.33690533 -0.05991433 ... -0.1941502   0.1763676\n",
            "   -0.25884926]\n",
            "  [-0.33131137  0.33690533 -0.05991433 ... -0.1941502   0.1763676\n",
            "   -0.25884926]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[-0.33131137  0.33690533 -0.05991433 ... -0.1941502   0.1763676\n",
            "   -0.25884926]\n",
            "  [-0.33131137  0.33690533 -0.05991433 ... -0.1941502   0.1763676\n",
            "   -0.25884926]\n",
            "  [-0.33131137  0.33690533 -0.05991433 ... -0.1941502   0.1763676\n",
            "   -0.25884926]\n",
            "  ...\n",
            "  [-0.33131137  0.33690533 -0.05991433 ... -0.1941502   0.1763676\n",
            "   -0.25884926]\n",
            "  [-0.33131137  0.33690533 -0.05991433 ... -0.1941502   0.1763676\n",
            "   -0.25884926]\n",
            "  [-0.33131137  0.33690533 -0.05991433 ... -0.1941502   0.1763676\n",
            "   -0.25884926]]\n",
            "\n",
            " [[-0.33131137  0.33690533 -0.05991433 ... -0.1941502   0.1763676\n",
            "   -0.25884926]\n",
            "  [-0.33131137  0.33690533 -0.05991433 ... -0.1941502   0.1763676\n",
            "   -0.25884926]\n",
            "  [-0.33131137  0.33690533 -0.05991433 ... -0.1941502   0.1763676\n",
            "   -0.25884926]\n",
            "  ...\n",
            "  [-0.33131137  0.33690533 -0.05991433 ... -0.1941502   0.1763676\n",
            "   -0.25884926]\n",
            "  [-0.33131137  0.33690533 -0.05991433 ... -0.1941502   0.1763676\n",
            "   -0.25884926]\n",
            "  [-0.33131137  0.33690533 -0.05991433 ... -0.1941502   0.1763676\n",
            "   -0.25884926]]\n",
            "\n",
            " [[-0.33131137  0.33690533 -0.05991433 ... -0.1941502   0.1763676\n",
            "   -0.25884926]\n",
            "  [-0.33131137  0.33690533 -0.05991433 ... -0.1941502   0.1763676\n",
            "   -0.25884926]\n",
            "  [-0.33131137  0.33690533 -0.05991433 ... -0.1941502   0.1763676\n",
            "   -0.25884926]\n",
            "  ...\n",
            "  [-0.33131137  0.33690533 -0.05991433 ... -0.1941502   0.1763676\n",
            "   -0.25884926]\n",
            "  [-0.33131137  0.33690533 -0.05991433 ... -0.1941502   0.1763676\n",
            "   -0.25884926]\n",
            "  [-0.33131137  0.33690533 -0.05991433 ... -0.1941502   0.1763676\n",
            "   -0.25884926]]], shape=(128, 764, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[0.08344136 0.08344136 0.08344136 ... 0.08344136 0.08344136 0.08344136]\n",
            " [0.08344136 0.08344136 0.08344136 ... 0.08344136 0.08344136 0.08344136]\n",
            " [0.08344136 0.08344136 0.08344136 ... 0.08344136 0.08344136 0.08344136]\n",
            " ...\n",
            " [0.08344136 0.08344136 0.08344136 ... 0.08344136 0.08344136 0.08344136]\n",
            " [0.08344136 0.08344136 0.08344136 ... 0.08344136 0.08344136 0.08344136]\n",
            " [0.08344136 0.08344136 0.08344136 ... 0.08344136 0.08344136 0.08344136]], shape=(512, 128), dtype=float32) tf.Tensor(\n",
            "[[0.08344136 0.08344136 0.08344136 ... 0.08344136 0.08344136 0.08344136]\n",
            " [0.08344136 0.08344136 0.08344136 ... 0.08344136 0.08344136 0.08344136]\n",
            " [0.08344136 0.08344136 0.08344136 ... 0.08344136 0.08344136 0.08344136]\n",
            " ...\n",
            " [0.08344136 0.08344136 0.08344136 ... 0.08344136 0.08344136 0.08344136]\n",
            " [0.08344136 0.08344136 0.08344136 ... 0.08344136 0.08344136 0.08344136]\n",
            " [0.08344136 0.08344136 0.08344136 ... 0.08344136 0.08344136 0.08344136]], shape=(252, 128), dtype=float32)\n",
            "(128, 764) (512, 1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_15/kernel:0', 'dense_15/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_15/kernel:0', 'dense_15/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch 1, Batch 43/100, Loss=2.16659e-02\n",
            "(1, 764, 1)\n",
            "tf.Tensor(\n",
            "[[[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " [[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " [[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]], shape=(128, 764, 1), dtype=float32) tf.Tensor(\n",
            "[[[-0.32642916  0.33628273 -0.0514464  ... -0.20383167  0.17051353\n",
            "   -0.2476714 ]\n",
            "  [-0.32642916  0.33628273 -0.0514464  ... -0.20383167  0.17051353\n",
            "   -0.2476714 ]\n",
            "  [-0.32642916  0.33628273 -0.0514464  ... -0.20383167  0.17051353\n",
            "   -0.2476714 ]\n",
            "  ...\n",
            "  [-0.32642916  0.33628273 -0.0514464  ... -0.20383167  0.17051353\n",
            "   -0.2476714 ]\n",
            "  [-0.32642916  0.33628273 -0.0514464  ... -0.20383167  0.17051353\n",
            "   -0.2476714 ]\n",
            "  [-0.32642916  0.33628273 -0.0514464  ... -0.20383167  0.17051353\n",
            "   -0.2476714 ]]\n",
            "\n",
            " [[-0.32642916  0.33628273 -0.0514464  ... -0.20383167  0.17051353\n",
            "   -0.2476714 ]\n",
            "  [-0.32642916  0.33628273 -0.0514464  ... -0.20383167  0.17051353\n",
            "   -0.2476714 ]\n",
            "  [-0.32642916  0.33628273 -0.0514464  ... -0.20383167  0.17051353\n",
            "   -0.2476714 ]\n",
            "  ...\n",
            "  [-0.32642916  0.33628273 -0.0514464  ... -0.20383167  0.17051353\n",
            "   -0.2476714 ]\n",
            "  [-0.32642916  0.33628273 -0.0514464  ... -0.20383167  0.17051353\n",
            "   -0.2476714 ]\n",
            "  [-0.32642916  0.33628273 -0.0514464  ... -0.20383167  0.17051353\n",
            "   -0.2476714 ]]\n",
            "\n",
            " [[-0.32642916  0.33628273 -0.0514464  ... -0.20383167  0.17051353\n",
            "   -0.2476714 ]\n",
            "  [-0.32642916  0.33628273 -0.0514464  ... -0.20383167  0.17051353\n",
            "   -0.2476714 ]\n",
            "  [-0.32642916  0.33628273 -0.0514464  ... -0.20383167  0.17051353\n",
            "   -0.2476714 ]\n",
            "  ...\n",
            "  [-0.32642916  0.33628273 -0.0514464  ... -0.20383167  0.17051353\n",
            "   -0.2476714 ]\n",
            "  [-0.32642916  0.33628273 -0.0514464  ... -0.20383167  0.17051353\n",
            "   -0.2476714 ]\n",
            "  [-0.32642916  0.33628273 -0.0514464  ... -0.20383167  0.17051353\n",
            "   -0.2476714 ]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[-0.32642916  0.33628273 -0.0514464  ... -0.20383167  0.17051353\n",
            "   -0.2476714 ]\n",
            "  [-0.32642916  0.33628273 -0.0514464  ... -0.20383167  0.17051353\n",
            "   -0.2476714 ]\n",
            "  [-0.32642916  0.33628273 -0.0514464  ... -0.20383167  0.17051353\n",
            "   -0.2476714 ]\n",
            "  ...\n",
            "  [-0.32642916  0.33628273 -0.0514464  ... -0.20383167  0.17051353\n",
            "   -0.2476714 ]\n",
            "  [-0.32642916  0.33628273 -0.0514464  ... -0.20383167  0.17051353\n",
            "   -0.2476714 ]\n",
            "  [-0.32642916  0.33628273 -0.0514464  ... -0.20383167  0.17051353\n",
            "   -0.2476714 ]]\n",
            "\n",
            " [[-0.32642916  0.33628273 -0.0514464  ... -0.20383167  0.17051353\n",
            "   -0.2476714 ]\n",
            "  [-0.32642916  0.33628273 -0.0514464  ... -0.20383167  0.17051353\n",
            "   -0.2476714 ]\n",
            "  [-0.32642916  0.33628273 -0.0514464  ... -0.20383167  0.17051353\n",
            "   -0.2476714 ]\n",
            "  ...\n",
            "  [-0.32642916  0.33628273 -0.0514464  ... -0.20383167  0.17051353\n",
            "   -0.2476714 ]\n",
            "  [-0.32642916  0.33628273 -0.0514464  ... -0.20383167  0.17051353\n",
            "   -0.2476714 ]\n",
            "  [-0.32642916  0.33628273 -0.0514464  ... -0.20383167  0.17051353\n",
            "   -0.2476714 ]]\n",
            "\n",
            " [[-0.32642916  0.33628273 -0.0514464  ... -0.20383167  0.17051353\n",
            "   -0.2476714 ]\n",
            "  [-0.32642916  0.33628273 -0.0514464  ... -0.20383167  0.17051353\n",
            "   -0.2476714 ]\n",
            "  [-0.32642916  0.33628273 -0.0514464  ... -0.20383167  0.17051353\n",
            "   -0.2476714 ]\n",
            "  ...\n",
            "  [-0.32642916  0.33628273 -0.0514464  ... -0.20383167  0.17051353\n",
            "   -0.2476714 ]\n",
            "  [-0.32642916  0.33628273 -0.0514464  ... -0.20383167  0.17051353\n",
            "   -0.2476714 ]\n",
            "  [-0.32642916  0.33628273 -0.0514464  ... -0.20383167  0.17051353\n",
            "   -0.2476714 ]]], shape=(128, 764, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[0.13435867 0.13435867 0.13435867 ... 0.13435867 0.13435867 0.13435867]\n",
            " [0.13435867 0.13435867 0.13435867 ... 0.13435867 0.13435867 0.13435867]\n",
            " [0.13435867 0.13435867 0.13435867 ... 0.13435867 0.13435867 0.13435867]\n",
            " ...\n",
            " [0.13435867 0.13435867 0.13435867 ... 0.13435867 0.13435867 0.13435867]\n",
            " [0.13435867 0.13435867 0.13435867 ... 0.13435867 0.13435867 0.13435867]\n",
            " [0.13435867 0.13435867 0.13435867 ... 0.13435867 0.13435867 0.13435867]], shape=(512, 128), dtype=float32) tf.Tensor(\n",
            "[[0.13435867 0.13435867 0.13435867 ... 0.13435867 0.13435867 0.13435867]\n",
            " [0.13435867 0.13435867 0.13435867 ... 0.13435867 0.13435867 0.13435867]\n",
            " [0.13435867 0.13435867 0.13435867 ... 0.13435867 0.13435867 0.13435867]\n",
            " ...\n",
            " [0.13435867 0.13435867 0.13435867 ... 0.13435867 0.13435867 0.13435867]\n",
            " [0.13435867 0.13435867 0.13435867 ... 0.13435867 0.13435867 0.13435867]\n",
            " [0.13435867 0.13435867 0.13435867 ... 0.13435867 0.13435867 0.13435867]], shape=(252, 128), dtype=float32)\n",
            "(128, 764) (512, 1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_15/kernel:0', 'dense_15/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_15/kernel:0', 'dense_15/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch 1, Batch 44/100, Loss=3.90510e-02\n",
            "(1, 764, 1)\n",
            "tf.Tensor(\n",
            "[[[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " [[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " [[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]], shape=(128, 764, 1), dtype=float32) tf.Tensor(\n",
            "[[[-0.3243988   0.33598348 -0.04652153 ... -0.21059346  0.16736192\n",
            "   -0.23984902]\n",
            "  [-0.3243988   0.33598348 -0.04652153 ... -0.21059346  0.16736192\n",
            "   -0.23984902]\n",
            "  [-0.3243988   0.33598348 -0.04652153 ... -0.21059346  0.16736192\n",
            "   -0.23984902]\n",
            "  ...\n",
            "  [-0.3243988   0.33598348 -0.04652153 ... -0.21059346  0.16736192\n",
            "   -0.23984902]\n",
            "  [-0.3243988   0.33598348 -0.04652153 ... -0.21059346  0.16736192\n",
            "   -0.23984902]\n",
            "  [-0.3243988   0.33598348 -0.04652153 ... -0.21059346  0.16736192\n",
            "   -0.23984902]]\n",
            "\n",
            " [[-0.3243988   0.33598348 -0.04652153 ... -0.21059346  0.16736192\n",
            "   -0.23984902]\n",
            "  [-0.3243988   0.33598348 -0.04652153 ... -0.21059346  0.16736192\n",
            "   -0.23984902]\n",
            "  [-0.3243988   0.33598348 -0.04652153 ... -0.21059346  0.16736192\n",
            "   -0.23984902]\n",
            "  ...\n",
            "  [-0.3243988   0.33598348 -0.04652153 ... -0.21059346  0.16736192\n",
            "   -0.23984902]\n",
            "  [-0.3243988   0.33598348 -0.04652153 ... -0.21059346  0.16736192\n",
            "   -0.23984902]\n",
            "  [-0.3243988   0.33598348 -0.04652153 ... -0.21059346  0.16736192\n",
            "   -0.23984902]]\n",
            "\n",
            " [[-0.3243988   0.33598348 -0.04652153 ... -0.21059346  0.16736192\n",
            "   -0.23984902]\n",
            "  [-0.3243988   0.33598348 -0.04652153 ... -0.21059346  0.16736192\n",
            "   -0.23984902]\n",
            "  [-0.3243988   0.33598348 -0.04652153 ... -0.21059346  0.16736192\n",
            "   -0.23984902]\n",
            "  ...\n",
            "  [-0.3243988   0.33598348 -0.04652153 ... -0.21059346  0.16736192\n",
            "   -0.23984902]\n",
            "  [-0.3243988   0.33598348 -0.04652153 ... -0.21059346  0.16736192\n",
            "   -0.23984902]\n",
            "  [-0.3243988   0.33598348 -0.04652153 ... -0.21059346  0.16736192\n",
            "   -0.23984902]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[-0.3243988   0.33598348 -0.04652153 ... -0.21059346  0.16736192\n",
            "   -0.23984902]\n",
            "  [-0.3243988   0.33598348 -0.04652153 ... -0.21059346  0.16736192\n",
            "   -0.23984902]\n",
            "  [-0.3243988   0.33598348 -0.04652153 ... -0.21059346  0.16736192\n",
            "   -0.23984902]\n",
            "  ...\n",
            "  [-0.3243988   0.33598348 -0.04652153 ... -0.21059346  0.16736192\n",
            "   -0.23984902]\n",
            "  [-0.3243988   0.33598348 -0.04652153 ... -0.21059346  0.16736192\n",
            "   -0.23984902]\n",
            "  [-0.3243988   0.33598348 -0.04652153 ... -0.21059346  0.16736192\n",
            "   -0.23984902]]\n",
            "\n",
            " [[-0.3243988   0.33598348 -0.04652153 ... -0.21059346  0.16736192\n",
            "   -0.23984902]\n",
            "  [-0.3243988   0.33598348 -0.04652153 ... -0.21059346  0.16736192\n",
            "   -0.23984902]\n",
            "  [-0.3243988   0.33598348 -0.04652153 ... -0.21059346  0.16736192\n",
            "   -0.23984902]\n",
            "  ...\n",
            "  [-0.3243988   0.33598348 -0.04652153 ... -0.21059346  0.16736192\n",
            "   -0.23984902]\n",
            "  [-0.3243988   0.33598348 -0.04652153 ... -0.21059346  0.16736192\n",
            "   -0.23984902]\n",
            "  [-0.3243988   0.33598348 -0.04652153 ... -0.21059346  0.16736192\n",
            "   -0.23984902]]\n",
            "\n",
            " [[-0.3243988   0.33598348 -0.04652153 ... -0.21059346  0.16736192\n",
            "   -0.23984902]\n",
            "  [-0.3243988   0.33598348 -0.04652153 ... -0.21059346  0.16736192\n",
            "   -0.23984902]\n",
            "  [-0.3243988   0.33598348 -0.04652153 ... -0.21059346  0.16736192\n",
            "   -0.23984902]\n",
            "  ...\n",
            "  [-0.3243988   0.33598348 -0.04652153 ... -0.21059346  0.16736192\n",
            "   -0.23984902]\n",
            "  [-0.3243988   0.33598348 -0.04652153 ... -0.21059346  0.16736192\n",
            "   -0.23984902]\n",
            "  [-0.3243988   0.33598348 -0.04652153 ... -0.21059346  0.16736192\n",
            "   -0.23984902]]], shape=(128, 764, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[0.16445446 0.16445446 0.16445446 ... 0.16445446 0.16445446 0.16445446]\n",
            " [0.16445446 0.16445446 0.16445446 ... 0.16445446 0.16445446 0.16445446]\n",
            " [0.16445446 0.16445446 0.16445446 ... 0.16445446 0.16445446 0.16445446]\n",
            " ...\n",
            " [0.16445446 0.16445446 0.16445446 ... 0.16445446 0.16445446 0.16445446]\n",
            " [0.16445446 0.16445446 0.16445446 ... 0.16445446 0.16445446 0.16445446]\n",
            " [0.16445446 0.16445446 0.16445446 ... 0.16445446 0.16445446 0.16445446]], shape=(512, 128), dtype=float32) tf.Tensor(\n",
            "[[0.16445446 0.16445446 0.16445446 ... 0.16445446 0.16445446 0.16445446]\n",
            " [0.16445446 0.16445446 0.16445446 ... 0.16445446 0.16445446 0.16445446]\n",
            " [0.16445446 0.16445446 0.16445446 ... 0.16445446 0.16445446 0.16445446]\n",
            " ...\n",
            " [0.16445446 0.16445446 0.16445446 ... 0.16445446 0.16445446 0.16445446]\n",
            " [0.16445446 0.16445446 0.16445446 ... 0.16445446 0.16445446 0.16445446]\n",
            " [0.16445446 0.16445446 0.16445446 ... 0.16445446 0.16445446 0.16445446]], shape=(252, 128), dtype=float32)\n",
            "(128, 764) (512, 1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_15/kernel:0', 'dense_15/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_15/kernel:0', 'dense_15/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch 1, Batch 45/100, Loss=5.05821e-02\n",
            "(1, 764, 1)\n",
            "tf.Tensor(\n",
            "[[[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " [[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " [[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " [[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " [[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]], shape=(128, 764, 1), dtype=float32) tf.Tensor(\n",
            "[[[-0.32545155  0.33605337 -0.0453953  ... -0.21437702  0.1670441\n",
            "   -0.23552701]\n",
            "  [-0.32545155  0.33605337 -0.0453953  ... -0.21437702  0.1670441\n",
            "   -0.23552701]\n",
            "  [-0.32545155  0.33605337 -0.0453953  ... -0.21437702  0.1670441\n",
            "   -0.23552701]\n",
            "  ...\n",
            "  [-0.32545155  0.33605337 -0.0453953  ... -0.21437702  0.1670441\n",
            "   -0.23552701]\n",
            "  [-0.32545155  0.33605337 -0.0453953  ... -0.21437702  0.1670441\n",
            "   -0.23552701]\n",
            "  [-0.32545155  0.33605337 -0.0453953  ... -0.21437702  0.1670441\n",
            "   -0.23552701]]\n",
            "\n",
            " [[-0.32545155  0.33605337 -0.0453953  ... -0.21437702  0.1670441\n",
            "   -0.23552701]\n",
            "  [-0.32545155  0.33605337 -0.0453953  ... -0.21437702  0.1670441\n",
            "   -0.23552701]\n",
            "  [-0.32545155  0.33605337 -0.0453953  ... -0.21437702  0.1670441\n",
            "   -0.23552701]\n",
            "  ...\n",
            "  [-0.32545155  0.33605337 -0.0453953  ... -0.21437702  0.1670441\n",
            "   -0.23552701]\n",
            "  [-0.32545155  0.33605337 -0.0453953  ... -0.21437702  0.1670441\n",
            "   -0.23552701]\n",
            "  [-0.32545155  0.33605337 -0.0453953  ... -0.21437702  0.1670441\n",
            "   -0.23552701]]\n",
            "\n",
            " [[-0.32545155  0.33605337 -0.0453953  ... -0.21437702  0.1670441\n",
            "   -0.23552701]\n",
            "  [-0.32545155  0.33605337 -0.0453953  ... -0.21437702  0.1670441\n",
            "   -0.23552701]\n",
            "  [-0.32545155  0.33605337 -0.0453953  ... -0.21437702  0.1670441\n",
            "   -0.23552701]\n",
            "  ...\n",
            "  [-0.32545155  0.33605337 -0.0453953  ... -0.21437702  0.1670441\n",
            "   -0.23552701]\n",
            "  [-0.32545155  0.33605337 -0.0453953  ... -0.21437702  0.1670441\n",
            "   -0.23552701]\n",
            "  [-0.32545155  0.33605337 -0.0453953  ... -0.21437702  0.1670441\n",
            "   -0.23552701]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[-0.32545155  0.33605337 -0.0453953  ... -0.21437702  0.1670441\n",
            "   -0.23552701]\n",
            "  [-0.32545155  0.33605337 -0.0453953  ... -0.21437702  0.1670441\n",
            "   -0.23552701]\n",
            "  [-0.32545155  0.33605337 -0.0453953  ... -0.21437702  0.1670441\n",
            "   -0.23552701]\n",
            "  ...\n",
            "  [-0.32545155  0.33605337 -0.0453953  ... -0.21437702  0.1670441\n",
            "   -0.23552701]\n",
            "  [-0.32545155  0.33605337 -0.0453953  ... -0.21437702  0.1670441\n",
            "   -0.23552701]\n",
            "  [-0.32545155  0.33605337 -0.0453953  ... -0.21437702  0.1670441\n",
            "   -0.23552701]]\n",
            "\n",
            " [[-0.32545155  0.33605337 -0.0453953  ... -0.21437702  0.1670441\n",
            "   -0.23552701]\n",
            "  [-0.32545155  0.33605337 -0.0453953  ... -0.21437702  0.1670441\n",
            "   -0.23552701]\n",
            "  [-0.32545155  0.33605337 -0.0453953  ... -0.21437702  0.1670441\n",
            "   -0.23552701]\n",
            "  ...\n",
            "  [-0.32545155  0.33605337 -0.0453953  ... -0.21437702  0.1670441\n",
            "   -0.23552701]\n",
            "  [-0.32545155  0.33605337 -0.0453953  ... -0.21437702  0.1670441\n",
            "   -0.23552701]\n",
            "  [-0.32545155  0.33605337 -0.0453953  ... -0.21437702  0.1670441\n",
            "   -0.23552701]]\n",
            "\n",
            " [[-0.32545155  0.33605337 -0.0453953  ... -0.21437702  0.1670441\n",
            "   -0.23552701]\n",
            "  [-0.32545155  0.33605337 -0.0453953  ... -0.21437702  0.1670441\n",
            "   -0.23552701]\n",
            "  [-0.32545155  0.33605337 -0.0453953  ... -0.21437702  0.1670441\n",
            "   -0.23552701]\n",
            "  ...\n",
            "  [-0.32545155  0.33605337 -0.0453953  ... -0.21437702  0.1670441\n",
            "   -0.23552701]\n",
            "  [-0.32545155  0.33605337 -0.0453953  ... -0.21437702  0.1670441\n",
            "   -0.23552701]\n",
            "  [-0.32545155  0.33605337 -0.0453953  ... -0.21437702  0.1670441\n",
            "   -0.23552701]]], shape=(128, 764, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[0.17279476 0.17279476 0.17279476 ... 0.17279476 0.17279476 0.17279476]\n",
            " [0.17279476 0.17279476 0.17279476 ... 0.17279476 0.17279476 0.17279476]\n",
            " [0.17279476 0.17279476 0.17279476 ... 0.17279476 0.17279476 0.17279476]\n",
            " ...\n",
            " [0.17279476 0.17279476 0.17279476 ... 0.17279476 0.17279476 0.17279476]\n",
            " [0.17279476 0.17279476 0.17279476 ... 0.17279476 0.17279476 0.17279476]\n",
            " [0.17279476 0.17279476 0.17279476 ... 0.17279476 0.17279476 0.17279476]], shape=(512, 128), dtype=float32) tf.Tensor(\n",
            "[[0.17279476 0.17279476 0.17279476 ... 0.17279476 0.17279476 0.17279476]\n",
            " [0.17279476 0.17279476 0.17279476 ... 0.17279476 0.17279476 0.17279476]\n",
            " [0.17279476 0.17279476 0.17279476 ... 0.17279476 0.17279476 0.17279476]\n",
            " ...\n",
            " [0.17279476 0.17279476 0.17279476 ... 0.17279476 0.17279476 0.17279476]\n",
            " [0.17279476 0.17279476 0.17279476 ... 0.17279476 0.17279476 0.17279476]\n",
            " [0.17279476 0.17279476 0.17279476 ... 0.17279476 0.17279476 0.17279476]], shape=(252, 128), dtype=float32)\n",
            "(128, 764) (512, 1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_15/kernel:0', 'dense_15/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_15/kernel:0', 'dense_15/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch 1, Batch 46/100, Loss=5.46780e-02\n",
            "(1, 764, 1)\n",
            "tf.Tensor(\n",
            "[[[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]], shape=(128, 764, 1), dtype=float32) tf.Tensor(\n",
            "[[[-0.3294923   0.33649465 -0.04794789 ... -0.21534911  0.16942142\n",
            "   -0.23453794]\n",
            "  [-0.3294923   0.33649465 -0.04794789 ... -0.21534911  0.16942142\n",
            "   -0.23453794]\n",
            "  [-0.3294923   0.33649465 -0.04794789 ... -0.21534911  0.16942142\n",
            "   -0.23453794]\n",
            "  ...\n",
            "  [-0.3294923   0.33649465 -0.04794789 ... -0.21534911  0.16942142\n",
            "   -0.23453794]\n",
            "  [-0.3294923   0.33649465 -0.04794789 ... -0.21534911  0.16942142\n",
            "   -0.23453794]\n",
            "  [-0.3294923   0.33649465 -0.04794789 ... -0.21534911  0.16942142\n",
            "   -0.23453794]]\n",
            "\n",
            " [[-0.3294923   0.33649465 -0.04794789 ... -0.21534911  0.16942142\n",
            "   -0.23453794]\n",
            "  [-0.3294923   0.33649465 -0.04794789 ... -0.21534911  0.16942142\n",
            "   -0.23453794]\n",
            "  [-0.3294923   0.33649465 -0.04794789 ... -0.21534911  0.16942142\n",
            "   -0.23453794]\n",
            "  ...\n",
            "  [-0.3294923   0.33649465 -0.04794789 ... -0.21534911  0.16942142\n",
            "   -0.23453794]\n",
            "  [-0.3294923   0.33649465 -0.04794789 ... -0.21534911  0.16942142\n",
            "   -0.23453794]\n",
            "  [-0.3294923   0.33649465 -0.04794789 ... -0.21534911  0.16942142\n",
            "   -0.23453794]]\n",
            "\n",
            " [[-0.3294923   0.33649465 -0.04794789 ... -0.21534911  0.16942142\n",
            "   -0.23453794]\n",
            "  [-0.3294923   0.33649465 -0.04794789 ... -0.21534911  0.16942142\n",
            "   -0.23453794]\n",
            "  [-0.3294923   0.33649465 -0.04794789 ... -0.21534911  0.16942142\n",
            "   -0.23453794]\n",
            "  ...\n",
            "  [-0.3294923   0.33649465 -0.04794789 ... -0.21534911  0.16942142\n",
            "   -0.23453794]\n",
            "  [-0.3294923   0.33649465 -0.04794789 ... -0.21534911  0.16942142\n",
            "   -0.23453794]\n",
            "  [-0.3294923   0.33649465 -0.04794789 ... -0.21534911  0.16942142\n",
            "   -0.23453794]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[-0.3294923   0.33649465 -0.04794789 ... -0.21534911  0.16942142\n",
            "   -0.23453794]\n",
            "  [-0.3294923   0.33649465 -0.04794789 ... -0.21534911  0.16942142\n",
            "   -0.23453794]\n",
            "  [-0.3294923   0.33649465 -0.04794789 ... -0.21534911  0.16942142\n",
            "   -0.23453794]\n",
            "  ...\n",
            "  [-0.3294923   0.33649465 -0.04794789 ... -0.21534911  0.16942142\n",
            "   -0.23453794]\n",
            "  [-0.3294923   0.33649465 -0.04794789 ... -0.21534911  0.16942142\n",
            "   -0.23453794]\n",
            "  [-0.3294923   0.33649465 -0.04794789 ... -0.21534911  0.16942142\n",
            "   -0.23453794]]\n",
            "\n",
            " [[-0.3294923   0.33649465 -0.04794789 ... -0.21534911  0.16942142\n",
            "   -0.23453794]\n",
            "  [-0.3294923   0.33649465 -0.04794789 ... -0.21534911  0.16942142\n",
            "   -0.23453794]\n",
            "  [-0.3294923   0.33649465 -0.04794789 ... -0.21534911  0.16942142\n",
            "   -0.23453794]\n",
            "  ...\n",
            "  [-0.3294923   0.33649465 -0.04794789 ... -0.21534911  0.16942142\n",
            "   -0.23453794]\n",
            "  [-0.3294923   0.33649465 -0.04794789 ... -0.21534911  0.16942142\n",
            "   -0.23453794]\n",
            "  [-0.3294923   0.33649465 -0.04794789 ... -0.21534911  0.16942142\n",
            "   -0.23453794]]\n",
            "\n",
            " [[-0.3294923   0.33649465 -0.04794789 ... -0.21534911  0.16942142\n",
            "   -0.23453794]\n",
            "  [-0.3294923   0.33649465 -0.04794789 ... -0.21534911  0.16942142\n",
            "   -0.23453794]\n",
            "  [-0.3294923   0.33649465 -0.04794789 ... -0.21534911  0.16942142\n",
            "   -0.23453794]\n",
            "  ...\n",
            "  [-0.3294923   0.33649465 -0.04794789 ... -0.21534911  0.16942142\n",
            "   -0.23453794]\n",
            "  [-0.3294923   0.33649465 -0.04794789 ... -0.21534911  0.16942142\n",
            "   -0.23453794]\n",
            "  [-0.3294923   0.33649465 -0.04794789 ... -0.21534911  0.16942142\n",
            "   -0.23453794]]], shape=(128, 764, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[0.16045128 0.16045128 0.16045128 ... 0.16045128 0.16045128 0.16045128]\n",
            " [0.16045128 0.16045128 0.16045128 ... 0.16045128 0.16045128 0.16045128]\n",
            " [0.16045128 0.16045128 0.16045128 ... 0.16045128 0.16045128 0.16045128]\n",
            " ...\n",
            " [0.16045128 0.16045128 0.16045128 ... 0.16045128 0.16045128 0.16045128]\n",
            " [0.16045128 0.16045128 0.16045128 ... 0.16045128 0.16045128 0.16045128]\n",
            " [0.16045128 0.16045128 0.16045128 ... 0.16045128 0.16045128 0.16045128]], shape=(512, 128), dtype=float32) tf.Tensor(\n",
            "[[0.16045128 0.16045128 0.16045128 ... 0.16045128 0.16045128 0.16045128]\n",
            " [0.16045128 0.16045128 0.16045128 ... 0.16045128 0.16045128 0.16045128]\n",
            " [0.16045128 0.16045128 0.16045128 ... 0.16045128 0.16045128 0.16045128]\n",
            " ...\n",
            " [0.16045128 0.16045128 0.16045128 ... 0.16045128 0.16045128 0.16045128]\n",
            " [0.16045128 0.16045128 0.16045128 ... 0.16045128 0.16045128 0.16045128]\n",
            " [0.16045128 0.16045128 0.16045128 ... 0.16045128 0.16045128 0.16045128]], shape=(252, 128), dtype=float32)\n",
            "(128, 764) (512, 1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_15/kernel:0', 'dense_15/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_15/kernel:0', 'dense_15/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch 1, Batch 47/100, Loss=4.86636e-02\n",
            "(1, 764, 1)\n",
            "tf.Tensor(\n",
            "[[[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " [[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " [[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]], shape=(128, 764, 1), dtype=float32) tf.Tensor(\n",
            "[[[-0.33610445  0.33725694 -0.0536614  ... -0.21390143  0.1741011\n",
            "   -0.23641583]\n",
            "  [-0.33610445  0.33725694 -0.0536614  ... -0.21390143  0.1741011\n",
            "   -0.23641583]\n",
            "  [-0.33610445  0.33725694 -0.0536614  ... -0.21390143  0.1741011\n",
            "   -0.23641583]\n",
            "  ...\n",
            "  [-0.33610445  0.33725694 -0.0536614  ... -0.21390143  0.1741011\n",
            "   -0.23641583]\n",
            "  [-0.33610445  0.33725694 -0.0536614  ... -0.21390143  0.1741011\n",
            "   -0.23641583]\n",
            "  [-0.33610445  0.33725694 -0.0536614  ... -0.21390143  0.1741011\n",
            "   -0.23641583]]\n",
            "\n",
            " [[-0.33610445  0.33725694 -0.0536614  ... -0.21390143  0.1741011\n",
            "   -0.23641583]\n",
            "  [-0.33610445  0.33725694 -0.0536614  ... -0.21390143  0.1741011\n",
            "   -0.23641583]\n",
            "  [-0.33610445  0.33725694 -0.0536614  ... -0.21390143  0.1741011\n",
            "   -0.23641583]\n",
            "  ...\n",
            "  [-0.33610445  0.33725694 -0.0536614  ... -0.21390143  0.1741011\n",
            "   -0.23641583]\n",
            "  [-0.33610445  0.33725694 -0.0536614  ... -0.21390143  0.1741011\n",
            "   -0.23641583]\n",
            "  [-0.33610445  0.33725694 -0.0536614  ... -0.21390143  0.1741011\n",
            "   -0.23641583]]\n",
            "\n",
            " [[-0.33610445  0.33725694 -0.0536614  ... -0.21390143  0.1741011\n",
            "   -0.23641583]\n",
            "  [-0.33610445  0.33725694 -0.0536614  ... -0.21390143  0.1741011\n",
            "   -0.23641583]\n",
            "  [-0.33610445  0.33725694 -0.0536614  ... -0.21390143  0.1741011\n",
            "   -0.23641583]\n",
            "  ...\n",
            "  [-0.33610445  0.33725694 -0.0536614  ... -0.21390143  0.1741011\n",
            "   -0.23641583]\n",
            "  [-0.33610445  0.33725694 -0.0536614  ... -0.21390143  0.1741011\n",
            "   -0.23641583]\n",
            "  [-0.33610445  0.33725694 -0.0536614  ... -0.21390143  0.1741011\n",
            "   -0.23641583]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[-0.33610445  0.33725694 -0.0536614  ... -0.21390143  0.1741011\n",
            "   -0.23641583]\n",
            "  [-0.33610445  0.33725694 -0.0536614  ... -0.21390143  0.1741011\n",
            "   -0.23641583]\n",
            "  [-0.33610445  0.33725694 -0.0536614  ... -0.21390143  0.1741011\n",
            "   -0.23641583]\n",
            "  ...\n",
            "  [-0.33610445  0.33725694 -0.0536614  ... -0.21390143  0.1741011\n",
            "   -0.23641583]\n",
            "  [-0.33610445  0.33725694 -0.0536614  ... -0.21390143  0.1741011\n",
            "   -0.23641583]\n",
            "  [-0.33610445  0.33725694 -0.0536614  ... -0.21390143  0.1741011\n",
            "   -0.23641583]]\n",
            "\n",
            " [[-0.33610445  0.33725694 -0.0536614  ... -0.21390143  0.1741011\n",
            "   -0.23641583]\n",
            "  [-0.33610445  0.33725694 -0.0536614  ... -0.21390143  0.1741011\n",
            "   -0.23641583]\n",
            "  [-0.33610445  0.33725694 -0.0536614  ... -0.21390143  0.1741011\n",
            "   -0.23641583]\n",
            "  ...\n",
            "  [-0.33610445  0.33725694 -0.0536614  ... -0.21390143  0.1741011\n",
            "   -0.23641583]\n",
            "  [-0.33610445  0.33725694 -0.0536614  ... -0.21390143  0.1741011\n",
            "   -0.23641583]\n",
            "  [-0.33610445  0.33725694 -0.0536614  ... -0.21390143  0.1741011\n",
            "   -0.23641583]]\n",
            "\n",
            " [[-0.33610445  0.33725694 -0.0536614  ... -0.21390143  0.1741011\n",
            "   -0.23641583]\n",
            "  [-0.33610445  0.33725694 -0.0536614  ... -0.21390143  0.1741011\n",
            "   -0.23641583]\n",
            "  [-0.33610445  0.33725694 -0.0536614  ... -0.21390143  0.1741011\n",
            "   -0.23641583]\n",
            "  ...\n",
            "  [-0.33610445  0.33725694 -0.0536614  ... -0.21390143  0.1741011\n",
            "   -0.23641583]\n",
            "  [-0.33610445  0.33725694 -0.0536614  ... -0.21390143  0.1741011\n",
            "   -0.23641583]\n",
            "  [-0.33610445  0.33725694 -0.0536614  ... -0.21390143  0.1741011\n",
            "   -0.23641583]]], shape=(128, 764, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[0.13041122 0.13041122 0.13041122 ... 0.13041122 0.13041122 0.13041122]\n",
            " [0.13041122 0.13041122 0.13041122 ... 0.13041122 0.13041122 0.13041122]\n",
            " [0.13041122 0.13041122 0.13041122 ... 0.13041122 0.13041122 0.13041122]\n",
            " ...\n",
            " [0.13041122 0.13041122 0.13041122 ... 0.13041122 0.13041122 0.13041122]\n",
            " [0.13041122 0.13041122 0.13041122 ... 0.13041122 0.13041122 0.13041122]\n",
            " [0.13041122 0.13041122 0.13041122 ... 0.13041122 0.13041122 0.13041122]], shape=(512, 128), dtype=float32) tf.Tensor(\n",
            "[[0.13041122 0.13041122 0.13041122 ... 0.13041122 0.13041122 0.13041122]\n",
            " [0.13041122 0.13041122 0.13041122 ... 0.13041122 0.13041122 0.13041122]\n",
            " [0.13041122 0.13041122 0.13041122 ... 0.13041122 0.13041122 0.13041122]\n",
            " ...\n",
            " [0.13041122 0.13041122 0.13041122 ... 0.13041122 0.13041122 0.13041122]\n",
            " [0.13041122 0.13041122 0.13041122 ... 0.13041122 0.13041122 0.13041122]\n",
            " [0.13041122 0.13041122 0.13041122 ... 0.13041122 0.13041122 0.13041122]], shape=(252, 128), dtype=float32)\n",
            "(128, 764) (512, 1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_15/kernel:0', 'dense_15/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_15/kernel:0', 'dense_15/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch 1, Batch 48/100, Loss=3.64047e-02\n",
            "(1, 764, 1)\n",
            "tf.Tensor(\n",
            "[[[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]], shape=(128, 764, 1), dtype=float32) tf.Tensor(\n",
            "[[[-0.34480646  0.3382904  -0.06189289 ... -0.21046574  0.18063818\n",
            "   -0.24061465]\n",
            "  [-0.34480646  0.3382904  -0.06189289 ... -0.21046574  0.18063818\n",
            "   -0.24061465]\n",
            "  [-0.34480646  0.3382904  -0.06189289 ... -0.21046574  0.18063818\n",
            "   -0.24061465]\n",
            "  ...\n",
            "  [-0.34480646  0.3382904  -0.06189289 ... -0.21046574  0.18063818\n",
            "   -0.24061465]\n",
            "  [-0.34480646  0.3382904  -0.06189289 ... -0.21046574  0.18063818\n",
            "   -0.24061465]\n",
            "  [-0.34480646  0.3382904  -0.06189289 ... -0.21046574  0.18063818\n",
            "   -0.24061465]]\n",
            "\n",
            " [[-0.34480646  0.3382904  -0.06189289 ... -0.21046574  0.18063818\n",
            "   -0.24061465]\n",
            "  [-0.34480646  0.3382904  -0.06189289 ... -0.21046574  0.18063818\n",
            "   -0.24061465]\n",
            "  [-0.34480646  0.3382904  -0.06189289 ... -0.21046574  0.18063818\n",
            "   -0.24061465]\n",
            "  ...\n",
            "  [-0.34480646  0.3382904  -0.06189289 ... -0.21046574  0.18063818\n",
            "   -0.24061465]\n",
            "  [-0.34480646  0.3382904  -0.06189289 ... -0.21046574  0.18063818\n",
            "   -0.24061465]\n",
            "  [-0.34480646  0.3382904  -0.06189289 ... -0.21046574  0.18063818\n",
            "   -0.24061465]]\n",
            "\n",
            " [[-0.34480646  0.3382904  -0.06189289 ... -0.21046574  0.18063818\n",
            "   -0.24061465]\n",
            "  [-0.34480646  0.3382904  -0.06189289 ... -0.21046574  0.18063818\n",
            "   -0.24061465]\n",
            "  [-0.34480646  0.3382904  -0.06189289 ... -0.21046574  0.18063818\n",
            "   -0.24061465]\n",
            "  ...\n",
            "  [-0.34480646  0.3382904  -0.06189289 ... -0.21046574  0.18063818\n",
            "   -0.24061465]\n",
            "  [-0.34480646  0.3382904  -0.06189289 ... -0.21046574  0.18063818\n",
            "   -0.24061465]\n",
            "  [-0.34480646  0.3382904  -0.06189289 ... -0.21046574  0.18063818\n",
            "   -0.24061465]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[-0.34480646  0.3382904  -0.06189289 ... -0.21046574  0.18063818\n",
            "   -0.24061465]\n",
            "  [-0.34480646  0.3382904  -0.06189289 ... -0.21046574  0.18063818\n",
            "   -0.24061465]\n",
            "  [-0.34480646  0.3382904  -0.06189289 ... -0.21046574  0.18063818\n",
            "   -0.24061465]\n",
            "  ...\n",
            "  [-0.34480646  0.3382904  -0.06189289 ... -0.21046574  0.18063818\n",
            "   -0.24061465]\n",
            "  [-0.34480646  0.3382904  -0.06189289 ... -0.21046574  0.18063818\n",
            "   -0.24061465]\n",
            "  [-0.34480646  0.3382904  -0.06189289 ... -0.21046574  0.18063818\n",
            "   -0.24061465]]\n",
            "\n",
            " [[-0.34480646  0.3382904  -0.06189289 ... -0.21046574  0.18063818\n",
            "   -0.24061465]\n",
            "  [-0.34480646  0.3382904  -0.06189289 ... -0.21046574  0.18063818\n",
            "   -0.24061465]\n",
            "  [-0.34480646  0.3382904  -0.06189289 ... -0.21046574  0.18063818\n",
            "   -0.24061465]\n",
            "  ...\n",
            "  [-0.34480646  0.3382904  -0.06189289 ... -0.21046574  0.18063818\n",
            "   -0.24061465]\n",
            "  [-0.34480646  0.3382904  -0.06189289 ... -0.21046574  0.18063818\n",
            "   -0.24061465]\n",
            "  [-0.34480646  0.3382904  -0.06189289 ... -0.21046574  0.18063818\n",
            "   -0.24061465]]\n",
            "\n",
            " [[-0.34480646  0.3382904  -0.06189289 ... -0.21046574  0.18063818\n",
            "   -0.24061465]\n",
            "  [-0.34480646  0.3382904  -0.06189289 ... -0.21046574  0.18063818\n",
            "   -0.24061465]\n",
            "  [-0.34480646  0.3382904  -0.06189289 ... -0.21046574  0.18063818\n",
            "   -0.24061465]\n",
            "  ...\n",
            "  [-0.34480646  0.3382904  -0.06189289 ... -0.21046574  0.18063818\n",
            "   -0.24061465]\n",
            "  [-0.34480646  0.3382904  -0.06189289 ... -0.21046574  0.18063818\n",
            "   -0.24061465]\n",
            "  [-0.34480646  0.3382904  -0.06189289 ... -0.21046574  0.18063818\n",
            "   -0.24061465]]], shape=(128, 764, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[0.08609454 0.08609454 0.08609454 ... 0.08609454 0.08609454 0.08609454]\n",
            " [0.08609454 0.08609454 0.08609454 ... 0.08609454 0.08609454 0.08609454]\n",
            " [0.08609454 0.08609454 0.08609454 ... 0.08609454 0.08609454 0.08609454]\n",
            " ...\n",
            " [0.08609454 0.08609454 0.08609454 ... 0.08609454 0.08609454 0.08609454]\n",
            " [0.08609454 0.08609454 0.08609454 ... 0.08609454 0.08609454 0.08609454]\n",
            " [0.08609454 0.08609454 0.08609454 ... 0.08609454 0.08609454 0.08609454]], shape=(512, 128), dtype=float32) tf.Tensor(\n",
            "[[0.08609454 0.08609454 0.08609454 ... 0.08609454 0.08609454 0.08609454]\n",
            " [0.08609454 0.08609454 0.08609454 ... 0.08609454 0.08609454 0.08609454]\n",
            " [0.08609454 0.08609454 0.08609454 ... 0.08609454 0.08609454 0.08609454]\n",
            " ...\n",
            " [0.08609454 0.08609454 0.08609454 ... 0.08609454 0.08609454 0.08609454]\n",
            " [0.08609454 0.08609454 0.08609454 ... 0.08609454 0.08609454 0.08609454]\n",
            " [0.08609454 0.08609454 0.08609454 ... 0.08609454 0.08609454 0.08609454]], shape=(252, 128), dtype=float32)\n",
            "(128, 764) (512, 1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_15/kernel:0', 'dense_15/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_15/kernel:0', 'dense_15/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch 1, Batch 49/100, Loss=1.89763e-02\n",
            "(1, 764, 1)\n",
            "tf.Tensor(\n",
            "[[[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]], shape=(128, 764, 1), dtype=float32) tf.Tensor(\n",
            "[[[-0.3543416   0.3394323  -0.07120185 ... -0.20603812  0.1879659\n",
            "   -0.24593438]\n",
            "  [-0.3543416   0.3394323  -0.07120185 ... -0.20603812  0.1879659\n",
            "   -0.24593438]\n",
            "  [-0.3543416   0.3394323  -0.07120185 ... -0.20603812  0.1879659\n",
            "   -0.24593438]\n",
            "  ...\n",
            "  [-0.3543416   0.3394323  -0.07120185 ... -0.20603812  0.1879659\n",
            "   -0.24593438]\n",
            "  [-0.3543416   0.3394323  -0.07120185 ... -0.20603812  0.1879659\n",
            "   -0.24593438]\n",
            "  [-0.3543416   0.3394323  -0.07120185 ... -0.20603812  0.1879659\n",
            "   -0.24593438]]\n",
            "\n",
            " [[-0.3543416   0.3394323  -0.07120185 ... -0.20603812  0.1879659\n",
            "   -0.24593438]\n",
            "  [-0.3543416   0.3394323  -0.07120185 ... -0.20603812  0.1879659\n",
            "   -0.24593438]\n",
            "  [-0.3543416   0.3394323  -0.07120185 ... -0.20603812  0.1879659\n",
            "   -0.24593438]\n",
            "  ...\n",
            "  [-0.3543416   0.3394323  -0.07120185 ... -0.20603812  0.1879659\n",
            "   -0.24593438]\n",
            "  [-0.3543416   0.3394323  -0.07120185 ... -0.20603812  0.1879659\n",
            "   -0.24593438]\n",
            "  [-0.3543416   0.3394323  -0.07120185 ... -0.20603812  0.1879659\n",
            "   -0.24593438]]\n",
            "\n",
            " [[-0.3543416   0.3394323  -0.07120185 ... -0.20603812  0.1879659\n",
            "   -0.24593438]\n",
            "  [-0.3543416   0.3394323  -0.07120185 ... -0.20603812  0.1879659\n",
            "   -0.24593438]\n",
            "  [-0.3543416   0.3394323  -0.07120185 ... -0.20603812  0.1879659\n",
            "   -0.24593438]\n",
            "  ...\n",
            "  [-0.3543416   0.3394323  -0.07120185 ... -0.20603812  0.1879659\n",
            "   -0.24593438]\n",
            "  [-0.3543416   0.3394323  -0.07120185 ... -0.20603812  0.1879659\n",
            "   -0.24593438]\n",
            "  [-0.3543416   0.3394323  -0.07120185 ... -0.20603812  0.1879659\n",
            "   -0.24593438]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[-0.3543416   0.3394323  -0.07120185 ... -0.20603812  0.1879659\n",
            "   -0.24593438]\n",
            "  [-0.3543416   0.3394323  -0.07120185 ... -0.20603812  0.1879659\n",
            "   -0.24593438]\n",
            "  [-0.3543416   0.3394323  -0.07120185 ... -0.20603812  0.1879659\n",
            "   -0.24593438]\n",
            "  ...\n",
            "  [-0.3543416   0.3394323  -0.07120185 ... -0.20603812  0.1879659\n",
            "   -0.24593438]\n",
            "  [-0.3543416   0.3394323  -0.07120185 ... -0.20603812  0.1879659\n",
            "   -0.24593438]\n",
            "  [-0.3543416   0.3394323  -0.07120185 ... -0.20603812  0.1879659\n",
            "   -0.24593438]]\n",
            "\n",
            " [[-0.3543416   0.3394323  -0.07120185 ... -0.20603812  0.1879659\n",
            "   -0.24593438]\n",
            "  [-0.3543416   0.3394323  -0.07120185 ... -0.20603812  0.1879659\n",
            "   -0.24593438]\n",
            "  [-0.3543416   0.3394323  -0.07120185 ... -0.20603812  0.1879659\n",
            "   -0.24593438]\n",
            "  ...\n",
            "  [-0.3543416   0.3394323  -0.07120185 ... -0.20603812  0.1879659\n",
            "   -0.24593438]\n",
            "  [-0.3543416   0.3394323  -0.07120185 ... -0.20603812  0.1879659\n",
            "   -0.24593438]\n",
            "  [-0.3543416   0.3394323  -0.07120185 ... -0.20603812  0.1879659\n",
            "   -0.24593438]]\n",
            "\n",
            " [[-0.3543416   0.3394323  -0.07120185 ... -0.20603812  0.1879659\n",
            "   -0.24593438]\n",
            "  [-0.3543416   0.3394323  -0.07120185 ... -0.20603812  0.1879659\n",
            "   -0.24593438]\n",
            "  [-0.3543416   0.3394323  -0.07120185 ... -0.20603812  0.1879659\n",
            "   -0.24593438]\n",
            "  ...\n",
            "  [-0.3543416   0.3394323  -0.07120185 ... -0.20603812  0.1879659\n",
            "   -0.24593438]\n",
            "  [-0.3543416   0.3394323  -0.07120185 ... -0.20603812  0.1879659\n",
            "   -0.24593438]\n",
            "  [-0.3543416   0.3394323  -0.07120185 ... -0.20603812  0.1879659\n",
            "   -0.24593438]]], shape=(128, 764, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[0.03554173 0.03554173 0.03554173 ... 0.03554173 0.03554173 0.03554173]\n",
            " [0.03554173 0.03554173 0.03554173 ... 0.03554173 0.03554173 0.03554173]\n",
            " [0.03554173 0.03554173 0.03554173 ... 0.03554173 0.03554173 0.03554173]\n",
            " ...\n",
            " [0.03554173 0.03554173 0.03554173 ... 0.03554173 0.03554173 0.03554173]\n",
            " [0.03554173 0.03554173 0.03554173 ... 0.03554173 0.03554173 0.03554173]\n",
            " [0.03554173 0.03554173 0.03554173 ... 0.03554173 0.03554173 0.03554173]], shape=(512, 128), dtype=float32) tf.Tensor(\n",
            "[[0.03554173 0.03554173 0.03554173 ... 0.03554173 0.03554173 0.03554173]\n",
            " [0.03554173 0.03554173 0.03554173 ... 0.03554173 0.03554173 0.03554173]\n",
            " [0.03554173 0.03554173 0.03554173 ... 0.03554173 0.03554173 0.03554173]\n",
            " ...\n",
            " [0.03554173 0.03554173 0.03554173 ... 0.03554173 0.03554173 0.03554173]\n",
            " [0.03554173 0.03554173 0.03554173 ... 0.03554173 0.03554173 0.03554173]\n",
            " [0.03554173 0.03554173 0.03554173 ... 0.03554173 0.03554173 0.03554173]], shape=(252, 128), dtype=float32)\n",
            "(128, 764) (512, 1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_15/kernel:0', 'dense_15/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_15/kernel:0', 'dense_15/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch 1, Batch 50/100, Loss=8.24991e-03\n",
            "(1, 764, 1)\n",
            "tf.Tensor(\n",
            "[[[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]], shape=(128, 764, 1), dtype=float32) tf.Tensor(\n",
            "[[[-0.3636518   0.3405524  -0.08040392 ... -0.20146972  0.19518715\n",
            "   -0.2513653 ]\n",
            "  [-0.3636518   0.3405524  -0.08040392 ... -0.20146972  0.19518715\n",
            "   -0.2513653 ]\n",
            "  [-0.3636518   0.3405524  -0.08040392 ... -0.20146972  0.19518715\n",
            "   -0.2513653 ]\n",
            "  ...\n",
            "  [-0.3636518   0.3405524  -0.08040392 ... -0.20146972  0.19518715\n",
            "   -0.2513653 ]\n",
            "  [-0.3636518   0.3405524  -0.08040392 ... -0.20146972  0.19518715\n",
            "   -0.2513653 ]\n",
            "  [-0.3636518   0.3405524  -0.08040392 ... -0.20146972  0.19518715\n",
            "   -0.2513653 ]]\n",
            "\n",
            " [[-0.3636518   0.3405524  -0.08040392 ... -0.20146972  0.19518715\n",
            "   -0.2513653 ]\n",
            "  [-0.3636518   0.3405524  -0.08040392 ... -0.20146972  0.19518715\n",
            "   -0.2513653 ]\n",
            "  [-0.3636518   0.3405524  -0.08040392 ... -0.20146972  0.19518715\n",
            "   -0.2513653 ]\n",
            "  ...\n",
            "  [-0.3636518   0.3405524  -0.08040392 ... -0.20146972  0.19518715\n",
            "   -0.2513653 ]\n",
            "  [-0.3636518   0.3405524  -0.08040392 ... -0.20146972  0.19518715\n",
            "   -0.2513653 ]\n",
            "  [-0.3636518   0.3405524  -0.08040392 ... -0.20146972  0.19518715\n",
            "   -0.2513653 ]]\n",
            "\n",
            " [[-0.3636518   0.3405524  -0.08040392 ... -0.20146972  0.19518715\n",
            "   -0.2513653 ]\n",
            "  [-0.3636518   0.3405524  -0.08040392 ... -0.20146972  0.19518715\n",
            "   -0.2513653 ]\n",
            "  [-0.3636518   0.3405524  -0.08040392 ... -0.20146972  0.19518715\n",
            "   -0.2513653 ]\n",
            "  ...\n",
            "  [-0.3636518   0.3405524  -0.08040392 ... -0.20146972  0.19518715\n",
            "   -0.2513653 ]\n",
            "  [-0.3636518   0.3405524  -0.08040392 ... -0.20146972  0.19518715\n",
            "   -0.2513653 ]\n",
            "  [-0.3636518   0.3405524  -0.08040392 ... -0.20146972  0.19518715\n",
            "   -0.2513653 ]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[-0.3636518   0.3405524  -0.08040392 ... -0.20146972  0.19518715\n",
            "   -0.2513653 ]\n",
            "  [-0.3636518   0.3405524  -0.08040392 ... -0.20146972  0.19518715\n",
            "   -0.2513653 ]\n",
            "  [-0.3636518   0.3405524  -0.08040392 ... -0.20146972  0.19518715\n",
            "   -0.2513653 ]\n",
            "  ...\n",
            "  [-0.3636518   0.3405524  -0.08040392 ... -0.20146972  0.19518715\n",
            "   -0.2513653 ]\n",
            "  [-0.3636518   0.3405524  -0.08040392 ... -0.20146972  0.19518715\n",
            "   -0.2513653 ]\n",
            "  [-0.3636518   0.3405524  -0.08040392 ... -0.20146972  0.19518715\n",
            "   -0.2513653 ]]\n",
            "\n",
            " [[-0.3636518   0.3405524  -0.08040392 ... -0.20146972  0.19518715\n",
            "   -0.2513653 ]\n",
            "  [-0.3636518   0.3405524  -0.08040392 ... -0.20146972  0.19518715\n",
            "   -0.2513653 ]\n",
            "  [-0.3636518   0.3405524  -0.08040392 ... -0.20146972  0.19518715\n",
            "   -0.2513653 ]\n",
            "  ...\n",
            "  [-0.3636518   0.3405524  -0.08040392 ... -0.20146972  0.19518715\n",
            "   -0.2513653 ]\n",
            "  [-0.3636518   0.3405524  -0.08040392 ... -0.20146972  0.19518715\n",
            "   -0.2513653 ]\n",
            "  [-0.3636518   0.3405524  -0.08040392 ... -0.20146972  0.19518715\n",
            "   -0.2513653 ]]\n",
            "\n",
            " [[-0.3636518   0.3405524  -0.08040392 ... -0.20146972  0.19518715\n",
            "   -0.2513653 ]\n",
            "  [-0.3636518   0.3405524  -0.08040392 ... -0.20146972  0.19518715\n",
            "   -0.2513653 ]\n",
            "  [-0.3636518   0.3405524  -0.08040392 ... -0.20146972  0.19518715\n",
            "   -0.2513653 ]\n",
            "  ...\n",
            "  [-0.3636518   0.3405524  -0.08040392 ... -0.20146972  0.19518715\n",
            "   -0.2513653 ]\n",
            "  [-0.3636518   0.3405524  -0.08040392 ... -0.20146972  0.19518715\n",
            "   -0.2513653 ]\n",
            "  [-0.3636518   0.3405524  -0.08040392 ... -0.20146972  0.19518715\n",
            "   -0.2513653 ]]], shape=(128, 764, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.01449014 -0.01449014 -0.01449014 ... -0.01449014 -0.01449014\n",
            "  -0.01449014]\n",
            " [-0.01449014 -0.01449014 -0.01449014 ... -0.01449014 -0.01449014\n",
            "  -0.01449014]\n",
            " [-0.01449014 -0.01449014 -0.01449014 ... -0.01449014 -0.01449014\n",
            "  -0.01449014]\n",
            " ...\n",
            " [-0.01449014 -0.01449014 -0.01449014 ... -0.01449014 -0.01449014\n",
            "  -0.01449014]\n",
            " [-0.01449014 -0.01449014 -0.01449014 ... -0.01449014 -0.01449014\n",
            "  -0.01449014]\n",
            " [-0.01449014 -0.01449014 -0.01449014 ... -0.01449014 -0.01449014\n",
            "  -0.01449014]], shape=(512, 128), dtype=float32) tf.Tensor(\n",
            "[[-0.01449014 -0.01449014 -0.01449014 ... -0.01449014 -0.01449014\n",
            "  -0.01449014]\n",
            " [-0.01449014 -0.01449014 -0.01449014 ... -0.01449014 -0.01449014\n",
            "  -0.01449014]\n",
            " [-0.01449014 -0.01449014 -0.01449014 ... -0.01449014 -0.01449014\n",
            "  -0.01449014]\n",
            " ...\n",
            " [-0.01449014 -0.01449014 -0.01449014 ... -0.01449014 -0.01449014\n",
            "  -0.01449014]\n",
            " [-0.01449014 -0.01449014 -0.01449014 ... -0.01449014 -0.01449014\n",
            "  -0.01449014]\n",
            " [-0.01449014 -0.01449014 -0.01449014 ... -0.01449014 -0.01449014\n",
            "  -0.01449014]], shape=(252, 128), dtype=float32)\n",
            "(128, 764) (512, 1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_15/kernel:0', 'dense_15/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_15/kernel:0', 'dense_15/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch 1, Batch 51/100, Loss=4.45235e-03\n",
            "(1, 764, 1)\n",
            "tf.Tensor(\n",
            "[[[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " [[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " [[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]], shape=(128, 764, 1), dtype=float32) tf.Tensor(\n",
            "[[[-0.37183374  0.34153417 -0.08853083 ... -0.1975035   0.20153683\n",
            "   -0.2560686 ]\n",
            "  [-0.37183374  0.34153417 -0.08853083 ... -0.1975035   0.20153683\n",
            "   -0.2560686 ]\n",
            "  [-0.37183374  0.34153417 -0.08853083 ... -0.1975035   0.20153683\n",
            "   -0.2560686 ]\n",
            "  ...\n",
            "  [-0.37183374  0.34153417 -0.08853083 ... -0.1975035   0.20153683\n",
            "   -0.2560686 ]\n",
            "  [-0.37183374  0.34153417 -0.08853083 ... -0.1975035   0.20153683\n",
            "   -0.2560686 ]\n",
            "  [-0.37183374  0.34153417 -0.08853083 ... -0.1975035   0.20153683\n",
            "   -0.2560686 ]]\n",
            "\n",
            " [[-0.37183374  0.34153417 -0.08853083 ... -0.1975035   0.20153683\n",
            "   -0.2560686 ]\n",
            "  [-0.37183374  0.34153417 -0.08853083 ... -0.1975035   0.20153683\n",
            "   -0.2560686 ]\n",
            "  [-0.37183374  0.34153417 -0.08853083 ... -0.1975035   0.20153683\n",
            "   -0.2560686 ]\n",
            "  ...\n",
            "  [-0.37183374  0.34153417 -0.08853083 ... -0.1975035   0.20153683\n",
            "   -0.2560686 ]\n",
            "  [-0.37183374  0.34153417 -0.08853083 ... -0.1975035   0.20153683\n",
            "   -0.2560686 ]\n",
            "  [-0.37183374  0.34153417 -0.08853083 ... -0.1975035   0.20153683\n",
            "   -0.2560686 ]]\n",
            "\n",
            " [[-0.37183374  0.34153417 -0.08853083 ... -0.1975035   0.20153683\n",
            "   -0.2560686 ]\n",
            "  [-0.37183374  0.34153417 -0.08853083 ... -0.1975035   0.20153683\n",
            "   -0.2560686 ]\n",
            "  [-0.37183374  0.34153417 -0.08853083 ... -0.1975035   0.20153683\n",
            "   -0.2560686 ]\n",
            "  ...\n",
            "  [-0.37183374  0.34153417 -0.08853083 ... -0.1975035   0.20153683\n",
            "   -0.2560686 ]\n",
            "  [-0.37183374  0.34153417 -0.08853083 ... -0.1975035   0.20153683\n",
            "   -0.2560686 ]\n",
            "  [-0.37183374  0.34153417 -0.08853083 ... -0.1975035   0.20153683\n",
            "   -0.2560686 ]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[-0.37183374  0.34153417 -0.08853083 ... -0.1975035   0.20153683\n",
            "   -0.2560686 ]\n",
            "  [-0.37183374  0.34153417 -0.08853083 ... -0.1975035   0.20153683\n",
            "   -0.2560686 ]\n",
            "  [-0.37183374  0.34153417 -0.08853083 ... -0.1975035   0.20153683\n",
            "   -0.2560686 ]\n",
            "  ...\n",
            "  [-0.37183374  0.34153417 -0.08853083 ... -0.1975035   0.20153683\n",
            "   -0.2560686 ]\n",
            "  [-0.37183374  0.34153417 -0.08853083 ... -0.1975035   0.20153683\n",
            "   -0.2560686 ]\n",
            "  [-0.37183374  0.34153417 -0.08853083 ... -0.1975035   0.20153683\n",
            "   -0.2560686 ]]\n",
            "\n",
            " [[-0.37183374  0.34153417 -0.08853083 ... -0.1975035   0.20153683\n",
            "   -0.2560686 ]\n",
            "  [-0.37183374  0.34153417 -0.08853083 ... -0.1975035   0.20153683\n",
            "   -0.2560686 ]\n",
            "  [-0.37183374  0.34153417 -0.08853083 ... -0.1975035   0.20153683\n",
            "   -0.2560686 ]\n",
            "  ...\n",
            "  [-0.37183374  0.34153417 -0.08853083 ... -0.1975035   0.20153683\n",
            "   -0.2560686 ]\n",
            "  [-0.37183374  0.34153417 -0.08853083 ... -0.1975035   0.20153683\n",
            "   -0.2560686 ]\n",
            "  [-0.37183374  0.34153417 -0.08853083 ... -0.1975035   0.20153683\n",
            "   -0.2560686 ]]\n",
            "\n",
            " [[-0.37183374  0.34153417 -0.08853083 ... -0.1975035   0.20153683\n",
            "   -0.2560686 ]\n",
            "  [-0.37183374  0.34153417 -0.08853083 ... -0.1975035   0.20153683\n",
            "   -0.2560686 ]\n",
            "  [-0.37183374  0.34153417 -0.08853083 ... -0.1975035   0.20153683\n",
            "   -0.2560686 ]\n",
            "  ...\n",
            "  [-0.37183374  0.34153417 -0.08853083 ... -0.1975035   0.20153683\n",
            "   -0.2560686 ]\n",
            "  [-0.37183374  0.34153417 -0.08853083 ... -0.1975035   0.20153683\n",
            "   -0.2560686 ]\n",
            "  [-0.37183374  0.34153417 -0.08853083 ... -0.1975035   0.20153683\n",
            "   -0.2560686 ]]], shape=(128, 764, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.05828911 -0.05828911 -0.05828911 ... -0.05828911 -0.05828911\n",
            "  -0.05828911]\n",
            " [-0.05828911 -0.05828911 -0.05828911 ... -0.05828911 -0.05828911\n",
            "  -0.05828911]\n",
            " [-0.05828911 -0.05828911 -0.05828911 ... -0.05828911 -0.05828911\n",
            "  -0.05828911]\n",
            " ...\n",
            " [-0.05828911 -0.05828911 -0.05828911 ... -0.05828911 -0.05828911\n",
            "  -0.05828911]\n",
            " [-0.05828911 -0.05828911 -0.05828911 ... -0.05828911 -0.05828911\n",
            "  -0.05828911]\n",
            " [-0.05828911 -0.05828911 -0.05828911 ... -0.05828911 -0.05828911\n",
            "  -0.05828911]], shape=(512, 128), dtype=float32) tf.Tensor(\n",
            "[[-0.05828911 -0.05828911 -0.05828911 ... -0.05828911 -0.05828911\n",
            "  -0.05828911]\n",
            " [-0.05828911 -0.05828911 -0.05828911 ... -0.05828911 -0.05828911\n",
            "  -0.05828911]\n",
            " [-0.05828911 -0.05828911 -0.05828911 ... -0.05828911 -0.05828911\n",
            "  -0.05828911]\n",
            " ...\n",
            " [-0.05828911 -0.05828911 -0.05828911 ... -0.05828911 -0.05828911\n",
            "  -0.05828911]\n",
            " [-0.05828911 -0.05828911 -0.05828911 ... -0.05828911 -0.05828911\n",
            "  -0.05828911]\n",
            " [-0.05828911 -0.05828911 -0.05828911 ... -0.05828911 -0.05828911\n",
            "  -0.05828911]], shape=(252, 128), dtype=float32)\n",
            "(128, 764) (512, 1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_15/kernel:0', 'dense_15/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_15/kernel:0', 'dense_15/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch 1, Batch 52/100, Loss=8.10696e-03\n",
            "(1, 764, 1)\n",
            "tf.Tensor(\n",
            "[[[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " [[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " [[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]], shape=(128, 764, 1), dtype=float32) tf.Tensor(\n",
            "[[[-0.37792775  0.34225264 -0.09465539 ... -0.19490339  0.20620441\n",
            "   -0.2592192 ]\n",
            "  [-0.37792775  0.34225264 -0.09465539 ... -0.19490339  0.20620441\n",
            "   -0.2592192 ]\n",
            "  [-0.37792775  0.34225264 -0.09465539 ... -0.19490339  0.20620441\n",
            "   -0.2592192 ]\n",
            "  ...\n",
            "  [-0.37792775  0.34225264 -0.09465539 ... -0.19490339  0.20620441\n",
            "   -0.2592192 ]\n",
            "  [-0.37792775  0.34225264 -0.09465539 ... -0.19490339  0.20620441\n",
            "   -0.2592192 ]\n",
            "  [-0.37792775  0.34225264 -0.09465539 ... -0.19490339  0.20620441\n",
            "   -0.2592192 ]]\n",
            "\n",
            " [[-0.37792775  0.34225264 -0.09465539 ... -0.19490339  0.20620441\n",
            "   -0.2592192 ]\n",
            "  [-0.37792775  0.34225264 -0.09465539 ... -0.19490339  0.20620441\n",
            "   -0.2592192 ]\n",
            "  [-0.37792775  0.34225264 -0.09465539 ... -0.19490339  0.20620441\n",
            "   -0.2592192 ]\n",
            "  ...\n",
            "  [-0.37792775  0.34225264 -0.09465539 ... -0.19490339  0.20620441\n",
            "   -0.2592192 ]\n",
            "  [-0.37792775  0.34225264 -0.09465539 ... -0.19490339  0.20620441\n",
            "   -0.2592192 ]\n",
            "  [-0.37792775  0.34225264 -0.09465539 ... -0.19490339  0.20620441\n",
            "   -0.2592192 ]]\n",
            "\n",
            " [[-0.37792775  0.34225264 -0.09465539 ... -0.19490339  0.20620441\n",
            "   -0.2592192 ]\n",
            "  [-0.37792775  0.34225264 -0.09465539 ... -0.19490339  0.20620441\n",
            "   -0.2592192 ]\n",
            "  [-0.37792775  0.34225264 -0.09465539 ... -0.19490339  0.20620441\n",
            "   -0.2592192 ]\n",
            "  ...\n",
            "  [-0.37792775  0.34225264 -0.09465539 ... -0.19490339  0.20620441\n",
            "   -0.2592192 ]\n",
            "  [-0.37792775  0.34225264 -0.09465539 ... -0.19490339  0.20620441\n",
            "   -0.2592192 ]\n",
            "  [-0.37792775  0.34225264 -0.09465539 ... -0.19490339  0.20620441\n",
            "   -0.2592192 ]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[-0.37792775  0.34225264 -0.09465539 ... -0.19490339  0.20620441\n",
            "   -0.2592192 ]\n",
            "  [-0.37792775  0.34225264 -0.09465539 ... -0.19490339  0.20620441\n",
            "   -0.2592192 ]\n",
            "  [-0.37792775  0.34225264 -0.09465539 ... -0.19490339  0.20620441\n",
            "   -0.2592192 ]\n",
            "  ...\n",
            "  [-0.37792775  0.34225264 -0.09465539 ... -0.19490339  0.20620441\n",
            "   -0.2592192 ]\n",
            "  [-0.37792775  0.34225264 -0.09465539 ... -0.19490339  0.20620441\n",
            "   -0.2592192 ]\n",
            "  [-0.37792775  0.34225264 -0.09465539 ... -0.19490339  0.20620441\n",
            "   -0.2592192 ]]\n",
            "\n",
            " [[-0.37792775  0.34225264 -0.09465539 ... -0.19490339  0.20620441\n",
            "   -0.2592192 ]\n",
            "  [-0.37792775  0.34225264 -0.09465539 ... -0.19490339  0.20620441\n",
            "   -0.2592192 ]\n",
            "  [-0.37792775  0.34225264 -0.09465539 ... -0.19490339  0.20620441\n",
            "   -0.2592192 ]\n",
            "  ...\n",
            "  [-0.37792775  0.34225264 -0.09465539 ... -0.19490339  0.20620441\n",
            "   -0.2592192 ]\n",
            "  [-0.37792775  0.34225264 -0.09465539 ... -0.19490339  0.20620441\n",
            "   -0.2592192 ]\n",
            "  [-0.37792775  0.34225264 -0.09465539 ... -0.19490339  0.20620441\n",
            "   -0.2592192 ]]\n",
            "\n",
            " [[-0.37792775  0.34225264 -0.09465539 ... -0.19490339  0.20620441\n",
            "   -0.2592192 ]\n",
            "  [-0.37792775  0.34225264 -0.09465539 ... -0.19490339  0.20620441\n",
            "   -0.2592192 ]\n",
            "  [-0.37792775  0.34225264 -0.09465539 ... -0.19490339  0.20620441\n",
            "   -0.2592192 ]\n",
            "  ...\n",
            "  [-0.37792775  0.34225264 -0.09465539 ... -0.19490339  0.20620441\n",
            "   -0.2592192 ]\n",
            "  [-0.37792775  0.34225264 -0.09465539 ... -0.19490339  0.20620441\n",
            "   -0.2592192 ]\n",
            "  [-0.37792775  0.34225264 -0.09465539 ... -0.19490339  0.20620441\n",
            "   -0.2592192 ]]], shape=(128, 764, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.0899577 -0.0899577 -0.0899577 ... -0.0899577 -0.0899577 -0.0899577]\n",
            " [-0.0899577 -0.0899577 -0.0899577 ... -0.0899577 -0.0899577 -0.0899577]\n",
            " [-0.0899577 -0.0899577 -0.0899577 ... -0.0899577 -0.0899577 -0.0899577]\n",
            " ...\n",
            " [-0.0899577 -0.0899577 -0.0899577 ... -0.0899577 -0.0899577 -0.0899577]\n",
            " [-0.0899577 -0.0899577 -0.0899577 ... -0.0899577 -0.0899577 -0.0899577]\n",
            " [-0.0899577 -0.0899577 -0.0899577 ... -0.0899577 -0.0899577 -0.0899577]], shape=(512, 128), dtype=float32) tf.Tensor(\n",
            "[[-0.0899577 -0.0899577 -0.0899577 ... -0.0899577 -0.0899577 -0.0899577]\n",
            " [-0.0899577 -0.0899577 -0.0899577 ... -0.0899577 -0.0899577 -0.0899577]\n",
            " [-0.0899577 -0.0899577 -0.0899577 ... -0.0899577 -0.0899577 -0.0899577]\n",
            " ...\n",
            " [-0.0899577 -0.0899577 -0.0899577 ... -0.0899577 -0.0899577 -0.0899577]\n",
            " [-0.0899577 -0.0899577 -0.0899577 ... -0.0899577 -0.0899577 -0.0899577]\n",
            " [-0.0899577 -0.0899577 -0.0899577 ... -0.0899577 -0.0899577 -0.0899577]], shape=(252, 128), dtype=float32)\n",
            "(128, 764) (512, 1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_15/kernel:0', 'dense_15/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_15/kernel:0', 'dense_15/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch 1, Batch 53/100, Loss=1.37397e-02\n",
            "(1, 764, 1)\n",
            "tf.Tensor(\n",
            "[[[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " [[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " [[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]], shape=(128, 764, 1), dtype=float32) tf.Tensor(\n",
            "[[[-0.3815084   0.34264836 -0.09843767 ... -0.1940019   0.20882893\n",
            "   -0.26048926]\n",
            "  [-0.3815084   0.34264836 -0.09843767 ... -0.1940019   0.20882893\n",
            "   -0.26048926]\n",
            "  [-0.3815084   0.34264836 -0.09843767 ... -0.1940019   0.20882893\n",
            "   -0.26048926]\n",
            "  ...\n",
            "  [-0.3815084   0.34264836 -0.09843767 ... -0.1940019   0.20882893\n",
            "   -0.26048926]\n",
            "  [-0.3815084   0.34264836 -0.09843767 ... -0.1940019   0.20882893\n",
            "   -0.26048926]\n",
            "  [-0.3815084   0.34264836 -0.09843767 ... -0.1940019   0.20882893\n",
            "   -0.26048926]]\n",
            "\n",
            " [[-0.3815084   0.34264836 -0.09843767 ... -0.1940019   0.20882893\n",
            "   -0.26048926]\n",
            "  [-0.3815084   0.34264836 -0.09843767 ... -0.1940019   0.20882893\n",
            "   -0.26048926]\n",
            "  [-0.3815084   0.34264836 -0.09843767 ... -0.1940019   0.20882893\n",
            "   -0.26048926]\n",
            "  ...\n",
            "  [-0.3815084   0.34264836 -0.09843767 ... -0.1940019   0.20882893\n",
            "   -0.26048926]\n",
            "  [-0.3815084   0.34264836 -0.09843767 ... -0.1940019   0.20882893\n",
            "   -0.26048926]\n",
            "  [-0.3815084   0.34264836 -0.09843767 ... -0.1940019   0.20882893\n",
            "   -0.26048926]]\n",
            "\n",
            " [[-0.3815084   0.34264836 -0.09843767 ... -0.1940019   0.20882893\n",
            "   -0.26048926]\n",
            "  [-0.3815084   0.34264836 -0.09843767 ... -0.1940019   0.20882893\n",
            "   -0.26048926]\n",
            "  [-0.3815084   0.34264836 -0.09843767 ... -0.1940019   0.20882893\n",
            "   -0.26048926]\n",
            "  ...\n",
            "  [-0.3815084   0.34264836 -0.09843767 ... -0.1940019   0.20882893\n",
            "   -0.26048926]\n",
            "  [-0.3815084   0.34264836 -0.09843767 ... -0.1940019   0.20882893\n",
            "   -0.26048926]\n",
            "  [-0.3815084   0.34264836 -0.09843767 ... -0.1940019   0.20882893\n",
            "   -0.26048926]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[-0.3815084   0.34264836 -0.09843767 ... -0.1940019   0.20882893\n",
            "   -0.26048926]\n",
            "  [-0.3815084   0.34264836 -0.09843767 ... -0.1940019   0.20882893\n",
            "   -0.26048926]\n",
            "  [-0.3815084   0.34264836 -0.09843767 ... -0.1940019   0.20882893\n",
            "   -0.26048926]\n",
            "  ...\n",
            "  [-0.3815084   0.34264836 -0.09843767 ... -0.1940019   0.20882893\n",
            "   -0.26048926]\n",
            "  [-0.3815084   0.34264836 -0.09843767 ... -0.1940019   0.20882893\n",
            "   -0.26048926]\n",
            "  [-0.3815084   0.34264836 -0.09843767 ... -0.1940019   0.20882893\n",
            "   -0.26048926]]\n",
            "\n",
            " [[-0.3815084   0.34264836 -0.09843767 ... -0.1940019   0.20882893\n",
            "   -0.26048926]\n",
            "  [-0.3815084   0.34264836 -0.09843767 ... -0.1940019   0.20882893\n",
            "   -0.26048926]\n",
            "  [-0.3815084   0.34264836 -0.09843767 ... -0.1940019   0.20882893\n",
            "   -0.26048926]\n",
            "  ...\n",
            "  [-0.3815084   0.34264836 -0.09843767 ... -0.1940019   0.20882893\n",
            "   -0.26048926]\n",
            "  [-0.3815084   0.34264836 -0.09843767 ... -0.1940019   0.20882893\n",
            "   -0.26048926]\n",
            "  [-0.3815084   0.34264836 -0.09843767 ... -0.1940019   0.20882893\n",
            "   -0.26048926]]\n",
            "\n",
            " [[-0.3815084   0.34264836 -0.09843767 ... -0.1940019   0.20882893\n",
            "   -0.26048926]\n",
            "  [-0.3815084   0.34264836 -0.09843767 ... -0.1940019   0.20882893\n",
            "   -0.26048926]\n",
            "  [-0.3815084   0.34264836 -0.09843767 ... -0.1940019   0.20882893\n",
            "   -0.26048926]\n",
            "  ...\n",
            "  [-0.3815084   0.34264836 -0.09843767 ... -0.1940019   0.20882893\n",
            "   -0.26048926]\n",
            "  [-0.3815084   0.34264836 -0.09843767 ... -0.1940019   0.20882893\n",
            "   -0.26048926]\n",
            "  [-0.3815084   0.34264836 -0.09843767 ... -0.1940019   0.20882893\n",
            "   -0.26048926]]], shape=(128, 764, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.10699652 -0.10699652 -0.10699652 ... -0.10699652 -0.10699652\n",
            "  -0.10699652]\n",
            " [-0.10699652 -0.10699652 -0.10699652 ... -0.10699652 -0.10699652\n",
            "  -0.10699652]\n",
            " [-0.10699652 -0.10699652 -0.10699652 ... -0.10699652 -0.10699652\n",
            "  -0.10699652]\n",
            " ...\n",
            " [-0.10699652 -0.10699652 -0.10699652 ... -0.10699652 -0.10699652\n",
            "  -0.10699652]\n",
            " [-0.10699652 -0.10699652 -0.10699652 ... -0.10699652 -0.10699652\n",
            "  -0.10699652]\n",
            " [-0.10699652 -0.10699652 -0.10699652 ... -0.10699652 -0.10699652\n",
            "  -0.10699652]], shape=(512, 128), dtype=float32) tf.Tensor(\n",
            "[[-0.10699652 -0.10699652 -0.10699652 ... -0.10699652 -0.10699652\n",
            "  -0.10699652]\n",
            " [-0.10699652 -0.10699652 -0.10699652 ... -0.10699652 -0.10699652\n",
            "  -0.10699652]\n",
            " [-0.10699652 -0.10699652 -0.10699652 ... -0.10699652 -0.10699652\n",
            "  -0.10699652]\n",
            " ...\n",
            " [-0.10699652 -0.10699652 -0.10699652 ... -0.10699652 -0.10699652\n",
            "  -0.10699652]\n",
            " [-0.10699652 -0.10699652 -0.10699652 ... -0.10699652 -0.10699652\n",
            "  -0.10699652]\n",
            " [-0.10699652 -0.10699652 -0.10699652 ... -0.10699652 -0.10699652\n",
            "  -0.10699652]], shape=(252, 128), dtype=float32)\n",
            "(128, 764) (512, 1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_15/kernel:0', 'dense_15/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_15/kernel:0', 'dense_15/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch 1, Batch 54/100, Loss=1.75901e-02\n",
            "(1, 764, 1)\n",
            "tf.Tensor(\n",
            "[[[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " [[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " [[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]], shape=(128, 764, 1), dtype=float32) tf.Tensor(\n",
            "[[[-0.38239673  0.3426853  -0.09979361 ... -0.19492178  0.20925716\n",
            "   -0.25978678]\n",
            "  [-0.38239673  0.3426853  -0.09979361 ... -0.19492178  0.20925716\n",
            "   -0.25978678]\n",
            "  [-0.38239673  0.3426853  -0.09979361 ... -0.19492178  0.20925716\n",
            "   -0.25978678]\n",
            "  ...\n",
            "  [-0.38239673  0.3426853  -0.09979361 ... -0.19492178  0.20925716\n",
            "   -0.25978678]\n",
            "  [-0.38239673  0.3426853  -0.09979361 ... -0.19492178  0.20925716\n",
            "   -0.25978678]\n",
            "  [-0.38239673  0.3426853  -0.09979361 ... -0.19492178  0.20925716\n",
            "   -0.25978678]]\n",
            "\n",
            " [[-0.38239673  0.3426853  -0.09979361 ... -0.19492178  0.20925716\n",
            "   -0.25978678]\n",
            "  [-0.38239673  0.3426853  -0.09979361 ... -0.19492178  0.20925716\n",
            "   -0.25978678]\n",
            "  [-0.38239673  0.3426853  -0.09979361 ... -0.19492178  0.20925716\n",
            "   -0.25978678]\n",
            "  ...\n",
            "  [-0.38239673  0.3426853  -0.09979361 ... -0.19492178  0.20925716\n",
            "   -0.25978678]\n",
            "  [-0.38239673  0.3426853  -0.09979361 ... -0.19492178  0.20925716\n",
            "   -0.25978678]\n",
            "  [-0.38239673  0.3426853  -0.09979361 ... -0.19492178  0.20925716\n",
            "   -0.25978678]]\n",
            "\n",
            " [[-0.38239673  0.3426853  -0.09979361 ... -0.19492178  0.20925716\n",
            "   -0.25978678]\n",
            "  [-0.38239673  0.3426853  -0.09979361 ... -0.19492178  0.20925716\n",
            "   -0.25978678]\n",
            "  [-0.38239673  0.3426853  -0.09979361 ... -0.19492178  0.20925716\n",
            "   -0.25978678]\n",
            "  ...\n",
            "  [-0.38239673  0.3426853  -0.09979361 ... -0.19492178  0.20925716\n",
            "   -0.25978678]\n",
            "  [-0.38239673  0.3426853  -0.09979361 ... -0.19492178  0.20925716\n",
            "   -0.25978678]\n",
            "  [-0.38239673  0.3426853  -0.09979361 ... -0.19492178  0.20925716\n",
            "   -0.25978678]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[-0.38239673  0.3426853  -0.09979361 ... -0.19492178  0.20925716\n",
            "   -0.25978678]\n",
            "  [-0.38239673  0.3426853  -0.09979361 ... -0.19492178  0.20925716\n",
            "   -0.25978678]\n",
            "  [-0.38239673  0.3426853  -0.09979361 ... -0.19492178  0.20925716\n",
            "   -0.25978678]\n",
            "  ...\n",
            "  [-0.38239673  0.3426853  -0.09979361 ... -0.19492178  0.20925716\n",
            "   -0.25978678]\n",
            "  [-0.38239673  0.3426853  -0.09979361 ... -0.19492178  0.20925716\n",
            "   -0.25978678]\n",
            "  [-0.38239673  0.3426853  -0.09979361 ... -0.19492178  0.20925716\n",
            "   -0.25978678]]\n",
            "\n",
            " [[-0.38239673  0.3426853  -0.09979361 ... -0.19492178  0.20925716\n",
            "   -0.25978678]\n",
            "  [-0.38239673  0.3426853  -0.09979361 ... -0.19492178  0.20925716\n",
            "   -0.25978678]\n",
            "  [-0.38239673  0.3426853  -0.09979361 ... -0.19492178  0.20925716\n",
            "   -0.25978678]\n",
            "  ...\n",
            "  [-0.38239673  0.3426853  -0.09979361 ... -0.19492178  0.20925716\n",
            "   -0.25978678]\n",
            "  [-0.38239673  0.3426853  -0.09979361 ... -0.19492178  0.20925716\n",
            "   -0.25978678]\n",
            "  [-0.38239673  0.3426853  -0.09979361 ... -0.19492178  0.20925716\n",
            "   -0.25978678]]\n",
            "\n",
            " [[-0.38239673  0.3426853  -0.09979361 ... -0.19492178  0.20925716\n",
            "   -0.25978678]\n",
            "  [-0.38239673  0.3426853  -0.09979361 ... -0.19492178  0.20925716\n",
            "   -0.25978678]\n",
            "  [-0.38239673  0.3426853  -0.09979361 ... -0.19492178  0.20925716\n",
            "   -0.25978678]\n",
            "  ...\n",
            "  [-0.38239673  0.3426853  -0.09979361 ... -0.19492178  0.20925716\n",
            "   -0.25978678]\n",
            "  [-0.38239673  0.3426853  -0.09979361 ... -0.19492178  0.20925716\n",
            "   -0.25978678]\n",
            "  [-0.38239673  0.3426853  -0.09979361 ... -0.19492178  0.20925716\n",
            "   -0.25978678]]], shape=(128, 764, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.10854809 -0.10854809 -0.10854809 ... -0.10854809 -0.10854809\n",
            "  -0.10854809]\n",
            " [-0.10854809 -0.10854809 -0.10854809 ... -0.10854809 -0.10854809\n",
            "  -0.10854809]\n",
            " [-0.10854809 -0.10854809 -0.10854809 ... -0.10854809 -0.10854809\n",
            "  -0.10854809]\n",
            " ...\n",
            " [-0.10854809 -0.10854809 -0.10854809 ... -0.10854809 -0.10854809\n",
            "  -0.10854809]\n",
            " [-0.10854809 -0.10854809 -0.10854809 ... -0.10854809 -0.10854809\n",
            "  -0.10854809]\n",
            " [-0.10854809 -0.10854809 -0.10854809 ... -0.10854809 -0.10854809\n",
            "  -0.10854809]], shape=(512, 128), dtype=float32) tf.Tensor(\n",
            "[[-0.10854809 -0.10854809 -0.10854809 ... -0.10854809 -0.10854809\n",
            "  -0.10854809]\n",
            " [-0.10854809 -0.10854809 -0.10854809 ... -0.10854809 -0.10854809\n",
            "  -0.10854809]\n",
            " [-0.10854809 -0.10854809 -0.10854809 ... -0.10854809 -0.10854809\n",
            "  -0.10854809]\n",
            " ...\n",
            " [-0.10854809 -0.10854809 -0.10854809 ... -0.10854809 -0.10854809\n",
            "  -0.10854809]\n",
            " [-0.10854809 -0.10854809 -0.10854809 ... -0.10854809 -0.10854809\n",
            "  -0.10854809]\n",
            " [-0.10854809 -0.10854809 -0.10854809 ... -0.10854809 -0.10854809\n",
            "  -0.10854809]], shape=(252, 128), dtype=float32)\n",
            "(128, 764) (512, 1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_15/kernel:0', 'dense_15/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_15/kernel:0', 'dense_15/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch 1, Batch 55/100, Loss=1.71321e-02\n",
            "(1, 764, 1)\n",
            "tf.Tensor(\n",
            "[[[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " [[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " [[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]], shape=(128, 764, 1), dtype=float32) tf.Tensor(\n",
            "[[[-0.3808306   0.34237745 -0.09900479 ... -0.19746652  0.20768096\n",
            "   -0.25736004]\n",
            "  [-0.3808306   0.34237745 -0.09900479 ... -0.19746652  0.20768096\n",
            "   -0.25736004]\n",
            "  [-0.3808306   0.34237745 -0.09900479 ... -0.19746652  0.20768096\n",
            "   -0.25736004]\n",
            "  ...\n",
            "  [-0.3808306   0.34237745 -0.09900479 ... -0.19746652  0.20768096\n",
            "   -0.25736004]\n",
            "  [-0.3808306   0.34237745 -0.09900479 ... -0.19746652  0.20768096\n",
            "   -0.25736004]\n",
            "  [-0.3808306   0.34237745 -0.09900479 ... -0.19746652  0.20768096\n",
            "   -0.25736004]]\n",
            "\n",
            " [[-0.3808306   0.34237745 -0.09900479 ... -0.19746652  0.20768096\n",
            "   -0.25736004]\n",
            "  [-0.3808306   0.34237745 -0.09900479 ... -0.19746652  0.20768096\n",
            "   -0.25736004]\n",
            "  [-0.3808306   0.34237745 -0.09900479 ... -0.19746652  0.20768096\n",
            "   -0.25736004]\n",
            "  ...\n",
            "  [-0.3808306   0.34237745 -0.09900479 ... -0.19746652  0.20768096\n",
            "   -0.25736004]\n",
            "  [-0.3808306   0.34237745 -0.09900479 ... -0.19746652  0.20768096\n",
            "   -0.25736004]\n",
            "  [-0.3808306   0.34237745 -0.09900479 ... -0.19746652  0.20768096\n",
            "   -0.25736004]]\n",
            "\n",
            " [[-0.3808306   0.34237745 -0.09900479 ... -0.19746652  0.20768096\n",
            "   -0.25736004]\n",
            "  [-0.3808306   0.34237745 -0.09900479 ... -0.19746652  0.20768096\n",
            "   -0.25736004]\n",
            "  [-0.3808306   0.34237745 -0.09900479 ... -0.19746652  0.20768096\n",
            "   -0.25736004]\n",
            "  ...\n",
            "  [-0.3808306   0.34237745 -0.09900479 ... -0.19746652  0.20768096\n",
            "   -0.25736004]\n",
            "  [-0.3808306   0.34237745 -0.09900479 ... -0.19746652  0.20768096\n",
            "   -0.25736004]\n",
            "  [-0.3808306   0.34237745 -0.09900479 ... -0.19746652  0.20768096\n",
            "   -0.25736004]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[-0.3808306   0.34237745 -0.09900479 ... -0.19746652  0.20768096\n",
            "   -0.25736004]\n",
            "  [-0.3808306   0.34237745 -0.09900479 ... -0.19746652  0.20768096\n",
            "   -0.25736004]\n",
            "  [-0.3808306   0.34237745 -0.09900479 ... -0.19746652  0.20768096\n",
            "   -0.25736004]\n",
            "  ...\n",
            "  [-0.3808306   0.34237745 -0.09900479 ... -0.19746652  0.20768096\n",
            "   -0.25736004]\n",
            "  [-0.3808306   0.34237745 -0.09900479 ... -0.19746652  0.20768096\n",
            "   -0.25736004]\n",
            "  [-0.3808306   0.34237745 -0.09900479 ... -0.19746652  0.20768096\n",
            "   -0.25736004]]\n",
            "\n",
            " [[-0.3808306   0.34237745 -0.09900479 ... -0.19746652  0.20768096\n",
            "   -0.25736004]\n",
            "  [-0.3808306   0.34237745 -0.09900479 ... -0.19746652  0.20768096\n",
            "   -0.25736004]\n",
            "  [-0.3808306   0.34237745 -0.09900479 ... -0.19746652  0.20768096\n",
            "   -0.25736004]\n",
            "  ...\n",
            "  [-0.3808306   0.34237745 -0.09900479 ... -0.19746652  0.20768096\n",
            "   -0.25736004]\n",
            "  [-0.3808306   0.34237745 -0.09900479 ... -0.19746652  0.20768096\n",
            "   -0.25736004]\n",
            "  [-0.3808306   0.34237745 -0.09900479 ... -0.19746652  0.20768096\n",
            "   -0.25736004]]\n",
            "\n",
            " [[-0.3808306   0.34237745 -0.09900479 ... -0.19746652  0.20768096\n",
            "   -0.25736004]\n",
            "  [-0.3808306   0.34237745 -0.09900479 ... -0.19746652  0.20768096\n",
            "   -0.25736004]\n",
            "  [-0.3808306   0.34237745 -0.09900479 ... -0.19746652  0.20768096\n",
            "   -0.25736004]\n",
            "  ...\n",
            "  [-0.3808306   0.34237745 -0.09900479 ... -0.19746652  0.20768096\n",
            "   -0.25736004]\n",
            "  [-0.3808306   0.34237745 -0.09900479 ... -0.19746652  0.20768096\n",
            "   -0.25736004]\n",
            "  [-0.3808306   0.34237745 -0.09900479 ... -0.19746652  0.20768096\n",
            "   -0.25736004]]], shape=(128, 764, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.09627544 -0.09627544 -0.09627544 ... -0.09627544 -0.09627544\n",
            "  -0.09627544]\n",
            " [-0.09627544 -0.09627544 -0.09627544 ... -0.09627544 -0.09627544\n",
            "  -0.09627544]\n",
            " [-0.09627544 -0.09627544 -0.09627544 ... -0.09627544 -0.09627544\n",
            "  -0.09627544]\n",
            " ...\n",
            " [-0.09627544 -0.09627544 -0.09627544 ... -0.09627544 -0.09627544\n",
            "  -0.09627544]\n",
            " [-0.09627544 -0.09627544 -0.09627544 ... -0.09627544 -0.09627544\n",
            "  -0.09627544]\n",
            " [-0.09627544 -0.09627544 -0.09627544 ... -0.09627544 -0.09627544\n",
            "  -0.09627544]], shape=(512, 128), dtype=float32) tf.Tensor(\n",
            "[[-0.09627544 -0.09627544 -0.09627544 ... -0.09627544 -0.09627544\n",
            "  -0.09627544]\n",
            " [-0.09627544 -0.09627544 -0.09627544 ... -0.09627544 -0.09627544\n",
            "  -0.09627544]\n",
            " [-0.09627544 -0.09627544 -0.09627544 ... -0.09627544 -0.09627544\n",
            "  -0.09627544]\n",
            " ...\n",
            " [-0.09627544 -0.09627544 -0.09627544 ... -0.09627544 -0.09627544\n",
            "  -0.09627544]\n",
            " [-0.09627544 -0.09627544 -0.09627544 ... -0.09627544 -0.09627544\n",
            "  -0.09627544]\n",
            " [-0.09627544 -0.09627544 -0.09627544 ... -0.09627544 -0.09627544\n",
            "  -0.09627544]], shape=(252, 128), dtype=float32)\n",
            "(128, 764) (512, 1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_15/kernel:0', 'dense_15/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_15/kernel:0', 'dense_15/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch 1, Batch 56/100, Loss=1.41621e-02\n",
            "(1, 764, 1)\n",
            "tf.Tensor(\n",
            "[[[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " [[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " [[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]], shape=(128, 764, 1), dtype=float32) tf.Tensor(\n",
            "[[[-0.37726793  0.3417758  -0.09652749 ... -0.20126863  0.2044753\n",
            "   -0.2536126 ]\n",
            "  [-0.37726793  0.3417758  -0.09652749 ... -0.20126863  0.2044753\n",
            "   -0.2536126 ]\n",
            "  [-0.37726793  0.3417758  -0.09652749 ... -0.20126863  0.2044753\n",
            "   -0.2536126 ]\n",
            "  ...\n",
            "  [-0.37726793  0.3417758  -0.09652749 ... -0.20126863  0.2044753\n",
            "   -0.2536126 ]\n",
            "  [-0.37726793  0.3417758  -0.09652749 ... -0.20126863  0.2044753\n",
            "   -0.2536126 ]\n",
            "  [-0.37726793  0.3417758  -0.09652749 ... -0.20126863  0.2044753\n",
            "   -0.2536126 ]]\n",
            "\n",
            " [[-0.37726793  0.3417758  -0.09652749 ... -0.20126863  0.2044753\n",
            "   -0.2536126 ]\n",
            "  [-0.37726793  0.3417758  -0.09652749 ... -0.20126863  0.2044753\n",
            "   -0.2536126 ]\n",
            "  [-0.37726793  0.3417758  -0.09652749 ... -0.20126863  0.2044753\n",
            "   -0.2536126 ]\n",
            "  ...\n",
            "  [-0.37726793  0.3417758  -0.09652749 ... -0.20126863  0.2044753\n",
            "   -0.2536126 ]\n",
            "  [-0.37726793  0.3417758  -0.09652749 ... -0.20126863  0.2044753\n",
            "   -0.2536126 ]\n",
            "  [-0.37726793  0.3417758  -0.09652749 ... -0.20126863  0.2044753\n",
            "   -0.2536126 ]]\n",
            "\n",
            " [[-0.37726793  0.3417758  -0.09652749 ... -0.20126863  0.2044753\n",
            "   -0.2536126 ]\n",
            "  [-0.37726793  0.3417758  -0.09652749 ... -0.20126863  0.2044753\n",
            "   -0.2536126 ]\n",
            "  [-0.37726793  0.3417758  -0.09652749 ... -0.20126863  0.2044753\n",
            "   -0.2536126 ]\n",
            "  ...\n",
            "  [-0.37726793  0.3417758  -0.09652749 ... -0.20126863  0.2044753\n",
            "   -0.2536126 ]\n",
            "  [-0.37726793  0.3417758  -0.09652749 ... -0.20126863  0.2044753\n",
            "   -0.2536126 ]\n",
            "  [-0.37726793  0.3417758  -0.09652749 ... -0.20126863  0.2044753\n",
            "   -0.2536126 ]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[-0.37726793  0.3417758  -0.09652749 ... -0.20126863  0.2044753\n",
            "   -0.2536126 ]\n",
            "  [-0.37726793  0.3417758  -0.09652749 ... -0.20126863  0.2044753\n",
            "   -0.2536126 ]\n",
            "  [-0.37726793  0.3417758  -0.09652749 ... -0.20126863  0.2044753\n",
            "   -0.2536126 ]\n",
            "  ...\n",
            "  [-0.37726793  0.3417758  -0.09652749 ... -0.20126863  0.2044753\n",
            "   -0.2536126 ]\n",
            "  [-0.37726793  0.3417758  -0.09652749 ... -0.20126863  0.2044753\n",
            "   -0.2536126 ]\n",
            "  [-0.37726793  0.3417758  -0.09652749 ... -0.20126863  0.2044753\n",
            "   -0.2536126 ]]\n",
            "\n",
            " [[-0.37726793  0.3417758  -0.09652749 ... -0.20126863  0.2044753\n",
            "   -0.2536126 ]\n",
            "  [-0.37726793  0.3417758  -0.09652749 ... -0.20126863  0.2044753\n",
            "   -0.2536126 ]\n",
            "  [-0.37726793  0.3417758  -0.09652749 ... -0.20126863  0.2044753\n",
            "   -0.2536126 ]\n",
            "  ...\n",
            "  [-0.37726793  0.3417758  -0.09652749 ... -0.20126863  0.2044753\n",
            "   -0.2536126 ]\n",
            "  [-0.37726793  0.3417758  -0.09652749 ... -0.20126863  0.2044753\n",
            "   -0.2536126 ]\n",
            "  [-0.37726793  0.3417758  -0.09652749 ... -0.20126863  0.2044753\n",
            "   -0.2536126 ]]\n",
            "\n",
            " [[-0.37726793  0.3417758  -0.09652749 ... -0.20126863  0.2044753\n",
            "   -0.2536126 ]\n",
            "  [-0.37726793  0.3417758  -0.09652749 ... -0.20126863  0.2044753\n",
            "   -0.2536126 ]\n",
            "  [-0.37726793  0.3417758  -0.09652749 ... -0.20126863  0.2044753\n",
            "   -0.2536126 ]\n",
            "  ...\n",
            "  [-0.37726793  0.3417758  -0.09652749 ... -0.20126863  0.2044753\n",
            "   -0.2536126 ]\n",
            "  [-0.37726793  0.3417758  -0.09652749 ... -0.20126863  0.2044753\n",
            "   -0.2536126 ]\n",
            "  [-0.37726793  0.3417758  -0.09652749 ... -0.20126863  0.2044753\n",
            "   -0.2536126 ]]], shape=(128, 764, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.07309483 -0.07309483 -0.07309483 ... -0.07309483 -0.07309483\n",
            "  -0.07309483]\n",
            " [-0.07309483 -0.07309483 -0.07309483 ... -0.07309483 -0.07309483\n",
            "  -0.07309483]\n",
            " [-0.07309483 -0.07309483 -0.07309483 ... -0.07309483 -0.07309483\n",
            "  -0.07309483]\n",
            " ...\n",
            " [-0.07309483 -0.07309483 -0.07309483 ... -0.07309483 -0.07309483\n",
            "  -0.07309483]\n",
            " [-0.07309483 -0.07309483 -0.07309483 ... -0.07309483 -0.07309483\n",
            "  -0.07309483]\n",
            " [-0.07309483 -0.07309483 -0.07309483 ... -0.07309483 -0.07309483\n",
            "  -0.07309483]], shape=(512, 128), dtype=float32) tf.Tensor(\n",
            "[[-0.07309483 -0.07309483 -0.07309483 ... -0.07309483 -0.07309483\n",
            "  -0.07309483]\n",
            " [-0.07309483 -0.07309483 -0.07309483 ... -0.07309483 -0.07309483\n",
            "  -0.07309483]\n",
            " [-0.07309483 -0.07309483 -0.07309483 ... -0.07309483 -0.07309483\n",
            "  -0.07309483]\n",
            " ...\n",
            " [-0.07309483 -0.07309483 -0.07309483 ... -0.07309483 -0.07309483\n",
            "  -0.07309483]\n",
            " [-0.07309483 -0.07309483 -0.07309483 ... -0.07309483 -0.07309483\n",
            "  -0.07309483]\n",
            " [-0.07309483 -0.07309483 -0.07309483 ... -0.07309483 -0.07309483\n",
            "  -0.07309483]], shape=(252, 128), dtype=float32)\n",
            "(128, 764) (512, 1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_15/kernel:0', 'dense_15/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_15/kernel:0', 'dense_15/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch 1, Batch 57/100, Loss=9.22419e-03\n",
            "(1, 764, 1)\n",
            "tf.Tensor(\n",
            "[[[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " [[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " [[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]], shape=(128, 764, 1), dtype=float32) tf.Tensor(\n",
            "[[[-0.37244377  0.34097612 -0.09300679 ... -0.20578894  0.20024545\n",
            "   -0.24911521]\n",
            "  [-0.37244377  0.34097612 -0.09300679 ... -0.20578894  0.20024545\n",
            "   -0.24911521]\n",
            "  [-0.37244377  0.34097612 -0.09300679 ... -0.20578894  0.20024545\n",
            "   -0.24911521]\n",
            "  ...\n",
            "  [-0.37244377  0.34097612 -0.09300679 ... -0.20578894  0.20024545\n",
            "   -0.24911521]\n",
            "  [-0.37244377  0.34097612 -0.09300679 ... -0.20578894  0.20024545\n",
            "   -0.24911521]\n",
            "  [-0.37244377  0.34097612 -0.09300679 ... -0.20578894  0.20024545\n",
            "   -0.24911521]]\n",
            "\n",
            " [[-0.37244377  0.34097612 -0.09300679 ... -0.20578894  0.20024545\n",
            "   -0.24911521]\n",
            "  [-0.37244377  0.34097612 -0.09300679 ... -0.20578894  0.20024545\n",
            "   -0.24911521]\n",
            "  [-0.37244377  0.34097612 -0.09300679 ... -0.20578894  0.20024545\n",
            "   -0.24911521]\n",
            "  ...\n",
            "  [-0.37244377  0.34097612 -0.09300679 ... -0.20578894  0.20024545\n",
            "   -0.24911521]\n",
            "  [-0.37244377  0.34097612 -0.09300679 ... -0.20578894  0.20024545\n",
            "   -0.24911521]\n",
            "  [-0.37244377  0.34097612 -0.09300679 ... -0.20578894  0.20024545\n",
            "   -0.24911521]]\n",
            "\n",
            " [[-0.37244377  0.34097612 -0.09300679 ... -0.20578894  0.20024545\n",
            "   -0.24911521]\n",
            "  [-0.37244377  0.34097612 -0.09300679 ... -0.20578894  0.20024545\n",
            "   -0.24911521]\n",
            "  [-0.37244377  0.34097612 -0.09300679 ... -0.20578894  0.20024545\n",
            "   -0.24911521]\n",
            "  ...\n",
            "  [-0.37244377  0.34097612 -0.09300679 ... -0.20578894  0.20024545\n",
            "   -0.24911521]\n",
            "  [-0.37244377  0.34097612 -0.09300679 ... -0.20578894  0.20024545\n",
            "   -0.24911521]\n",
            "  [-0.37244377  0.34097612 -0.09300679 ... -0.20578894  0.20024545\n",
            "   -0.24911521]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[-0.37244377  0.34097612 -0.09300679 ... -0.20578894  0.20024545\n",
            "   -0.24911521]\n",
            "  [-0.37244377  0.34097612 -0.09300679 ... -0.20578894  0.20024545\n",
            "   -0.24911521]\n",
            "  [-0.37244377  0.34097612 -0.09300679 ... -0.20578894  0.20024545\n",
            "   -0.24911521]\n",
            "  ...\n",
            "  [-0.37244377  0.34097612 -0.09300679 ... -0.20578894  0.20024545\n",
            "   -0.24911521]\n",
            "  [-0.37244377  0.34097612 -0.09300679 ... -0.20578894  0.20024545\n",
            "   -0.24911521]\n",
            "  [-0.37244377  0.34097612 -0.09300679 ... -0.20578894  0.20024545\n",
            "   -0.24911521]]\n",
            "\n",
            " [[-0.37244377  0.34097612 -0.09300679 ... -0.20578894  0.20024545\n",
            "   -0.24911521]\n",
            "  [-0.37244377  0.34097612 -0.09300679 ... -0.20578894  0.20024545\n",
            "   -0.24911521]\n",
            "  [-0.37244377  0.34097612 -0.09300679 ... -0.20578894  0.20024545\n",
            "   -0.24911521]\n",
            "  ...\n",
            "  [-0.37244377  0.34097612 -0.09300679 ... -0.20578894  0.20024545\n",
            "   -0.24911521]\n",
            "  [-0.37244377  0.34097612 -0.09300679 ... -0.20578894  0.20024545\n",
            "   -0.24911521]\n",
            "  [-0.37244377  0.34097612 -0.09300679 ... -0.20578894  0.20024545\n",
            "   -0.24911521]]\n",
            "\n",
            " [[-0.37244377  0.34097612 -0.09300679 ... -0.20578894  0.20024545\n",
            "   -0.24911521]\n",
            "  [-0.37244377  0.34097612 -0.09300679 ... -0.20578894  0.20024545\n",
            "   -0.24911521]\n",
            "  [-0.37244377  0.34097612 -0.09300679 ... -0.20578894  0.20024545\n",
            "   -0.24911521]\n",
            "  ...\n",
            "  [-0.37244377  0.34097612 -0.09300679 ... -0.20578894  0.20024545\n",
            "   -0.24911521]\n",
            "  [-0.37244377  0.34097612 -0.09300679 ... -0.20578894  0.20024545\n",
            "   -0.24911521]\n",
            "  [-0.37244377  0.34097612 -0.09300679 ... -0.20578894  0.20024545\n",
            "   -0.24911521]]], shape=(128, 764, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.04335748 -0.04335748 -0.04335748 ... -0.04335748 -0.04335748\n",
            "  -0.04335748]\n",
            " [-0.04335748 -0.04335748 -0.04335748 ... -0.04335748 -0.04335748\n",
            "  -0.04335748]\n",
            " [-0.04335748 -0.04335748 -0.04335748 ... -0.04335748 -0.04335748\n",
            "  -0.04335748]\n",
            " ...\n",
            " [-0.04335748 -0.04335748 -0.04335748 ... -0.04335748 -0.04335748\n",
            "  -0.04335748]\n",
            " [-0.04335748 -0.04335748 -0.04335748 ... -0.04335748 -0.04335748\n",
            "  -0.04335748]\n",
            " [-0.04335748 -0.04335748 -0.04335748 ... -0.04335748 -0.04335748\n",
            "  -0.04335748]], shape=(512, 128), dtype=float32) tf.Tensor(\n",
            "[[-0.04335748 -0.04335748 -0.04335748 ... -0.04335748 -0.04335748\n",
            "  -0.04335748]\n",
            " [-0.04335748 -0.04335748 -0.04335748 ... -0.04335748 -0.04335748\n",
            "  -0.04335748]\n",
            " [-0.04335748 -0.04335748 -0.04335748 ... -0.04335748 -0.04335748\n",
            "  -0.04335748]\n",
            " ...\n",
            " [-0.04335748 -0.04335748 -0.04335748 ... -0.04335748 -0.04335748\n",
            "  -0.04335748]\n",
            " [-0.04335748 -0.04335748 -0.04335748 ... -0.04335748 -0.04335748\n",
            "  -0.04335748]\n",
            " [-0.04335748 -0.04335748 -0.04335748 ... -0.04335748 -0.04335748\n",
            "  -0.04335748]], shape=(252, 128), dtype=float32)\n",
            "(128, 764) (512, 1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_15/kernel:0', 'dense_15/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_15/kernel:0', 'dense_15/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch 1, Batch 58/100, Loss=5.87963e-03\n",
            "(1, 764, 1)\n",
            "tf.Tensor(\n",
            "[[[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " [[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " [[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]], shape=(128, 764, 1), dtype=float32) tf.Tensor(\n",
            "[[[-0.36713868  0.34008864 -0.08907019 ... -0.21049713  0.1956274\n",
            "   -0.24441774]\n",
            "  [-0.36713868  0.34008864 -0.08907019 ... -0.21049713  0.1956274\n",
            "   -0.24441774]\n",
            "  [-0.36713868  0.34008864 -0.08907019 ... -0.21049713  0.1956274\n",
            "   -0.24441774]\n",
            "  ...\n",
            "  [-0.36713868  0.34008864 -0.08907019 ... -0.21049713  0.1956274\n",
            "   -0.24441774]\n",
            "  [-0.36713868  0.34008864 -0.08907019 ... -0.21049713  0.1956274\n",
            "   -0.24441774]\n",
            "  [-0.36713868  0.34008864 -0.08907019 ... -0.21049713  0.1956274\n",
            "   -0.24441774]]\n",
            "\n",
            " [[-0.36713868  0.34008864 -0.08907019 ... -0.21049713  0.1956274\n",
            "   -0.24441774]\n",
            "  [-0.36713868  0.34008864 -0.08907019 ... -0.21049713  0.1956274\n",
            "   -0.24441774]\n",
            "  [-0.36713868  0.34008864 -0.08907019 ... -0.21049713  0.1956274\n",
            "   -0.24441774]\n",
            "  ...\n",
            "  [-0.36713868  0.34008864 -0.08907019 ... -0.21049713  0.1956274\n",
            "   -0.24441774]\n",
            "  [-0.36713868  0.34008864 -0.08907019 ... -0.21049713  0.1956274\n",
            "   -0.24441774]\n",
            "  [-0.36713868  0.34008864 -0.08907019 ... -0.21049713  0.1956274\n",
            "   -0.24441774]]\n",
            "\n",
            " [[-0.36713868  0.34008864 -0.08907019 ... -0.21049713  0.1956274\n",
            "   -0.24441774]\n",
            "  [-0.36713868  0.34008864 -0.08907019 ... -0.21049713  0.1956274\n",
            "   -0.24441774]\n",
            "  [-0.36713868  0.34008864 -0.08907019 ... -0.21049713  0.1956274\n",
            "   -0.24441774]\n",
            "  ...\n",
            "  [-0.36713868  0.34008864 -0.08907019 ... -0.21049713  0.1956274\n",
            "   -0.24441774]\n",
            "  [-0.36713868  0.34008864 -0.08907019 ... -0.21049713  0.1956274\n",
            "   -0.24441774]\n",
            "  [-0.36713868  0.34008864 -0.08907019 ... -0.21049713  0.1956274\n",
            "   -0.24441774]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[-0.36713868  0.34008864 -0.08907019 ... -0.21049713  0.1956274\n",
            "   -0.24441774]\n",
            "  [-0.36713868  0.34008864 -0.08907019 ... -0.21049713  0.1956274\n",
            "   -0.24441774]\n",
            "  [-0.36713868  0.34008864 -0.08907019 ... -0.21049713  0.1956274\n",
            "   -0.24441774]\n",
            "  ...\n",
            "  [-0.36713868  0.34008864 -0.08907019 ... -0.21049713  0.1956274\n",
            "   -0.24441774]\n",
            "  [-0.36713868  0.34008864 -0.08907019 ... -0.21049713  0.1956274\n",
            "   -0.24441774]\n",
            "  [-0.36713868  0.34008864 -0.08907019 ... -0.21049713  0.1956274\n",
            "   -0.24441774]]\n",
            "\n",
            " [[-0.36713868  0.34008864 -0.08907019 ... -0.21049713  0.1956274\n",
            "   -0.24441774]\n",
            "  [-0.36713868  0.34008864 -0.08907019 ... -0.21049713  0.1956274\n",
            "   -0.24441774]\n",
            "  [-0.36713868  0.34008864 -0.08907019 ... -0.21049713  0.1956274\n",
            "   -0.24441774]\n",
            "  ...\n",
            "  [-0.36713868  0.34008864 -0.08907019 ... -0.21049713  0.1956274\n",
            "   -0.24441774]\n",
            "  [-0.36713868  0.34008864 -0.08907019 ... -0.21049713  0.1956274\n",
            "   -0.24441774]\n",
            "  [-0.36713868  0.34008864 -0.08907019 ... -0.21049713  0.1956274\n",
            "   -0.24441774]]\n",
            "\n",
            " [[-0.36713868  0.34008864 -0.08907019 ... -0.21049713  0.1956274\n",
            "   -0.24441774]\n",
            "  [-0.36713868  0.34008864 -0.08907019 ... -0.21049713  0.1956274\n",
            "   -0.24441774]\n",
            "  [-0.36713868  0.34008864 -0.08907019 ... -0.21049713  0.1956274\n",
            "   -0.24441774]\n",
            "  ...\n",
            "  [-0.36713868  0.34008864 -0.08907019 ... -0.21049713  0.1956274\n",
            "   -0.24441774]\n",
            "  [-0.36713868  0.34008864 -0.08907019 ... -0.21049713  0.1956274\n",
            "   -0.24441774]\n",
            "  [-0.36713868  0.34008864 -0.08907019 ... -0.21049713  0.1956274\n",
            "   -0.24441774]]], shape=(128, 764, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.01146739 -0.01146739 -0.01146739 ... -0.01146739 -0.01146739\n",
            "  -0.01146739]\n",
            " [-0.01146739 -0.01146739 -0.01146739 ... -0.01146739 -0.01146739\n",
            "  -0.01146739]\n",
            " [-0.01146739 -0.01146739 -0.01146739 ... -0.01146739 -0.01146739\n",
            "  -0.01146739]\n",
            " ...\n",
            " [-0.01146739 -0.01146739 -0.01146739 ... -0.01146739 -0.01146739\n",
            "  -0.01146739]\n",
            " [-0.01146739 -0.01146739 -0.01146739 ... -0.01146739 -0.01146739\n",
            "  -0.01146739]\n",
            " [-0.01146739 -0.01146739 -0.01146739 ... -0.01146739 -0.01146739\n",
            "  -0.01146739]], shape=(512, 128), dtype=float32) tf.Tensor(\n",
            "[[-0.01146739 -0.01146739 -0.01146739 ... -0.01146739 -0.01146739\n",
            "  -0.01146739]\n",
            " [-0.01146739 -0.01146739 -0.01146739 ... -0.01146739 -0.01146739\n",
            "  -0.01146739]\n",
            " [-0.01146739 -0.01146739 -0.01146739 ... -0.01146739 -0.01146739\n",
            "  -0.01146739]\n",
            " ...\n",
            " [-0.01146739 -0.01146739 -0.01146739 ... -0.01146739 -0.01146739\n",
            "  -0.01146739]\n",
            " [-0.01146739 -0.01146739 -0.01146739 ... -0.01146739 -0.01146739\n",
            "  -0.01146739]\n",
            " [-0.01146739 -0.01146739 -0.01146739 ... -0.01146739 -0.01146739\n",
            "  -0.01146739]], shape=(252, 128), dtype=float32)\n",
            "(128, 764) (512, 1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_15/kernel:0', 'dense_15/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_15/kernel:0', 'dense_15/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch 1, Batch 59/100, Loss=3.16874e-03\n",
            "(1, 764, 1)\n",
            "tf.Tensor(\n",
            "[[[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " [[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]], shape=(128, 764, 1), dtype=float32) tf.Tensor(\n",
            "[[[-0.36215115  0.33924237 -0.08534644 ... -0.21487781  0.19127633\n",
            "   -0.24004121]\n",
            "  [-0.36215115  0.33924237 -0.08534644 ... -0.21487781  0.19127633\n",
            "   -0.24004121]\n",
            "  [-0.36215115  0.33924237 -0.08534644 ... -0.21487781  0.19127633\n",
            "   -0.24004121]\n",
            "  ...\n",
            "  [-0.36215115  0.33924237 -0.08534644 ... -0.21487781  0.19127633\n",
            "   -0.24004121]\n",
            "  [-0.36215115  0.33924237 -0.08534644 ... -0.21487781  0.19127633\n",
            "   -0.24004121]\n",
            "  [-0.36215115  0.33924237 -0.08534644 ... -0.21487781  0.19127633\n",
            "   -0.24004121]]\n",
            "\n",
            " [[-0.36215115  0.33924237 -0.08534644 ... -0.21487781  0.19127633\n",
            "   -0.24004121]\n",
            "  [-0.36215115  0.33924237 -0.08534644 ... -0.21487781  0.19127633\n",
            "   -0.24004121]\n",
            "  [-0.36215115  0.33924237 -0.08534644 ... -0.21487781  0.19127633\n",
            "   -0.24004121]\n",
            "  ...\n",
            "  [-0.36215115  0.33924237 -0.08534644 ... -0.21487781  0.19127633\n",
            "   -0.24004121]\n",
            "  [-0.36215115  0.33924237 -0.08534644 ... -0.21487781  0.19127633\n",
            "   -0.24004121]\n",
            "  [-0.36215115  0.33924237 -0.08534644 ... -0.21487781  0.19127633\n",
            "   -0.24004121]]\n",
            "\n",
            " [[-0.36215115  0.33924237 -0.08534644 ... -0.21487781  0.19127633\n",
            "   -0.24004121]\n",
            "  [-0.36215115  0.33924237 -0.08534644 ... -0.21487781  0.19127633\n",
            "   -0.24004121]\n",
            "  [-0.36215115  0.33924237 -0.08534644 ... -0.21487781  0.19127633\n",
            "   -0.24004121]\n",
            "  ...\n",
            "  [-0.36215115  0.33924237 -0.08534644 ... -0.21487781  0.19127633\n",
            "   -0.24004121]\n",
            "  [-0.36215115  0.33924237 -0.08534644 ... -0.21487781  0.19127633\n",
            "   -0.24004121]\n",
            "  [-0.36215115  0.33924237 -0.08534644 ... -0.21487781  0.19127633\n",
            "   -0.24004121]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[-0.36215115  0.33924237 -0.08534644 ... -0.21487781  0.19127633\n",
            "   -0.24004121]\n",
            "  [-0.36215115  0.33924237 -0.08534644 ... -0.21487781  0.19127633\n",
            "   -0.24004121]\n",
            "  [-0.36215115  0.33924237 -0.08534644 ... -0.21487781  0.19127633\n",
            "   -0.24004121]\n",
            "  ...\n",
            "  [-0.36215115  0.33924237 -0.08534644 ... -0.21487781  0.19127633\n",
            "   -0.24004121]\n",
            "  [-0.36215115  0.33924237 -0.08534644 ... -0.21487781  0.19127633\n",
            "   -0.24004121]\n",
            "  [-0.36215115  0.33924237 -0.08534644 ... -0.21487781  0.19127633\n",
            "   -0.24004121]]\n",
            "\n",
            " [[-0.36215115  0.33924237 -0.08534644 ... -0.21487781  0.19127633\n",
            "   -0.24004121]\n",
            "  [-0.36215115  0.33924237 -0.08534644 ... -0.21487781  0.19127633\n",
            "   -0.24004121]\n",
            "  [-0.36215115  0.33924237 -0.08534644 ... -0.21487781  0.19127633\n",
            "   -0.24004121]\n",
            "  ...\n",
            "  [-0.36215115  0.33924237 -0.08534644 ... -0.21487781  0.19127633\n",
            "   -0.24004121]\n",
            "  [-0.36215115  0.33924237 -0.08534644 ... -0.21487781  0.19127633\n",
            "   -0.24004121]\n",
            "  [-0.36215115  0.33924237 -0.08534644 ... -0.21487781  0.19127633\n",
            "   -0.24004121]]\n",
            "\n",
            " [[-0.36215115  0.33924237 -0.08534644 ... -0.21487781  0.19127633\n",
            "   -0.24004121]\n",
            "  [-0.36215115  0.33924237 -0.08534644 ... -0.21487781  0.19127633\n",
            "   -0.24004121]\n",
            "  [-0.36215115  0.33924237 -0.08534644 ... -0.21487781  0.19127633\n",
            "   -0.24004121]\n",
            "  ...\n",
            "  [-0.36215115  0.33924237 -0.08534644 ... -0.21487781  0.19127633\n",
            "   -0.24004121]\n",
            "  [-0.36215115  0.33924237 -0.08534644 ... -0.21487781  0.19127633\n",
            "   -0.24004121]\n",
            "  [-0.36215115  0.33924237 -0.08534644 ... -0.21487781  0.19127633\n",
            "   -0.24004121]]], shape=(128, 764, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[0.01828154 0.01828154 0.01828154 ... 0.01828154 0.01828154 0.01828154]\n",
            " [0.01828154 0.01828154 0.01828154 ... 0.01828154 0.01828154 0.01828154]\n",
            " [0.01828154 0.01828154 0.01828154 ... 0.01828154 0.01828154 0.01828154]\n",
            " ...\n",
            " [0.01828154 0.01828154 0.01828154 ... 0.01828154 0.01828154 0.01828154]\n",
            " [0.01828154 0.01828154 0.01828154 ... 0.01828154 0.01828154 0.01828154]\n",
            " [0.01828154 0.01828154 0.01828154 ... 0.01828154 0.01828154 0.01828154]], shape=(512, 128), dtype=float32) tf.Tensor(\n",
            "[[0.01828154 0.01828154 0.01828154 ... 0.01828154 0.01828154 0.01828154]\n",
            " [0.01828154 0.01828154 0.01828154 ... 0.01828154 0.01828154 0.01828154]\n",
            " [0.01828154 0.01828154 0.01828154 ... 0.01828154 0.01828154 0.01828154]\n",
            " ...\n",
            " [0.01828154 0.01828154 0.01828154 ... 0.01828154 0.01828154 0.01828154]\n",
            " [0.01828154 0.01828154 0.01828154 ... 0.01828154 0.01828154 0.01828154]\n",
            " [0.01828154 0.01828154 0.01828154 ... 0.01828154 0.01828154 0.01828154]], shape=(252, 128), dtype=float32)\n",
            "(128, 764) (512, 1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_15/kernel:0', 'dense_15/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_15/kernel:0', 'dense_15/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch 1, Batch 60/100, Loss=5.19900e-03\n",
            "(1, 764, 1)\n",
            "tf.Tensor(\n",
            "[[[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " [[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " [[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]], shape=(128, 764, 1), dtype=float32) tf.Tensor(\n",
            "[[[-0.35828048  0.33856925 -0.08241657 ... -0.21846326  0.18783028\n",
            "   -0.23646605]\n",
            "  [-0.35828048  0.33856925 -0.08241657 ... -0.21846326  0.18783028\n",
            "   -0.23646605]\n",
            "  [-0.35828048  0.33856925 -0.08241657 ... -0.21846326  0.18783028\n",
            "   -0.23646605]\n",
            "  ...\n",
            "  [-0.35828048  0.33856925 -0.08241657 ... -0.21846326  0.18783028\n",
            "   -0.23646605]\n",
            "  [-0.35828048  0.33856925 -0.08241657 ... -0.21846326  0.18783028\n",
            "   -0.23646605]\n",
            "  [-0.35828048  0.33856925 -0.08241657 ... -0.21846326  0.18783028\n",
            "   -0.23646605]]\n",
            "\n",
            " [[-0.35828048  0.33856925 -0.08241657 ... -0.21846326  0.18783028\n",
            "   -0.23646605]\n",
            "  [-0.35828048  0.33856925 -0.08241657 ... -0.21846326  0.18783028\n",
            "   -0.23646605]\n",
            "  [-0.35828048  0.33856925 -0.08241657 ... -0.21846326  0.18783028\n",
            "   -0.23646605]\n",
            "  ...\n",
            "  [-0.35828048  0.33856925 -0.08241657 ... -0.21846326  0.18783028\n",
            "   -0.23646605]\n",
            "  [-0.35828048  0.33856925 -0.08241657 ... -0.21846326  0.18783028\n",
            "   -0.23646605]\n",
            "  [-0.35828048  0.33856925 -0.08241657 ... -0.21846326  0.18783028\n",
            "   -0.23646605]]\n",
            "\n",
            " [[-0.35828048  0.33856925 -0.08241657 ... -0.21846326  0.18783028\n",
            "   -0.23646605]\n",
            "  [-0.35828048  0.33856925 -0.08241657 ... -0.21846326  0.18783028\n",
            "   -0.23646605]\n",
            "  [-0.35828048  0.33856925 -0.08241657 ... -0.21846326  0.18783028\n",
            "   -0.23646605]\n",
            "  ...\n",
            "  [-0.35828048  0.33856925 -0.08241657 ... -0.21846326  0.18783028\n",
            "   -0.23646605]\n",
            "  [-0.35828048  0.33856925 -0.08241657 ... -0.21846326  0.18783028\n",
            "   -0.23646605]\n",
            "  [-0.35828048  0.33856925 -0.08241657 ... -0.21846326  0.18783028\n",
            "   -0.23646605]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[-0.35828048  0.33856925 -0.08241657 ... -0.21846326  0.18783028\n",
            "   -0.23646605]\n",
            "  [-0.35828048  0.33856925 -0.08241657 ... -0.21846326  0.18783028\n",
            "   -0.23646605]\n",
            "  [-0.35828048  0.33856925 -0.08241657 ... -0.21846326  0.18783028\n",
            "   -0.23646605]\n",
            "  ...\n",
            "  [-0.35828048  0.33856925 -0.08241657 ... -0.21846326  0.18783028\n",
            "   -0.23646605]\n",
            "  [-0.35828048  0.33856925 -0.08241657 ... -0.21846326  0.18783028\n",
            "   -0.23646605]\n",
            "  [-0.35828048  0.33856925 -0.08241657 ... -0.21846326  0.18783028\n",
            "   -0.23646605]]\n",
            "\n",
            " [[-0.35828048  0.33856925 -0.08241657 ... -0.21846326  0.18783028\n",
            "   -0.23646605]\n",
            "  [-0.35828048  0.33856925 -0.08241657 ... -0.21846326  0.18783028\n",
            "   -0.23646605]\n",
            "  [-0.35828048  0.33856925 -0.08241657 ... -0.21846326  0.18783028\n",
            "   -0.23646605]\n",
            "  ...\n",
            "  [-0.35828048  0.33856925 -0.08241657 ... -0.21846326  0.18783028\n",
            "   -0.23646605]\n",
            "  [-0.35828048  0.33856925 -0.08241657 ... -0.21846326  0.18783028\n",
            "   -0.23646605]\n",
            "  [-0.35828048  0.33856925 -0.08241657 ... -0.21846326  0.18783028\n",
            "   -0.23646605]]\n",
            "\n",
            " [[-0.35828048  0.33856925 -0.08241657 ... -0.21846326  0.18783028\n",
            "   -0.23646605]\n",
            "  [-0.35828048  0.33856925 -0.08241657 ... -0.21846326  0.18783028\n",
            "   -0.23646605]\n",
            "  [-0.35828048  0.33856925 -0.08241657 ... -0.21846326  0.18783028\n",
            "   -0.23646605]\n",
            "  ...\n",
            "  [-0.35828048  0.33856925 -0.08241657 ... -0.21846326  0.18783028\n",
            "   -0.23646605]\n",
            "  [-0.35828048  0.33856925 -0.08241657 ... -0.21846326  0.18783028\n",
            "   -0.23646605]\n",
            "  [-0.35828048  0.33856925 -0.08241657 ... -0.21846326  0.18783028\n",
            "   -0.23646605]]], shape=(128, 764, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[0.04175159 0.04175159 0.04175159 ... 0.04175159 0.04175159 0.04175159]\n",
            " [0.04175159 0.04175159 0.04175159 ... 0.04175159 0.04175159 0.04175159]\n",
            " [0.04175159 0.04175159 0.04175159 ... 0.04175159 0.04175159 0.04175159]\n",
            " ...\n",
            " [0.04175159 0.04175159 0.04175159 ... 0.04175159 0.04175159 0.04175159]\n",
            " [0.04175159 0.04175159 0.04175159 ... 0.04175159 0.04175159 0.04175159]\n",
            " [0.04175159 0.04175159 0.04175159 ... 0.04175159 0.04175159 0.04175159]], shape=(512, 128), dtype=float32) tf.Tensor(\n",
            "[[0.04175159 0.04175159 0.04175159 ... 0.04175159 0.04175159 0.04175159]\n",
            " [0.04175159 0.04175159 0.04175159 ... 0.04175159 0.04175159 0.04175159]\n",
            " [0.04175159 0.04175159 0.04175159 ... 0.04175159 0.04175159 0.04175159]\n",
            " ...\n",
            " [0.04175159 0.04175159 0.04175159 ... 0.04175159 0.04175159 0.04175159]\n",
            " [0.04175159 0.04175159 0.04175159 ... 0.04175159 0.04175159 0.04175159]\n",
            " [0.04175159 0.04175159 0.04175159 ... 0.04175159 0.04175159 0.04175159]], shape=(252, 128), dtype=float32)\n",
            "(128, 764) (512, 1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_15/kernel:0', 'dense_15/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_15/kernel:0', 'dense_15/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch 1, Batch 61/100, Loss=8.05314e-03\n",
            "(1, 764, 1)\n",
            "tf.Tensor(\n",
            "[[[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " [[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " [[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " [[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]], shape=(128, 764, 1), dtype=float32) tf.Tensor(\n",
            "[[[-0.35605496  0.33816168 -0.08066583 ... -0.2209642   0.18570943\n",
            "   -0.23398957]\n",
            "  [-0.35605496  0.33816168 -0.08066583 ... -0.2209642   0.18570943\n",
            "   -0.23398957]\n",
            "  [-0.35605496  0.33816168 -0.08066583 ... -0.2209642   0.18570943\n",
            "   -0.23398957]\n",
            "  ...\n",
            "  [-0.35605496  0.33816168 -0.08066583 ... -0.2209642   0.18570943\n",
            "   -0.23398957]\n",
            "  [-0.35605496  0.33816168 -0.08066583 ... -0.2209642   0.18570943\n",
            "   -0.23398957]\n",
            "  [-0.35605496  0.33816168 -0.08066583 ... -0.2209642   0.18570943\n",
            "   -0.23398957]]\n",
            "\n",
            " [[-0.35605496  0.33816168 -0.08066583 ... -0.2209642   0.18570943\n",
            "   -0.23398957]\n",
            "  [-0.35605496  0.33816168 -0.08066583 ... -0.2209642   0.18570943\n",
            "   -0.23398957]\n",
            "  [-0.35605496  0.33816168 -0.08066583 ... -0.2209642   0.18570943\n",
            "   -0.23398957]\n",
            "  ...\n",
            "  [-0.35605496  0.33816168 -0.08066583 ... -0.2209642   0.18570943\n",
            "   -0.23398957]\n",
            "  [-0.35605496  0.33816168 -0.08066583 ... -0.2209642   0.18570943\n",
            "   -0.23398957]\n",
            "  [-0.35605496  0.33816168 -0.08066583 ... -0.2209642   0.18570943\n",
            "   -0.23398957]]\n",
            "\n",
            " [[-0.35605496  0.33816168 -0.08066583 ... -0.2209642   0.18570943\n",
            "   -0.23398957]\n",
            "  [-0.35605496  0.33816168 -0.08066583 ... -0.2209642   0.18570943\n",
            "   -0.23398957]\n",
            "  [-0.35605496  0.33816168 -0.08066583 ... -0.2209642   0.18570943\n",
            "   -0.23398957]\n",
            "  ...\n",
            "  [-0.35605496  0.33816168 -0.08066583 ... -0.2209642   0.18570943\n",
            "   -0.23398957]\n",
            "  [-0.35605496  0.33816168 -0.08066583 ... -0.2209642   0.18570943\n",
            "   -0.23398957]\n",
            "  [-0.35605496  0.33816168 -0.08066583 ... -0.2209642   0.18570943\n",
            "   -0.23398957]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[-0.35605496  0.33816168 -0.08066583 ... -0.2209642   0.18570943\n",
            "   -0.23398957]\n",
            "  [-0.35605496  0.33816168 -0.08066583 ... -0.2209642   0.18570943\n",
            "   -0.23398957]\n",
            "  [-0.35605496  0.33816168 -0.08066583 ... -0.2209642   0.18570943\n",
            "   -0.23398957]\n",
            "  ...\n",
            "  [-0.35605496  0.33816168 -0.08066583 ... -0.2209642   0.18570943\n",
            "   -0.23398957]\n",
            "  [-0.35605496  0.33816168 -0.08066583 ... -0.2209642   0.18570943\n",
            "   -0.23398957]\n",
            "  [-0.35605496  0.33816168 -0.08066583 ... -0.2209642   0.18570943\n",
            "   -0.23398957]]\n",
            "\n",
            " [[-0.35605496  0.33816168 -0.08066583 ... -0.2209642   0.18570943\n",
            "   -0.23398957]\n",
            "  [-0.35605496  0.33816168 -0.08066583 ... -0.2209642   0.18570943\n",
            "   -0.23398957]\n",
            "  [-0.35605496  0.33816168 -0.08066583 ... -0.2209642   0.18570943\n",
            "   -0.23398957]\n",
            "  ...\n",
            "  [-0.35605496  0.33816168 -0.08066583 ... -0.2209642   0.18570943\n",
            "   -0.23398957]\n",
            "  [-0.35605496  0.33816168 -0.08066583 ... -0.2209642   0.18570943\n",
            "   -0.23398957]\n",
            "  [-0.35605496  0.33816168 -0.08066583 ... -0.2209642   0.18570943\n",
            "   -0.23398957]]\n",
            "\n",
            " [[-0.35605496  0.33816168 -0.08066583 ... -0.2209642   0.18570943\n",
            "   -0.23398957]\n",
            "  [-0.35605496  0.33816168 -0.08066583 ... -0.2209642   0.18570943\n",
            "   -0.23398957]\n",
            "  [-0.35605496  0.33816168 -0.08066583 ... -0.2209642   0.18570943\n",
            "   -0.23398957]\n",
            "  ...\n",
            "  [-0.35605496  0.33816168 -0.08066583 ... -0.2209642   0.18570943\n",
            "   -0.23398957]\n",
            "  [-0.35605496  0.33816168 -0.08066583 ... -0.2209642   0.18570943\n",
            "   -0.23398957]\n",
            "  [-0.35605496  0.33816168 -0.08066583 ... -0.2209642   0.18570943\n",
            "   -0.23398957]]], shape=(128, 764, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[0.05630002 0.05630002 0.05630002 ... 0.05630002 0.05630002 0.05630002]\n",
            " [0.05630002 0.05630002 0.05630002 ... 0.05630002 0.05630002 0.05630002]\n",
            " [0.05630002 0.05630002 0.05630002 ... 0.05630002 0.05630002 0.05630002]\n",
            " ...\n",
            " [0.05630002 0.05630002 0.05630002 ... 0.05630002 0.05630002 0.05630002]\n",
            " [0.05630002 0.05630002 0.05630002 ... 0.05630002 0.05630002 0.05630002]\n",
            " [0.05630002 0.05630002 0.05630002 ... 0.05630002 0.05630002 0.05630002]], shape=(512, 128), dtype=float32) tf.Tensor(\n",
            "[[0.05630002 0.05630002 0.05630002 ... 0.05630002 0.05630002 0.05630002]\n",
            " [0.05630002 0.05630002 0.05630002 ... 0.05630002 0.05630002 0.05630002]\n",
            " [0.05630002 0.05630002 0.05630002 ... 0.05630002 0.05630002 0.05630002]\n",
            " ...\n",
            " [0.05630002 0.05630002 0.05630002 ... 0.05630002 0.05630002 0.05630002]\n",
            " [0.05630002 0.05630002 0.05630002 ... 0.05630002 0.05630002 0.05630002]\n",
            " [0.05630002 0.05630002 0.05630002 ... 0.05630002 0.05630002 0.05630002]], shape=(252, 128), dtype=float32)\n",
            "(128, 764) (512, 1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_15/kernel:0', 'dense_15/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_15/kernel:0', 'dense_15/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch 1, Batch 62/100, Loss=9.44300e-03\n",
            "(1, 764, 1)\n",
            "tf.Tensor(\n",
            "[[[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " [[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " [[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]], shape=(128, 764, 1), dtype=float32) tf.Tensor(\n",
            "[[[-0.35563934  0.33805445 -0.08022805 ... -0.22230433  0.18504444\n",
            "   -0.2326904 ]\n",
            "  [-0.35563934  0.33805445 -0.08022805 ... -0.22230433  0.18504444\n",
            "   -0.2326904 ]\n",
            "  [-0.35563934  0.33805445 -0.08022805 ... -0.22230433  0.18504444\n",
            "   -0.2326904 ]\n",
            "  ...\n",
            "  [-0.35563934  0.33805445 -0.08022805 ... -0.22230433  0.18504444\n",
            "   -0.2326904 ]\n",
            "  [-0.35563934  0.33805445 -0.08022805 ... -0.22230433  0.18504444\n",
            "   -0.2326904 ]\n",
            "  [-0.35563934  0.33805445 -0.08022805 ... -0.22230433  0.18504444\n",
            "   -0.2326904 ]]\n",
            "\n",
            " [[-0.35563934  0.33805445 -0.08022805 ... -0.22230433  0.18504444\n",
            "   -0.2326904 ]\n",
            "  [-0.35563934  0.33805445 -0.08022805 ... -0.22230433  0.18504444\n",
            "   -0.2326904 ]\n",
            "  [-0.35563934  0.33805445 -0.08022805 ... -0.22230433  0.18504444\n",
            "   -0.2326904 ]\n",
            "  ...\n",
            "  [-0.35563934  0.33805445 -0.08022805 ... -0.22230433  0.18504444\n",
            "   -0.2326904 ]\n",
            "  [-0.35563934  0.33805445 -0.08022805 ... -0.22230433  0.18504444\n",
            "   -0.2326904 ]\n",
            "  [-0.35563934  0.33805445 -0.08022805 ... -0.22230433  0.18504444\n",
            "   -0.2326904 ]]\n",
            "\n",
            " [[-0.35563934  0.33805445 -0.08022805 ... -0.22230433  0.18504444\n",
            "   -0.2326904 ]\n",
            "  [-0.35563934  0.33805445 -0.08022805 ... -0.22230433  0.18504444\n",
            "   -0.2326904 ]\n",
            "  [-0.35563934  0.33805445 -0.08022805 ... -0.22230433  0.18504444\n",
            "   -0.2326904 ]\n",
            "  ...\n",
            "  [-0.35563934  0.33805445 -0.08022805 ... -0.22230433  0.18504444\n",
            "   -0.2326904 ]\n",
            "  [-0.35563934  0.33805445 -0.08022805 ... -0.22230433  0.18504444\n",
            "   -0.2326904 ]\n",
            "  [-0.35563934  0.33805445 -0.08022805 ... -0.22230433  0.18504444\n",
            "   -0.2326904 ]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[-0.35563934  0.33805445 -0.08022805 ... -0.22230433  0.18504444\n",
            "   -0.2326904 ]\n",
            "  [-0.35563934  0.33805445 -0.08022805 ... -0.22230433  0.18504444\n",
            "   -0.2326904 ]\n",
            "  [-0.35563934  0.33805445 -0.08022805 ... -0.22230433  0.18504444\n",
            "   -0.2326904 ]\n",
            "  ...\n",
            "  [-0.35563934  0.33805445 -0.08022805 ... -0.22230433  0.18504444\n",
            "   -0.2326904 ]\n",
            "  [-0.35563934  0.33805445 -0.08022805 ... -0.22230433  0.18504444\n",
            "   -0.2326904 ]\n",
            "  [-0.35563934  0.33805445 -0.08022805 ... -0.22230433  0.18504444\n",
            "   -0.2326904 ]]\n",
            "\n",
            " [[-0.35563934  0.33805445 -0.08022805 ... -0.22230433  0.18504444\n",
            "   -0.2326904 ]\n",
            "  [-0.35563934  0.33805445 -0.08022805 ... -0.22230433  0.18504444\n",
            "   -0.2326904 ]\n",
            "  [-0.35563934  0.33805445 -0.08022805 ... -0.22230433  0.18504444\n",
            "   -0.2326904 ]\n",
            "  ...\n",
            "  [-0.35563934  0.33805445 -0.08022805 ... -0.22230433  0.18504444\n",
            "   -0.2326904 ]\n",
            "  [-0.35563934  0.33805445 -0.08022805 ... -0.22230433  0.18504444\n",
            "   -0.2326904 ]\n",
            "  [-0.35563934  0.33805445 -0.08022805 ... -0.22230433  0.18504444\n",
            "   -0.2326904 ]]\n",
            "\n",
            " [[-0.35563934  0.33805445 -0.08022805 ... -0.22230433  0.18504444\n",
            "   -0.2326904 ]\n",
            "  [-0.35563934  0.33805445 -0.08022805 ... -0.22230433  0.18504444\n",
            "   -0.2326904 ]\n",
            "  [-0.35563934  0.33805445 -0.08022805 ... -0.22230433  0.18504444\n",
            "   -0.2326904 ]\n",
            "  ...\n",
            "  [-0.35563934  0.33805445 -0.08022805 ... -0.22230433  0.18504444\n",
            "   -0.2326904 ]\n",
            "  [-0.35563934  0.33805445 -0.08022805 ... -0.22230433  0.18504444\n",
            "   -0.2326904 ]\n",
            "  [-0.35563934  0.33805445 -0.08022805 ... -0.22230433  0.18504444\n",
            "   -0.2326904 ]]], shape=(128, 764, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[0.06117437 0.06117437 0.06117437 ... 0.06117437 0.06117437 0.06117437]\n",
            " [0.06117437 0.06117437 0.06117437 ... 0.06117437 0.06117437 0.06117437]\n",
            " [0.06117437 0.06117437 0.06117437 ... 0.06117437 0.06117437 0.06117437]\n",
            " ...\n",
            " [0.06117437 0.06117437 0.06117437 ... 0.06117437 0.06117437 0.06117437]\n",
            " [0.06117437 0.06117437 0.06117437 ... 0.06117437 0.06117437 0.06117437]\n",
            " [0.06117437 0.06117437 0.06117437 ... 0.06117437 0.06117437 0.06117437]], shape=(512, 128), dtype=float32) tf.Tensor(\n",
            "[[0.06117437 0.06117437 0.06117437 ... 0.06117437 0.06117437 0.06117437]\n",
            " [0.06117437 0.06117437 0.06117437 ... 0.06117437 0.06117437 0.06117437]\n",
            " [0.06117437 0.06117437 0.06117437 ... 0.06117437 0.06117437 0.06117437]\n",
            " ...\n",
            " [0.06117437 0.06117437 0.06117437 ... 0.06117437 0.06117437 0.06117437]\n",
            " [0.06117437 0.06117437 0.06117437 ... 0.06117437 0.06117437 0.06117437]\n",
            " [0.06117437 0.06117437 0.06117437 ... 0.06117437 0.06117437 0.06117437]], shape=(252, 128), dtype=float32)\n",
            "(128, 764) (512, 1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_15/kernel:0', 'dense_15/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_15/kernel:0', 'dense_15/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch 1, Batch 63/100, Loss=1.02296e-02\n",
            "(1, 764, 1)\n",
            "tf.Tensor(\n",
            "[[[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " [[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " [[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]], shape=(128, 764, 1), dtype=float32) tf.Tensor(\n",
            "[[[-0.3569336   0.33823153 -0.08102963 ... -0.2225689   0.18574801\n",
            "   -0.23249364]\n",
            "  [-0.3569336   0.33823153 -0.08102963 ... -0.2225689   0.18574801\n",
            "   -0.23249364]\n",
            "  [-0.3569336   0.33823153 -0.08102963 ... -0.2225689   0.18574801\n",
            "   -0.23249364]\n",
            "  ...\n",
            "  [-0.3569336   0.33823153 -0.08102963 ... -0.2225689   0.18574801\n",
            "   -0.23249364]\n",
            "  [-0.3569336   0.33823153 -0.08102963 ... -0.2225689   0.18574801\n",
            "   -0.23249364]\n",
            "  [-0.3569336   0.33823153 -0.08102963 ... -0.2225689   0.18574801\n",
            "   -0.23249364]]\n",
            "\n",
            " [[-0.3569336   0.33823153 -0.08102963 ... -0.2225689   0.18574801\n",
            "   -0.23249364]\n",
            "  [-0.3569336   0.33823153 -0.08102963 ... -0.2225689   0.18574801\n",
            "   -0.23249364]\n",
            "  [-0.3569336   0.33823153 -0.08102963 ... -0.2225689   0.18574801\n",
            "   -0.23249364]\n",
            "  ...\n",
            "  [-0.3569336   0.33823153 -0.08102963 ... -0.2225689   0.18574801\n",
            "   -0.23249364]\n",
            "  [-0.3569336   0.33823153 -0.08102963 ... -0.2225689   0.18574801\n",
            "   -0.23249364]\n",
            "  [-0.3569336   0.33823153 -0.08102963 ... -0.2225689   0.18574801\n",
            "   -0.23249364]]\n",
            "\n",
            " [[-0.3569336   0.33823153 -0.08102963 ... -0.2225689   0.18574801\n",
            "   -0.23249364]\n",
            "  [-0.3569336   0.33823153 -0.08102963 ... -0.2225689   0.18574801\n",
            "   -0.23249364]\n",
            "  [-0.3569336   0.33823153 -0.08102963 ... -0.2225689   0.18574801\n",
            "   -0.23249364]\n",
            "  ...\n",
            "  [-0.3569336   0.33823153 -0.08102963 ... -0.2225689   0.18574801\n",
            "   -0.23249364]\n",
            "  [-0.3569336   0.33823153 -0.08102963 ... -0.2225689   0.18574801\n",
            "   -0.23249364]\n",
            "  [-0.3569336   0.33823153 -0.08102963 ... -0.2225689   0.18574801\n",
            "   -0.23249364]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[-0.3569336   0.33823153 -0.08102963 ... -0.2225689   0.18574801\n",
            "   -0.23249364]\n",
            "  [-0.3569336   0.33823153 -0.08102963 ... -0.2225689   0.18574801\n",
            "   -0.23249364]\n",
            "  [-0.3569336   0.33823153 -0.08102963 ... -0.2225689   0.18574801\n",
            "   -0.23249364]\n",
            "  ...\n",
            "  [-0.3569336   0.33823153 -0.08102963 ... -0.2225689   0.18574801\n",
            "   -0.23249364]\n",
            "  [-0.3569336   0.33823153 -0.08102963 ... -0.2225689   0.18574801\n",
            "   -0.23249364]\n",
            "  [-0.3569336   0.33823153 -0.08102963 ... -0.2225689   0.18574801\n",
            "   -0.23249364]]\n",
            "\n",
            " [[-0.3569336   0.33823153 -0.08102963 ... -0.2225689   0.18574801\n",
            "   -0.23249364]\n",
            "  [-0.3569336   0.33823153 -0.08102963 ... -0.2225689   0.18574801\n",
            "   -0.23249364]\n",
            "  [-0.3569336   0.33823153 -0.08102963 ... -0.2225689   0.18574801\n",
            "   -0.23249364]\n",
            "  ...\n",
            "  [-0.3569336   0.33823153 -0.08102963 ... -0.2225689   0.18574801\n",
            "   -0.23249364]\n",
            "  [-0.3569336   0.33823153 -0.08102963 ... -0.2225689   0.18574801\n",
            "   -0.23249364]\n",
            "  [-0.3569336   0.33823153 -0.08102963 ... -0.2225689   0.18574801\n",
            "   -0.23249364]]\n",
            "\n",
            " [[-0.3569336   0.33823153 -0.08102963 ... -0.2225689   0.18574801\n",
            "   -0.23249364]\n",
            "  [-0.3569336   0.33823153 -0.08102963 ... -0.2225689   0.18574801\n",
            "   -0.23249364]\n",
            "  [-0.3569336   0.33823153 -0.08102963 ... -0.2225689   0.18574801\n",
            "   -0.23249364]\n",
            "  ...\n",
            "  [-0.3569336   0.33823153 -0.08102963 ... -0.2225689   0.18574801\n",
            "   -0.23249364]\n",
            "  [-0.3569336   0.33823153 -0.08102963 ... -0.2225689   0.18574801\n",
            "   -0.23249364]\n",
            "  [-0.3569336   0.33823153 -0.08102963 ... -0.2225689   0.18574801\n",
            "   -0.23249364]]], shape=(128, 764, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[0.05695853 0.05695853 0.05695853 ... 0.05695853 0.05695853 0.05695853]\n",
            " [0.05695853 0.05695853 0.05695853 ... 0.05695853 0.05695853 0.05695853]\n",
            " [0.05695853 0.05695853 0.05695853 ... 0.05695853 0.05695853 0.05695853]\n",
            " ...\n",
            " [0.05695853 0.05695853 0.05695853 ... 0.05695853 0.05695853 0.05695853]\n",
            " [0.05695853 0.05695853 0.05695853 ... 0.05695853 0.05695853 0.05695853]\n",
            " [0.05695853 0.05695853 0.05695853 ... 0.05695853 0.05695853 0.05695853]], shape=(512, 128), dtype=float32) tf.Tensor(\n",
            "[[0.05695853 0.05695853 0.05695853 ... 0.05695853 0.05695853 0.05695853]\n",
            " [0.05695853 0.05695853 0.05695853 ... 0.05695853 0.05695853 0.05695853]\n",
            " [0.05695853 0.05695853 0.05695853 ... 0.05695853 0.05695853 0.05695853]\n",
            " ...\n",
            " [0.05695853 0.05695853 0.05695853 ... 0.05695853 0.05695853 0.05695853]\n",
            " [0.05695853 0.05695853 0.05695853 ... 0.05695853 0.05695853 0.05695853]\n",
            " [0.05695853 0.05695853 0.05695853 ... 0.05695853 0.05695853 0.05695853]], shape=(252, 128), dtype=float32)\n",
            "(128, 764) (512, 1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_15/kernel:0', 'dense_15/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_15/kernel:0', 'dense_15/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch 1, Batch 64/100, Loss=8.73293e-03\n",
            "(1, 764, 1)\n",
            "tf.Tensor(\n",
            "[[[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " [[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " [[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]], shape=(128, 764, 1), dtype=float32) tf.Tensor(\n",
            "[[[-0.35976383  0.33865938 -0.08297257 ... -0.22185962  0.18768358\n",
            "   -0.23330629]\n",
            "  [-0.35976383  0.33865938 -0.08297257 ... -0.22185962  0.18768358\n",
            "   -0.23330629]\n",
            "  [-0.35976383  0.33865938 -0.08297257 ... -0.22185962  0.18768358\n",
            "   -0.23330629]\n",
            "  ...\n",
            "  [-0.35976383  0.33865938 -0.08297257 ... -0.22185962  0.18768358\n",
            "   -0.23330629]\n",
            "  [-0.35976383  0.33865938 -0.08297257 ... -0.22185962  0.18768358\n",
            "   -0.23330629]\n",
            "  [-0.35976383  0.33865938 -0.08297257 ... -0.22185962  0.18768358\n",
            "   -0.23330629]]\n",
            "\n",
            " [[-0.35976383  0.33865938 -0.08297257 ... -0.22185962  0.18768358\n",
            "   -0.23330629]\n",
            "  [-0.35976383  0.33865938 -0.08297257 ... -0.22185962  0.18768358\n",
            "   -0.23330629]\n",
            "  [-0.35976383  0.33865938 -0.08297257 ... -0.22185962  0.18768358\n",
            "   -0.23330629]\n",
            "  ...\n",
            "  [-0.35976383  0.33865938 -0.08297257 ... -0.22185962  0.18768358\n",
            "   -0.23330629]\n",
            "  [-0.35976383  0.33865938 -0.08297257 ... -0.22185962  0.18768358\n",
            "   -0.23330629]\n",
            "  [-0.35976383  0.33865938 -0.08297257 ... -0.22185962  0.18768358\n",
            "   -0.23330629]]\n",
            "\n",
            " [[-0.35976383  0.33865938 -0.08297257 ... -0.22185962  0.18768358\n",
            "   -0.23330629]\n",
            "  [-0.35976383  0.33865938 -0.08297257 ... -0.22185962  0.18768358\n",
            "   -0.23330629]\n",
            "  [-0.35976383  0.33865938 -0.08297257 ... -0.22185962  0.18768358\n",
            "   -0.23330629]\n",
            "  ...\n",
            "  [-0.35976383  0.33865938 -0.08297257 ... -0.22185962  0.18768358\n",
            "   -0.23330629]\n",
            "  [-0.35976383  0.33865938 -0.08297257 ... -0.22185962  0.18768358\n",
            "   -0.23330629]\n",
            "  [-0.35976383  0.33865938 -0.08297257 ... -0.22185962  0.18768358\n",
            "   -0.23330629]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[-0.35976383  0.33865938 -0.08297257 ... -0.22185962  0.18768358\n",
            "   -0.23330629]\n",
            "  [-0.35976383  0.33865938 -0.08297257 ... -0.22185962  0.18768358\n",
            "   -0.23330629]\n",
            "  [-0.35976383  0.33865938 -0.08297257 ... -0.22185962  0.18768358\n",
            "   -0.23330629]\n",
            "  ...\n",
            "  [-0.35976383  0.33865938 -0.08297257 ... -0.22185962  0.18768358\n",
            "   -0.23330629]\n",
            "  [-0.35976383  0.33865938 -0.08297257 ... -0.22185962  0.18768358\n",
            "   -0.23330629]\n",
            "  [-0.35976383  0.33865938 -0.08297257 ... -0.22185962  0.18768358\n",
            "   -0.23330629]]\n",
            "\n",
            " [[-0.35976383  0.33865938 -0.08297257 ... -0.22185962  0.18768358\n",
            "   -0.23330629]\n",
            "  [-0.35976383  0.33865938 -0.08297257 ... -0.22185962  0.18768358\n",
            "   -0.23330629]\n",
            "  [-0.35976383  0.33865938 -0.08297257 ... -0.22185962  0.18768358\n",
            "   -0.23330629]\n",
            "  ...\n",
            "  [-0.35976383  0.33865938 -0.08297257 ... -0.22185962  0.18768358\n",
            "   -0.23330629]\n",
            "  [-0.35976383  0.33865938 -0.08297257 ... -0.22185962  0.18768358\n",
            "   -0.23330629]\n",
            "  [-0.35976383  0.33865938 -0.08297257 ... -0.22185962  0.18768358\n",
            "   -0.23330629]]\n",
            "\n",
            " [[-0.35976383  0.33865938 -0.08297257 ... -0.22185962  0.18768358\n",
            "   -0.23330629]\n",
            "  [-0.35976383  0.33865938 -0.08297257 ... -0.22185962  0.18768358\n",
            "   -0.23330629]\n",
            "  [-0.35976383  0.33865938 -0.08297257 ... -0.22185962  0.18768358\n",
            "   -0.23330629]\n",
            "  ...\n",
            "  [-0.35976383  0.33865938 -0.08297257 ... -0.22185962  0.18768358\n",
            "   -0.23330629]\n",
            "  [-0.35976383  0.33865938 -0.08297257 ... -0.22185962  0.18768358\n",
            "   -0.23330629]\n",
            "  [-0.35976383  0.33865938 -0.08297257 ... -0.22185962  0.18768358\n",
            "   -0.23330629]]], shape=(128, 764, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[0.04450723 0.04450723 0.04450723 ... 0.04450723 0.04450723 0.04450723]\n",
            " [0.04450723 0.04450723 0.04450723 ... 0.04450723 0.04450723 0.04450723]\n",
            " [0.04450723 0.04450723 0.04450723 ... 0.04450723 0.04450723 0.04450723]\n",
            " ...\n",
            " [0.04450723 0.04450723 0.04450723 ... 0.04450723 0.04450723 0.04450723]\n",
            " [0.04450723 0.04450723 0.04450723 ... 0.04450723 0.04450723 0.04450723]\n",
            " [0.04450723 0.04450723 0.04450723 ... 0.04450723 0.04450723 0.04450723]], shape=(512, 128), dtype=float32) tf.Tensor(\n",
            "[[0.04450723 0.04450723 0.04450723 ... 0.04450723 0.04450723 0.04450723]\n",
            " [0.04450723 0.04450723 0.04450723 ... 0.04450723 0.04450723 0.04450723]\n",
            " [0.04450723 0.04450723 0.04450723 ... 0.04450723 0.04450723 0.04450723]\n",
            " ...\n",
            " [0.04450723 0.04450723 0.04450723 ... 0.04450723 0.04450723 0.04450723]\n",
            " [0.04450723 0.04450723 0.04450723 ... 0.04450723 0.04450723 0.04450723]\n",
            " [0.04450723 0.04450723 0.04450723 ... 0.04450723 0.04450723 0.04450723]], shape=(252, 128), dtype=float32)\n",
            "(128, 764) (512, 1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_15/kernel:0', 'dense_15/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_15/kernel:0', 'dense_15/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch 1, Batch 65/100, Loss=5.09251e-03\n",
            "(1, 764, 1)\n",
            "tf.Tensor(\n",
            "[[[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " [[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " [[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]], shape=(128, 764, 1), dtype=float32) tf.Tensor(\n",
            "[[[-0.36360484  0.33925077 -0.08569317 ... -0.2204798   0.19043827\n",
            "   -0.23481885]\n",
            "  [-0.36360484  0.33925077 -0.08569317 ... -0.2204798   0.19043827\n",
            "   -0.23481885]\n",
            "  [-0.36360484  0.33925077 -0.08569317 ... -0.2204798   0.19043827\n",
            "   -0.23481885]\n",
            "  ...\n",
            "  [-0.36360484  0.33925077 -0.08569317 ... -0.2204798   0.19043827\n",
            "   -0.23481885]\n",
            "  [-0.36360484  0.33925077 -0.08569317 ... -0.2204798   0.19043827\n",
            "   -0.23481885]\n",
            "  [-0.36360484  0.33925077 -0.08569317 ... -0.2204798   0.19043827\n",
            "   -0.23481885]]\n",
            "\n",
            " [[-0.36360484  0.33925077 -0.08569317 ... -0.2204798   0.19043827\n",
            "   -0.23481885]\n",
            "  [-0.36360484  0.33925077 -0.08569317 ... -0.2204798   0.19043827\n",
            "   -0.23481885]\n",
            "  [-0.36360484  0.33925077 -0.08569317 ... -0.2204798   0.19043827\n",
            "   -0.23481885]\n",
            "  ...\n",
            "  [-0.36360484  0.33925077 -0.08569317 ... -0.2204798   0.19043827\n",
            "   -0.23481885]\n",
            "  [-0.36360484  0.33925077 -0.08569317 ... -0.2204798   0.19043827\n",
            "   -0.23481885]\n",
            "  [-0.36360484  0.33925077 -0.08569317 ... -0.2204798   0.19043827\n",
            "   -0.23481885]]\n",
            "\n",
            " [[-0.36360484  0.33925077 -0.08569317 ... -0.2204798   0.19043827\n",
            "   -0.23481885]\n",
            "  [-0.36360484  0.33925077 -0.08569317 ... -0.2204798   0.19043827\n",
            "   -0.23481885]\n",
            "  [-0.36360484  0.33925077 -0.08569317 ... -0.2204798   0.19043827\n",
            "   -0.23481885]\n",
            "  ...\n",
            "  [-0.36360484  0.33925077 -0.08569317 ... -0.2204798   0.19043827\n",
            "   -0.23481885]\n",
            "  [-0.36360484  0.33925077 -0.08569317 ... -0.2204798   0.19043827\n",
            "   -0.23481885]\n",
            "  [-0.36360484  0.33925077 -0.08569317 ... -0.2204798   0.19043827\n",
            "   -0.23481885]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[-0.36360484  0.33925077 -0.08569317 ... -0.2204798   0.19043827\n",
            "   -0.23481885]\n",
            "  [-0.36360484  0.33925077 -0.08569317 ... -0.2204798   0.19043827\n",
            "   -0.23481885]\n",
            "  [-0.36360484  0.33925077 -0.08569317 ... -0.2204798   0.19043827\n",
            "   -0.23481885]\n",
            "  ...\n",
            "  [-0.36360484  0.33925077 -0.08569317 ... -0.2204798   0.19043827\n",
            "   -0.23481885]\n",
            "  [-0.36360484  0.33925077 -0.08569317 ... -0.2204798   0.19043827\n",
            "   -0.23481885]\n",
            "  [-0.36360484  0.33925077 -0.08569317 ... -0.2204798   0.19043827\n",
            "   -0.23481885]]\n",
            "\n",
            " [[-0.36360484  0.33925077 -0.08569317 ... -0.2204798   0.19043827\n",
            "   -0.23481885]\n",
            "  [-0.36360484  0.33925077 -0.08569317 ... -0.2204798   0.19043827\n",
            "   -0.23481885]\n",
            "  [-0.36360484  0.33925077 -0.08569317 ... -0.2204798   0.19043827\n",
            "   -0.23481885]\n",
            "  ...\n",
            "  [-0.36360484  0.33925077 -0.08569317 ... -0.2204798   0.19043827\n",
            "   -0.23481885]\n",
            "  [-0.36360484  0.33925077 -0.08569317 ... -0.2204798   0.19043827\n",
            "   -0.23481885]\n",
            "  [-0.36360484  0.33925077 -0.08569317 ... -0.2204798   0.19043827\n",
            "   -0.23481885]]\n",
            "\n",
            " [[-0.36360484  0.33925077 -0.08569317 ... -0.2204798   0.19043827\n",
            "   -0.23481885]\n",
            "  [-0.36360484  0.33925077 -0.08569317 ... -0.2204798   0.19043827\n",
            "   -0.23481885]\n",
            "  [-0.36360484  0.33925077 -0.08569317 ... -0.2204798   0.19043827\n",
            "   -0.23481885]\n",
            "  ...\n",
            "  [-0.36360484  0.33925077 -0.08569317 ... -0.2204798   0.19043827\n",
            "   -0.23481885]\n",
            "  [-0.36360484  0.33925077 -0.08569317 ... -0.2204798   0.19043827\n",
            "   -0.23481885]\n",
            "  [-0.36360484  0.33925077 -0.08569317 ... -0.2204798   0.19043827\n",
            "   -0.23481885]]], shape=(128, 764, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[0.0265255 0.0265255 0.0265255 ... 0.0265255 0.0265255 0.0265255]\n",
            " [0.0265255 0.0265255 0.0265255 ... 0.0265255 0.0265255 0.0265255]\n",
            " [0.0265255 0.0265255 0.0265255 ... 0.0265255 0.0265255 0.0265255]\n",
            " ...\n",
            " [0.0265255 0.0265255 0.0265255 ... 0.0265255 0.0265255 0.0265255]\n",
            " [0.0265255 0.0265255 0.0265255 ... 0.0265255 0.0265255 0.0265255]\n",
            " [0.0265255 0.0265255 0.0265255 ... 0.0265255 0.0265255 0.0265255]], shape=(512, 128), dtype=float32) tf.Tensor(\n",
            "[[0.0265255 0.0265255 0.0265255 ... 0.0265255 0.0265255 0.0265255]\n",
            " [0.0265255 0.0265255 0.0265255 ... 0.0265255 0.0265255 0.0265255]\n",
            " [0.0265255 0.0265255 0.0265255 ... 0.0265255 0.0265255 0.0265255]\n",
            " ...\n",
            " [0.0265255 0.0265255 0.0265255 ... 0.0265255 0.0265255 0.0265255]\n",
            " [0.0265255 0.0265255 0.0265255 ... 0.0265255 0.0265255 0.0265255]\n",
            " [0.0265255 0.0265255 0.0265255 ... 0.0265255 0.0265255 0.0265255]], shape=(252, 128), dtype=float32)\n",
            "(128, 764) (512, 1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_15/kernel:0', 'dense_15/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_15/kernel:0', 'dense_15/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch 1, Batch 66/100, Loss=2.14888e-03\n",
            "(1, 764, 1)\n",
            "tf.Tensor(\n",
            "[[[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " [[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " [[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " [[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]], shape=(128, 764, 1), dtype=float32) tf.Tensor(\n",
            "[[[-0.36786097  0.3399066  -0.08875097 ... -0.21877782  0.19354168\n",
            "   -0.23667018]\n",
            "  [-0.36786097  0.3399066  -0.08875097 ... -0.21877782  0.19354168\n",
            "   -0.23667018]\n",
            "  [-0.36786097  0.3399066  -0.08875097 ... -0.21877782  0.19354168\n",
            "   -0.23667018]\n",
            "  ...\n",
            "  [-0.36786097  0.3399066  -0.08875097 ... -0.21877782  0.19354168\n",
            "   -0.23667018]\n",
            "  [-0.36786097  0.3399066  -0.08875097 ... -0.21877782  0.19354168\n",
            "   -0.23667018]\n",
            "  [-0.36786097  0.3399066  -0.08875097 ... -0.21877782  0.19354168\n",
            "   -0.23667018]]\n",
            "\n",
            " [[-0.36786097  0.3399066  -0.08875097 ... -0.21877782  0.19354168\n",
            "   -0.23667018]\n",
            "  [-0.36786097  0.3399066  -0.08875097 ... -0.21877782  0.19354168\n",
            "   -0.23667018]\n",
            "  [-0.36786097  0.3399066  -0.08875097 ... -0.21877782  0.19354168\n",
            "   -0.23667018]\n",
            "  ...\n",
            "  [-0.36786097  0.3399066  -0.08875097 ... -0.21877782  0.19354168\n",
            "   -0.23667018]\n",
            "  [-0.36786097  0.3399066  -0.08875097 ... -0.21877782  0.19354168\n",
            "   -0.23667018]\n",
            "  [-0.36786097  0.3399066  -0.08875097 ... -0.21877782  0.19354168\n",
            "   -0.23667018]]\n",
            "\n",
            " [[-0.36786097  0.3399066  -0.08875097 ... -0.21877782  0.19354168\n",
            "   -0.23667018]\n",
            "  [-0.36786097  0.3399066  -0.08875097 ... -0.21877782  0.19354168\n",
            "   -0.23667018]\n",
            "  [-0.36786097  0.3399066  -0.08875097 ... -0.21877782  0.19354168\n",
            "   -0.23667018]\n",
            "  ...\n",
            "  [-0.36786097  0.3399066  -0.08875097 ... -0.21877782  0.19354168\n",
            "   -0.23667018]\n",
            "  [-0.36786097  0.3399066  -0.08875097 ... -0.21877782  0.19354168\n",
            "   -0.23667018]\n",
            "  [-0.36786097  0.3399066  -0.08875097 ... -0.21877782  0.19354168\n",
            "   -0.23667018]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[-0.36786097  0.3399066  -0.08875097 ... -0.21877782  0.19354168\n",
            "   -0.23667018]\n",
            "  [-0.36786097  0.3399066  -0.08875097 ... -0.21877782  0.19354168\n",
            "   -0.23667018]\n",
            "  [-0.36786097  0.3399066  -0.08875097 ... -0.21877782  0.19354168\n",
            "   -0.23667018]\n",
            "  ...\n",
            "  [-0.36786097  0.3399066  -0.08875097 ... -0.21877782  0.19354168\n",
            "   -0.23667018]\n",
            "  [-0.36786097  0.3399066  -0.08875097 ... -0.21877782  0.19354168\n",
            "   -0.23667018]\n",
            "  [-0.36786097  0.3399066  -0.08875097 ... -0.21877782  0.19354168\n",
            "   -0.23667018]]\n",
            "\n",
            " [[-0.36786097  0.3399066  -0.08875097 ... -0.21877782  0.19354168\n",
            "   -0.23667018]\n",
            "  [-0.36786097  0.3399066  -0.08875097 ... -0.21877782  0.19354168\n",
            "   -0.23667018]\n",
            "  [-0.36786097  0.3399066  -0.08875097 ... -0.21877782  0.19354168\n",
            "   -0.23667018]\n",
            "  ...\n",
            "  [-0.36786097  0.3399066  -0.08875097 ... -0.21877782  0.19354168\n",
            "   -0.23667018]\n",
            "  [-0.36786097  0.3399066  -0.08875097 ... -0.21877782  0.19354168\n",
            "   -0.23667018]\n",
            "  [-0.36786097  0.3399066  -0.08875097 ... -0.21877782  0.19354168\n",
            "   -0.23667018]]\n",
            "\n",
            " [[-0.36786097  0.3399066  -0.08875097 ... -0.21877782  0.19354168\n",
            "   -0.23667018]\n",
            "  [-0.36786097  0.3399066  -0.08875097 ... -0.21877782  0.19354168\n",
            "   -0.23667018]\n",
            "  [-0.36786097  0.3399066  -0.08875097 ... -0.21877782  0.19354168\n",
            "   -0.23667018]\n",
            "  ...\n",
            "  [-0.36786097  0.3399066  -0.08875097 ... -0.21877782  0.19354168\n",
            "   -0.23667018]\n",
            "  [-0.36786097  0.3399066  -0.08875097 ... -0.21877782  0.19354168\n",
            "   -0.23667018]\n",
            "  [-0.36786097  0.3399066  -0.08875097 ... -0.21877782  0.19354168\n",
            "   -0.23667018]]], shape=(128, 764, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[0.00611306 0.00611306 0.00611306 ... 0.00611306 0.00611306 0.00611306]\n",
            " [0.00611306 0.00611306 0.00611306 ... 0.00611306 0.00611306 0.00611306]\n",
            " [0.00611306 0.00611306 0.00611306 ... 0.00611306 0.00611306 0.00611306]\n",
            " ...\n",
            " [0.00611306 0.00611306 0.00611306 ... 0.00611306 0.00611306 0.00611306]\n",
            " [0.00611306 0.00611306 0.00611306 ... 0.00611306 0.00611306 0.00611306]\n",
            " [0.00611306 0.00611306 0.00611306 ... 0.00611306 0.00611306 0.00611306]], shape=(512, 128), dtype=float32) tf.Tensor(\n",
            "[[0.00611306 0.00611306 0.00611306 ... 0.00611306 0.00611306 0.00611306]\n",
            " [0.00611306 0.00611306 0.00611306 ... 0.00611306 0.00611306 0.00611306]\n",
            " [0.00611306 0.00611306 0.00611306 ... 0.00611306 0.00611306 0.00611306]\n",
            " ...\n",
            " [0.00611306 0.00611306 0.00611306 ... 0.00611306 0.00611306 0.00611306]\n",
            " [0.00611306 0.00611306 0.00611306 ... 0.00611306 0.00611306 0.00611306]\n",
            " [0.00611306 0.00611306 0.00611306 ... 0.00611306 0.00611306 0.00611306]], shape=(252, 128), dtype=float32)\n",
            "(128, 764) (512, 1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_15/kernel:0', 'dense_15/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_15/kernel:0', 'dense_15/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch 1, Batch 67/100, Loss=5.94337e-04\n",
            "(1, 764, 1)\n",
            "tf.Tensor(\n",
            "[[[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " [[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " [[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]], shape=(128, 764, 1), dtype=float32) tf.Tensor(\n",
            "[[[-0.3718886   0.34052077 -0.09165274 ... -0.21713595  0.19648957\n",
            "   -0.23845753]\n",
            "  [-0.3718886   0.34052077 -0.09165274 ... -0.21713595  0.19648957\n",
            "   -0.23845753]\n",
            "  [-0.3718886   0.34052077 -0.09165274 ... -0.21713595  0.19648957\n",
            "   -0.23845753]\n",
            "  ...\n",
            "  [-0.3718886   0.34052077 -0.09165274 ... -0.21713595  0.19648957\n",
            "   -0.23845753]\n",
            "  [-0.3718886   0.34052077 -0.09165274 ... -0.21713595  0.19648957\n",
            "   -0.23845753]\n",
            "  [-0.3718886   0.34052077 -0.09165274 ... -0.21713595  0.19648957\n",
            "   -0.23845753]]\n",
            "\n",
            " [[-0.3718886   0.34052077 -0.09165274 ... -0.21713595  0.19648957\n",
            "   -0.23845753]\n",
            "  [-0.3718886   0.34052077 -0.09165274 ... -0.21713595  0.19648957\n",
            "   -0.23845753]\n",
            "  [-0.3718886   0.34052077 -0.09165274 ... -0.21713595  0.19648957\n",
            "   -0.23845753]\n",
            "  ...\n",
            "  [-0.3718886   0.34052077 -0.09165274 ... -0.21713595  0.19648957\n",
            "   -0.23845753]\n",
            "  [-0.3718886   0.34052077 -0.09165274 ... -0.21713595  0.19648957\n",
            "   -0.23845753]\n",
            "  [-0.3718886   0.34052077 -0.09165274 ... -0.21713595  0.19648957\n",
            "   -0.23845753]]\n",
            "\n",
            " [[-0.3718886   0.34052077 -0.09165274 ... -0.21713595  0.19648957\n",
            "   -0.23845753]\n",
            "  [-0.3718886   0.34052077 -0.09165274 ... -0.21713595  0.19648957\n",
            "   -0.23845753]\n",
            "  [-0.3718886   0.34052077 -0.09165274 ... -0.21713595  0.19648957\n",
            "   -0.23845753]\n",
            "  ...\n",
            "  [-0.3718886   0.34052077 -0.09165274 ... -0.21713595  0.19648957\n",
            "   -0.23845753]\n",
            "  [-0.3718886   0.34052077 -0.09165274 ... -0.21713595  0.19648957\n",
            "   -0.23845753]\n",
            "  [-0.3718886   0.34052077 -0.09165274 ... -0.21713595  0.19648957\n",
            "   -0.23845753]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[-0.3718886   0.34052077 -0.09165274 ... -0.21713595  0.19648957\n",
            "   -0.23845753]\n",
            "  [-0.3718886   0.34052077 -0.09165274 ... -0.21713595  0.19648957\n",
            "   -0.23845753]\n",
            "  [-0.3718886   0.34052077 -0.09165274 ... -0.21713595  0.19648957\n",
            "   -0.23845753]\n",
            "  ...\n",
            "  [-0.3718886   0.34052077 -0.09165274 ... -0.21713595  0.19648957\n",
            "   -0.23845753]\n",
            "  [-0.3718886   0.34052077 -0.09165274 ... -0.21713595  0.19648957\n",
            "   -0.23845753]\n",
            "  [-0.3718886   0.34052077 -0.09165274 ... -0.21713595  0.19648957\n",
            "   -0.23845753]]\n",
            "\n",
            " [[-0.3718886   0.34052077 -0.09165274 ... -0.21713595  0.19648957\n",
            "   -0.23845753]\n",
            "  [-0.3718886   0.34052077 -0.09165274 ... -0.21713595  0.19648957\n",
            "   -0.23845753]\n",
            "  [-0.3718886   0.34052077 -0.09165274 ... -0.21713595  0.19648957\n",
            "   -0.23845753]\n",
            "  ...\n",
            "  [-0.3718886   0.34052077 -0.09165274 ... -0.21713595  0.19648957\n",
            "   -0.23845753]\n",
            "  [-0.3718886   0.34052077 -0.09165274 ... -0.21713595  0.19648957\n",
            "   -0.23845753]\n",
            "  [-0.3718886   0.34052077 -0.09165274 ... -0.21713595  0.19648957\n",
            "   -0.23845753]]\n",
            "\n",
            " [[-0.3718886   0.34052077 -0.09165274 ... -0.21713595  0.19648957\n",
            "   -0.23845753]\n",
            "  [-0.3718886   0.34052077 -0.09165274 ... -0.21713595  0.19648957\n",
            "   -0.23845753]\n",
            "  [-0.3718886   0.34052077 -0.09165274 ... -0.21713595  0.19648957\n",
            "   -0.23845753]\n",
            "  ...\n",
            "  [-0.3718886   0.34052077 -0.09165274 ... -0.21713595  0.19648957\n",
            "   -0.23845753]\n",
            "  [-0.3718886   0.34052077 -0.09165274 ... -0.21713595  0.19648957\n",
            "   -0.23845753]\n",
            "  [-0.3718886   0.34052077 -0.09165274 ... -0.21713595  0.19648957\n",
            "   -0.23845753]]], shape=(128, 764, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.01333592 -0.01333592 -0.01333592 ... -0.01333592 -0.01333592\n",
            "  -0.01333592]\n",
            " [-0.01333592 -0.01333592 -0.01333592 ... -0.01333592 -0.01333592\n",
            "  -0.01333592]\n",
            " [-0.01333592 -0.01333592 -0.01333592 ... -0.01333592 -0.01333592\n",
            "  -0.01333592]\n",
            " ...\n",
            " [-0.01333592 -0.01333592 -0.01333592 ... -0.01333592 -0.01333592\n",
            "  -0.01333592]\n",
            " [-0.01333592 -0.01333592 -0.01333592 ... -0.01333592 -0.01333592\n",
            "  -0.01333592]\n",
            " [-0.01333592 -0.01333592 -0.01333592 ... -0.01333592 -0.01333592\n",
            "  -0.01333592]], shape=(512, 128), dtype=float32) tf.Tensor(\n",
            "[[-0.01333592 -0.01333592 -0.01333592 ... -0.01333592 -0.01333592\n",
            "  -0.01333592]\n",
            " [-0.01333592 -0.01333592 -0.01333592 ... -0.01333592 -0.01333592\n",
            "  -0.01333592]\n",
            " [-0.01333592 -0.01333592 -0.01333592 ... -0.01333592 -0.01333592\n",
            "  -0.01333592]\n",
            " ...\n",
            " [-0.01333592 -0.01333592 -0.01333592 ... -0.01333592 -0.01333592\n",
            "  -0.01333592]\n",
            " [-0.01333592 -0.01333592 -0.01333592 ... -0.01333592 -0.01333592\n",
            "  -0.01333592]\n",
            " [-0.01333592 -0.01333592 -0.01333592 ... -0.01333592 -0.01333592\n",
            "  -0.01333592]], shape=(252, 128), dtype=float32)\n",
            "(128, 764) (512, 1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_15/kernel:0', 'dense_15/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_15/kernel:0', 'dense_15/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch 1, Batch 68/100, Loss=5.65045e-04\n",
            "(1, 764, 1)\n",
            "tf.Tensor(\n",
            "[[[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " [[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " [[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]], shape=(128, 764, 1), dtype=float32) tf.Tensor(\n",
            "[[[-0.37522078  0.34102306 -0.09402168 ... -0.21584156  0.19891304\n",
            "   -0.23987073]\n",
            "  [-0.37522078  0.34102306 -0.09402168 ... -0.21584156  0.19891304\n",
            "   -0.23987073]\n",
            "  [-0.37522078  0.34102306 -0.09402168 ... -0.21584156  0.19891304\n",
            "   -0.23987073]\n",
            "  ...\n",
            "  [-0.37522078  0.34102306 -0.09402168 ... -0.21584156  0.19891304\n",
            "   -0.23987073]\n",
            "  [-0.37522078  0.34102306 -0.09402168 ... -0.21584156  0.19891304\n",
            "   -0.23987073]\n",
            "  [-0.37522078  0.34102306 -0.09402168 ... -0.21584156  0.19891304\n",
            "   -0.23987073]]\n",
            "\n",
            " [[-0.37522078  0.34102306 -0.09402168 ... -0.21584156  0.19891304\n",
            "   -0.23987073]\n",
            "  [-0.37522078  0.34102306 -0.09402168 ... -0.21584156  0.19891304\n",
            "   -0.23987073]\n",
            "  [-0.37522078  0.34102306 -0.09402168 ... -0.21584156  0.19891304\n",
            "   -0.23987073]\n",
            "  ...\n",
            "  [-0.37522078  0.34102306 -0.09402168 ... -0.21584156  0.19891304\n",
            "   -0.23987073]\n",
            "  [-0.37522078  0.34102306 -0.09402168 ... -0.21584156  0.19891304\n",
            "   -0.23987073]\n",
            "  [-0.37522078  0.34102306 -0.09402168 ... -0.21584156  0.19891304\n",
            "   -0.23987073]]\n",
            "\n",
            " [[-0.37522078  0.34102306 -0.09402168 ... -0.21584156  0.19891304\n",
            "   -0.23987073]\n",
            "  [-0.37522078  0.34102306 -0.09402168 ... -0.21584156  0.19891304\n",
            "   -0.23987073]\n",
            "  [-0.37522078  0.34102306 -0.09402168 ... -0.21584156  0.19891304\n",
            "   -0.23987073]\n",
            "  ...\n",
            "  [-0.37522078  0.34102306 -0.09402168 ... -0.21584156  0.19891304\n",
            "   -0.23987073]\n",
            "  [-0.37522078  0.34102306 -0.09402168 ... -0.21584156  0.19891304\n",
            "   -0.23987073]\n",
            "  [-0.37522078  0.34102306 -0.09402168 ... -0.21584156  0.19891304\n",
            "   -0.23987073]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[-0.37522078  0.34102306 -0.09402168 ... -0.21584156  0.19891304\n",
            "   -0.23987073]\n",
            "  [-0.37522078  0.34102306 -0.09402168 ... -0.21584156  0.19891304\n",
            "   -0.23987073]\n",
            "  [-0.37522078  0.34102306 -0.09402168 ... -0.21584156  0.19891304\n",
            "   -0.23987073]\n",
            "  ...\n",
            "  [-0.37522078  0.34102306 -0.09402168 ... -0.21584156  0.19891304\n",
            "   -0.23987073]\n",
            "  [-0.37522078  0.34102306 -0.09402168 ... -0.21584156  0.19891304\n",
            "   -0.23987073]\n",
            "  [-0.37522078  0.34102306 -0.09402168 ... -0.21584156  0.19891304\n",
            "   -0.23987073]]\n",
            "\n",
            " [[-0.37522078  0.34102306 -0.09402168 ... -0.21584156  0.19891304\n",
            "   -0.23987073]\n",
            "  [-0.37522078  0.34102306 -0.09402168 ... -0.21584156  0.19891304\n",
            "   -0.23987073]\n",
            "  [-0.37522078  0.34102306 -0.09402168 ... -0.21584156  0.19891304\n",
            "   -0.23987073]\n",
            "  ...\n",
            "  [-0.37522078  0.34102306 -0.09402168 ... -0.21584156  0.19891304\n",
            "   -0.23987073]\n",
            "  [-0.37522078  0.34102306 -0.09402168 ... -0.21584156  0.19891304\n",
            "   -0.23987073]\n",
            "  [-0.37522078  0.34102306 -0.09402168 ... -0.21584156  0.19891304\n",
            "   -0.23987073]]\n",
            "\n",
            " [[-0.37522078  0.34102306 -0.09402168 ... -0.21584156  0.19891304\n",
            "   -0.23987073]\n",
            "  [-0.37522078  0.34102306 -0.09402168 ... -0.21584156  0.19891304\n",
            "   -0.23987073]\n",
            "  [-0.37522078  0.34102306 -0.09402168 ... -0.21584156  0.19891304\n",
            "   -0.23987073]\n",
            "  ...\n",
            "  [-0.37522078  0.34102306 -0.09402168 ... -0.21584156  0.19891304\n",
            "   -0.23987073]\n",
            "  [-0.37522078  0.34102306 -0.09402168 ... -0.21584156  0.19891304\n",
            "   -0.23987073]\n",
            "  [-0.37522078  0.34102306 -0.09402168 ... -0.21584156  0.19891304\n",
            "   -0.23987073]]], shape=(128, 764, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.02927311 -0.02927311 -0.02927311 ... -0.02927311 -0.02927311\n",
            "  -0.02927311]\n",
            " [-0.02927311 -0.02927311 -0.02927311 ... -0.02927311 -0.02927311\n",
            "  -0.02927311]\n",
            " [-0.02927311 -0.02927311 -0.02927311 ... -0.02927311 -0.02927311\n",
            "  -0.02927311]\n",
            " ...\n",
            " [-0.02927311 -0.02927311 -0.02927311 ... -0.02927311 -0.02927311\n",
            "  -0.02927311]\n",
            " [-0.02927311 -0.02927311 -0.02927311 ... -0.02927311 -0.02927311\n",
            "  -0.02927311]\n",
            " [-0.02927311 -0.02927311 -0.02927311 ... -0.02927311 -0.02927311\n",
            "  -0.02927311]], shape=(512, 128), dtype=float32) tf.Tensor(\n",
            "[[-0.02927311 -0.02927311 -0.02927311 ... -0.02927311 -0.02927311\n",
            "  -0.02927311]\n",
            " [-0.02927311 -0.02927311 -0.02927311 ... -0.02927311 -0.02927311\n",
            "  -0.02927311]\n",
            " [-0.02927311 -0.02927311 -0.02927311 ... -0.02927311 -0.02927311\n",
            "  -0.02927311]\n",
            " ...\n",
            " [-0.02927311 -0.02927311 -0.02927311 ... -0.02927311 -0.02927311\n",
            "  -0.02927311]\n",
            " [-0.02927311 -0.02927311 -0.02927311 ... -0.02927311 -0.02927311\n",
            "  -0.02927311]\n",
            " [-0.02927311 -0.02927311 -0.02927311 ... -0.02927311 -0.02927311\n",
            "  -0.02927311]], shape=(252, 128), dtype=float32)\n",
            "(128, 764) (512, 1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_15/kernel:0', 'dense_15/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_15/kernel:0', 'dense_15/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch 1, Batch 69/100, Loss=1.69875e-03\n",
            "(1, 764, 1)\n",
            "tf.Tensor(\n",
            "[[[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " [[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " [[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]], shape=(128, 764, 1), dtype=float32) tf.Tensor(\n",
            "[[[-0.37748146  0.34135646 -0.09553604 ... -0.2151381   0.20051672\n",
            "   -0.24064389]\n",
            "  [-0.37748146  0.34135646 -0.09553604 ... -0.2151381   0.20051672\n",
            "   -0.24064389]\n",
            "  [-0.37748146  0.34135646 -0.09553604 ... -0.2151381   0.20051672\n",
            "   -0.24064389]\n",
            "  ...\n",
            "  [-0.37748146  0.34135646 -0.09553604 ... -0.2151381   0.20051672\n",
            "   -0.24064389]\n",
            "  [-0.37748146  0.34135646 -0.09553604 ... -0.2151381   0.20051672\n",
            "   -0.24064389]\n",
            "  [-0.37748146  0.34135646 -0.09553604 ... -0.2151381   0.20051672\n",
            "   -0.24064389]]\n",
            "\n",
            " [[-0.37748146  0.34135646 -0.09553604 ... -0.2151381   0.20051672\n",
            "   -0.24064389]\n",
            "  [-0.37748146  0.34135646 -0.09553604 ... -0.2151381   0.20051672\n",
            "   -0.24064389]\n",
            "  [-0.37748146  0.34135646 -0.09553604 ... -0.2151381   0.20051672\n",
            "   -0.24064389]\n",
            "  ...\n",
            "  [-0.37748146  0.34135646 -0.09553604 ... -0.2151381   0.20051672\n",
            "   -0.24064389]\n",
            "  [-0.37748146  0.34135646 -0.09553604 ... -0.2151381   0.20051672\n",
            "   -0.24064389]\n",
            "  [-0.37748146  0.34135646 -0.09553604 ... -0.2151381   0.20051672\n",
            "   -0.24064389]]\n",
            "\n",
            " [[-0.37748146  0.34135646 -0.09553604 ... -0.2151381   0.20051672\n",
            "   -0.24064389]\n",
            "  [-0.37748146  0.34135646 -0.09553604 ... -0.2151381   0.20051672\n",
            "   -0.24064389]\n",
            "  [-0.37748146  0.34135646 -0.09553604 ... -0.2151381   0.20051672\n",
            "   -0.24064389]\n",
            "  ...\n",
            "  [-0.37748146  0.34135646 -0.09553604 ... -0.2151381   0.20051672\n",
            "   -0.24064389]\n",
            "  [-0.37748146  0.34135646 -0.09553604 ... -0.2151381   0.20051672\n",
            "   -0.24064389]\n",
            "  [-0.37748146  0.34135646 -0.09553604 ... -0.2151381   0.20051672\n",
            "   -0.24064389]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[-0.37748146  0.34135646 -0.09553604 ... -0.2151381   0.20051672\n",
            "   -0.24064389]\n",
            "  [-0.37748146  0.34135646 -0.09553604 ... -0.2151381   0.20051672\n",
            "   -0.24064389]\n",
            "  [-0.37748146  0.34135646 -0.09553604 ... -0.2151381   0.20051672\n",
            "   -0.24064389]\n",
            "  ...\n",
            "  [-0.37748146  0.34135646 -0.09553604 ... -0.2151381   0.20051672\n",
            "   -0.24064389]\n",
            "  [-0.37748146  0.34135646 -0.09553604 ... -0.2151381   0.20051672\n",
            "   -0.24064389]\n",
            "  [-0.37748146  0.34135646 -0.09553604 ... -0.2151381   0.20051672\n",
            "   -0.24064389]]\n",
            "\n",
            " [[-0.37748146  0.34135646 -0.09553604 ... -0.2151381   0.20051672\n",
            "   -0.24064389]\n",
            "  [-0.37748146  0.34135646 -0.09553604 ... -0.2151381   0.20051672\n",
            "   -0.24064389]\n",
            "  [-0.37748146  0.34135646 -0.09553604 ... -0.2151381   0.20051672\n",
            "   -0.24064389]\n",
            "  ...\n",
            "  [-0.37748146  0.34135646 -0.09553604 ... -0.2151381   0.20051672\n",
            "   -0.24064389]\n",
            "  [-0.37748146  0.34135646 -0.09553604 ... -0.2151381   0.20051672\n",
            "   -0.24064389]\n",
            "  [-0.37748146  0.34135646 -0.09553604 ... -0.2151381   0.20051672\n",
            "   -0.24064389]]\n",
            "\n",
            " [[-0.37748146  0.34135646 -0.09553604 ... -0.2151381   0.20051672\n",
            "   -0.24064389]\n",
            "  [-0.37748146  0.34135646 -0.09553604 ... -0.2151381   0.20051672\n",
            "   -0.24064389]\n",
            "  [-0.37748146  0.34135646 -0.09553604 ... -0.2151381   0.20051672\n",
            "   -0.24064389]\n",
            "  ...\n",
            "  [-0.37748146  0.34135646 -0.09553604 ... -0.2151381   0.20051672\n",
            "   -0.24064389]\n",
            "  [-0.37748146  0.34135646 -0.09553604 ... -0.2151381   0.20051672\n",
            "   -0.24064389]\n",
            "  [-0.37748146  0.34135646 -0.09553604 ... -0.2151381   0.20051672\n",
            "   -0.24064389]]], shape=(128, 764, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.03959017 -0.03959017 -0.03959017 ... -0.03959017 -0.03959017\n",
            "  -0.03959017]\n",
            " [-0.03959017 -0.03959017 -0.03959017 ... -0.03959017 -0.03959017\n",
            "  -0.03959017]\n",
            " [-0.03959017 -0.03959017 -0.03959017 ... -0.03959017 -0.03959017\n",
            "  -0.03959017]\n",
            " ...\n",
            " [-0.03959017 -0.03959017 -0.03959017 ... -0.03959017 -0.03959017\n",
            "  -0.03959017]\n",
            " [-0.03959017 -0.03959017 -0.03959017 ... -0.03959017 -0.03959017\n",
            "  -0.03959017]\n",
            " [-0.03959017 -0.03959017 -0.03959017 ... -0.03959017 -0.03959017\n",
            "  -0.03959017]], shape=(512, 128), dtype=float32) tf.Tensor(\n",
            "[[-0.03959017 -0.03959017 -0.03959017 ... -0.03959017 -0.03959017\n",
            "  -0.03959017]\n",
            " [-0.03959017 -0.03959017 -0.03959017 ... -0.03959017 -0.03959017\n",
            "  -0.03959017]\n",
            " [-0.03959017 -0.03959017 -0.03959017 ... -0.03959017 -0.03959017\n",
            "  -0.03959017]\n",
            " ...\n",
            " [-0.03959017 -0.03959017 -0.03959017 ... -0.03959017 -0.03959017\n",
            "  -0.03959017]\n",
            " [-0.03959017 -0.03959017 -0.03959017 ... -0.03959017 -0.03959017\n",
            "  -0.03959017]\n",
            " [-0.03959017 -0.03959017 -0.03959017 ... -0.03959017 -0.03959017\n",
            "  -0.03959017]], shape=(252, 128), dtype=float32)\n",
            "(128, 764) (512, 1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_15/kernel:0', 'dense_15/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_15/kernel:0', 'dense_15/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch 1, Batch 70/100, Loss=3.12345e-03\n",
            "(1, 764, 1)\n",
            "tf.Tensor(\n",
            "[[[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " [[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " [[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]], shape=(128, 764, 1), dtype=float32) tf.Tensor(\n",
            "[[[-0.37848666  0.34149987 -0.0960343  ... -0.21514764  0.20115899\n",
            "   -0.24063359]\n",
            "  [-0.37848666  0.34149987 -0.0960343  ... -0.21514764  0.20115899\n",
            "   -0.24063359]\n",
            "  [-0.37848666  0.34149987 -0.0960343  ... -0.21514764  0.20115899\n",
            "   -0.24063359]\n",
            "  ...\n",
            "  [-0.37848666  0.34149987 -0.0960343  ... -0.21514764  0.20115899\n",
            "   -0.24063359]\n",
            "  [-0.37848666  0.34149987 -0.0960343  ... -0.21514764  0.20115899\n",
            "   -0.24063359]\n",
            "  [-0.37848666  0.34149987 -0.0960343  ... -0.21514764  0.20115899\n",
            "   -0.24063359]]\n",
            "\n",
            " [[-0.37848666  0.34149987 -0.0960343  ... -0.21514764  0.20115899\n",
            "   -0.24063359]\n",
            "  [-0.37848666  0.34149987 -0.0960343  ... -0.21514764  0.20115899\n",
            "   -0.24063359]\n",
            "  [-0.37848666  0.34149987 -0.0960343  ... -0.21514764  0.20115899\n",
            "   -0.24063359]\n",
            "  ...\n",
            "  [-0.37848666  0.34149987 -0.0960343  ... -0.21514764  0.20115899\n",
            "   -0.24063359]\n",
            "  [-0.37848666  0.34149987 -0.0960343  ... -0.21514764  0.20115899\n",
            "   -0.24063359]\n",
            "  [-0.37848666  0.34149987 -0.0960343  ... -0.21514764  0.20115899\n",
            "   -0.24063359]]\n",
            "\n",
            " [[-0.37848666  0.34149987 -0.0960343  ... -0.21514764  0.20115899\n",
            "   -0.24063359]\n",
            "  [-0.37848666  0.34149987 -0.0960343  ... -0.21514764  0.20115899\n",
            "   -0.24063359]\n",
            "  [-0.37848666  0.34149987 -0.0960343  ... -0.21514764  0.20115899\n",
            "   -0.24063359]\n",
            "  ...\n",
            "  [-0.37848666  0.34149987 -0.0960343  ... -0.21514764  0.20115899\n",
            "   -0.24063359]\n",
            "  [-0.37848666  0.34149987 -0.0960343  ... -0.21514764  0.20115899\n",
            "   -0.24063359]\n",
            "  [-0.37848666  0.34149987 -0.0960343  ... -0.21514764  0.20115899\n",
            "   -0.24063359]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[-0.37848666  0.34149987 -0.0960343  ... -0.21514764  0.20115899\n",
            "   -0.24063359]\n",
            "  [-0.37848666  0.34149987 -0.0960343  ... -0.21514764  0.20115899\n",
            "   -0.24063359]\n",
            "  [-0.37848666  0.34149987 -0.0960343  ... -0.21514764  0.20115899\n",
            "   -0.24063359]\n",
            "  ...\n",
            "  [-0.37848666  0.34149987 -0.0960343  ... -0.21514764  0.20115899\n",
            "   -0.24063359]\n",
            "  [-0.37848666  0.34149987 -0.0960343  ... -0.21514764  0.20115899\n",
            "   -0.24063359]\n",
            "  [-0.37848666  0.34149987 -0.0960343  ... -0.21514764  0.20115899\n",
            "   -0.24063359]]\n",
            "\n",
            " [[-0.37848666  0.34149987 -0.0960343  ... -0.21514764  0.20115899\n",
            "   -0.24063359]\n",
            "  [-0.37848666  0.34149987 -0.0960343  ... -0.21514764  0.20115899\n",
            "   -0.24063359]\n",
            "  [-0.37848666  0.34149987 -0.0960343  ... -0.21514764  0.20115899\n",
            "   -0.24063359]\n",
            "  ...\n",
            "  [-0.37848666  0.34149987 -0.0960343  ... -0.21514764  0.20115899\n",
            "   -0.24063359]\n",
            "  [-0.37848666  0.34149987 -0.0960343  ... -0.21514764  0.20115899\n",
            "   -0.24063359]\n",
            "  [-0.37848666  0.34149987 -0.0960343  ... -0.21514764  0.20115899\n",
            "   -0.24063359]]\n",
            "\n",
            " [[-0.37848666  0.34149987 -0.0960343  ... -0.21514764  0.20115899\n",
            "   -0.24063359]\n",
            "  [-0.37848666  0.34149987 -0.0960343  ... -0.21514764  0.20115899\n",
            "   -0.24063359]\n",
            "  [-0.37848666  0.34149987 -0.0960343  ... -0.21514764  0.20115899\n",
            "   -0.24063359]\n",
            "  ...\n",
            "  [-0.37848666  0.34149987 -0.0960343  ... -0.21514764  0.20115899\n",
            "   -0.24063359]\n",
            "  [-0.37848666  0.34149987 -0.0960343  ... -0.21514764  0.20115899\n",
            "   -0.24063359]\n",
            "  [-0.37848666  0.34149987 -0.0960343  ... -0.21514764  0.20115899\n",
            "   -0.24063359]]], shape=(128, 764, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.04319184 -0.04319184 -0.04319184 ... -0.04319184 -0.04319184\n",
            "  -0.04319184]\n",
            " [-0.04319184 -0.04319184 -0.04319184 ... -0.04319184 -0.04319184\n",
            "  -0.04319184]\n",
            " [-0.04319184 -0.04319184 -0.04319184 ... -0.04319184 -0.04319184\n",
            "  -0.04319184]\n",
            " ...\n",
            " [-0.04319184 -0.04319184 -0.04319184 ... -0.04319184 -0.04319184\n",
            "  -0.04319184]\n",
            " [-0.04319184 -0.04319184 -0.04319184 ... -0.04319184 -0.04319184\n",
            "  -0.04319184]\n",
            " [-0.04319184 -0.04319184 -0.04319184 ... -0.04319184 -0.04319184\n",
            "  -0.04319184]], shape=(512, 128), dtype=float32) tf.Tensor(\n",
            "[[-0.04319184 -0.04319184 -0.04319184 ... -0.04319184 -0.04319184\n",
            "  -0.04319184]\n",
            " [-0.04319184 -0.04319184 -0.04319184 ... -0.04319184 -0.04319184\n",
            "  -0.04319184]\n",
            " [-0.04319184 -0.04319184 -0.04319184 ... -0.04319184 -0.04319184\n",
            "  -0.04319184]\n",
            " ...\n",
            " [-0.04319184 -0.04319184 -0.04319184 ... -0.04319184 -0.04319184\n",
            "  -0.04319184]\n",
            " [-0.04319184 -0.04319184 -0.04319184 ... -0.04319184 -0.04319184\n",
            "  -0.04319184]\n",
            " [-0.04319184 -0.04319184 -0.04319184 ... -0.04319184 -0.04319184\n",
            "  -0.04319184]], shape=(252, 128), dtype=float32)\n",
            "(128, 764) (512, 1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_15/kernel:0', 'dense_15/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_15/kernel:0', 'dense_15/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch 1, Batch 71/100, Loss=4.26319e-03\n",
            "(1, 764, 1)\n",
            "tf.Tensor(\n",
            "[[[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " [[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " [[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " [[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]], shape=(128, 764, 1), dtype=float32) tf.Tensor(\n",
            "[[[-0.3782348   0.34145305 -0.09550112 ... -0.2158822   0.20084278\n",
            "   -0.23982191]\n",
            "  [-0.3782348   0.34145305 -0.09550112 ... -0.2158822   0.20084278\n",
            "   -0.23982191]\n",
            "  [-0.3782348   0.34145305 -0.09550112 ... -0.2158822   0.20084278\n",
            "   -0.23982191]\n",
            "  ...\n",
            "  [-0.3782348   0.34145305 -0.09550112 ... -0.2158822   0.20084278\n",
            "   -0.23982191]\n",
            "  [-0.3782348   0.34145305 -0.09550112 ... -0.2158822   0.20084278\n",
            "   -0.23982191]\n",
            "  [-0.3782348   0.34145305 -0.09550112 ... -0.2158822   0.20084278\n",
            "   -0.23982191]]\n",
            "\n",
            " [[-0.3782348   0.34145305 -0.09550112 ... -0.2158822   0.20084278\n",
            "   -0.23982191]\n",
            "  [-0.3782348   0.34145305 -0.09550112 ... -0.2158822   0.20084278\n",
            "   -0.23982191]\n",
            "  [-0.3782348   0.34145305 -0.09550112 ... -0.2158822   0.20084278\n",
            "   -0.23982191]\n",
            "  ...\n",
            "  [-0.3782348   0.34145305 -0.09550112 ... -0.2158822   0.20084278\n",
            "   -0.23982191]\n",
            "  [-0.3782348   0.34145305 -0.09550112 ... -0.2158822   0.20084278\n",
            "   -0.23982191]\n",
            "  [-0.3782348   0.34145305 -0.09550112 ... -0.2158822   0.20084278\n",
            "   -0.23982191]]\n",
            "\n",
            " [[-0.3782348   0.34145305 -0.09550112 ... -0.2158822   0.20084278\n",
            "   -0.23982191]\n",
            "  [-0.3782348   0.34145305 -0.09550112 ... -0.2158822   0.20084278\n",
            "   -0.23982191]\n",
            "  [-0.3782348   0.34145305 -0.09550112 ... -0.2158822   0.20084278\n",
            "   -0.23982191]\n",
            "  ...\n",
            "  [-0.3782348   0.34145305 -0.09550112 ... -0.2158822   0.20084278\n",
            "   -0.23982191]\n",
            "  [-0.3782348   0.34145305 -0.09550112 ... -0.2158822   0.20084278\n",
            "   -0.23982191]\n",
            "  [-0.3782348   0.34145305 -0.09550112 ... -0.2158822   0.20084278\n",
            "   -0.23982191]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[-0.3782348   0.34145305 -0.09550112 ... -0.2158822   0.20084278\n",
            "   -0.23982191]\n",
            "  [-0.3782348   0.34145305 -0.09550112 ... -0.2158822   0.20084278\n",
            "   -0.23982191]\n",
            "  [-0.3782348   0.34145305 -0.09550112 ... -0.2158822   0.20084278\n",
            "   -0.23982191]\n",
            "  ...\n",
            "  [-0.3782348   0.34145305 -0.09550112 ... -0.2158822   0.20084278\n",
            "   -0.23982191]\n",
            "  [-0.3782348   0.34145305 -0.09550112 ... -0.2158822   0.20084278\n",
            "   -0.23982191]\n",
            "  [-0.3782348   0.34145305 -0.09550112 ... -0.2158822   0.20084278\n",
            "   -0.23982191]]\n",
            "\n",
            " [[-0.3782348   0.34145305 -0.09550112 ... -0.2158822   0.20084278\n",
            "   -0.23982191]\n",
            "  [-0.3782348   0.34145305 -0.09550112 ... -0.2158822   0.20084278\n",
            "   -0.23982191]\n",
            "  [-0.3782348   0.34145305 -0.09550112 ... -0.2158822   0.20084278\n",
            "   -0.23982191]\n",
            "  ...\n",
            "  [-0.3782348   0.34145305 -0.09550112 ... -0.2158822   0.20084278\n",
            "   -0.23982191]\n",
            "  [-0.3782348   0.34145305 -0.09550112 ... -0.2158822   0.20084278\n",
            "   -0.23982191]\n",
            "  [-0.3782348   0.34145305 -0.09550112 ... -0.2158822   0.20084278\n",
            "   -0.23982191]]\n",
            "\n",
            " [[-0.3782348   0.34145305 -0.09550112 ... -0.2158822   0.20084278\n",
            "   -0.23982191]\n",
            "  [-0.3782348   0.34145305 -0.09550112 ... -0.2158822   0.20084278\n",
            "   -0.23982191]\n",
            "  [-0.3782348   0.34145305 -0.09550112 ... -0.2158822   0.20084278\n",
            "   -0.23982191]\n",
            "  ...\n",
            "  [-0.3782348   0.34145305 -0.09550112 ... -0.2158822   0.20084278\n",
            "   -0.23982191]\n",
            "  [-0.3782348   0.34145305 -0.09550112 ... -0.2158822   0.20084278\n",
            "   -0.23982191]\n",
            "  [-0.3782348   0.34145305 -0.09550112 ... -0.2158822   0.20084278\n",
            "   -0.23982191]]], shape=(128, 764, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.04001657 -0.04001657 -0.04001657 ... -0.04001657 -0.04001657\n",
            "  -0.04001657]\n",
            " [-0.04001657 -0.04001657 -0.04001657 ... -0.04001657 -0.04001657\n",
            "  -0.04001657]\n",
            " [-0.04001657 -0.04001657 -0.04001657 ... -0.04001657 -0.04001657\n",
            "  -0.04001657]\n",
            " ...\n",
            " [-0.04001657 -0.04001657 -0.04001657 ... -0.04001657 -0.04001657\n",
            "  -0.04001657]\n",
            " [-0.04001657 -0.04001657 -0.04001657 ... -0.04001657 -0.04001657\n",
            "  -0.04001657]\n",
            " [-0.04001657 -0.04001657 -0.04001657 ... -0.04001657 -0.04001657\n",
            "  -0.04001657]], shape=(512, 128), dtype=float32) tf.Tensor(\n",
            "[[-0.04001657 -0.04001657 -0.04001657 ... -0.04001657 -0.04001657\n",
            "  -0.04001657]\n",
            " [-0.04001657 -0.04001657 -0.04001657 ... -0.04001657 -0.04001657\n",
            "  -0.04001657]\n",
            " [-0.04001657 -0.04001657 -0.04001657 ... -0.04001657 -0.04001657\n",
            "  -0.04001657]\n",
            " ...\n",
            " [-0.04001657 -0.04001657 -0.04001657 ... -0.04001657 -0.04001657\n",
            "  -0.04001657]\n",
            " [-0.04001657 -0.04001657 -0.04001657 ... -0.04001657 -0.04001657\n",
            "  -0.04001657]\n",
            " [-0.04001657 -0.04001657 -0.04001657 ... -0.04001657 -0.04001657\n",
            "  -0.04001657]], shape=(252, 128), dtype=float32)\n",
            "(128, 764) (512, 1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_15/kernel:0', 'dense_15/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_15/kernel:0', 'dense_15/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch 1, Batch 72/100, Loss=3.51976e-03\n",
            "(1, 764, 1)\n",
            "tf.Tensor(\n",
            "[[[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " [[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " [[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]], shape=(128, 764, 1), dtype=float32) tf.Tensor(\n",
            "[[[-0.37692606  0.3412483  -0.0940859  ... -0.21722835  0.19971879\n",
            "   -0.2383291 ]\n",
            "  [-0.37692606  0.3412483  -0.0940859  ... -0.21722835  0.19971879\n",
            "   -0.2383291 ]\n",
            "  [-0.37692606  0.3412483  -0.0940859  ... -0.21722835  0.19971879\n",
            "   -0.2383291 ]\n",
            "  ...\n",
            "  [-0.37692606  0.3412483  -0.0940859  ... -0.21722835  0.19971879\n",
            "   -0.2383291 ]\n",
            "  [-0.37692606  0.3412483  -0.0940859  ... -0.21722835  0.19971879\n",
            "   -0.2383291 ]\n",
            "  [-0.37692606  0.3412483  -0.0940859  ... -0.21722835  0.19971879\n",
            "   -0.2383291 ]]\n",
            "\n",
            " [[-0.37692606  0.3412483  -0.0940859  ... -0.21722835  0.19971879\n",
            "   -0.2383291 ]\n",
            "  [-0.37692606  0.3412483  -0.0940859  ... -0.21722835  0.19971879\n",
            "   -0.2383291 ]\n",
            "  [-0.37692606  0.3412483  -0.0940859  ... -0.21722835  0.19971879\n",
            "   -0.2383291 ]\n",
            "  ...\n",
            "  [-0.37692606  0.3412483  -0.0940859  ... -0.21722835  0.19971879\n",
            "   -0.2383291 ]\n",
            "  [-0.37692606  0.3412483  -0.0940859  ... -0.21722835  0.19971879\n",
            "   -0.2383291 ]\n",
            "  [-0.37692606  0.3412483  -0.0940859  ... -0.21722835  0.19971879\n",
            "   -0.2383291 ]]\n",
            "\n",
            " [[-0.37692606  0.3412483  -0.0940859  ... -0.21722835  0.19971879\n",
            "   -0.2383291 ]\n",
            "  [-0.37692606  0.3412483  -0.0940859  ... -0.21722835  0.19971879\n",
            "   -0.2383291 ]\n",
            "  [-0.37692606  0.3412483  -0.0940859  ... -0.21722835  0.19971879\n",
            "   -0.2383291 ]\n",
            "  ...\n",
            "  [-0.37692606  0.3412483  -0.0940859  ... -0.21722835  0.19971879\n",
            "   -0.2383291 ]\n",
            "  [-0.37692606  0.3412483  -0.0940859  ... -0.21722835  0.19971879\n",
            "   -0.2383291 ]\n",
            "  [-0.37692606  0.3412483  -0.0940859  ... -0.21722835  0.19971879\n",
            "   -0.2383291 ]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[-0.37692606  0.3412483  -0.0940859  ... -0.21722835  0.19971879\n",
            "   -0.2383291 ]\n",
            "  [-0.37692606  0.3412483  -0.0940859  ... -0.21722835  0.19971879\n",
            "   -0.2383291 ]\n",
            "  [-0.37692606  0.3412483  -0.0940859  ... -0.21722835  0.19971879\n",
            "   -0.2383291 ]\n",
            "  ...\n",
            "  [-0.37692606  0.3412483  -0.0940859  ... -0.21722835  0.19971879\n",
            "   -0.2383291 ]\n",
            "  [-0.37692606  0.3412483  -0.0940859  ... -0.21722835  0.19971879\n",
            "   -0.2383291 ]\n",
            "  [-0.37692606  0.3412483  -0.0940859  ... -0.21722835  0.19971879\n",
            "   -0.2383291 ]]\n",
            "\n",
            " [[-0.37692606  0.3412483  -0.0940859  ... -0.21722835  0.19971879\n",
            "   -0.2383291 ]\n",
            "  [-0.37692606  0.3412483  -0.0940859  ... -0.21722835  0.19971879\n",
            "   -0.2383291 ]\n",
            "  [-0.37692606  0.3412483  -0.0940859  ... -0.21722835  0.19971879\n",
            "   -0.2383291 ]\n",
            "  ...\n",
            "  [-0.37692606  0.3412483  -0.0940859  ... -0.21722835  0.19971879\n",
            "   -0.2383291 ]\n",
            "  [-0.37692606  0.3412483  -0.0940859  ... -0.21722835  0.19971879\n",
            "   -0.2383291 ]\n",
            "  [-0.37692606  0.3412483  -0.0940859  ... -0.21722835  0.19971879\n",
            "   -0.2383291 ]]\n",
            "\n",
            " [[-0.37692606  0.3412483  -0.0940859  ... -0.21722835  0.19971879\n",
            "   -0.2383291 ]\n",
            "  [-0.37692606  0.3412483  -0.0940859  ... -0.21722835  0.19971879\n",
            "   -0.2383291 ]\n",
            "  [-0.37692606  0.3412483  -0.0940859  ... -0.21722835  0.19971879\n",
            "   -0.2383291 ]\n",
            "  ...\n",
            "  [-0.37692606  0.3412483  -0.0940859  ... -0.21722835  0.19971879\n",
            "   -0.2383291 ]\n",
            "  [-0.37692606  0.3412483  -0.0940859  ... -0.21722835  0.19971879\n",
            "   -0.2383291 ]\n",
            "  [-0.37692606  0.3412483  -0.0940859  ... -0.21722835  0.19971879\n",
            "   -0.2383291 ]]], shape=(128, 764, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.03111562 -0.03111562 -0.03111562 ... -0.03111562 -0.03111562\n",
            "  -0.03111562]\n",
            " [-0.03111562 -0.03111562 -0.03111562 ... -0.03111562 -0.03111562\n",
            "  -0.03111562]\n",
            " [-0.03111562 -0.03111562 -0.03111562 ... -0.03111562 -0.03111562\n",
            "  -0.03111562]\n",
            " ...\n",
            " [-0.03111562 -0.03111562 -0.03111562 ... -0.03111562 -0.03111562\n",
            "  -0.03111562]\n",
            " [-0.03111562 -0.03111562 -0.03111562 ... -0.03111562 -0.03111562\n",
            "  -0.03111562]\n",
            " [-0.03111562 -0.03111562 -0.03111562 ... -0.03111562 -0.03111562\n",
            "  -0.03111562]], shape=(512, 128), dtype=float32) tf.Tensor(\n",
            "[[-0.03111562 -0.03111562 -0.03111562 ... -0.03111562 -0.03111562\n",
            "  -0.03111562]\n",
            " [-0.03111562 -0.03111562 -0.03111562 ... -0.03111562 -0.03111562\n",
            "  -0.03111562]\n",
            " [-0.03111562 -0.03111562 -0.03111562 ... -0.03111562 -0.03111562\n",
            "  -0.03111562]\n",
            " ...\n",
            " [-0.03111562 -0.03111562 -0.03111562 ... -0.03111562 -0.03111562\n",
            "  -0.03111562]\n",
            " [-0.03111562 -0.03111562 -0.03111562 ... -0.03111562 -0.03111562\n",
            "  -0.03111562]\n",
            " [-0.03111562 -0.03111562 -0.03111562 ... -0.03111562 -0.03111562\n",
            "  -0.03111562]], shape=(252, 128), dtype=float32)\n",
            "(128, 764) (512, 1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_15/kernel:0', 'dense_15/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_15/kernel:0', 'dense_15/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch 1, Batch 73/100, Loss=2.91058e-03\n",
            "(1, 764, 1)\n",
            "tf.Tensor(\n",
            "[[[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]], shape=(128, 764, 1), dtype=float32) tf.Tensor(\n",
            "[[[-0.3748999   0.3409362  -0.09208816 ... -0.21897016  0.19805697\n",
            "   -0.2363892 ]\n",
            "  [-0.3748999   0.3409362  -0.09208816 ... -0.21897016  0.19805697\n",
            "   -0.2363892 ]\n",
            "  [-0.3748999   0.3409362  -0.09208816 ... -0.21897016  0.19805697\n",
            "   -0.2363892 ]\n",
            "  ...\n",
            "  [-0.3748999   0.3409362  -0.09208816 ... -0.21897016  0.19805697\n",
            "   -0.2363892 ]\n",
            "  [-0.3748999   0.3409362  -0.09208816 ... -0.21897016  0.19805697\n",
            "   -0.2363892 ]\n",
            "  [-0.3748999   0.3409362  -0.09208816 ... -0.21897016  0.19805697\n",
            "   -0.2363892 ]]\n",
            "\n",
            " [[-0.3748999   0.3409362  -0.09208816 ... -0.21897016  0.19805697\n",
            "   -0.2363892 ]\n",
            "  [-0.3748999   0.3409362  -0.09208816 ... -0.21897016  0.19805697\n",
            "   -0.2363892 ]\n",
            "  [-0.3748999   0.3409362  -0.09208816 ... -0.21897016  0.19805697\n",
            "   -0.2363892 ]\n",
            "  ...\n",
            "  [-0.3748999   0.3409362  -0.09208816 ... -0.21897016  0.19805697\n",
            "   -0.2363892 ]\n",
            "  [-0.3748999   0.3409362  -0.09208816 ... -0.21897016  0.19805697\n",
            "   -0.2363892 ]\n",
            "  [-0.3748999   0.3409362  -0.09208816 ... -0.21897016  0.19805697\n",
            "   -0.2363892 ]]\n",
            "\n",
            " [[-0.3748999   0.3409362  -0.09208816 ... -0.21897016  0.19805697\n",
            "   -0.2363892 ]\n",
            "  [-0.3748999   0.3409362  -0.09208816 ... -0.21897016  0.19805697\n",
            "   -0.2363892 ]\n",
            "  [-0.3748999   0.3409362  -0.09208816 ... -0.21897016  0.19805697\n",
            "   -0.2363892 ]\n",
            "  ...\n",
            "  [-0.3748999   0.3409362  -0.09208816 ... -0.21897016  0.19805697\n",
            "   -0.2363892 ]\n",
            "  [-0.3748999   0.3409362  -0.09208816 ... -0.21897016  0.19805697\n",
            "   -0.2363892 ]\n",
            "  [-0.3748999   0.3409362  -0.09208816 ... -0.21897016  0.19805697\n",
            "   -0.2363892 ]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[-0.3748999   0.3409362  -0.09208816 ... -0.21897016  0.19805697\n",
            "   -0.2363892 ]\n",
            "  [-0.3748999   0.3409362  -0.09208816 ... -0.21897016  0.19805697\n",
            "   -0.2363892 ]\n",
            "  [-0.3748999   0.3409362  -0.09208816 ... -0.21897016  0.19805697\n",
            "   -0.2363892 ]\n",
            "  ...\n",
            "  [-0.3748999   0.3409362  -0.09208816 ... -0.21897016  0.19805697\n",
            "   -0.2363892 ]\n",
            "  [-0.3748999   0.3409362  -0.09208816 ... -0.21897016  0.19805697\n",
            "   -0.2363892 ]\n",
            "  [-0.3748999   0.3409362  -0.09208816 ... -0.21897016  0.19805697\n",
            "   -0.2363892 ]]\n",
            "\n",
            " [[-0.3748999   0.3409362  -0.09208816 ... -0.21897016  0.19805697\n",
            "   -0.2363892 ]\n",
            "  [-0.3748999   0.3409362  -0.09208816 ... -0.21897016  0.19805697\n",
            "   -0.2363892 ]\n",
            "  [-0.3748999   0.3409362  -0.09208816 ... -0.21897016  0.19805697\n",
            "   -0.2363892 ]\n",
            "  ...\n",
            "  [-0.3748999   0.3409362  -0.09208816 ... -0.21897016  0.19805697\n",
            "   -0.2363892 ]\n",
            "  [-0.3748999   0.3409362  -0.09208816 ... -0.21897016  0.19805697\n",
            "   -0.2363892 ]\n",
            "  [-0.3748999   0.3409362  -0.09208816 ... -0.21897016  0.19805697\n",
            "   -0.2363892 ]]\n",
            "\n",
            " [[-0.3748999   0.3409362  -0.09208816 ... -0.21897016  0.19805697\n",
            "   -0.2363892 ]\n",
            "  [-0.3748999   0.3409362  -0.09208816 ... -0.21897016  0.19805697\n",
            "   -0.2363892 ]\n",
            "  [-0.3748999   0.3409362  -0.09208816 ... -0.21897016  0.19805697\n",
            "   -0.2363892 ]\n",
            "  ...\n",
            "  [-0.3748999   0.3409362  -0.09208816 ... -0.21897016  0.19805697\n",
            "   -0.2363892 ]\n",
            "  [-0.3748999   0.3409362  -0.09208816 ... -0.21897016  0.19805697\n",
            "   -0.2363892 ]\n",
            "  [-0.3748999   0.3409362  -0.09208816 ... -0.21897016  0.19805697\n",
            "   -0.2363892 ]]], shape=(128, 764, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.01838135 -0.01838135 -0.01838135 ... -0.01838135 -0.01838135\n",
            "  -0.01838135]\n",
            " [-0.01838135 -0.01838135 -0.01838135 ... -0.01838135 -0.01838135\n",
            "  -0.01838135]\n",
            " [-0.01838135 -0.01838135 -0.01838135 ... -0.01838135 -0.01838135\n",
            "  -0.01838135]\n",
            " ...\n",
            " [-0.01838135 -0.01838135 -0.01838135 ... -0.01838135 -0.01838135\n",
            "  -0.01838135]\n",
            " [-0.01838135 -0.01838135 -0.01838135 ... -0.01838135 -0.01838135\n",
            "  -0.01838135]\n",
            " [-0.01838135 -0.01838135 -0.01838135 ... -0.01838135 -0.01838135\n",
            "  -0.01838135]], shape=(512, 128), dtype=float32) tf.Tensor(\n",
            "[[-0.01838135 -0.01838135 -0.01838135 ... -0.01838135 -0.01838135\n",
            "  -0.01838135]\n",
            " [-0.01838135 -0.01838135 -0.01838135 ... -0.01838135 -0.01838135\n",
            "  -0.01838135]\n",
            " [-0.01838135 -0.01838135 -0.01838135 ... -0.01838135 -0.01838135\n",
            "  -0.01838135]\n",
            " ...\n",
            " [-0.01838135 -0.01838135 -0.01838135 ... -0.01838135 -0.01838135\n",
            "  -0.01838135]\n",
            " [-0.01838135 -0.01838135 -0.01838135 ... -0.01838135 -0.01838135\n",
            "  -0.01838135]\n",
            " [-0.01838135 -0.01838135 -0.01838135 ... -0.01838135 -0.01838135\n",
            "  -0.01838135]], shape=(252, 128), dtype=float32)\n",
            "(128, 764) (512, 1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_15/kernel:0', 'dense_15/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_15/kernel:0', 'dense_15/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch 1, Batch 74/100, Loss=1.86239e-03\n",
            "(1, 764, 1)\n",
            "tf.Tensor(\n",
            "[[[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " [[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " [[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " [[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]], shape=(128, 764, 1), dtype=float32) tf.Tensor(\n",
            "[[[-0.3725748   0.3405782  -0.08987045 ... -0.2208457   0.19618343\n",
            "   -0.23429358]\n",
            "  [-0.3725748   0.3405782  -0.08987045 ... -0.2208457   0.19618343\n",
            "   -0.23429358]\n",
            "  [-0.3725748   0.3405782  -0.08987045 ... -0.2208457   0.19618343\n",
            "   -0.23429358]\n",
            "  ...\n",
            "  [-0.3725748   0.3405782  -0.08987045 ... -0.2208457   0.19618343\n",
            "   -0.23429358]\n",
            "  [-0.3725748   0.3405782  -0.08987045 ... -0.2208457   0.19618343\n",
            "   -0.23429358]\n",
            "  [-0.3725748   0.3405782  -0.08987045 ... -0.2208457   0.19618343\n",
            "   -0.23429358]]\n",
            "\n",
            " [[-0.3725748   0.3405782  -0.08987045 ... -0.2208457   0.19618343\n",
            "   -0.23429358]\n",
            "  [-0.3725748   0.3405782  -0.08987045 ... -0.2208457   0.19618343\n",
            "   -0.23429358]\n",
            "  [-0.3725748   0.3405782  -0.08987045 ... -0.2208457   0.19618343\n",
            "   -0.23429358]\n",
            "  ...\n",
            "  [-0.3725748   0.3405782  -0.08987045 ... -0.2208457   0.19618343\n",
            "   -0.23429358]\n",
            "  [-0.3725748   0.3405782  -0.08987045 ... -0.2208457   0.19618343\n",
            "   -0.23429358]\n",
            "  [-0.3725748   0.3405782  -0.08987045 ... -0.2208457   0.19618343\n",
            "   -0.23429358]]\n",
            "\n",
            " [[-0.3725748   0.3405782  -0.08987045 ... -0.2208457   0.19618343\n",
            "   -0.23429358]\n",
            "  [-0.3725748   0.3405782  -0.08987045 ... -0.2208457   0.19618343\n",
            "   -0.23429358]\n",
            "  [-0.3725748   0.3405782  -0.08987045 ... -0.2208457   0.19618343\n",
            "   -0.23429358]\n",
            "  ...\n",
            "  [-0.3725748   0.3405782  -0.08987045 ... -0.2208457   0.19618343\n",
            "   -0.23429358]\n",
            "  [-0.3725748   0.3405782  -0.08987045 ... -0.2208457   0.19618343\n",
            "   -0.23429358]\n",
            "  [-0.3725748   0.3405782  -0.08987045 ... -0.2208457   0.19618343\n",
            "   -0.23429358]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[-0.3725748   0.3405782  -0.08987045 ... -0.2208457   0.19618343\n",
            "   -0.23429358]\n",
            "  [-0.3725748   0.3405782  -0.08987045 ... -0.2208457   0.19618343\n",
            "   -0.23429358]\n",
            "  [-0.3725748   0.3405782  -0.08987045 ... -0.2208457   0.19618343\n",
            "   -0.23429358]\n",
            "  ...\n",
            "  [-0.3725748   0.3405782  -0.08987045 ... -0.2208457   0.19618343\n",
            "   -0.23429358]\n",
            "  [-0.3725748   0.3405782  -0.08987045 ... -0.2208457   0.19618343\n",
            "   -0.23429358]\n",
            "  [-0.3725748   0.3405782  -0.08987045 ... -0.2208457   0.19618343\n",
            "   -0.23429358]]\n",
            "\n",
            " [[-0.3725748   0.3405782  -0.08987045 ... -0.2208457   0.19618343\n",
            "   -0.23429358]\n",
            "  [-0.3725748   0.3405782  -0.08987045 ... -0.2208457   0.19618343\n",
            "   -0.23429358]\n",
            "  [-0.3725748   0.3405782  -0.08987045 ... -0.2208457   0.19618343\n",
            "   -0.23429358]\n",
            "  ...\n",
            "  [-0.3725748   0.3405782  -0.08987045 ... -0.2208457   0.19618343\n",
            "   -0.23429358]\n",
            "  [-0.3725748   0.3405782  -0.08987045 ... -0.2208457   0.19618343\n",
            "   -0.23429358]\n",
            "  [-0.3725748   0.3405782  -0.08987045 ... -0.2208457   0.19618343\n",
            "   -0.23429358]]\n",
            "\n",
            " [[-0.3725748   0.3405782  -0.08987045 ... -0.2208457   0.19618343\n",
            "   -0.23429358]\n",
            "  [-0.3725748   0.3405782  -0.08987045 ... -0.2208457   0.19618343\n",
            "   -0.23429358]\n",
            "  [-0.3725748   0.3405782  -0.08987045 ... -0.2208457   0.19618343\n",
            "   -0.23429358]\n",
            "  ...\n",
            "  [-0.3725748   0.3405782  -0.08987045 ... -0.2208457   0.19618343\n",
            "   -0.23429358]\n",
            "  [-0.3725748   0.3405782  -0.08987045 ... -0.2208457   0.19618343\n",
            "   -0.23429358]\n",
            "  [-0.3725748   0.3405782  -0.08987045 ... -0.2208457   0.19618343\n",
            "   -0.23429358]]], shape=(128, 764, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.00415359 -0.00415359 -0.00415359 ... -0.00415359 -0.00415359\n",
            "  -0.00415359]\n",
            " [-0.00415359 -0.00415359 -0.00415359 ... -0.00415359 -0.00415359\n",
            "  -0.00415359]\n",
            " [-0.00415359 -0.00415359 -0.00415359 ... -0.00415359 -0.00415359\n",
            "  -0.00415359]\n",
            " ...\n",
            " [-0.00415359 -0.00415359 -0.00415359 ... -0.00415359 -0.00415359\n",
            "  -0.00415359]\n",
            " [-0.00415359 -0.00415359 -0.00415359 ... -0.00415359 -0.00415359\n",
            "  -0.00415359]\n",
            " [-0.00415359 -0.00415359 -0.00415359 ... -0.00415359 -0.00415359\n",
            "  -0.00415359]], shape=(512, 128), dtype=float32) tf.Tensor(\n",
            "[[-0.00415359 -0.00415359 -0.00415359 ... -0.00415359 -0.00415359\n",
            "  -0.00415359]\n",
            " [-0.00415359 -0.00415359 -0.00415359 ... -0.00415359 -0.00415359\n",
            "  -0.00415359]\n",
            " [-0.00415359 -0.00415359 -0.00415359 ... -0.00415359 -0.00415359\n",
            "  -0.00415359]\n",
            " ...\n",
            " [-0.00415359 -0.00415359 -0.00415359 ... -0.00415359 -0.00415359\n",
            "  -0.00415359]\n",
            " [-0.00415359 -0.00415359 -0.00415359 ... -0.00415359 -0.00415359\n",
            "  -0.00415359]\n",
            " [-0.00415359 -0.00415359 -0.00415359 ... -0.00415359 -0.00415359\n",
            "  -0.00415359]], shape=(252, 128), dtype=float32)\n",
            "(128, 764) (512, 1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_15/kernel:0', 'dense_15/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_15/kernel:0', 'dense_15/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch 1, Batch 75/100, Loss=1.08124e-03\n",
            "(1, 764, 1)\n",
            "tf.Tensor(\n",
            "[[[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " [[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " [[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " [[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]], shape=(128, 764, 1), dtype=float32) tf.Tensor(\n",
            "[[[-0.37036204  0.3402353  -0.08779172 ... -0.22259973  0.19441403\n",
            "   -0.23232853]\n",
            "  [-0.37036204  0.3402353  -0.08779172 ... -0.22259973  0.19441403\n",
            "   -0.23232853]\n",
            "  [-0.37036204  0.3402353  -0.08779172 ... -0.22259973  0.19441403\n",
            "   -0.23232853]\n",
            "  ...\n",
            "  [-0.37036204  0.3402353  -0.08779172 ... -0.22259973  0.19441403\n",
            "   -0.23232853]\n",
            "  [-0.37036204  0.3402353  -0.08779172 ... -0.22259973  0.19441403\n",
            "   -0.23232853]\n",
            "  [-0.37036204  0.3402353  -0.08779172 ... -0.22259973  0.19441403\n",
            "   -0.23232853]]\n",
            "\n",
            " [[-0.37036204  0.3402353  -0.08779172 ... -0.22259973  0.19441403\n",
            "   -0.23232853]\n",
            "  [-0.37036204  0.3402353  -0.08779172 ... -0.22259973  0.19441403\n",
            "   -0.23232853]\n",
            "  [-0.37036204  0.3402353  -0.08779172 ... -0.22259973  0.19441403\n",
            "   -0.23232853]\n",
            "  ...\n",
            "  [-0.37036204  0.3402353  -0.08779172 ... -0.22259973  0.19441403\n",
            "   -0.23232853]\n",
            "  [-0.37036204  0.3402353  -0.08779172 ... -0.22259973  0.19441403\n",
            "   -0.23232853]\n",
            "  [-0.37036204  0.3402353  -0.08779172 ... -0.22259973  0.19441403\n",
            "   -0.23232853]]\n",
            "\n",
            " [[-0.37036204  0.3402353  -0.08779172 ... -0.22259973  0.19441403\n",
            "   -0.23232853]\n",
            "  [-0.37036204  0.3402353  -0.08779172 ... -0.22259973  0.19441403\n",
            "   -0.23232853]\n",
            "  [-0.37036204  0.3402353  -0.08779172 ... -0.22259973  0.19441403\n",
            "   -0.23232853]\n",
            "  ...\n",
            "  [-0.37036204  0.3402353  -0.08779172 ... -0.22259973  0.19441403\n",
            "   -0.23232853]\n",
            "  [-0.37036204  0.3402353  -0.08779172 ... -0.22259973  0.19441403\n",
            "   -0.23232853]\n",
            "  [-0.37036204  0.3402353  -0.08779172 ... -0.22259973  0.19441403\n",
            "   -0.23232853]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[-0.37036204  0.3402353  -0.08779172 ... -0.22259973  0.19441403\n",
            "   -0.23232853]\n",
            "  [-0.37036204  0.3402353  -0.08779172 ... -0.22259973  0.19441403\n",
            "   -0.23232853]\n",
            "  [-0.37036204  0.3402353  -0.08779172 ... -0.22259973  0.19441403\n",
            "   -0.23232853]\n",
            "  ...\n",
            "  [-0.37036204  0.3402353  -0.08779172 ... -0.22259973  0.19441403\n",
            "   -0.23232853]\n",
            "  [-0.37036204  0.3402353  -0.08779172 ... -0.22259973  0.19441403\n",
            "   -0.23232853]\n",
            "  [-0.37036204  0.3402353  -0.08779172 ... -0.22259973  0.19441403\n",
            "   -0.23232853]]\n",
            "\n",
            " [[-0.37036204  0.3402353  -0.08779172 ... -0.22259973  0.19441403\n",
            "   -0.23232853]\n",
            "  [-0.37036204  0.3402353  -0.08779172 ... -0.22259973  0.19441403\n",
            "   -0.23232853]\n",
            "  [-0.37036204  0.3402353  -0.08779172 ... -0.22259973  0.19441403\n",
            "   -0.23232853]\n",
            "  ...\n",
            "  [-0.37036204  0.3402353  -0.08779172 ... -0.22259973  0.19441403\n",
            "   -0.23232853]\n",
            "  [-0.37036204  0.3402353  -0.08779172 ... -0.22259973  0.19441403\n",
            "   -0.23232853]\n",
            "  [-0.37036204  0.3402353  -0.08779172 ... -0.22259973  0.19441403\n",
            "   -0.23232853]]\n",
            "\n",
            " [[-0.37036204  0.3402353  -0.08779172 ... -0.22259973  0.19441403\n",
            "   -0.23232853]\n",
            "  [-0.37036204  0.3402353  -0.08779172 ... -0.22259973  0.19441403\n",
            "   -0.23232853]\n",
            "  [-0.37036204  0.3402353  -0.08779172 ... -0.22259973  0.19441403\n",
            "   -0.23232853]\n",
            "  ...\n",
            "  [-0.37036204  0.3402353  -0.08779172 ... -0.22259973  0.19441403\n",
            "   -0.23232853]\n",
            "  [-0.37036204  0.3402353  -0.08779172 ... -0.22259973  0.19441403\n",
            "   -0.23232853]\n",
            "  [-0.37036204  0.3402353  -0.08779172 ... -0.22259973  0.19441403\n",
            "   -0.23232853]]], shape=(128, 764, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[0.00929223 0.00929223 0.00929223 ... 0.00929223 0.00929223 0.00929223]\n",
            " [0.00929223 0.00929223 0.00929223 ... 0.00929223 0.00929223 0.00929223]\n",
            " [0.00929223 0.00929223 0.00929223 ... 0.00929223 0.00929223 0.00929223]\n",
            " ...\n",
            " [0.00929223 0.00929223 0.00929223 ... 0.00929223 0.00929223 0.00929223]\n",
            " [0.00929223 0.00929223 0.00929223 ... 0.00929223 0.00929223 0.00929223]\n",
            " [0.00929223 0.00929223 0.00929223 ... 0.00929223 0.00929223 0.00929223]], shape=(512, 128), dtype=float32) tf.Tensor(\n",
            "[[0.00929223 0.00929223 0.00929223 ... 0.00929223 0.00929223 0.00929223]\n",
            " [0.00929223 0.00929223 0.00929223 ... 0.00929223 0.00929223 0.00929223]\n",
            " [0.00929223 0.00929223 0.00929223 ... 0.00929223 0.00929223 0.00929223]\n",
            " ...\n",
            " [0.00929223 0.00929223 0.00929223 ... 0.00929223 0.00929223 0.00929223]\n",
            " [0.00929223 0.00929223 0.00929223 ... 0.00929223 0.00929223 0.00929223]\n",
            " [0.00929223 0.00929223 0.00929223 ... 0.00929223 0.00929223 0.00929223]], shape=(252, 128), dtype=float32)\n",
            "(128, 764) (512, 1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_15/kernel:0', 'dense_15/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_15/kernel:0', 'dense_15/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch 1, Batch 76/100, Loss=9.94794e-04\n",
            "(1, 764, 1)\n",
            "tf.Tensor(\n",
            "[[[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " [[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " [[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]], shape=(128, 764, 1), dtype=float32) tf.Tensor(\n",
            "[[[-0.36860812  0.3399615  -0.08615644 ... -0.22401747  0.19301611\n",
            "   -0.2307339 ]\n",
            "  [-0.36860812  0.3399615  -0.08615644 ... -0.22401747  0.19301611\n",
            "   -0.2307339 ]\n",
            "  [-0.36860812  0.3399615  -0.08615644 ... -0.22401747  0.19301611\n",
            "   -0.2307339 ]\n",
            "  ...\n",
            "  [-0.36860812  0.3399615  -0.08615644 ... -0.22401747  0.19301611\n",
            "   -0.2307339 ]\n",
            "  [-0.36860812  0.3399615  -0.08615644 ... -0.22401747  0.19301611\n",
            "   -0.2307339 ]\n",
            "  [-0.36860812  0.3399615  -0.08615644 ... -0.22401747  0.19301611\n",
            "   -0.2307339 ]]\n",
            "\n",
            " [[-0.36860812  0.3399615  -0.08615644 ... -0.22401747  0.19301611\n",
            "   -0.2307339 ]\n",
            "  [-0.36860812  0.3399615  -0.08615644 ... -0.22401747  0.19301611\n",
            "   -0.2307339 ]\n",
            "  [-0.36860812  0.3399615  -0.08615644 ... -0.22401747  0.19301611\n",
            "   -0.2307339 ]\n",
            "  ...\n",
            "  [-0.36860812  0.3399615  -0.08615644 ... -0.22401747  0.19301611\n",
            "   -0.2307339 ]\n",
            "  [-0.36860812  0.3399615  -0.08615644 ... -0.22401747  0.19301611\n",
            "   -0.2307339 ]\n",
            "  [-0.36860812  0.3399615  -0.08615644 ... -0.22401747  0.19301611\n",
            "   -0.2307339 ]]\n",
            "\n",
            " [[-0.36860812  0.3399615  -0.08615644 ... -0.22401747  0.19301611\n",
            "   -0.2307339 ]\n",
            "  [-0.36860812  0.3399615  -0.08615644 ... -0.22401747  0.19301611\n",
            "   -0.2307339 ]\n",
            "  [-0.36860812  0.3399615  -0.08615644 ... -0.22401747  0.19301611\n",
            "   -0.2307339 ]\n",
            "  ...\n",
            "  [-0.36860812  0.3399615  -0.08615644 ... -0.22401747  0.19301611\n",
            "   -0.2307339 ]\n",
            "  [-0.36860812  0.3399615  -0.08615644 ... -0.22401747  0.19301611\n",
            "   -0.2307339 ]\n",
            "  [-0.36860812  0.3399615  -0.08615644 ... -0.22401747  0.19301611\n",
            "   -0.2307339 ]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[-0.36860812  0.3399615  -0.08615644 ... -0.22401747  0.19301611\n",
            "   -0.2307339 ]\n",
            "  [-0.36860812  0.3399615  -0.08615644 ... -0.22401747  0.19301611\n",
            "   -0.2307339 ]\n",
            "  [-0.36860812  0.3399615  -0.08615644 ... -0.22401747  0.19301611\n",
            "   -0.2307339 ]\n",
            "  ...\n",
            "  [-0.36860812  0.3399615  -0.08615644 ... -0.22401747  0.19301611\n",
            "   -0.2307339 ]\n",
            "  [-0.36860812  0.3399615  -0.08615644 ... -0.22401747  0.19301611\n",
            "   -0.2307339 ]\n",
            "  [-0.36860812  0.3399615  -0.08615644 ... -0.22401747  0.19301611\n",
            "   -0.2307339 ]]\n",
            "\n",
            " [[-0.36860812  0.3399615  -0.08615644 ... -0.22401747  0.19301611\n",
            "   -0.2307339 ]\n",
            "  [-0.36860812  0.3399615  -0.08615644 ... -0.22401747  0.19301611\n",
            "   -0.2307339 ]\n",
            "  [-0.36860812  0.3399615  -0.08615644 ... -0.22401747  0.19301611\n",
            "   -0.2307339 ]\n",
            "  ...\n",
            "  [-0.36860812  0.3399615  -0.08615644 ... -0.22401747  0.19301611\n",
            "   -0.2307339 ]\n",
            "  [-0.36860812  0.3399615  -0.08615644 ... -0.22401747  0.19301611\n",
            "   -0.2307339 ]\n",
            "  [-0.36860812  0.3399615  -0.08615644 ... -0.22401747  0.19301611\n",
            "   -0.2307339 ]]\n",
            "\n",
            " [[-0.36860812  0.3399615  -0.08615644 ... -0.22401747  0.19301611\n",
            "   -0.2307339 ]\n",
            "  [-0.36860812  0.3399615  -0.08615644 ... -0.22401747  0.19301611\n",
            "   -0.2307339 ]\n",
            "  [-0.36860812  0.3399615  -0.08615644 ... -0.22401747  0.19301611\n",
            "   -0.2307339 ]\n",
            "  ...\n",
            "  [-0.36860812  0.3399615  -0.08615644 ... -0.22401747  0.19301611\n",
            "   -0.2307339 ]\n",
            "  [-0.36860812  0.3399615  -0.08615644 ... -0.22401747  0.19301611\n",
            "   -0.2307339 ]\n",
            "  [-0.36860812  0.3399615  -0.08615644 ... -0.22401747  0.19301611\n",
            "   -0.2307339 ]]], shape=(128, 764, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[0.02004498 0.02004498 0.02004498 ... 0.02004498 0.02004498 0.02004498]\n",
            " [0.02004498 0.02004498 0.02004498 ... 0.02004498 0.02004498 0.02004498]\n",
            " [0.02004498 0.02004498 0.02004498 ... 0.02004498 0.02004498 0.02004498]\n",
            " ...\n",
            " [0.02004498 0.02004498 0.02004498 ... 0.02004498 0.02004498 0.02004498]\n",
            " [0.02004498 0.02004498 0.02004498 ... 0.02004498 0.02004498 0.02004498]\n",
            " [0.02004498 0.02004498 0.02004498 ... 0.02004498 0.02004498 0.02004498]], shape=(512, 128), dtype=float32) tf.Tensor(\n",
            "[[0.02004498 0.02004498 0.02004498 ... 0.02004498 0.02004498 0.02004498]\n",
            " [0.02004498 0.02004498 0.02004498 ... 0.02004498 0.02004498 0.02004498]\n",
            " [0.02004498 0.02004498 0.02004498 ... 0.02004498 0.02004498 0.02004498]\n",
            " ...\n",
            " [0.02004498 0.02004498 0.02004498 ... 0.02004498 0.02004498 0.02004498]\n",
            " [0.02004498 0.02004498 0.02004498 ... 0.02004498 0.02004498 0.02004498]\n",
            " [0.02004498 0.02004498 0.02004498 ... 0.02004498 0.02004498 0.02004498]], shape=(252, 128), dtype=float32)\n",
            "(128, 764) (512, 1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_15/kernel:0', 'dense_15/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_15/kernel:0', 'dense_15/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch 1, Batch 77/100, Loss=1.28024e-03\n",
            "(1, 764, 1)\n",
            "tf.Tensor(\n",
            "[[[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " [[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " [[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]], shape=(128, 764, 1), dtype=float32) tf.Tensor(\n",
            "[[[-0.36753535  0.33979303 -0.08515669 ... -0.2249637   0.19216016\n",
            "   -0.22965907]\n",
            "  [-0.36753535  0.33979303 -0.08515669 ... -0.2249637   0.19216016\n",
            "   -0.22965907]\n",
            "  [-0.36753535  0.33979303 -0.08515669 ... -0.2249637   0.19216016\n",
            "   -0.22965907]\n",
            "  ...\n",
            "  [-0.36753535  0.33979303 -0.08515669 ... -0.2249637   0.19216016\n",
            "   -0.22965907]\n",
            "  [-0.36753535  0.33979303 -0.08515669 ... -0.2249637   0.19216016\n",
            "   -0.22965907]\n",
            "  [-0.36753535  0.33979303 -0.08515669 ... -0.2249637   0.19216016\n",
            "   -0.22965907]]\n",
            "\n",
            " [[-0.36753535  0.33979303 -0.08515669 ... -0.2249637   0.19216016\n",
            "   -0.22965907]\n",
            "  [-0.36753535  0.33979303 -0.08515669 ... -0.2249637   0.19216016\n",
            "   -0.22965907]\n",
            "  [-0.36753535  0.33979303 -0.08515669 ... -0.2249637   0.19216016\n",
            "   -0.22965907]\n",
            "  ...\n",
            "  [-0.36753535  0.33979303 -0.08515669 ... -0.2249637   0.19216016\n",
            "   -0.22965907]\n",
            "  [-0.36753535  0.33979303 -0.08515669 ... -0.2249637   0.19216016\n",
            "   -0.22965907]\n",
            "  [-0.36753535  0.33979303 -0.08515669 ... -0.2249637   0.19216016\n",
            "   -0.22965907]]\n",
            "\n",
            " [[-0.36753535  0.33979303 -0.08515669 ... -0.2249637   0.19216016\n",
            "   -0.22965907]\n",
            "  [-0.36753535  0.33979303 -0.08515669 ... -0.2249637   0.19216016\n",
            "   -0.22965907]\n",
            "  [-0.36753535  0.33979303 -0.08515669 ... -0.2249637   0.19216016\n",
            "   -0.22965907]\n",
            "  ...\n",
            "  [-0.36753535  0.33979303 -0.08515669 ... -0.2249637   0.19216016\n",
            "   -0.22965907]\n",
            "  [-0.36753535  0.33979303 -0.08515669 ... -0.2249637   0.19216016\n",
            "   -0.22965907]\n",
            "  [-0.36753535  0.33979303 -0.08515669 ... -0.2249637   0.19216016\n",
            "   -0.22965907]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[-0.36753535  0.33979303 -0.08515669 ... -0.2249637   0.19216016\n",
            "   -0.22965907]\n",
            "  [-0.36753535  0.33979303 -0.08515669 ... -0.2249637   0.19216016\n",
            "   -0.22965907]\n",
            "  [-0.36753535  0.33979303 -0.08515669 ... -0.2249637   0.19216016\n",
            "   -0.22965907]\n",
            "  ...\n",
            "  [-0.36753535  0.33979303 -0.08515669 ... -0.2249637   0.19216016\n",
            "   -0.22965907]\n",
            "  [-0.36753535  0.33979303 -0.08515669 ... -0.2249637   0.19216016\n",
            "   -0.22965907]\n",
            "  [-0.36753535  0.33979303 -0.08515669 ... -0.2249637   0.19216016\n",
            "   -0.22965907]]\n",
            "\n",
            " [[-0.36753535  0.33979303 -0.08515669 ... -0.2249637   0.19216016\n",
            "   -0.22965907]\n",
            "  [-0.36753535  0.33979303 -0.08515669 ... -0.2249637   0.19216016\n",
            "   -0.22965907]\n",
            "  [-0.36753535  0.33979303 -0.08515669 ... -0.2249637   0.19216016\n",
            "   -0.22965907]\n",
            "  ...\n",
            "  [-0.36753535  0.33979303 -0.08515669 ... -0.2249637   0.19216016\n",
            "   -0.22965907]\n",
            "  [-0.36753535  0.33979303 -0.08515669 ... -0.2249637   0.19216016\n",
            "   -0.22965907]\n",
            "  [-0.36753535  0.33979303 -0.08515669 ... -0.2249637   0.19216016\n",
            "   -0.22965907]]\n",
            "\n",
            " [[-0.36753535  0.33979303 -0.08515669 ... -0.2249637   0.19216016\n",
            "   -0.22965907]\n",
            "  [-0.36753535  0.33979303 -0.08515669 ... -0.2249637   0.19216016\n",
            "   -0.22965907]\n",
            "  [-0.36753535  0.33979303 -0.08515669 ... -0.2249637   0.19216016\n",
            "   -0.22965907]\n",
            "  ...\n",
            "  [-0.36753535  0.33979303 -0.08515669 ... -0.2249637   0.19216016\n",
            "   -0.22965907]\n",
            "  [-0.36753535  0.33979303 -0.08515669 ... -0.2249637   0.19216016\n",
            "   -0.22965907]\n",
            "  [-0.36753535  0.33979303 -0.08515669 ... -0.2249637   0.19216016\n",
            "   -0.22965907]]], shape=(128, 764, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[0.02689446 0.02689446 0.02689446 ... 0.02689446 0.02689446 0.02689446]\n",
            " [0.02689446 0.02689446 0.02689446 ... 0.02689446 0.02689446 0.02689446]\n",
            " [0.02689446 0.02689446 0.02689446 ... 0.02689446 0.02689446 0.02689446]\n",
            " ...\n",
            " [0.02689446 0.02689446 0.02689446 ... 0.02689446 0.02689446 0.02689446]\n",
            " [0.02689446 0.02689446 0.02689446 ... 0.02689446 0.02689446 0.02689446]\n",
            " [0.02689446 0.02689446 0.02689446 ... 0.02689446 0.02689446 0.02689446]], shape=(512, 128), dtype=float32) tf.Tensor(\n",
            "[[0.02689446 0.02689446 0.02689446 ... 0.02689446 0.02689446 0.02689446]\n",
            " [0.02689446 0.02689446 0.02689446 ... 0.02689446 0.02689446 0.02689446]\n",
            " [0.02689446 0.02689446 0.02689446 ... 0.02689446 0.02689446 0.02689446]\n",
            " ...\n",
            " [0.02689446 0.02689446 0.02689446 ... 0.02689446 0.02689446 0.02689446]\n",
            " [0.02689446 0.02689446 0.02689446 ... 0.02689446 0.02689446 0.02689446]\n",
            " [0.02689446 0.02689446 0.02689446 ... 0.02689446 0.02689446 0.02689446]], shape=(252, 128), dtype=float32)\n",
            "(128, 764) (512, 1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_15/kernel:0', 'dense_15/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_15/kernel:0', 'dense_15/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch 1, Batch 78/100, Loss=1.65943e-03\n",
            "(1, 764, 1)\n",
            "tf.Tensor(\n",
            "[[[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]], shape=(128, 764, 1), dtype=float32) tf.Tensor(\n",
            "[[[-0.36729792  0.33975375 -0.08491658 ... -0.22535016  0.19196291\n",
            "   -0.22920178]\n",
            "  [-0.36729792  0.33975375 -0.08491658 ... -0.22535016  0.19196291\n",
            "   -0.22920178]\n",
            "  [-0.36729792  0.33975375 -0.08491658 ... -0.22535016  0.19196291\n",
            "   -0.22920178]\n",
            "  ...\n",
            "  [-0.36729792  0.33975375 -0.08491658 ... -0.22535016  0.19196291\n",
            "   -0.22920178]\n",
            "  [-0.36729792  0.33975375 -0.08491658 ... -0.22535016  0.19196291\n",
            "   -0.22920178]\n",
            "  [-0.36729792  0.33975375 -0.08491658 ... -0.22535016  0.19196291\n",
            "   -0.22920178]]\n",
            "\n",
            " [[-0.36729792  0.33975375 -0.08491658 ... -0.22535016  0.19196291\n",
            "   -0.22920178]\n",
            "  [-0.36729792  0.33975375 -0.08491658 ... -0.22535016  0.19196291\n",
            "   -0.22920178]\n",
            "  [-0.36729792  0.33975375 -0.08491658 ... -0.22535016  0.19196291\n",
            "   -0.22920178]\n",
            "  ...\n",
            "  [-0.36729792  0.33975375 -0.08491658 ... -0.22535016  0.19196291\n",
            "   -0.22920178]\n",
            "  [-0.36729792  0.33975375 -0.08491658 ... -0.22535016  0.19196291\n",
            "   -0.22920178]\n",
            "  [-0.36729792  0.33975375 -0.08491658 ... -0.22535016  0.19196291\n",
            "   -0.22920178]]\n",
            "\n",
            " [[-0.36729792  0.33975375 -0.08491658 ... -0.22535016  0.19196291\n",
            "   -0.22920178]\n",
            "  [-0.36729792  0.33975375 -0.08491658 ... -0.22535016  0.19196291\n",
            "   -0.22920178]\n",
            "  [-0.36729792  0.33975375 -0.08491658 ... -0.22535016  0.19196291\n",
            "   -0.22920178]\n",
            "  ...\n",
            "  [-0.36729792  0.33975375 -0.08491658 ... -0.22535016  0.19196291\n",
            "   -0.22920178]\n",
            "  [-0.36729792  0.33975375 -0.08491658 ... -0.22535016  0.19196291\n",
            "   -0.22920178]\n",
            "  [-0.36729792  0.33975375 -0.08491658 ... -0.22535016  0.19196291\n",
            "   -0.22920178]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[-0.36729792  0.33975375 -0.08491658 ... -0.22535016  0.19196291\n",
            "   -0.22920178]\n",
            "  [-0.36729792  0.33975375 -0.08491658 ... -0.22535016  0.19196291\n",
            "   -0.22920178]\n",
            "  [-0.36729792  0.33975375 -0.08491658 ... -0.22535016  0.19196291\n",
            "   -0.22920178]\n",
            "  ...\n",
            "  [-0.36729792  0.33975375 -0.08491658 ... -0.22535016  0.19196291\n",
            "   -0.22920178]\n",
            "  [-0.36729792  0.33975375 -0.08491658 ... -0.22535016  0.19196291\n",
            "   -0.22920178]\n",
            "  [-0.36729792  0.33975375 -0.08491658 ... -0.22535016  0.19196291\n",
            "   -0.22920178]]\n",
            "\n",
            " [[-0.36729792  0.33975375 -0.08491658 ... -0.22535016  0.19196291\n",
            "   -0.22920178]\n",
            "  [-0.36729792  0.33975375 -0.08491658 ... -0.22535016  0.19196291\n",
            "   -0.22920178]\n",
            "  [-0.36729792  0.33975375 -0.08491658 ... -0.22535016  0.19196291\n",
            "   -0.22920178]\n",
            "  ...\n",
            "  [-0.36729792  0.33975375 -0.08491658 ... -0.22535016  0.19196291\n",
            "   -0.22920178]\n",
            "  [-0.36729792  0.33975375 -0.08491658 ... -0.22535016  0.19196291\n",
            "   -0.22920178]\n",
            "  [-0.36729792  0.33975375 -0.08491658 ... -0.22535016  0.19196291\n",
            "   -0.22920178]]\n",
            "\n",
            " [[-0.36729792  0.33975375 -0.08491658 ... -0.22535016  0.19196291\n",
            "   -0.22920178]\n",
            "  [-0.36729792  0.33975375 -0.08491658 ... -0.22535016  0.19196291\n",
            "   -0.22920178]\n",
            "  [-0.36729792  0.33975375 -0.08491658 ... -0.22535016  0.19196291\n",
            "   -0.22920178]\n",
            "  ...\n",
            "  [-0.36729792  0.33975375 -0.08491658 ... -0.22535016  0.19196291\n",
            "   -0.22920178]\n",
            "  [-0.36729792  0.33975375 -0.08491658 ... -0.22535016  0.19196291\n",
            "   -0.22920178]\n",
            "  [-0.36729792  0.33975375 -0.08491658 ... -0.22535016  0.19196291\n",
            "   -0.22920178]]], shape=(128, 764, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[0.02902439 0.02902439 0.02902439 ... 0.02902439 0.02902439 0.02902439]\n",
            " [0.02902439 0.02902439 0.02902439 ... 0.02902439 0.02902439 0.02902439]\n",
            " [0.02902439 0.02902439 0.02902439 ... 0.02902439 0.02902439 0.02902439]\n",
            " ...\n",
            " [0.02902439 0.02902439 0.02902439 ... 0.02902439 0.02902439 0.02902439]\n",
            " [0.02902439 0.02902439 0.02902439 ... 0.02902439 0.02902439 0.02902439]\n",
            " [0.02902439 0.02902439 0.02902439 ... 0.02902439 0.02902439 0.02902439]], shape=(512, 128), dtype=float32) tf.Tensor(\n",
            "[[0.02902439 0.02902439 0.02902439 ... 0.02902439 0.02902439 0.02902439]\n",
            " [0.02902439 0.02902439 0.02902439 ... 0.02902439 0.02902439 0.02902439]\n",
            " [0.02902439 0.02902439 0.02902439 ... 0.02902439 0.02902439 0.02902439]\n",
            " ...\n",
            " [0.02902439 0.02902439 0.02902439 ... 0.02902439 0.02902439 0.02902439]\n",
            " [0.02902439 0.02902439 0.02902439 ... 0.02902439 0.02902439 0.02902439]\n",
            " [0.02902439 0.02902439 0.02902439 ... 0.02902439 0.02902439 0.02902439]], shape=(252, 128), dtype=float32)\n",
            "(128, 764) (512, 1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_15/kernel:0', 'dense_15/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_15/kernel:0', 'dense_15/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch 1, Batch 79/100, Loss=1.82073e-03\n",
            "(1, 764, 1)\n",
            "tf.Tensor(\n",
            "[[[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " [[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " [[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]], shape=(128, 764, 1), dtype=float32) tf.Tensor(\n",
            "[[[-0.36792812  0.33985013 -0.08545248 ... -0.22516347  0.19244699\n",
            "   -0.22937441]\n",
            "  [-0.36792812  0.33985013 -0.08545248 ... -0.22516347  0.19244699\n",
            "   -0.22937441]\n",
            "  [-0.36792812  0.33985013 -0.08545248 ... -0.22516347  0.19244699\n",
            "   -0.22937441]\n",
            "  ...\n",
            "  [-0.36792812  0.33985013 -0.08545248 ... -0.22516347  0.19244699\n",
            "   -0.22937441]\n",
            "  [-0.36792812  0.33985013 -0.08545248 ... -0.22516347  0.19244699\n",
            "   -0.22937441]\n",
            "  [-0.36792812  0.33985013 -0.08545248 ... -0.22516347  0.19244699\n",
            "   -0.22937441]]\n",
            "\n",
            " [[-0.36792812  0.33985013 -0.08545248 ... -0.22516347  0.19244699\n",
            "   -0.22937441]\n",
            "  [-0.36792812  0.33985013 -0.08545248 ... -0.22516347  0.19244699\n",
            "   -0.22937441]\n",
            "  [-0.36792812  0.33985013 -0.08545248 ... -0.22516347  0.19244699\n",
            "   -0.22937441]\n",
            "  ...\n",
            "  [-0.36792812  0.33985013 -0.08545248 ... -0.22516347  0.19244699\n",
            "   -0.22937441]\n",
            "  [-0.36792812  0.33985013 -0.08545248 ... -0.22516347  0.19244699\n",
            "   -0.22937441]\n",
            "  [-0.36792812  0.33985013 -0.08545248 ... -0.22516347  0.19244699\n",
            "   -0.22937441]]\n",
            "\n",
            " [[-0.36792812  0.33985013 -0.08545248 ... -0.22516347  0.19244699\n",
            "   -0.22937441]\n",
            "  [-0.36792812  0.33985013 -0.08545248 ... -0.22516347  0.19244699\n",
            "   -0.22937441]\n",
            "  [-0.36792812  0.33985013 -0.08545248 ... -0.22516347  0.19244699\n",
            "   -0.22937441]\n",
            "  ...\n",
            "  [-0.36792812  0.33985013 -0.08545248 ... -0.22516347  0.19244699\n",
            "   -0.22937441]\n",
            "  [-0.36792812  0.33985013 -0.08545248 ... -0.22516347  0.19244699\n",
            "   -0.22937441]\n",
            "  [-0.36792812  0.33985013 -0.08545248 ... -0.22516347  0.19244699\n",
            "   -0.22937441]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[-0.36792812  0.33985013 -0.08545248 ... -0.22516347  0.19244699\n",
            "   -0.22937441]\n",
            "  [-0.36792812  0.33985013 -0.08545248 ... -0.22516347  0.19244699\n",
            "   -0.22937441]\n",
            "  [-0.36792812  0.33985013 -0.08545248 ... -0.22516347  0.19244699\n",
            "   -0.22937441]\n",
            "  ...\n",
            "  [-0.36792812  0.33985013 -0.08545248 ... -0.22516347  0.19244699\n",
            "   -0.22937441]\n",
            "  [-0.36792812  0.33985013 -0.08545248 ... -0.22516347  0.19244699\n",
            "   -0.22937441]\n",
            "  [-0.36792812  0.33985013 -0.08545248 ... -0.22516347  0.19244699\n",
            "   -0.22937441]]\n",
            "\n",
            " [[-0.36792812  0.33985013 -0.08545248 ... -0.22516347  0.19244699\n",
            "   -0.22937441]\n",
            "  [-0.36792812  0.33985013 -0.08545248 ... -0.22516347  0.19244699\n",
            "   -0.22937441]\n",
            "  [-0.36792812  0.33985013 -0.08545248 ... -0.22516347  0.19244699\n",
            "   -0.22937441]\n",
            "  ...\n",
            "  [-0.36792812  0.33985013 -0.08545248 ... -0.22516347  0.19244699\n",
            "   -0.22937441]\n",
            "  [-0.36792812  0.33985013 -0.08545248 ... -0.22516347  0.19244699\n",
            "   -0.22937441]\n",
            "  [-0.36792812  0.33985013 -0.08545248 ... -0.22516347  0.19244699\n",
            "   -0.22937441]]\n",
            "\n",
            " [[-0.36792812  0.33985013 -0.08545248 ... -0.22516347  0.19244699\n",
            "   -0.22937441]\n",
            "  [-0.36792812  0.33985013 -0.08545248 ... -0.22516347  0.19244699\n",
            "   -0.22937441]\n",
            "  [-0.36792812  0.33985013 -0.08545248 ... -0.22516347  0.19244699\n",
            "   -0.22937441]\n",
            "  ...\n",
            "  [-0.36792812  0.33985013 -0.08545248 ... -0.22516347  0.19244699\n",
            "   -0.22937441]\n",
            "  [-0.36792812  0.33985013 -0.08545248 ... -0.22516347  0.19244699\n",
            "   -0.22937441]\n",
            "  [-0.36792812  0.33985013 -0.08545248 ... -0.22516347  0.19244699\n",
            "   -0.22937441]]], shape=(128, 764, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[0.0262916 0.0262916 0.0262916 ... 0.0262916 0.0262916 0.0262916]\n",
            " [0.0262916 0.0262916 0.0262916 ... 0.0262916 0.0262916 0.0262916]\n",
            " [0.0262916 0.0262916 0.0262916 ... 0.0262916 0.0262916 0.0262916]\n",
            " ...\n",
            " [0.0262916 0.0262916 0.0262916 ... 0.0262916 0.0262916 0.0262916]\n",
            " [0.0262916 0.0262916 0.0262916 ... 0.0262916 0.0262916 0.0262916]\n",
            " [0.0262916 0.0262916 0.0262916 ... 0.0262916 0.0262916 0.0262916]], shape=(512, 128), dtype=float32) tf.Tensor(\n",
            "[[0.0262916 0.0262916 0.0262916 ... 0.0262916 0.0262916 0.0262916]\n",
            " [0.0262916 0.0262916 0.0262916 ... 0.0262916 0.0262916 0.0262916]\n",
            " [0.0262916 0.0262916 0.0262916 ... 0.0262916 0.0262916 0.0262916]\n",
            " ...\n",
            " [0.0262916 0.0262916 0.0262916 ... 0.0262916 0.0262916 0.0262916]\n",
            " [0.0262916 0.0262916 0.0262916 ... 0.0262916 0.0262916 0.0262916]\n",
            " [0.0262916 0.0262916 0.0262916 ... 0.0262916 0.0262916 0.0262916]], shape=(252, 128), dtype=float32)\n",
            "(128, 764) (512, 1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_15/kernel:0', 'dense_15/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_15/kernel:0', 'dense_15/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch 1, Batch 80/100, Loss=1.39104e-03\n",
            "(1, 764, 1)\n",
            "tf.Tensor(\n",
            "[[[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " [[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]], shape=(128, 764, 1), dtype=float32) tf.Tensor(\n",
            "[[[-0.36924392  0.34005466 -0.08658959 ... -0.22452548  0.19346751\n",
            "   -0.23004152]\n",
            "  [-0.36924392  0.34005466 -0.08658959 ... -0.22452548  0.19346751\n",
            "   -0.23004152]\n",
            "  [-0.36924392  0.34005466 -0.08658959 ... -0.22452548  0.19346751\n",
            "   -0.23004152]\n",
            "  ...\n",
            "  [-0.36924392  0.34005466 -0.08658959 ... -0.22452548  0.19346751\n",
            "   -0.23004152]\n",
            "  [-0.36924392  0.34005466 -0.08658959 ... -0.22452548  0.19346751\n",
            "   -0.23004152]\n",
            "  [-0.36924392  0.34005466 -0.08658959 ... -0.22452548  0.19346751\n",
            "   -0.23004152]]\n",
            "\n",
            " [[-0.36924392  0.34005466 -0.08658959 ... -0.22452548  0.19346751\n",
            "   -0.23004152]\n",
            "  [-0.36924392  0.34005466 -0.08658959 ... -0.22452548  0.19346751\n",
            "   -0.23004152]\n",
            "  [-0.36924392  0.34005466 -0.08658959 ... -0.22452548  0.19346751\n",
            "   -0.23004152]\n",
            "  ...\n",
            "  [-0.36924392  0.34005466 -0.08658959 ... -0.22452548  0.19346751\n",
            "   -0.23004152]\n",
            "  [-0.36924392  0.34005466 -0.08658959 ... -0.22452548  0.19346751\n",
            "   -0.23004152]\n",
            "  [-0.36924392  0.34005466 -0.08658959 ... -0.22452548  0.19346751\n",
            "   -0.23004152]]\n",
            "\n",
            " [[-0.36924392  0.34005466 -0.08658959 ... -0.22452548  0.19346751\n",
            "   -0.23004152]\n",
            "  [-0.36924392  0.34005466 -0.08658959 ... -0.22452548  0.19346751\n",
            "   -0.23004152]\n",
            "  [-0.36924392  0.34005466 -0.08658959 ... -0.22452548  0.19346751\n",
            "   -0.23004152]\n",
            "  ...\n",
            "  [-0.36924392  0.34005466 -0.08658959 ... -0.22452548  0.19346751\n",
            "   -0.23004152]\n",
            "  [-0.36924392  0.34005466 -0.08658959 ... -0.22452548  0.19346751\n",
            "   -0.23004152]\n",
            "  [-0.36924392  0.34005466 -0.08658959 ... -0.22452548  0.19346751\n",
            "   -0.23004152]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[-0.36924392  0.34005466 -0.08658959 ... -0.22452548  0.19346751\n",
            "   -0.23004152]\n",
            "  [-0.36924392  0.34005466 -0.08658959 ... -0.22452548  0.19346751\n",
            "   -0.23004152]\n",
            "  [-0.36924392  0.34005466 -0.08658959 ... -0.22452548  0.19346751\n",
            "   -0.23004152]\n",
            "  ...\n",
            "  [-0.36924392  0.34005466 -0.08658959 ... -0.22452548  0.19346751\n",
            "   -0.23004152]\n",
            "  [-0.36924392  0.34005466 -0.08658959 ... -0.22452548  0.19346751\n",
            "   -0.23004152]\n",
            "  [-0.36924392  0.34005466 -0.08658959 ... -0.22452548  0.19346751\n",
            "   -0.23004152]]\n",
            "\n",
            " [[-0.36924392  0.34005466 -0.08658959 ... -0.22452548  0.19346751\n",
            "   -0.23004152]\n",
            "  [-0.36924392  0.34005466 -0.08658959 ... -0.22452548  0.19346751\n",
            "   -0.23004152]\n",
            "  [-0.36924392  0.34005466 -0.08658959 ... -0.22452548  0.19346751\n",
            "   -0.23004152]\n",
            "  ...\n",
            "  [-0.36924392  0.34005466 -0.08658959 ... -0.22452548  0.19346751\n",
            "   -0.23004152]\n",
            "  [-0.36924392  0.34005466 -0.08658959 ... -0.22452548  0.19346751\n",
            "   -0.23004152]\n",
            "  [-0.36924392  0.34005466 -0.08658959 ... -0.22452548  0.19346751\n",
            "   -0.23004152]]\n",
            "\n",
            " [[-0.36924392  0.34005466 -0.08658959 ... -0.22452548  0.19346751\n",
            "   -0.23004152]\n",
            "  [-0.36924392  0.34005466 -0.08658959 ... -0.22452548  0.19346751\n",
            "   -0.23004152]\n",
            "  [-0.36924392  0.34005466 -0.08658959 ... -0.22452548  0.19346751\n",
            "   -0.23004152]\n",
            "  ...\n",
            "  [-0.36924392  0.34005466 -0.08658959 ... -0.22452548  0.19346751\n",
            "   -0.23004152]\n",
            "  [-0.36924392  0.34005466 -0.08658959 ... -0.22452548  0.19346751\n",
            "   -0.23004152]\n",
            "  [-0.36924392  0.34005466 -0.08658959 ... -0.22452548  0.19346751\n",
            "   -0.23004152]]], shape=(128, 764, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[0.01972771 0.01972771 0.01972771 ... 0.01972771 0.01972771 0.01972771]\n",
            " [0.01972771 0.01972771 0.01972771 ... 0.01972771 0.01972771 0.01972771]\n",
            " [0.01972771 0.01972771 0.01972771 ... 0.01972771 0.01972771 0.01972771]\n",
            " ...\n",
            " [0.01972771 0.01972771 0.01972771 ... 0.01972771 0.01972771 0.01972771]\n",
            " [0.01972771 0.01972771 0.01972771 ... 0.01972771 0.01972771 0.01972771]\n",
            " [0.01972771 0.01972771 0.01972771 ... 0.01972771 0.01972771 0.01972771]], shape=(512, 128), dtype=float32) tf.Tensor(\n",
            "[[0.01972771 0.01972771 0.01972771 ... 0.01972771 0.01972771 0.01972771]\n",
            " [0.01972771 0.01972771 0.01972771 ... 0.01972771 0.01972771 0.01972771]\n",
            " [0.01972771 0.01972771 0.01972771 ... 0.01972771 0.01972771 0.01972771]\n",
            " ...\n",
            " [0.01972771 0.01972771 0.01972771 ... 0.01972771 0.01972771 0.01972771]\n",
            " [0.01972771 0.01972771 0.01972771 ... 0.01972771 0.01972771 0.01972771]\n",
            " [0.01972771 0.01972771 0.01972771 ... 0.01972771 0.01972771 0.01972771]], shape=(252, 128), dtype=float32)\n",
            "(128, 764) (512, 1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_15/kernel:0', 'dense_15/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_15/kernel:0', 'dense_15/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch 1, Batch 81/100, Loss=9.38896e-04\n",
            "(1, 764, 1)\n",
            "tf.Tensor(\n",
            "[[[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " [[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " [[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " [[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]], shape=(128, 764, 1), dtype=float32) tf.Tensor(\n",
            "[[[-0.3710659   0.34033826 -0.08816287 ... -0.22355244  0.19488443\n",
            "   -0.23107466]\n",
            "  [-0.3710659   0.34033826 -0.08816287 ... -0.22355244  0.19488443\n",
            "   -0.23107466]\n",
            "  [-0.3710659   0.34033826 -0.08816287 ... -0.22355244  0.19488443\n",
            "   -0.23107466]\n",
            "  ...\n",
            "  [-0.3710659   0.34033826 -0.08816287 ... -0.22355244  0.19488443\n",
            "   -0.23107466]\n",
            "  [-0.3710659   0.34033826 -0.08816287 ... -0.22355244  0.19488443\n",
            "   -0.23107466]\n",
            "  [-0.3710659   0.34033826 -0.08816287 ... -0.22355244  0.19488443\n",
            "   -0.23107466]]\n",
            "\n",
            " [[-0.3710659   0.34033826 -0.08816287 ... -0.22355244  0.19488443\n",
            "   -0.23107466]\n",
            "  [-0.3710659   0.34033826 -0.08816287 ... -0.22355244  0.19488443\n",
            "   -0.23107466]\n",
            "  [-0.3710659   0.34033826 -0.08816287 ... -0.22355244  0.19488443\n",
            "   -0.23107466]\n",
            "  ...\n",
            "  [-0.3710659   0.34033826 -0.08816287 ... -0.22355244  0.19488443\n",
            "   -0.23107466]\n",
            "  [-0.3710659   0.34033826 -0.08816287 ... -0.22355244  0.19488443\n",
            "   -0.23107466]\n",
            "  [-0.3710659   0.34033826 -0.08816287 ... -0.22355244  0.19488443\n",
            "   -0.23107466]]\n",
            "\n",
            " [[-0.3710659   0.34033826 -0.08816287 ... -0.22355244  0.19488443\n",
            "   -0.23107466]\n",
            "  [-0.3710659   0.34033826 -0.08816287 ... -0.22355244  0.19488443\n",
            "   -0.23107466]\n",
            "  [-0.3710659   0.34033826 -0.08816287 ... -0.22355244  0.19488443\n",
            "   -0.23107466]\n",
            "  ...\n",
            "  [-0.3710659   0.34033826 -0.08816287 ... -0.22355244  0.19488443\n",
            "   -0.23107466]\n",
            "  [-0.3710659   0.34033826 -0.08816287 ... -0.22355244  0.19488443\n",
            "   -0.23107466]\n",
            "  [-0.3710659   0.34033826 -0.08816287 ... -0.22355244  0.19488443\n",
            "   -0.23107466]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[-0.3710659   0.34033826 -0.08816287 ... -0.22355244  0.19488443\n",
            "   -0.23107466]\n",
            "  [-0.3710659   0.34033826 -0.08816287 ... -0.22355244  0.19488443\n",
            "   -0.23107466]\n",
            "  [-0.3710659   0.34033826 -0.08816287 ... -0.22355244  0.19488443\n",
            "   -0.23107466]\n",
            "  ...\n",
            "  [-0.3710659   0.34033826 -0.08816287 ... -0.22355244  0.19488443\n",
            "   -0.23107466]\n",
            "  [-0.3710659   0.34033826 -0.08816287 ... -0.22355244  0.19488443\n",
            "   -0.23107466]\n",
            "  [-0.3710659   0.34033826 -0.08816287 ... -0.22355244  0.19488443\n",
            "   -0.23107466]]\n",
            "\n",
            " [[-0.3710659   0.34033826 -0.08816287 ... -0.22355244  0.19488443\n",
            "   -0.23107466]\n",
            "  [-0.3710659   0.34033826 -0.08816287 ... -0.22355244  0.19488443\n",
            "   -0.23107466]\n",
            "  [-0.3710659   0.34033826 -0.08816287 ... -0.22355244  0.19488443\n",
            "   -0.23107466]\n",
            "  ...\n",
            "  [-0.3710659   0.34033826 -0.08816287 ... -0.22355244  0.19488443\n",
            "   -0.23107466]\n",
            "  [-0.3710659   0.34033826 -0.08816287 ... -0.22355244  0.19488443\n",
            "   -0.23107466]\n",
            "  [-0.3710659   0.34033826 -0.08816287 ... -0.22355244  0.19488443\n",
            "   -0.23107466]]\n",
            "\n",
            " [[-0.3710659   0.34033826 -0.08816287 ... -0.22355244  0.19488443\n",
            "   -0.23107466]\n",
            "  [-0.3710659   0.34033826 -0.08816287 ... -0.22355244  0.19488443\n",
            "   -0.23107466]\n",
            "  [-0.3710659   0.34033826 -0.08816287 ... -0.22355244  0.19488443\n",
            "   -0.23107466]\n",
            "  ...\n",
            "  [-0.3710659   0.34033826 -0.08816287 ... -0.22355244  0.19488443\n",
            "   -0.23107466]\n",
            "  [-0.3710659   0.34033826 -0.08816287 ... -0.22355244  0.19488443\n",
            "   -0.23107466]\n",
            "  [-0.3710659   0.34033826 -0.08816287 ... -0.22355244  0.19488443\n",
            "   -0.23107466]]], shape=(128, 764, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[0.01033078 0.01033078 0.01033078 ... 0.01033078 0.01033078 0.01033078]\n",
            " [0.01033078 0.01033078 0.01033078 ... 0.01033078 0.01033078 0.01033078]\n",
            " [0.01033078 0.01033078 0.01033078 ... 0.01033078 0.01033078 0.01033078]\n",
            " ...\n",
            " [0.01033078 0.01033078 0.01033078 ... 0.01033078 0.01033078 0.01033078]\n",
            " [0.01033078 0.01033078 0.01033078 ... 0.01033078 0.01033078 0.01033078]\n",
            " [0.01033078 0.01033078 0.01033078 ... 0.01033078 0.01033078 0.01033078]], shape=(512, 128), dtype=float32) tf.Tensor(\n",
            "[[0.01033078 0.01033078 0.01033078 ... 0.01033078 0.01033078 0.01033078]\n",
            " [0.01033078 0.01033078 0.01033078 ... 0.01033078 0.01033078 0.01033078]\n",
            " [0.01033078 0.01033078 0.01033078 ... 0.01033078 0.01033078 0.01033078]\n",
            " ...\n",
            " [0.01033078 0.01033078 0.01033078 ... 0.01033078 0.01033078 0.01033078]\n",
            " [0.01033078 0.01033078 0.01033078 ... 0.01033078 0.01033078 0.01033078]\n",
            " [0.01033078 0.01033078 0.01033078 ... 0.01033078 0.01033078 0.01033078]], shape=(252, 128), dtype=float32)\n",
            "(128, 764) (512, 1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_15/kernel:0', 'dense_15/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_15/kernel:0', 'dense_15/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch 1, Batch 82/100, Loss=3.91958e-04\n",
            "(1, 764, 1)\n",
            "tf.Tensor(\n",
            "[[[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " [[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " [[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " [[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " [[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]], shape=(128, 764, 1), dtype=float32) tf.Tensor(\n",
            "[[[-0.37306184  0.34064943 -0.08987853 ... -0.22245598  0.19643605\n",
            "   -0.23224172]\n",
            "  [-0.37306184  0.34064943 -0.08987853 ... -0.22245598  0.19643605\n",
            "   -0.23224172]\n",
            "  [-0.37306184  0.34064943 -0.08987853 ... -0.22245598  0.19643605\n",
            "   -0.23224172]\n",
            "  ...\n",
            "  [-0.37306184  0.34064943 -0.08987853 ... -0.22245598  0.19643605\n",
            "   -0.23224172]\n",
            "  [-0.37306184  0.34064943 -0.08987853 ... -0.22245598  0.19643605\n",
            "   -0.23224172]\n",
            "  [-0.37306184  0.34064943 -0.08987853 ... -0.22245598  0.19643605\n",
            "   -0.23224172]]\n",
            "\n",
            " [[-0.37306184  0.34064943 -0.08987853 ... -0.22245598  0.19643605\n",
            "   -0.23224172]\n",
            "  [-0.37306184  0.34064943 -0.08987853 ... -0.22245598  0.19643605\n",
            "   -0.23224172]\n",
            "  [-0.37306184  0.34064943 -0.08987853 ... -0.22245598  0.19643605\n",
            "   -0.23224172]\n",
            "  ...\n",
            "  [-0.37306184  0.34064943 -0.08987853 ... -0.22245598  0.19643605\n",
            "   -0.23224172]\n",
            "  [-0.37306184  0.34064943 -0.08987853 ... -0.22245598  0.19643605\n",
            "   -0.23224172]\n",
            "  [-0.37306184  0.34064943 -0.08987853 ... -0.22245598  0.19643605\n",
            "   -0.23224172]]\n",
            "\n",
            " [[-0.37306184  0.34064943 -0.08987853 ... -0.22245598  0.19643605\n",
            "   -0.23224172]\n",
            "  [-0.37306184  0.34064943 -0.08987853 ... -0.22245598  0.19643605\n",
            "   -0.23224172]\n",
            "  [-0.37306184  0.34064943 -0.08987853 ... -0.22245598  0.19643605\n",
            "   -0.23224172]\n",
            "  ...\n",
            "  [-0.37306184  0.34064943 -0.08987853 ... -0.22245598  0.19643605\n",
            "   -0.23224172]\n",
            "  [-0.37306184  0.34064943 -0.08987853 ... -0.22245598  0.19643605\n",
            "   -0.23224172]\n",
            "  [-0.37306184  0.34064943 -0.08987853 ... -0.22245598  0.19643605\n",
            "   -0.23224172]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[-0.37306184  0.34064943 -0.08987853 ... -0.22245598  0.19643605\n",
            "   -0.23224172]\n",
            "  [-0.37306184  0.34064943 -0.08987853 ... -0.22245598  0.19643605\n",
            "   -0.23224172]\n",
            "  [-0.37306184  0.34064943 -0.08987853 ... -0.22245598  0.19643605\n",
            "   -0.23224172]\n",
            "  ...\n",
            "  [-0.37306184  0.34064943 -0.08987853 ... -0.22245598  0.19643605\n",
            "   -0.23224172]\n",
            "  [-0.37306184  0.34064943 -0.08987853 ... -0.22245598  0.19643605\n",
            "   -0.23224172]\n",
            "  [-0.37306184  0.34064943 -0.08987853 ... -0.22245598  0.19643605\n",
            "   -0.23224172]]\n",
            "\n",
            " [[-0.37306184  0.34064943 -0.08987853 ... -0.22245598  0.19643605\n",
            "   -0.23224172]\n",
            "  [-0.37306184  0.34064943 -0.08987853 ... -0.22245598  0.19643605\n",
            "   -0.23224172]\n",
            "  [-0.37306184  0.34064943 -0.08987853 ... -0.22245598  0.19643605\n",
            "   -0.23224172]\n",
            "  ...\n",
            "  [-0.37306184  0.34064943 -0.08987853 ... -0.22245598  0.19643605\n",
            "   -0.23224172]\n",
            "  [-0.37306184  0.34064943 -0.08987853 ... -0.22245598  0.19643605\n",
            "   -0.23224172]\n",
            "  [-0.37306184  0.34064943 -0.08987853 ... -0.22245598  0.19643605\n",
            "   -0.23224172]]\n",
            "\n",
            " [[-0.37306184  0.34064943 -0.08987853 ... -0.22245598  0.19643605\n",
            "   -0.23224172]\n",
            "  [-0.37306184  0.34064943 -0.08987853 ... -0.22245598  0.19643605\n",
            "   -0.23224172]\n",
            "  [-0.37306184  0.34064943 -0.08987853 ... -0.22245598  0.19643605\n",
            "   -0.23224172]\n",
            "  ...\n",
            "  [-0.37306184  0.34064943 -0.08987853 ... -0.22245598  0.19643605\n",
            "   -0.23224172]\n",
            "  [-0.37306184  0.34064943 -0.08987853 ... -0.22245598  0.19643605\n",
            "   -0.23224172]\n",
            "  [-0.37306184  0.34064943 -0.08987853 ... -0.22245598  0.19643605\n",
            "   -0.23224172]]], shape=(128, 764, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-6.862526e-05 -6.862526e-05 -6.862526e-05 ... -6.862526e-05\n",
            "  -6.862526e-05 -6.862526e-05]\n",
            " [-6.862526e-05 -6.862526e-05 -6.862526e-05 ... -6.862526e-05\n",
            "  -6.862526e-05 -6.862526e-05]\n",
            " [-6.862526e-05 -6.862526e-05 -6.862526e-05 ... -6.862526e-05\n",
            "  -6.862526e-05 -6.862526e-05]\n",
            " ...\n",
            " [-6.862526e-05 -6.862526e-05 -6.862526e-05 ... -6.862526e-05\n",
            "  -6.862526e-05 -6.862526e-05]\n",
            " [-6.862526e-05 -6.862526e-05 -6.862526e-05 ... -6.862526e-05\n",
            "  -6.862526e-05 -6.862526e-05]\n",
            " [-6.862526e-05 -6.862526e-05 -6.862526e-05 ... -6.862526e-05\n",
            "  -6.862526e-05 -6.862526e-05]], shape=(512, 128), dtype=float32) tf.Tensor(\n",
            "[[-6.862526e-05 -6.862526e-05 -6.862526e-05 ... -6.862526e-05\n",
            "  -6.862526e-05 -6.862526e-05]\n",
            " [-6.862526e-05 -6.862526e-05 -6.862526e-05 ... -6.862526e-05\n",
            "  -6.862526e-05 -6.862526e-05]\n",
            " [-6.862526e-05 -6.862526e-05 -6.862526e-05 ... -6.862526e-05\n",
            "  -6.862526e-05 -6.862526e-05]\n",
            " ...\n",
            " [-6.862526e-05 -6.862526e-05 -6.862526e-05 ... -6.862526e-05\n",
            "  -6.862526e-05 -6.862526e-05]\n",
            " [-6.862526e-05 -6.862526e-05 -6.862526e-05 ... -6.862526e-05\n",
            "  -6.862526e-05 -6.862526e-05]\n",
            " [-6.862526e-05 -6.862526e-05 -6.862526e-05 ... -6.862526e-05\n",
            "  -6.862526e-05 -6.862526e-05]], shape=(252, 128), dtype=float32)\n",
            "(128, 764) (512, 1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_15/kernel:0', 'dense_15/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_15/kernel:0', 'dense_15/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch 1, Batch 83/100, Loss=2.17455e-04\n",
            "(1, 764, 1)\n",
            "tf.Tensor(\n",
            "[[[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " [[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " [[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]], shape=(128, 764, 1), dtype=float32) tf.Tensor(\n",
            "[[[-0.3749435   0.3409431  -0.09148798 ... -0.22141849  0.19789498\n",
            "   -0.23334557]\n",
            "  [-0.3749435   0.3409431  -0.09148798 ... -0.22141849  0.19789498\n",
            "   -0.23334557]\n",
            "  [-0.3749435   0.3409431  -0.09148798 ... -0.22141849  0.19789498\n",
            "   -0.23334557]\n",
            "  ...\n",
            "  [-0.3749435   0.3409431  -0.09148798 ... -0.22141849  0.19789498\n",
            "   -0.23334557]\n",
            "  [-0.3749435   0.3409431  -0.09148798 ... -0.22141849  0.19789498\n",
            "   -0.23334557]\n",
            "  [-0.3749435   0.3409431  -0.09148798 ... -0.22141849  0.19789498\n",
            "   -0.23334557]]\n",
            "\n",
            " [[-0.3749435   0.3409431  -0.09148798 ... -0.22141849  0.19789498\n",
            "   -0.23334557]\n",
            "  [-0.3749435   0.3409431  -0.09148798 ... -0.22141849  0.19789498\n",
            "   -0.23334557]\n",
            "  [-0.3749435   0.3409431  -0.09148798 ... -0.22141849  0.19789498\n",
            "   -0.23334557]\n",
            "  ...\n",
            "  [-0.3749435   0.3409431  -0.09148798 ... -0.22141849  0.19789498\n",
            "   -0.23334557]\n",
            "  [-0.3749435   0.3409431  -0.09148798 ... -0.22141849  0.19789498\n",
            "   -0.23334557]\n",
            "  [-0.3749435   0.3409431  -0.09148798 ... -0.22141849  0.19789498\n",
            "   -0.23334557]]\n",
            "\n",
            " [[-0.3749435   0.3409431  -0.09148798 ... -0.22141849  0.19789498\n",
            "   -0.23334557]\n",
            "  [-0.3749435   0.3409431  -0.09148798 ... -0.22141849  0.19789498\n",
            "   -0.23334557]\n",
            "  [-0.3749435   0.3409431  -0.09148798 ... -0.22141849  0.19789498\n",
            "   -0.23334557]\n",
            "  ...\n",
            "  [-0.3749435   0.3409431  -0.09148798 ... -0.22141849  0.19789498\n",
            "   -0.23334557]\n",
            "  [-0.3749435   0.3409431  -0.09148798 ... -0.22141849  0.19789498\n",
            "   -0.23334557]\n",
            "  [-0.3749435   0.3409431  -0.09148798 ... -0.22141849  0.19789498\n",
            "   -0.23334557]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[-0.3749435   0.3409431  -0.09148798 ... -0.22141849  0.19789498\n",
            "   -0.23334557]\n",
            "  [-0.3749435   0.3409431  -0.09148798 ... -0.22141849  0.19789498\n",
            "   -0.23334557]\n",
            "  [-0.3749435   0.3409431  -0.09148798 ... -0.22141849  0.19789498\n",
            "   -0.23334557]\n",
            "  ...\n",
            "  [-0.3749435   0.3409431  -0.09148798 ... -0.22141849  0.19789498\n",
            "   -0.23334557]\n",
            "  [-0.3749435   0.3409431  -0.09148798 ... -0.22141849  0.19789498\n",
            "   -0.23334557]\n",
            "  [-0.3749435   0.3409431  -0.09148798 ... -0.22141849  0.19789498\n",
            "   -0.23334557]]\n",
            "\n",
            " [[-0.3749435   0.3409431  -0.09148798 ... -0.22141849  0.19789498\n",
            "   -0.23334557]\n",
            "  [-0.3749435   0.3409431  -0.09148798 ... -0.22141849  0.19789498\n",
            "   -0.23334557]\n",
            "  [-0.3749435   0.3409431  -0.09148798 ... -0.22141849  0.19789498\n",
            "   -0.23334557]\n",
            "  ...\n",
            "  [-0.3749435   0.3409431  -0.09148798 ... -0.22141849  0.19789498\n",
            "   -0.23334557]\n",
            "  [-0.3749435   0.3409431  -0.09148798 ... -0.22141849  0.19789498\n",
            "   -0.23334557]\n",
            "  [-0.3749435   0.3409431  -0.09148798 ... -0.22141849  0.19789498\n",
            "   -0.23334557]]\n",
            "\n",
            " [[-0.3749435   0.3409431  -0.09148798 ... -0.22141849  0.19789498\n",
            "   -0.23334557]\n",
            "  [-0.3749435   0.3409431  -0.09148798 ... -0.22141849  0.19789498\n",
            "   -0.23334557]\n",
            "  [-0.3749435   0.3409431  -0.09148798 ... -0.22141849  0.19789498\n",
            "   -0.23334557]\n",
            "  ...\n",
            "  [-0.3749435   0.3409431  -0.09148798 ... -0.22141849  0.19789498\n",
            "   -0.23334557]\n",
            "  [-0.3749435   0.3409431  -0.09148798 ... -0.22141849  0.19789498\n",
            "   -0.23334557]\n",
            "  [-0.3749435   0.3409431  -0.09148798 ... -0.22141849  0.19789498\n",
            "   -0.23334557]]], shape=(128, 764, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.00988476 -0.00988476 -0.00988476 ... -0.00988476 -0.00988476\n",
            "  -0.00988476]\n",
            " [-0.00988476 -0.00988476 -0.00988476 ... -0.00988476 -0.00988476\n",
            "  -0.00988476]\n",
            " [-0.00988476 -0.00988476 -0.00988476 ... -0.00988476 -0.00988476\n",
            "  -0.00988476]\n",
            " ...\n",
            " [-0.00988476 -0.00988476 -0.00988476 ... -0.00988476 -0.00988476\n",
            "  -0.00988476]\n",
            " [-0.00988476 -0.00988476 -0.00988476 ... -0.00988476 -0.00988476\n",
            "  -0.00988476]\n",
            " [-0.00988476 -0.00988476 -0.00988476 ... -0.00988476 -0.00988476\n",
            "  -0.00988476]], shape=(512, 128), dtype=float32) tf.Tensor(\n",
            "[[-0.00988476 -0.00988476 -0.00988476 ... -0.00988476 -0.00988476\n",
            "  -0.00988476]\n",
            " [-0.00988476 -0.00988476 -0.00988476 ... -0.00988476 -0.00988476\n",
            "  -0.00988476]\n",
            " [-0.00988476 -0.00988476 -0.00988476 ... -0.00988476 -0.00988476\n",
            "  -0.00988476]\n",
            " ...\n",
            " [-0.00988476 -0.00988476 -0.00988476 ... -0.00988476 -0.00988476\n",
            "  -0.00988476]\n",
            " [-0.00988476 -0.00988476 -0.00988476 ... -0.00988476 -0.00988476\n",
            "  -0.00988476]\n",
            " [-0.00988476 -0.00988476 -0.00988476 ... -0.00988476 -0.00988476\n",
            "  -0.00988476]], shape=(252, 128), dtype=float32)\n",
            "(128, 764) (512, 1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_15/kernel:0', 'dense_15/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_15/kernel:0', 'dense_15/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch 1, Batch 84/100, Loss=3.27953e-04\n",
            "(1, 764, 1)\n",
            "tf.Tensor(\n",
            "[[[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " [[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]], shape=(128, 764, 1), dtype=float32) tf.Tensor(\n",
            "[[[-0.3764528   0.3411792  -0.09277563 ... -0.2206016   0.19905907\n",
            "   -0.2342123 ]\n",
            "  [-0.3764528   0.3411792  -0.09277563 ... -0.2206016   0.19905907\n",
            "   -0.2342123 ]\n",
            "  [-0.3764528   0.3411792  -0.09277563 ... -0.2206016   0.19905907\n",
            "   -0.2342123 ]\n",
            "  ...\n",
            "  [-0.3764528   0.3411792  -0.09277563 ... -0.2206016   0.19905907\n",
            "   -0.2342123 ]\n",
            "  [-0.3764528   0.3411792  -0.09277563 ... -0.2206016   0.19905907\n",
            "   -0.2342123 ]\n",
            "  [-0.3764528   0.3411792  -0.09277563 ... -0.2206016   0.19905907\n",
            "   -0.2342123 ]]\n",
            "\n",
            " [[-0.3764528   0.3411792  -0.09277563 ... -0.2206016   0.19905907\n",
            "   -0.2342123 ]\n",
            "  [-0.3764528   0.3411792  -0.09277563 ... -0.2206016   0.19905907\n",
            "   -0.2342123 ]\n",
            "  [-0.3764528   0.3411792  -0.09277563 ... -0.2206016   0.19905907\n",
            "   -0.2342123 ]\n",
            "  ...\n",
            "  [-0.3764528   0.3411792  -0.09277563 ... -0.2206016   0.19905907\n",
            "   -0.2342123 ]\n",
            "  [-0.3764528   0.3411792  -0.09277563 ... -0.2206016   0.19905907\n",
            "   -0.2342123 ]\n",
            "  [-0.3764528   0.3411792  -0.09277563 ... -0.2206016   0.19905907\n",
            "   -0.2342123 ]]\n",
            "\n",
            " [[-0.3764528   0.3411792  -0.09277563 ... -0.2206016   0.19905907\n",
            "   -0.2342123 ]\n",
            "  [-0.3764528   0.3411792  -0.09277563 ... -0.2206016   0.19905907\n",
            "   -0.2342123 ]\n",
            "  [-0.3764528   0.3411792  -0.09277563 ... -0.2206016   0.19905907\n",
            "   -0.2342123 ]\n",
            "  ...\n",
            "  [-0.3764528   0.3411792  -0.09277563 ... -0.2206016   0.19905907\n",
            "   -0.2342123 ]\n",
            "  [-0.3764528   0.3411792  -0.09277563 ... -0.2206016   0.19905907\n",
            "   -0.2342123 ]\n",
            "  [-0.3764528   0.3411792  -0.09277563 ... -0.2206016   0.19905907\n",
            "   -0.2342123 ]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[-0.3764528   0.3411792  -0.09277563 ... -0.2206016   0.19905907\n",
            "   -0.2342123 ]\n",
            "  [-0.3764528   0.3411792  -0.09277563 ... -0.2206016   0.19905907\n",
            "   -0.2342123 ]\n",
            "  [-0.3764528   0.3411792  -0.09277563 ... -0.2206016   0.19905907\n",
            "   -0.2342123 ]\n",
            "  ...\n",
            "  [-0.3764528   0.3411792  -0.09277563 ... -0.2206016   0.19905907\n",
            "   -0.2342123 ]\n",
            "  [-0.3764528   0.3411792  -0.09277563 ... -0.2206016   0.19905907\n",
            "   -0.2342123 ]\n",
            "  [-0.3764528   0.3411792  -0.09277563 ... -0.2206016   0.19905907\n",
            "   -0.2342123 ]]\n",
            "\n",
            " [[-0.3764528   0.3411792  -0.09277563 ... -0.2206016   0.19905907\n",
            "   -0.2342123 ]\n",
            "  [-0.3764528   0.3411792  -0.09277563 ... -0.2206016   0.19905907\n",
            "   -0.2342123 ]\n",
            "  [-0.3764528   0.3411792  -0.09277563 ... -0.2206016   0.19905907\n",
            "   -0.2342123 ]\n",
            "  ...\n",
            "  [-0.3764528   0.3411792  -0.09277563 ... -0.2206016   0.19905907\n",
            "   -0.2342123 ]\n",
            "  [-0.3764528   0.3411792  -0.09277563 ... -0.2206016   0.19905907\n",
            "   -0.2342123 ]\n",
            "  [-0.3764528   0.3411792  -0.09277563 ... -0.2206016   0.19905907\n",
            "   -0.2342123 ]]\n",
            "\n",
            " [[-0.3764528   0.3411792  -0.09277563 ... -0.2206016   0.19905907\n",
            "   -0.2342123 ]\n",
            "  [-0.3764528   0.3411792  -0.09277563 ... -0.2206016   0.19905907\n",
            "   -0.2342123 ]\n",
            "  [-0.3764528   0.3411792  -0.09277563 ... -0.2206016   0.19905907\n",
            "   -0.2342123 ]\n",
            "  ...\n",
            "  [-0.3764528   0.3411792  -0.09277563 ... -0.2206016   0.19905907\n",
            "   -0.2342123 ]\n",
            "  [-0.3764528   0.3411792  -0.09277563 ... -0.2206016   0.19905907\n",
            "   -0.2342123 ]\n",
            "  [-0.3764528   0.3411792  -0.09277563 ... -0.2206016   0.19905907\n",
            "   -0.2342123 ]]], shape=(128, 764, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.01770807 -0.01770807 -0.01770807 ... -0.01770807 -0.01770807\n",
            "  -0.01770807]\n",
            " [-0.01770807 -0.01770807 -0.01770807 ... -0.01770807 -0.01770807\n",
            "  -0.01770807]\n",
            " [-0.01770807 -0.01770807 -0.01770807 ... -0.01770807 -0.01770807\n",
            "  -0.01770807]\n",
            " ...\n",
            " [-0.01770807 -0.01770807 -0.01770807 ... -0.01770807 -0.01770807\n",
            "  -0.01770807]\n",
            " [-0.01770807 -0.01770807 -0.01770807 ... -0.01770807 -0.01770807\n",
            "  -0.01770807]\n",
            " [-0.01770807 -0.01770807 -0.01770807 ... -0.01770807 -0.01770807\n",
            "  -0.01770807]], shape=(512, 128), dtype=float32) tf.Tensor(\n",
            "[[-0.01770807 -0.01770807 -0.01770807 ... -0.01770807 -0.01770807\n",
            "  -0.01770807]\n",
            " [-0.01770807 -0.01770807 -0.01770807 ... -0.01770807 -0.01770807\n",
            "  -0.01770807]\n",
            " [-0.01770807 -0.01770807 -0.01770807 ... -0.01770807 -0.01770807\n",
            "  -0.01770807]\n",
            " ...\n",
            " [-0.01770807 -0.01770807 -0.01770807 ... -0.01770807 -0.01770807\n",
            "  -0.01770807]\n",
            " [-0.01770807 -0.01770807 -0.01770807 ... -0.01770807 -0.01770807\n",
            "  -0.01770807]\n",
            " [-0.01770807 -0.01770807 -0.01770807 ... -0.01770807 -0.01770807\n",
            "  -0.01770807]], shape=(252, 128), dtype=float32)\n",
            "(128, 764) (512, 1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_15/kernel:0', 'dense_15/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_15/kernel:0', 'dense_15/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch 1, Batch 85/100, Loss=6.39294e-04\n",
            "(1, 764, 1)\n",
            "tf.Tensor(\n",
            "[[[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " [[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " [[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]], shape=(128, 764, 1), dtype=float32) tf.Tensor(\n",
            "[[[-0.37734422  0.34131995 -0.09354141 ... -0.22015807  0.19973637\n",
            "   -0.23467986]\n",
            "  [-0.37734422  0.34131995 -0.09354141 ... -0.22015807  0.19973637\n",
            "   -0.23467986]\n",
            "  [-0.37734422  0.34131995 -0.09354141 ... -0.22015807  0.19973637\n",
            "   -0.23467986]\n",
            "  ...\n",
            "  [-0.37734422  0.34131995 -0.09354141 ... -0.22015807  0.19973637\n",
            "   -0.23467986]\n",
            "  [-0.37734422  0.34131995 -0.09354141 ... -0.22015807  0.19973637\n",
            "   -0.23467986]\n",
            "  [-0.37734422  0.34131995 -0.09354141 ... -0.22015807  0.19973637\n",
            "   -0.23467986]]\n",
            "\n",
            " [[-0.37734422  0.34131995 -0.09354141 ... -0.22015807  0.19973637\n",
            "   -0.23467986]\n",
            "  [-0.37734422  0.34131995 -0.09354141 ... -0.22015807  0.19973637\n",
            "   -0.23467986]\n",
            "  [-0.37734422  0.34131995 -0.09354141 ... -0.22015807  0.19973637\n",
            "   -0.23467986]\n",
            "  ...\n",
            "  [-0.37734422  0.34131995 -0.09354141 ... -0.22015807  0.19973637\n",
            "   -0.23467986]\n",
            "  [-0.37734422  0.34131995 -0.09354141 ... -0.22015807  0.19973637\n",
            "   -0.23467986]\n",
            "  [-0.37734422  0.34131995 -0.09354141 ... -0.22015807  0.19973637\n",
            "   -0.23467986]]\n",
            "\n",
            " [[-0.37734422  0.34131995 -0.09354141 ... -0.22015807  0.19973637\n",
            "   -0.23467986]\n",
            "  [-0.37734422  0.34131995 -0.09354141 ... -0.22015807  0.19973637\n",
            "   -0.23467986]\n",
            "  [-0.37734422  0.34131995 -0.09354141 ... -0.22015807  0.19973637\n",
            "   -0.23467986]\n",
            "  ...\n",
            "  [-0.37734422  0.34131995 -0.09354141 ... -0.22015807  0.19973637\n",
            "   -0.23467986]\n",
            "  [-0.37734422  0.34131995 -0.09354141 ... -0.22015807  0.19973637\n",
            "   -0.23467986]\n",
            "  [-0.37734422  0.34131995 -0.09354141 ... -0.22015807  0.19973637\n",
            "   -0.23467986]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[-0.37734422  0.34131995 -0.09354141 ... -0.22015807  0.19973637\n",
            "   -0.23467986]\n",
            "  [-0.37734422  0.34131995 -0.09354141 ... -0.22015807  0.19973637\n",
            "   -0.23467986]\n",
            "  [-0.37734422  0.34131995 -0.09354141 ... -0.22015807  0.19973637\n",
            "   -0.23467986]\n",
            "  ...\n",
            "  [-0.37734422  0.34131995 -0.09354141 ... -0.22015807  0.19973637\n",
            "   -0.23467986]\n",
            "  [-0.37734422  0.34131995 -0.09354141 ... -0.22015807  0.19973637\n",
            "   -0.23467986]\n",
            "  [-0.37734422  0.34131995 -0.09354141 ... -0.22015807  0.19973637\n",
            "   -0.23467986]]\n",
            "\n",
            " [[-0.37734422  0.34131995 -0.09354141 ... -0.22015807  0.19973637\n",
            "   -0.23467986]\n",
            "  [-0.37734422  0.34131995 -0.09354141 ... -0.22015807  0.19973637\n",
            "   -0.23467986]\n",
            "  [-0.37734422  0.34131995 -0.09354141 ... -0.22015807  0.19973637\n",
            "   -0.23467986]\n",
            "  ...\n",
            "  [-0.37734422  0.34131995 -0.09354141 ... -0.22015807  0.19973637\n",
            "   -0.23467986]\n",
            "  [-0.37734422  0.34131995 -0.09354141 ... -0.22015807  0.19973637\n",
            "   -0.23467986]\n",
            "  [-0.37734422  0.34131995 -0.09354141 ... -0.22015807  0.19973637\n",
            "   -0.23467986]]\n",
            "\n",
            " [[-0.37734422  0.34131995 -0.09354141 ... -0.22015807  0.19973637\n",
            "   -0.23467986]\n",
            "  [-0.37734422  0.34131995 -0.09354141 ... -0.22015807  0.19973637\n",
            "   -0.23467986]\n",
            "  [-0.37734422  0.34131995 -0.09354141 ... -0.22015807  0.19973637\n",
            "   -0.23467986]\n",
            "  ...\n",
            "  [-0.37734422  0.34131995 -0.09354141 ... -0.22015807  0.19973637\n",
            "   -0.23467986]\n",
            "  [-0.37734422  0.34131995 -0.09354141 ... -0.22015807  0.19973637\n",
            "   -0.23467986]\n",
            "  [-0.37734422  0.34131995 -0.09354141 ... -0.22015807  0.19973637\n",
            "   -0.23467986]]], shape=(128, 764, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.0222015 -0.0222015 -0.0222015 ... -0.0222015 -0.0222015 -0.0222015]\n",
            " [-0.0222015 -0.0222015 -0.0222015 ... -0.0222015 -0.0222015 -0.0222015]\n",
            " [-0.0222015 -0.0222015 -0.0222015 ... -0.0222015 -0.0222015 -0.0222015]\n",
            " ...\n",
            " [-0.0222015 -0.0222015 -0.0222015 ... -0.0222015 -0.0222015 -0.0222015]\n",
            " [-0.0222015 -0.0222015 -0.0222015 ... -0.0222015 -0.0222015 -0.0222015]\n",
            " [-0.0222015 -0.0222015 -0.0222015 ... -0.0222015 -0.0222015 -0.0222015]], shape=(512, 128), dtype=float32) tf.Tensor(\n",
            "[[-0.0222015 -0.0222015 -0.0222015 ... -0.0222015 -0.0222015 -0.0222015]\n",
            " [-0.0222015 -0.0222015 -0.0222015 ... -0.0222015 -0.0222015 -0.0222015]\n",
            " [-0.0222015 -0.0222015 -0.0222015 ... -0.0222015 -0.0222015 -0.0222015]\n",
            " ...\n",
            " [-0.0222015 -0.0222015 -0.0222015 ... -0.0222015 -0.0222015 -0.0222015]\n",
            " [-0.0222015 -0.0222015 -0.0222015 ... -0.0222015 -0.0222015 -0.0222015]\n",
            " [-0.0222015 -0.0222015 -0.0222015 ... -0.0222015 -0.0222015 -0.0222015]], shape=(252, 128), dtype=float32)\n",
            "(128, 764) (512, 1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_15/kernel:0', 'dense_15/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_15/kernel:0', 'dense_15/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch 1, Batch 86/100, Loss=8.61759e-04\n",
            "(1, 764, 1)\n",
            "tf.Tensor(\n",
            "[[[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]], shape=(128, 764, 1), dtype=float32) tf.Tensor(\n",
            "[[[-0.3776188   0.34136504 -0.09378755 ... -0.22008842  0.19992597\n",
            "   -0.23474866]\n",
            "  [-0.3776188   0.34136504 -0.09378755 ... -0.22008842  0.19992597\n",
            "   -0.23474866]\n",
            "  [-0.3776188   0.34136504 -0.09378755 ... -0.22008842  0.19992597\n",
            "   -0.23474866]\n",
            "  ...\n",
            "  [-0.3776188   0.34136504 -0.09378755 ... -0.22008842  0.19992597\n",
            "   -0.23474866]\n",
            "  [-0.3776188   0.34136504 -0.09378755 ... -0.22008842  0.19992597\n",
            "   -0.23474866]\n",
            "  [-0.3776188   0.34136504 -0.09378755 ... -0.22008842  0.19992597\n",
            "   -0.23474866]]\n",
            "\n",
            " [[-0.3776188   0.34136504 -0.09378755 ... -0.22008842  0.19992597\n",
            "   -0.23474866]\n",
            "  [-0.3776188   0.34136504 -0.09378755 ... -0.22008842  0.19992597\n",
            "   -0.23474866]\n",
            "  [-0.3776188   0.34136504 -0.09378755 ... -0.22008842  0.19992597\n",
            "   -0.23474866]\n",
            "  ...\n",
            "  [-0.3776188   0.34136504 -0.09378755 ... -0.22008842  0.19992597\n",
            "   -0.23474866]\n",
            "  [-0.3776188   0.34136504 -0.09378755 ... -0.22008842  0.19992597\n",
            "   -0.23474866]\n",
            "  [-0.3776188   0.34136504 -0.09378755 ... -0.22008842  0.19992597\n",
            "   -0.23474866]]\n",
            "\n",
            " [[-0.3776188   0.34136504 -0.09378755 ... -0.22008842  0.19992597\n",
            "   -0.23474866]\n",
            "  [-0.3776188   0.34136504 -0.09378755 ... -0.22008842  0.19992597\n",
            "   -0.23474866]\n",
            "  [-0.3776188   0.34136504 -0.09378755 ... -0.22008842  0.19992597\n",
            "   -0.23474866]\n",
            "  ...\n",
            "  [-0.3776188   0.34136504 -0.09378755 ... -0.22008842  0.19992597\n",
            "   -0.23474866]\n",
            "  [-0.3776188   0.34136504 -0.09378755 ... -0.22008842  0.19992597\n",
            "   -0.23474866]\n",
            "  [-0.3776188   0.34136504 -0.09378755 ... -0.22008842  0.19992597\n",
            "   -0.23474866]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[-0.3776188   0.34136504 -0.09378755 ... -0.22008842  0.19992597\n",
            "   -0.23474866]\n",
            "  [-0.3776188   0.34136504 -0.09378755 ... -0.22008842  0.19992597\n",
            "   -0.23474866]\n",
            "  [-0.3776188   0.34136504 -0.09378755 ... -0.22008842  0.19992597\n",
            "   -0.23474866]\n",
            "  ...\n",
            "  [-0.3776188   0.34136504 -0.09378755 ... -0.22008842  0.19992597\n",
            "   -0.23474866]\n",
            "  [-0.3776188   0.34136504 -0.09378755 ... -0.22008842  0.19992597\n",
            "   -0.23474866]\n",
            "  [-0.3776188   0.34136504 -0.09378755 ... -0.22008842  0.19992597\n",
            "   -0.23474866]]\n",
            "\n",
            " [[-0.3776188   0.34136504 -0.09378755 ... -0.22008842  0.19992597\n",
            "   -0.23474866]\n",
            "  [-0.3776188   0.34136504 -0.09378755 ... -0.22008842  0.19992597\n",
            "   -0.23474866]\n",
            "  [-0.3776188   0.34136504 -0.09378755 ... -0.22008842  0.19992597\n",
            "   -0.23474866]\n",
            "  ...\n",
            "  [-0.3776188   0.34136504 -0.09378755 ... -0.22008842  0.19992597\n",
            "   -0.23474866]\n",
            "  [-0.3776188   0.34136504 -0.09378755 ... -0.22008842  0.19992597\n",
            "   -0.23474866]\n",
            "  [-0.3776188   0.34136504 -0.09378755 ... -0.22008842  0.19992597\n",
            "   -0.23474866]]\n",
            "\n",
            " [[-0.3776188   0.34136504 -0.09378755 ... -0.22008842  0.19992597\n",
            "   -0.23474866]\n",
            "  [-0.3776188   0.34136504 -0.09378755 ... -0.22008842  0.19992597\n",
            "   -0.23474866]\n",
            "  [-0.3776188   0.34136504 -0.09378755 ... -0.22008842  0.19992597\n",
            "   -0.23474866]\n",
            "  ...\n",
            "  [-0.3776188   0.34136504 -0.09378755 ... -0.22008842  0.19992597\n",
            "   -0.23474866]\n",
            "  [-0.3776188   0.34136504 -0.09378755 ... -0.22008842  0.19992597\n",
            "   -0.23474866]\n",
            "  [-0.3776188   0.34136504 -0.09378755 ... -0.22008842  0.19992597\n",
            "   -0.23474866]]], shape=(128, 764, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.02336882 -0.02336882 -0.02336882 ... -0.02336882 -0.02336882\n",
            "  -0.02336882]\n",
            " [-0.02336882 -0.02336882 -0.02336882 ... -0.02336882 -0.02336882\n",
            "  -0.02336882]\n",
            " [-0.02336882 -0.02336882 -0.02336882 ... -0.02336882 -0.02336882\n",
            "  -0.02336882]\n",
            " ...\n",
            " [-0.02336882 -0.02336882 -0.02336882 ... -0.02336882 -0.02336882\n",
            "  -0.02336882]\n",
            " [-0.02336882 -0.02336882 -0.02336882 ... -0.02336882 -0.02336882\n",
            "  -0.02336882]\n",
            " [-0.02336882 -0.02336882 -0.02336882 ... -0.02336882 -0.02336882\n",
            "  -0.02336882]], shape=(512, 128), dtype=float32) tf.Tensor(\n",
            "[[-0.02336882 -0.02336882 -0.02336882 ... -0.02336882 -0.02336882\n",
            "  -0.02336882]\n",
            " [-0.02336882 -0.02336882 -0.02336882 ... -0.02336882 -0.02336882\n",
            "  -0.02336882]\n",
            " [-0.02336882 -0.02336882 -0.02336882 ... -0.02336882 -0.02336882\n",
            "  -0.02336882]\n",
            " ...\n",
            " [-0.02336882 -0.02336882 -0.02336882 ... -0.02336882 -0.02336882\n",
            "  -0.02336882]\n",
            " [-0.02336882 -0.02336882 -0.02336882 ... -0.02336882 -0.02336882\n",
            "  -0.02336882]\n",
            " [-0.02336882 -0.02336882 -0.02336882 ... -0.02336882 -0.02336882\n",
            "  -0.02336882]], shape=(252, 128), dtype=float32)\n",
            "(128, 764) (512, 1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_15/kernel:0', 'dense_15/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_15/kernel:0', 'dense_15/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch 1, Batch 87/100, Loss=9.32408e-04\n",
            "(1, 764, 1)\n",
            "tf.Tensor(\n",
            "[[[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " [[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " [[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " [[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]], shape=(128, 764, 1), dtype=float32) tf.Tensor(\n",
            "[[[-0.37730598  0.3413181  -0.0935396  ... -0.2203758   0.19965136\n",
            "   -0.23443905]\n",
            "  [-0.37730598  0.3413181  -0.0935396  ... -0.2203758   0.19965136\n",
            "   -0.23443905]\n",
            "  [-0.37730598  0.3413181  -0.0935396  ... -0.2203758   0.19965136\n",
            "   -0.23443905]\n",
            "  ...\n",
            "  [-0.37730598  0.3413181  -0.0935396  ... -0.2203758   0.19965136\n",
            "   -0.23443905]\n",
            "  [-0.37730598  0.3413181  -0.0935396  ... -0.2203758   0.19965136\n",
            "   -0.23443905]\n",
            "  [-0.37730598  0.3413181  -0.0935396  ... -0.2203758   0.19965136\n",
            "   -0.23443905]]\n",
            "\n",
            " [[-0.37730598  0.3413181  -0.0935396  ... -0.2203758   0.19965136\n",
            "   -0.23443905]\n",
            "  [-0.37730598  0.3413181  -0.0935396  ... -0.2203758   0.19965136\n",
            "   -0.23443905]\n",
            "  [-0.37730598  0.3413181  -0.0935396  ... -0.2203758   0.19965136\n",
            "   -0.23443905]\n",
            "  ...\n",
            "  [-0.37730598  0.3413181  -0.0935396  ... -0.2203758   0.19965136\n",
            "   -0.23443905]\n",
            "  [-0.37730598  0.3413181  -0.0935396  ... -0.2203758   0.19965136\n",
            "   -0.23443905]\n",
            "  [-0.37730598  0.3413181  -0.0935396  ... -0.2203758   0.19965136\n",
            "   -0.23443905]]\n",
            "\n",
            " [[-0.37730598  0.3413181  -0.0935396  ... -0.2203758   0.19965136\n",
            "   -0.23443905]\n",
            "  [-0.37730598  0.3413181  -0.0935396  ... -0.2203758   0.19965136\n",
            "   -0.23443905]\n",
            "  [-0.37730598  0.3413181  -0.0935396  ... -0.2203758   0.19965136\n",
            "   -0.23443905]\n",
            "  ...\n",
            "  [-0.37730598  0.3413181  -0.0935396  ... -0.2203758   0.19965136\n",
            "   -0.23443905]\n",
            "  [-0.37730598  0.3413181  -0.0935396  ... -0.2203758   0.19965136\n",
            "   -0.23443905]\n",
            "  [-0.37730598  0.3413181  -0.0935396  ... -0.2203758   0.19965136\n",
            "   -0.23443905]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[-0.37730598  0.3413181  -0.0935396  ... -0.2203758   0.19965136\n",
            "   -0.23443905]\n",
            "  [-0.37730598  0.3413181  -0.0935396  ... -0.2203758   0.19965136\n",
            "   -0.23443905]\n",
            "  [-0.37730598  0.3413181  -0.0935396  ... -0.2203758   0.19965136\n",
            "   -0.23443905]\n",
            "  ...\n",
            "  [-0.37730598  0.3413181  -0.0935396  ... -0.2203758   0.19965136\n",
            "   -0.23443905]\n",
            "  [-0.37730598  0.3413181  -0.0935396  ... -0.2203758   0.19965136\n",
            "   -0.23443905]\n",
            "  [-0.37730598  0.3413181  -0.0935396  ... -0.2203758   0.19965136\n",
            "   -0.23443905]]\n",
            "\n",
            " [[-0.37730598  0.3413181  -0.0935396  ... -0.2203758   0.19965136\n",
            "   -0.23443905]\n",
            "  [-0.37730598  0.3413181  -0.0935396  ... -0.2203758   0.19965136\n",
            "   -0.23443905]\n",
            "  [-0.37730598  0.3413181  -0.0935396  ... -0.2203758   0.19965136\n",
            "   -0.23443905]\n",
            "  ...\n",
            "  [-0.37730598  0.3413181  -0.0935396  ... -0.2203758   0.19965136\n",
            "   -0.23443905]\n",
            "  [-0.37730598  0.3413181  -0.0935396  ... -0.2203758   0.19965136\n",
            "   -0.23443905]\n",
            "  [-0.37730598  0.3413181  -0.0935396  ... -0.2203758   0.19965136\n",
            "   -0.23443905]]\n",
            "\n",
            " [[-0.37730598  0.3413181  -0.0935396  ... -0.2203758   0.19965136\n",
            "   -0.23443905]\n",
            "  [-0.37730598  0.3413181  -0.0935396  ... -0.2203758   0.19965136\n",
            "   -0.23443905]\n",
            "  [-0.37730598  0.3413181  -0.0935396  ... -0.2203758   0.19965136\n",
            "   -0.23443905]\n",
            "  ...\n",
            "  [-0.37730598  0.3413181  -0.0935396  ... -0.2203758   0.19965136\n",
            "   -0.23443905]\n",
            "  [-0.37730598  0.3413181  -0.0935396  ... -0.2203758   0.19965136\n",
            "   -0.23443905]\n",
            "  [-0.37730598  0.3413181  -0.0935396  ... -0.2203758   0.19965136\n",
            "   -0.23443905]]], shape=(128, 764, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.02137686 -0.02137686 -0.02137686 ... -0.02137686 -0.02137686\n",
            "  -0.02137686]\n",
            " [-0.02137686 -0.02137686 -0.02137686 ... -0.02137686 -0.02137686\n",
            "  -0.02137686]\n",
            " [-0.02137686 -0.02137686 -0.02137686 ... -0.02137686 -0.02137686\n",
            "  -0.02137686]\n",
            " ...\n",
            " [-0.02137686 -0.02137686 -0.02137686 ... -0.02137686 -0.02137686\n",
            "  -0.02137686]\n",
            " [-0.02137686 -0.02137686 -0.02137686 ... -0.02137686 -0.02137686\n",
            "  -0.02137686]\n",
            " [-0.02137686 -0.02137686 -0.02137686 ... -0.02137686 -0.02137686\n",
            "  -0.02137686]], shape=(512, 128), dtype=float32) tf.Tensor(\n",
            "[[-0.02137686 -0.02137686 -0.02137686 ... -0.02137686 -0.02137686\n",
            "  -0.02137686]\n",
            " [-0.02137686 -0.02137686 -0.02137686 ... -0.02137686 -0.02137686\n",
            "  -0.02137686]\n",
            " [-0.02137686 -0.02137686 -0.02137686 ... -0.02137686 -0.02137686\n",
            "  -0.02137686]\n",
            " ...\n",
            " [-0.02137686 -0.02137686 -0.02137686 ... -0.02137686 -0.02137686\n",
            "  -0.02137686]\n",
            " [-0.02137686 -0.02137686 -0.02137686 ... -0.02137686 -0.02137686\n",
            "  -0.02137686]\n",
            " [-0.02137686 -0.02137686 -0.02137686 ... -0.02137686 -0.02137686\n",
            "  -0.02137686]], shape=(252, 128), dtype=float32)\n",
            "(128, 764) (512, 1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_15/kernel:0', 'dense_15/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_15/kernel:0', 'dense_15/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch 1, Batch 88/100, Loss=8.85026e-04\n",
            "(1, 764, 1)\n",
            "tf.Tensor(\n",
            "[[[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " [[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " [[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]], shape=(128, 764, 1), dtype=float32) tf.Tensor(\n",
            "[[[-0.37649974  0.34119228 -0.09287447 ... -0.22096221  0.19898646\n",
            "   -0.23381336]\n",
            "  [-0.37649974  0.34119228 -0.09287447 ... -0.22096221  0.19898646\n",
            "   -0.23381336]\n",
            "  [-0.37649974  0.34119228 -0.09287447 ... -0.22096221  0.19898646\n",
            "   -0.23381336]\n",
            "  ...\n",
            "  [-0.37649974  0.34119228 -0.09287447 ... -0.22096221  0.19898646\n",
            "   -0.23381336]\n",
            "  [-0.37649974  0.34119228 -0.09287447 ... -0.22096221  0.19898646\n",
            "   -0.23381336]\n",
            "  [-0.37649974  0.34119228 -0.09287447 ... -0.22096221  0.19898646\n",
            "   -0.23381336]]\n",
            "\n",
            " [[-0.37649974  0.34119228 -0.09287447 ... -0.22096221  0.19898646\n",
            "   -0.23381336]\n",
            "  [-0.37649974  0.34119228 -0.09287447 ... -0.22096221  0.19898646\n",
            "   -0.23381336]\n",
            "  [-0.37649974  0.34119228 -0.09287447 ... -0.22096221  0.19898646\n",
            "   -0.23381336]\n",
            "  ...\n",
            "  [-0.37649974  0.34119228 -0.09287447 ... -0.22096221  0.19898646\n",
            "   -0.23381336]\n",
            "  [-0.37649974  0.34119228 -0.09287447 ... -0.22096221  0.19898646\n",
            "   -0.23381336]\n",
            "  [-0.37649974  0.34119228 -0.09287447 ... -0.22096221  0.19898646\n",
            "   -0.23381336]]\n",
            "\n",
            " [[-0.37649974  0.34119228 -0.09287447 ... -0.22096221  0.19898646\n",
            "   -0.23381336]\n",
            "  [-0.37649974  0.34119228 -0.09287447 ... -0.22096221  0.19898646\n",
            "   -0.23381336]\n",
            "  [-0.37649974  0.34119228 -0.09287447 ... -0.22096221  0.19898646\n",
            "   -0.23381336]\n",
            "  ...\n",
            "  [-0.37649974  0.34119228 -0.09287447 ... -0.22096221  0.19898646\n",
            "   -0.23381336]\n",
            "  [-0.37649974  0.34119228 -0.09287447 ... -0.22096221  0.19898646\n",
            "   -0.23381336]\n",
            "  [-0.37649974  0.34119228 -0.09287447 ... -0.22096221  0.19898646\n",
            "   -0.23381336]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[-0.37649974  0.34119228 -0.09287447 ... -0.22096221  0.19898646\n",
            "   -0.23381336]\n",
            "  [-0.37649974  0.34119228 -0.09287447 ... -0.22096221  0.19898646\n",
            "   -0.23381336]\n",
            "  [-0.37649974  0.34119228 -0.09287447 ... -0.22096221  0.19898646\n",
            "   -0.23381336]\n",
            "  ...\n",
            "  [-0.37649974  0.34119228 -0.09287447 ... -0.22096221  0.19898646\n",
            "   -0.23381336]\n",
            "  [-0.37649974  0.34119228 -0.09287447 ... -0.22096221  0.19898646\n",
            "   -0.23381336]\n",
            "  [-0.37649974  0.34119228 -0.09287447 ... -0.22096221  0.19898646\n",
            "   -0.23381336]]\n",
            "\n",
            " [[-0.37649974  0.34119228 -0.09287447 ... -0.22096221  0.19898646\n",
            "   -0.23381336]\n",
            "  [-0.37649974  0.34119228 -0.09287447 ... -0.22096221  0.19898646\n",
            "   -0.23381336]\n",
            "  [-0.37649974  0.34119228 -0.09287447 ... -0.22096221  0.19898646\n",
            "   -0.23381336]\n",
            "  ...\n",
            "  [-0.37649974  0.34119228 -0.09287447 ... -0.22096221  0.19898646\n",
            "   -0.23381336]\n",
            "  [-0.37649974  0.34119228 -0.09287447 ... -0.22096221  0.19898646\n",
            "   -0.23381336]\n",
            "  [-0.37649974  0.34119228 -0.09287447 ... -0.22096221  0.19898646\n",
            "   -0.23381336]]\n",
            "\n",
            " [[-0.37649974  0.34119228 -0.09287447 ... -0.22096221  0.19898646\n",
            "   -0.23381336]\n",
            "  [-0.37649974  0.34119228 -0.09287447 ... -0.22096221  0.19898646\n",
            "   -0.23381336]\n",
            "  [-0.37649974  0.34119228 -0.09287447 ... -0.22096221  0.19898646\n",
            "   -0.23381336]\n",
            "  ...\n",
            "  [-0.37649974  0.34119228 -0.09287447 ... -0.22096221  0.19898646\n",
            "   -0.23381336]\n",
            "  [-0.37649974  0.34119228 -0.09287447 ... -0.22096221  0.19898646\n",
            "   -0.23381336]\n",
            "  [-0.37649974  0.34119228 -0.09287447 ... -0.22096221  0.19898646\n",
            "   -0.23381336]]], shape=(128, 764, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.01674198 -0.01674198 -0.01674198 ... -0.01674198 -0.01674198\n",
            "  -0.01674198]\n",
            " [-0.01674198 -0.01674198 -0.01674198 ... -0.01674198 -0.01674198\n",
            "  -0.01674198]\n",
            " [-0.01674198 -0.01674198 -0.01674198 ... -0.01674198 -0.01674198\n",
            "  -0.01674198]\n",
            " ...\n",
            " [-0.01674198 -0.01674198 -0.01674198 ... -0.01674198 -0.01674198\n",
            "  -0.01674198]\n",
            " [-0.01674198 -0.01674198 -0.01674198 ... -0.01674198 -0.01674198\n",
            "  -0.01674198]\n",
            " [-0.01674198 -0.01674198 -0.01674198 ... -0.01674198 -0.01674198\n",
            "  -0.01674198]], shape=(512, 128), dtype=float32) tf.Tensor(\n",
            "[[-0.01674198 -0.01674198 -0.01674198 ... -0.01674198 -0.01674198\n",
            "  -0.01674198]\n",
            " [-0.01674198 -0.01674198 -0.01674198 ... -0.01674198 -0.01674198\n",
            "  -0.01674198]\n",
            " [-0.01674198 -0.01674198 -0.01674198 ... -0.01674198 -0.01674198\n",
            "  -0.01674198]\n",
            " ...\n",
            " [-0.01674198 -0.01674198 -0.01674198 ... -0.01674198 -0.01674198\n",
            "  -0.01674198]\n",
            " [-0.01674198 -0.01674198 -0.01674198 ... -0.01674198 -0.01674198\n",
            "  -0.01674198]\n",
            " [-0.01674198 -0.01674198 -0.01674198 ... -0.01674198 -0.01674198\n",
            "  -0.01674198]], shape=(252, 128), dtype=float32)\n",
            "(128, 764) (512, 1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_15/kernel:0', 'dense_15/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_15/kernel:0', 'dense_15/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch 1, Batch 89/100, Loss=6.25848e-04\n",
            "(1, 764, 1)\n",
            "tf.Tensor(\n",
            "[[[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " [[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " [[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " [[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]], shape=(128, 764, 1), dtype=float32) tf.Tensor(\n",
            "[[[-0.3753314   0.34100798 -0.09190463 ... -0.22176531  0.19803606\n",
            "   -0.23295803]\n",
            "  [-0.3753314   0.34100798 -0.09190463 ... -0.22176531  0.19803606\n",
            "   -0.23295803]\n",
            "  [-0.3753314   0.34100798 -0.09190463 ... -0.22176531  0.19803606\n",
            "   -0.23295803]\n",
            "  ...\n",
            "  [-0.3753314   0.34100798 -0.09190463 ... -0.22176531  0.19803606\n",
            "   -0.23295803]\n",
            "  [-0.3753314   0.34100798 -0.09190463 ... -0.22176531  0.19803606\n",
            "   -0.23295803]\n",
            "  [-0.3753314   0.34100798 -0.09190463 ... -0.22176531  0.19803606\n",
            "   -0.23295803]]\n",
            "\n",
            " [[-0.3753314   0.34100798 -0.09190463 ... -0.22176531  0.19803606\n",
            "   -0.23295803]\n",
            "  [-0.3753314   0.34100798 -0.09190463 ... -0.22176531  0.19803606\n",
            "   -0.23295803]\n",
            "  [-0.3753314   0.34100798 -0.09190463 ... -0.22176531  0.19803606\n",
            "   -0.23295803]\n",
            "  ...\n",
            "  [-0.3753314   0.34100798 -0.09190463 ... -0.22176531  0.19803606\n",
            "   -0.23295803]\n",
            "  [-0.3753314   0.34100798 -0.09190463 ... -0.22176531  0.19803606\n",
            "   -0.23295803]\n",
            "  [-0.3753314   0.34100798 -0.09190463 ... -0.22176531  0.19803606\n",
            "   -0.23295803]]\n",
            "\n",
            " [[-0.3753314   0.34100798 -0.09190463 ... -0.22176531  0.19803606\n",
            "   -0.23295803]\n",
            "  [-0.3753314   0.34100798 -0.09190463 ... -0.22176531  0.19803606\n",
            "   -0.23295803]\n",
            "  [-0.3753314   0.34100798 -0.09190463 ... -0.22176531  0.19803606\n",
            "   -0.23295803]\n",
            "  ...\n",
            "  [-0.3753314   0.34100798 -0.09190463 ... -0.22176531  0.19803606\n",
            "   -0.23295803]\n",
            "  [-0.3753314   0.34100798 -0.09190463 ... -0.22176531  0.19803606\n",
            "   -0.23295803]\n",
            "  [-0.3753314   0.34100798 -0.09190463 ... -0.22176531  0.19803606\n",
            "   -0.23295803]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[-0.3753314   0.34100798 -0.09190463 ... -0.22176531  0.19803606\n",
            "   -0.23295803]\n",
            "  [-0.3753314   0.34100798 -0.09190463 ... -0.22176531  0.19803606\n",
            "   -0.23295803]\n",
            "  [-0.3753314   0.34100798 -0.09190463 ... -0.22176531  0.19803606\n",
            "   -0.23295803]\n",
            "  ...\n",
            "  [-0.3753314   0.34100798 -0.09190463 ... -0.22176531  0.19803606\n",
            "   -0.23295803]\n",
            "  [-0.3753314   0.34100798 -0.09190463 ... -0.22176531  0.19803606\n",
            "   -0.23295803]\n",
            "  [-0.3753314   0.34100798 -0.09190463 ... -0.22176531  0.19803606\n",
            "   -0.23295803]]\n",
            "\n",
            " [[-0.3753314   0.34100798 -0.09190463 ... -0.22176531  0.19803606\n",
            "   -0.23295803]\n",
            "  [-0.3753314   0.34100798 -0.09190463 ... -0.22176531  0.19803606\n",
            "   -0.23295803]\n",
            "  [-0.3753314   0.34100798 -0.09190463 ... -0.22176531  0.19803606\n",
            "   -0.23295803]\n",
            "  ...\n",
            "  [-0.3753314   0.34100798 -0.09190463 ... -0.22176531  0.19803606\n",
            "   -0.23295803]\n",
            "  [-0.3753314   0.34100798 -0.09190463 ... -0.22176531  0.19803606\n",
            "   -0.23295803]\n",
            "  [-0.3753314   0.34100798 -0.09190463 ... -0.22176531  0.19803606\n",
            "   -0.23295803]]\n",
            "\n",
            " [[-0.3753314   0.34100798 -0.09190463 ... -0.22176531  0.19803606\n",
            "   -0.23295803]\n",
            "  [-0.3753314   0.34100798 -0.09190463 ... -0.22176531  0.19803606\n",
            "   -0.23295803]\n",
            "  [-0.3753314   0.34100798 -0.09190463 ... -0.22176531  0.19803606\n",
            "   -0.23295803]\n",
            "  ...\n",
            "  [-0.3753314   0.34100798 -0.09190463 ... -0.22176531  0.19803606\n",
            "   -0.23295803]\n",
            "  [-0.3753314   0.34100798 -0.09190463 ... -0.22176531  0.19803606\n",
            "   -0.23295803]\n",
            "  [-0.3753314   0.34100798 -0.09190463 ... -0.22176531  0.19803606\n",
            "   -0.23295803]]], shape=(128, 764, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.01017754 -0.01017754 -0.01017754 ... -0.01017754 -0.01017754\n",
            "  -0.01017754]\n",
            " [-0.01017754 -0.01017754 -0.01017754 ... -0.01017754 -0.01017754\n",
            "  -0.01017754]\n",
            " [-0.01017754 -0.01017754 -0.01017754 ... -0.01017754 -0.01017754\n",
            "  -0.01017754]\n",
            " ...\n",
            " [-0.01017754 -0.01017754 -0.01017754 ... -0.01017754 -0.01017754\n",
            "  -0.01017754]\n",
            " [-0.01017754 -0.01017754 -0.01017754 ... -0.01017754 -0.01017754\n",
            "  -0.01017754]\n",
            " [-0.01017754 -0.01017754 -0.01017754 ... -0.01017754 -0.01017754\n",
            "  -0.01017754]], shape=(512, 128), dtype=float32) tf.Tensor(\n",
            "[[-0.01017754 -0.01017754 -0.01017754 ... -0.01017754 -0.01017754\n",
            "  -0.01017754]\n",
            " [-0.01017754 -0.01017754 -0.01017754 ... -0.01017754 -0.01017754\n",
            "  -0.01017754]\n",
            " [-0.01017754 -0.01017754 -0.01017754 ... -0.01017754 -0.01017754\n",
            "  -0.01017754]\n",
            " ...\n",
            " [-0.01017754 -0.01017754 -0.01017754 ... -0.01017754 -0.01017754\n",
            "  -0.01017754]\n",
            " [-0.01017754 -0.01017754 -0.01017754 ... -0.01017754 -0.01017754\n",
            "  -0.01017754]\n",
            " [-0.01017754 -0.01017754 -0.01017754 ... -0.01017754 -0.01017754\n",
            "  -0.01017754]], shape=(252, 128), dtype=float32)\n",
            "(128, 764) (512, 1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_15/kernel:0', 'dense_15/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_15/kernel:0', 'dense_15/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch 1, Batch 90/100, Loss=3.94700e-04\n",
            "(1, 764, 1)\n",
            "tf.Tensor(\n",
            "[[[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " [[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " [[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " [[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]], shape=(128, 764, 1), dtype=float32) tf.Tensor(\n",
            "[[[-0.37405935  0.34080628 -0.09084032 ... -0.22262707  0.19700214\n",
            "   -0.23204187]\n",
            "  [-0.37405935  0.34080628 -0.09084032 ... -0.22262707  0.19700214\n",
            "   -0.23204187]\n",
            "  [-0.37405935  0.34080628 -0.09084032 ... -0.22262707  0.19700214\n",
            "   -0.23204187]\n",
            "  ...\n",
            "  [-0.37405935  0.34080628 -0.09084032 ... -0.22262707  0.19700214\n",
            "   -0.23204187]\n",
            "  [-0.37405935  0.34080628 -0.09084032 ... -0.22262707  0.19700214\n",
            "   -0.23204187]\n",
            "  [-0.37405935  0.34080628 -0.09084032 ... -0.22262707  0.19700214\n",
            "   -0.23204187]]\n",
            "\n",
            " [[-0.37405935  0.34080628 -0.09084032 ... -0.22262707  0.19700214\n",
            "   -0.23204187]\n",
            "  [-0.37405935  0.34080628 -0.09084032 ... -0.22262707  0.19700214\n",
            "   -0.23204187]\n",
            "  [-0.37405935  0.34080628 -0.09084032 ... -0.22262707  0.19700214\n",
            "   -0.23204187]\n",
            "  ...\n",
            "  [-0.37405935  0.34080628 -0.09084032 ... -0.22262707  0.19700214\n",
            "   -0.23204187]\n",
            "  [-0.37405935  0.34080628 -0.09084032 ... -0.22262707  0.19700214\n",
            "   -0.23204187]\n",
            "  [-0.37405935  0.34080628 -0.09084032 ... -0.22262707  0.19700214\n",
            "   -0.23204187]]\n",
            "\n",
            " [[-0.37405935  0.34080628 -0.09084032 ... -0.22262707  0.19700214\n",
            "   -0.23204187]\n",
            "  [-0.37405935  0.34080628 -0.09084032 ... -0.22262707  0.19700214\n",
            "   -0.23204187]\n",
            "  [-0.37405935  0.34080628 -0.09084032 ... -0.22262707  0.19700214\n",
            "   -0.23204187]\n",
            "  ...\n",
            "  [-0.37405935  0.34080628 -0.09084032 ... -0.22262707  0.19700214\n",
            "   -0.23204187]\n",
            "  [-0.37405935  0.34080628 -0.09084032 ... -0.22262707  0.19700214\n",
            "   -0.23204187]\n",
            "  [-0.37405935  0.34080628 -0.09084032 ... -0.22262707  0.19700214\n",
            "   -0.23204187]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[-0.37405935  0.34080628 -0.09084032 ... -0.22262707  0.19700214\n",
            "   -0.23204187]\n",
            "  [-0.37405935  0.34080628 -0.09084032 ... -0.22262707  0.19700214\n",
            "   -0.23204187]\n",
            "  [-0.37405935  0.34080628 -0.09084032 ... -0.22262707  0.19700214\n",
            "   -0.23204187]\n",
            "  ...\n",
            "  [-0.37405935  0.34080628 -0.09084032 ... -0.22262707  0.19700214\n",
            "   -0.23204187]\n",
            "  [-0.37405935  0.34080628 -0.09084032 ... -0.22262707  0.19700214\n",
            "   -0.23204187]\n",
            "  [-0.37405935  0.34080628 -0.09084032 ... -0.22262707  0.19700214\n",
            "   -0.23204187]]\n",
            "\n",
            " [[-0.37405935  0.34080628 -0.09084032 ... -0.22262707  0.19700214\n",
            "   -0.23204187]\n",
            "  [-0.37405935  0.34080628 -0.09084032 ... -0.22262707  0.19700214\n",
            "   -0.23204187]\n",
            "  [-0.37405935  0.34080628 -0.09084032 ... -0.22262707  0.19700214\n",
            "   -0.23204187]\n",
            "  ...\n",
            "  [-0.37405935  0.34080628 -0.09084032 ... -0.22262707  0.19700214\n",
            "   -0.23204187]\n",
            "  [-0.37405935  0.34080628 -0.09084032 ... -0.22262707  0.19700214\n",
            "   -0.23204187]\n",
            "  [-0.37405935  0.34080628 -0.09084032 ... -0.22262707  0.19700214\n",
            "   -0.23204187]]\n",
            "\n",
            " [[-0.37405935  0.34080628 -0.09084032 ... -0.22262707  0.19700214\n",
            "   -0.23204187]\n",
            "  [-0.37405935  0.34080628 -0.09084032 ... -0.22262707  0.19700214\n",
            "   -0.23204187]\n",
            "  [-0.37405935  0.34080628 -0.09084032 ... -0.22262707  0.19700214\n",
            "   -0.23204187]\n",
            "  ...\n",
            "  [-0.37405935  0.34080628 -0.09084032 ... -0.22262707  0.19700214\n",
            "   -0.23204187]\n",
            "  [-0.37405935  0.34080628 -0.09084032 ... -0.22262707  0.19700214\n",
            "   -0.23204187]\n",
            "  [-0.37405935  0.34080628 -0.09084032 ... -0.22262707  0.19700214\n",
            "   -0.23204187]]], shape=(128, 764, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.00307803 -0.00307803 -0.00307803 ... -0.00307803 -0.00307803\n",
            "  -0.00307803]\n",
            " [-0.00307803 -0.00307803 -0.00307803 ... -0.00307803 -0.00307803\n",
            "  -0.00307803]\n",
            " [-0.00307803 -0.00307803 -0.00307803 ... -0.00307803 -0.00307803\n",
            "  -0.00307803]\n",
            " ...\n",
            " [-0.00307803 -0.00307803 -0.00307803 ... -0.00307803 -0.00307803\n",
            "  -0.00307803]\n",
            " [-0.00307803 -0.00307803 -0.00307803 ... -0.00307803 -0.00307803\n",
            "  -0.00307803]\n",
            " [-0.00307803 -0.00307803 -0.00307803 ... -0.00307803 -0.00307803\n",
            "  -0.00307803]], shape=(512, 128), dtype=float32) tf.Tensor(\n",
            "[[-0.00307803 -0.00307803 -0.00307803 ... -0.00307803 -0.00307803\n",
            "  -0.00307803]\n",
            " [-0.00307803 -0.00307803 -0.00307803 ... -0.00307803 -0.00307803\n",
            "  -0.00307803]\n",
            " [-0.00307803 -0.00307803 -0.00307803 ... -0.00307803 -0.00307803\n",
            "  -0.00307803]\n",
            " ...\n",
            " [-0.00307803 -0.00307803 -0.00307803 ... -0.00307803 -0.00307803\n",
            "  -0.00307803]\n",
            " [-0.00307803 -0.00307803 -0.00307803 ... -0.00307803 -0.00307803\n",
            "  -0.00307803]\n",
            " [-0.00307803 -0.00307803 -0.00307803 ... -0.00307803 -0.00307803\n",
            "  -0.00307803]], shape=(252, 128), dtype=float32)\n",
            "(128, 764) (512, 1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_15/kernel:0', 'dense_15/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_15/kernel:0', 'dense_15/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch 1, Batch 91/100, Loss=3.13776e-04\n",
            "(1, 764, 1)\n",
            "tf.Tensor(\n",
            "[[[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " [[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]], shape=(128, 764, 1), dtype=float32) tf.Tensor(\n",
            "[[[-0.37288553  0.34061846 -0.08984713 ... -0.22342525  0.1960434\n",
            "   -0.23119548]\n",
            "  [-0.37288553  0.34061846 -0.08984713 ... -0.22342525  0.1960434\n",
            "   -0.23119548]\n",
            "  [-0.37288553  0.34061846 -0.08984713 ... -0.22342525  0.1960434\n",
            "   -0.23119548]\n",
            "  ...\n",
            "  [-0.37288553  0.34061846 -0.08984713 ... -0.22342525  0.1960434\n",
            "   -0.23119548]\n",
            "  [-0.37288553  0.34061846 -0.08984713 ... -0.22342525  0.1960434\n",
            "   -0.23119548]\n",
            "  [-0.37288553  0.34061846 -0.08984713 ... -0.22342525  0.1960434\n",
            "   -0.23119548]]\n",
            "\n",
            " [[-0.37288553  0.34061846 -0.08984713 ... -0.22342525  0.1960434\n",
            "   -0.23119548]\n",
            "  [-0.37288553  0.34061846 -0.08984713 ... -0.22342525  0.1960434\n",
            "   -0.23119548]\n",
            "  [-0.37288553  0.34061846 -0.08984713 ... -0.22342525  0.1960434\n",
            "   -0.23119548]\n",
            "  ...\n",
            "  [-0.37288553  0.34061846 -0.08984713 ... -0.22342525  0.1960434\n",
            "   -0.23119548]\n",
            "  [-0.37288553  0.34061846 -0.08984713 ... -0.22342525  0.1960434\n",
            "   -0.23119548]\n",
            "  [-0.37288553  0.34061846 -0.08984713 ... -0.22342525  0.1960434\n",
            "   -0.23119548]]\n",
            "\n",
            " [[-0.37288553  0.34061846 -0.08984713 ... -0.22342525  0.1960434\n",
            "   -0.23119548]\n",
            "  [-0.37288553  0.34061846 -0.08984713 ... -0.22342525  0.1960434\n",
            "   -0.23119548]\n",
            "  [-0.37288553  0.34061846 -0.08984713 ... -0.22342525  0.1960434\n",
            "   -0.23119548]\n",
            "  ...\n",
            "  [-0.37288553  0.34061846 -0.08984713 ... -0.22342525  0.1960434\n",
            "   -0.23119548]\n",
            "  [-0.37288553  0.34061846 -0.08984713 ... -0.22342525  0.1960434\n",
            "   -0.23119548]\n",
            "  [-0.37288553  0.34061846 -0.08984713 ... -0.22342525  0.1960434\n",
            "   -0.23119548]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[-0.37288553  0.34061846 -0.08984713 ... -0.22342525  0.1960434\n",
            "   -0.23119548]\n",
            "  [-0.37288553  0.34061846 -0.08984713 ... -0.22342525  0.1960434\n",
            "   -0.23119548]\n",
            "  [-0.37288553  0.34061846 -0.08984713 ... -0.22342525  0.1960434\n",
            "   -0.23119548]\n",
            "  ...\n",
            "  [-0.37288553  0.34061846 -0.08984713 ... -0.22342525  0.1960434\n",
            "   -0.23119548]\n",
            "  [-0.37288553  0.34061846 -0.08984713 ... -0.22342525  0.1960434\n",
            "   -0.23119548]\n",
            "  [-0.37288553  0.34061846 -0.08984713 ... -0.22342525  0.1960434\n",
            "   -0.23119548]]\n",
            "\n",
            " [[-0.37288553  0.34061846 -0.08984713 ... -0.22342525  0.1960434\n",
            "   -0.23119548]\n",
            "  [-0.37288553  0.34061846 -0.08984713 ... -0.22342525  0.1960434\n",
            "   -0.23119548]\n",
            "  [-0.37288553  0.34061846 -0.08984713 ... -0.22342525  0.1960434\n",
            "   -0.23119548]\n",
            "  ...\n",
            "  [-0.37288553  0.34061846 -0.08984713 ... -0.22342525  0.1960434\n",
            "   -0.23119548]\n",
            "  [-0.37288553  0.34061846 -0.08984713 ... -0.22342525  0.1960434\n",
            "   -0.23119548]\n",
            "  [-0.37288553  0.34061846 -0.08984713 ... -0.22342525  0.1960434\n",
            "   -0.23119548]]\n",
            "\n",
            " [[-0.37288553  0.34061846 -0.08984713 ... -0.22342525  0.1960434\n",
            "   -0.23119548]\n",
            "  [-0.37288553  0.34061846 -0.08984713 ... -0.22342525  0.1960434\n",
            "   -0.23119548]\n",
            "  [-0.37288553  0.34061846 -0.08984713 ... -0.22342525  0.1960434\n",
            "   -0.23119548]\n",
            "  ...\n",
            "  [-0.37288553  0.34061846 -0.08984713 ... -0.22342525  0.1960434\n",
            "   -0.23119548]\n",
            "  [-0.37288553  0.34061846 -0.08984713 ... -0.22342525  0.1960434\n",
            "   -0.23119548]\n",
            "  [-0.37288553  0.34061846 -0.08984713 ... -0.22342525  0.1960434\n",
            "   -0.23119548]]], shape=(128, 764, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[0.00346664 0.00346664 0.00346664 ... 0.00346664 0.00346664 0.00346664]\n",
            " [0.00346664 0.00346664 0.00346664 ... 0.00346664 0.00346664 0.00346664]\n",
            " [0.00346664 0.00346664 0.00346664 ... 0.00346664 0.00346664 0.00346664]\n",
            " ...\n",
            " [0.00346664 0.00346664 0.00346664 ... 0.00346664 0.00346664 0.00346664]\n",
            " [0.00346664 0.00346664 0.00346664 ... 0.00346664 0.00346664 0.00346664]\n",
            " [0.00346664 0.00346664 0.00346664 ... 0.00346664 0.00346664 0.00346664]], shape=(512, 128), dtype=float32) tf.Tensor(\n",
            "[[0.00346664 0.00346664 0.00346664 ... 0.00346664 0.00346664 0.00346664]\n",
            " [0.00346664 0.00346664 0.00346664 ... 0.00346664 0.00346664 0.00346664]\n",
            " [0.00346664 0.00346664 0.00346664 ... 0.00346664 0.00346664 0.00346664]\n",
            " ...\n",
            " [0.00346664 0.00346664 0.00346664 ... 0.00346664 0.00346664 0.00346664]\n",
            " [0.00346664 0.00346664 0.00346664 ... 0.00346664 0.00346664 0.00346664]\n",
            " [0.00346664 0.00346664 0.00346664 ... 0.00346664 0.00346664 0.00346664]], shape=(252, 128), dtype=float32)\n",
            "(128, 764) (512, 1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_15/kernel:0', 'dense_15/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_15/kernel:0', 'dense_15/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch 1, Batch 92/100, Loss=2.49368e-04\n",
            "(1, 764, 1)\n",
            "tf.Tensor(\n",
            "[[[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " [[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " [[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]], shape=(128, 764, 1), dtype=float32) tf.Tensor(\n",
            "[[[-0.37199935  0.34047487 -0.08908644 ... -0.22404301  0.1953104\n",
            "   -0.23054373]\n",
            "  [-0.37199935  0.34047487 -0.08908644 ... -0.22404301  0.1953104\n",
            "   -0.23054373]\n",
            "  [-0.37199935  0.34047487 -0.08908644 ... -0.22404301  0.1953104\n",
            "   -0.23054373]\n",
            "  ...\n",
            "  [-0.37199935  0.34047487 -0.08908644 ... -0.22404301  0.1953104\n",
            "   -0.23054373]\n",
            "  [-0.37199935  0.34047487 -0.08908644 ... -0.22404301  0.1953104\n",
            "   -0.23054373]\n",
            "  [-0.37199935  0.34047487 -0.08908644 ... -0.22404301  0.1953104\n",
            "   -0.23054373]]\n",
            "\n",
            " [[-0.37199935  0.34047487 -0.08908644 ... -0.22404301  0.1953104\n",
            "   -0.23054373]\n",
            "  [-0.37199935  0.34047487 -0.08908644 ... -0.22404301  0.1953104\n",
            "   -0.23054373]\n",
            "  [-0.37199935  0.34047487 -0.08908644 ... -0.22404301  0.1953104\n",
            "   -0.23054373]\n",
            "  ...\n",
            "  [-0.37199935  0.34047487 -0.08908644 ... -0.22404301  0.1953104\n",
            "   -0.23054373]\n",
            "  [-0.37199935  0.34047487 -0.08908644 ... -0.22404301  0.1953104\n",
            "   -0.23054373]\n",
            "  [-0.37199935  0.34047487 -0.08908644 ... -0.22404301  0.1953104\n",
            "   -0.23054373]]\n",
            "\n",
            " [[-0.37199935  0.34047487 -0.08908644 ... -0.22404301  0.1953104\n",
            "   -0.23054373]\n",
            "  [-0.37199935  0.34047487 -0.08908644 ... -0.22404301  0.1953104\n",
            "   -0.23054373]\n",
            "  [-0.37199935  0.34047487 -0.08908644 ... -0.22404301  0.1953104\n",
            "   -0.23054373]\n",
            "  ...\n",
            "  [-0.37199935  0.34047487 -0.08908644 ... -0.22404301  0.1953104\n",
            "   -0.23054373]\n",
            "  [-0.37199935  0.34047487 -0.08908644 ... -0.22404301  0.1953104\n",
            "   -0.23054373]\n",
            "  [-0.37199935  0.34047487 -0.08908644 ... -0.22404301  0.1953104\n",
            "   -0.23054373]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[-0.37199935  0.34047487 -0.08908644 ... -0.22404301  0.1953104\n",
            "   -0.23054373]\n",
            "  [-0.37199935  0.34047487 -0.08908644 ... -0.22404301  0.1953104\n",
            "   -0.23054373]\n",
            "  [-0.37199935  0.34047487 -0.08908644 ... -0.22404301  0.1953104\n",
            "   -0.23054373]\n",
            "  ...\n",
            "  [-0.37199935  0.34047487 -0.08908644 ... -0.22404301  0.1953104\n",
            "   -0.23054373]\n",
            "  [-0.37199935  0.34047487 -0.08908644 ... -0.22404301  0.1953104\n",
            "   -0.23054373]\n",
            "  [-0.37199935  0.34047487 -0.08908644 ... -0.22404301  0.1953104\n",
            "   -0.23054373]]\n",
            "\n",
            " [[-0.37199935  0.34047487 -0.08908644 ... -0.22404301  0.1953104\n",
            "   -0.23054373]\n",
            "  [-0.37199935  0.34047487 -0.08908644 ... -0.22404301  0.1953104\n",
            "   -0.23054373]\n",
            "  [-0.37199935  0.34047487 -0.08908644 ... -0.22404301  0.1953104\n",
            "   -0.23054373]\n",
            "  ...\n",
            "  [-0.37199935  0.34047487 -0.08908644 ... -0.22404301  0.1953104\n",
            "   -0.23054373]\n",
            "  [-0.37199935  0.34047487 -0.08908644 ... -0.22404301  0.1953104\n",
            "   -0.23054373]\n",
            "  [-0.37199935  0.34047487 -0.08908644 ... -0.22404301  0.1953104\n",
            "   -0.23054373]]\n",
            "\n",
            " [[-0.37199935  0.34047487 -0.08908644 ... -0.22404301  0.1953104\n",
            "   -0.23054373]\n",
            "  [-0.37199935  0.34047487 -0.08908644 ... -0.22404301  0.1953104\n",
            "   -0.23054373]\n",
            "  [-0.37199935  0.34047487 -0.08908644 ... -0.22404301  0.1953104\n",
            "   -0.23054373]\n",
            "  ...\n",
            "  [-0.37199935  0.34047487 -0.08908644 ... -0.22404301  0.1953104\n",
            "   -0.23054373]\n",
            "  [-0.37199935  0.34047487 -0.08908644 ... -0.22404301  0.1953104\n",
            "   -0.23054373]\n",
            "  [-0.37199935  0.34047487 -0.08908644 ... -0.22404301  0.1953104\n",
            "   -0.23054373]]], shape=(128, 764, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[0.00843666 0.00843666 0.00843666 ... 0.00843666 0.00843666 0.00843666]\n",
            " [0.00843666 0.00843666 0.00843666 ... 0.00843666 0.00843666 0.00843666]\n",
            " [0.00843666 0.00843666 0.00843666 ... 0.00843666 0.00843666 0.00843666]\n",
            " ...\n",
            " [0.00843666 0.00843666 0.00843666 ... 0.00843666 0.00843666 0.00843666]\n",
            " [0.00843666 0.00843666 0.00843666 ... 0.00843666 0.00843666 0.00843666]\n",
            " [0.00843666 0.00843666 0.00843666 ... 0.00843666 0.00843666 0.00843666]], shape=(512, 128), dtype=float32) tf.Tensor(\n",
            "[[0.00843666 0.00843666 0.00843666 ... 0.00843666 0.00843666 0.00843666]\n",
            " [0.00843666 0.00843666 0.00843666 ... 0.00843666 0.00843666 0.00843666]\n",
            " [0.00843666 0.00843666 0.00843666 ... 0.00843666 0.00843666 0.00843666]\n",
            " ...\n",
            " [0.00843666 0.00843666 0.00843666 ... 0.00843666 0.00843666 0.00843666]\n",
            " [0.00843666 0.00843666 0.00843666 ... 0.00843666 0.00843666 0.00843666]\n",
            " [0.00843666 0.00843666 0.00843666 ... 0.00843666 0.00843666 0.00843666]], shape=(252, 128), dtype=float32)\n",
            "(128, 764) (512, 1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_15/kernel:0', 'dense_15/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_15/kernel:0', 'dense_15/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch 1, Batch 93/100, Loss=3.65132e-04\n",
            "(1, 764, 1)\n",
            "tf.Tensor(\n",
            "[[[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " [[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " [[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]], shape=(128, 764, 1), dtype=float32) tf.Tensor(\n",
            "[[[-0.37148994  0.34038976 -0.08863511 ... -0.22442633  0.19487275\n",
            "   -0.23014444]\n",
            "  [-0.37148994  0.34038976 -0.08863511 ... -0.22442633  0.19487275\n",
            "   -0.23014444]\n",
            "  [-0.37148994  0.34038976 -0.08863511 ... -0.22442633  0.19487275\n",
            "   -0.23014444]\n",
            "  ...\n",
            "  [-0.37148994  0.34038976 -0.08863511 ... -0.22442633  0.19487275\n",
            "   -0.23014444]\n",
            "  [-0.37148994  0.34038976 -0.08863511 ... -0.22442633  0.19487275\n",
            "   -0.23014444]\n",
            "  [-0.37148994  0.34038976 -0.08863511 ... -0.22442633  0.19487275\n",
            "   -0.23014444]]\n",
            "\n",
            " [[-0.37148994  0.34038976 -0.08863511 ... -0.22442633  0.19487275\n",
            "   -0.23014444]\n",
            "  [-0.37148994  0.34038976 -0.08863511 ... -0.22442633  0.19487275\n",
            "   -0.23014444]\n",
            "  [-0.37148994  0.34038976 -0.08863511 ... -0.22442633  0.19487275\n",
            "   -0.23014444]\n",
            "  ...\n",
            "  [-0.37148994  0.34038976 -0.08863511 ... -0.22442633  0.19487275\n",
            "   -0.23014444]\n",
            "  [-0.37148994  0.34038976 -0.08863511 ... -0.22442633  0.19487275\n",
            "   -0.23014444]\n",
            "  [-0.37148994  0.34038976 -0.08863511 ... -0.22442633  0.19487275\n",
            "   -0.23014444]]\n",
            "\n",
            " [[-0.37148994  0.34038976 -0.08863511 ... -0.22442633  0.19487275\n",
            "   -0.23014444]\n",
            "  [-0.37148994  0.34038976 -0.08863511 ... -0.22442633  0.19487275\n",
            "   -0.23014444]\n",
            "  [-0.37148994  0.34038976 -0.08863511 ... -0.22442633  0.19487275\n",
            "   -0.23014444]\n",
            "  ...\n",
            "  [-0.37148994  0.34038976 -0.08863511 ... -0.22442633  0.19487275\n",
            "   -0.23014444]\n",
            "  [-0.37148994  0.34038976 -0.08863511 ... -0.22442633  0.19487275\n",
            "   -0.23014444]\n",
            "  [-0.37148994  0.34038976 -0.08863511 ... -0.22442633  0.19487275\n",
            "   -0.23014444]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[-0.37148994  0.34038976 -0.08863511 ... -0.22442633  0.19487275\n",
            "   -0.23014444]\n",
            "  [-0.37148994  0.34038976 -0.08863511 ... -0.22442633  0.19487275\n",
            "   -0.23014444]\n",
            "  [-0.37148994  0.34038976 -0.08863511 ... -0.22442633  0.19487275\n",
            "   -0.23014444]\n",
            "  ...\n",
            "  [-0.37148994  0.34038976 -0.08863511 ... -0.22442633  0.19487275\n",
            "   -0.23014444]\n",
            "  [-0.37148994  0.34038976 -0.08863511 ... -0.22442633  0.19487275\n",
            "   -0.23014444]\n",
            "  [-0.37148994  0.34038976 -0.08863511 ... -0.22442633  0.19487275\n",
            "   -0.23014444]]\n",
            "\n",
            " [[-0.37148994  0.34038976 -0.08863511 ... -0.22442633  0.19487275\n",
            "   -0.23014444]\n",
            "  [-0.37148994  0.34038976 -0.08863511 ... -0.22442633  0.19487275\n",
            "   -0.23014444]\n",
            "  [-0.37148994  0.34038976 -0.08863511 ... -0.22442633  0.19487275\n",
            "   -0.23014444]\n",
            "  ...\n",
            "  [-0.37148994  0.34038976 -0.08863511 ... -0.22442633  0.19487275\n",
            "   -0.23014444]\n",
            "  [-0.37148994  0.34038976 -0.08863511 ... -0.22442633  0.19487275\n",
            "   -0.23014444]\n",
            "  [-0.37148994  0.34038976 -0.08863511 ... -0.22442633  0.19487275\n",
            "   -0.23014444]]\n",
            "\n",
            " [[-0.37148994  0.34038976 -0.08863511 ... -0.22442633  0.19487275\n",
            "   -0.23014444]\n",
            "  [-0.37148994  0.34038976 -0.08863511 ... -0.22442633  0.19487275\n",
            "   -0.23014444]\n",
            "  [-0.37148994  0.34038976 -0.08863511 ... -0.22442633  0.19487275\n",
            "   -0.23014444]\n",
            "  ...\n",
            "  [-0.37148994  0.34038976 -0.08863511 ... -0.22442633  0.19487275\n",
            "   -0.23014444]\n",
            "  [-0.37148994  0.34038976 -0.08863511 ... -0.22442633  0.19487275\n",
            "   -0.23014444]\n",
            "  [-0.37148994  0.34038976 -0.08863511 ... -0.22442633  0.19487275\n",
            "   -0.23014444]]], shape=(128, 764, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[0.01134967 0.01134967 0.01134967 ... 0.01134967 0.01134967 0.01134967]\n",
            " [0.01134967 0.01134967 0.01134967 ... 0.01134967 0.01134967 0.01134967]\n",
            " [0.01134967 0.01134967 0.01134967 ... 0.01134967 0.01134967 0.01134967]\n",
            " ...\n",
            " [0.01134967 0.01134967 0.01134967 ... 0.01134967 0.01134967 0.01134967]\n",
            " [0.01134967 0.01134967 0.01134967 ... 0.01134967 0.01134967 0.01134967]\n",
            " [0.01134967 0.01134967 0.01134967 ... 0.01134967 0.01134967 0.01134967]], shape=(512, 128), dtype=float32) tf.Tensor(\n",
            "[[0.01134967 0.01134967 0.01134967 ... 0.01134967 0.01134967 0.01134967]\n",
            " [0.01134967 0.01134967 0.01134967 ... 0.01134967 0.01134967 0.01134967]\n",
            " [0.01134967 0.01134967 0.01134967 ... 0.01134967 0.01134967 0.01134967]\n",
            " ...\n",
            " [0.01134967 0.01134967 0.01134967 ... 0.01134967 0.01134967 0.01134967]\n",
            " [0.01134967 0.01134967 0.01134967 ... 0.01134967 0.01134967 0.01134967]\n",
            " [0.01134967 0.01134967 0.01134967 ... 0.01134967 0.01134967 0.01134967]], shape=(252, 128), dtype=float32)\n",
            "(128, 764) (512, 1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_15/kernel:0', 'dense_15/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_15/kernel:0', 'dense_15/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch 1, Batch 94/100, Loss=4.01037e-04\n",
            "(1, 764, 1)\n",
            "tf.Tensor(\n",
            "[[[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " [[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " [[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]], shape=(128, 764, 1), dtype=float32) tf.Tensor(\n",
            "[[[-0.37143025  0.34037519 -0.08855836 ... -0.22453043  0.19478892\n",
            "   -0.23004696]\n",
            "  [-0.37143025  0.34037519 -0.08855836 ... -0.22453043  0.19478892\n",
            "   -0.23004696]\n",
            "  [-0.37143025  0.34037519 -0.08855836 ... -0.22453043  0.19478892\n",
            "   -0.23004696]\n",
            "  ...\n",
            "  [-0.37143025  0.34037519 -0.08855836 ... -0.22453043  0.19478892\n",
            "   -0.23004696]\n",
            "  [-0.37143025  0.34037519 -0.08855836 ... -0.22453043  0.19478892\n",
            "   -0.23004696]\n",
            "  [-0.37143025  0.34037519 -0.08855836 ... -0.22453043  0.19478892\n",
            "   -0.23004696]]\n",
            "\n",
            " [[-0.37143025  0.34037519 -0.08855836 ... -0.22453043  0.19478892\n",
            "   -0.23004696]\n",
            "  [-0.37143025  0.34037519 -0.08855836 ... -0.22453043  0.19478892\n",
            "   -0.23004696]\n",
            "  [-0.37143025  0.34037519 -0.08855836 ... -0.22453043  0.19478892\n",
            "   -0.23004696]\n",
            "  ...\n",
            "  [-0.37143025  0.34037519 -0.08855836 ... -0.22453043  0.19478892\n",
            "   -0.23004696]\n",
            "  [-0.37143025  0.34037519 -0.08855836 ... -0.22453043  0.19478892\n",
            "   -0.23004696]\n",
            "  [-0.37143025  0.34037519 -0.08855836 ... -0.22453043  0.19478892\n",
            "   -0.23004696]]\n",
            "\n",
            " [[-0.37143025  0.34037519 -0.08855836 ... -0.22453043  0.19478892\n",
            "   -0.23004696]\n",
            "  [-0.37143025  0.34037519 -0.08855836 ... -0.22453043  0.19478892\n",
            "   -0.23004696]\n",
            "  [-0.37143025  0.34037519 -0.08855836 ... -0.22453043  0.19478892\n",
            "   -0.23004696]\n",
            "  ...\n",
            "  [-0.37143025  0.34037519 -0.08855836 ... -0.22453043  0.19478892\n",
            "   -0.23004696]\n",
            "  [-0.37143025  0.34037519 -0.08855836 ... -0.22453043  0.19478892\n",
            "   -0.23004696]\n",
            "  [-0.37143025  0.34037519 -0.08855836 ... -0.22453043  0.19478892\n",
            "   -0.23004696]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[-0.37143025  0.34037519 -0.08855836 ... -0.22453043  0.19478892\n",
            "   -0.23004696]\n",
            "  [-0.37143025  0.34037519 -0.08855836 ... -0.22453043  0.19478892\n",
            "   -0.23004696]\n",
            "  [-0.37143025  0.34037519 -0.08855836 ... -0.22453043  0.19478892\n",
            "   -0.23004696]\n",
            "  ...\n",
            "  [-0.37143025  0.34037519 -0.08855836 ... -0.22453043  0.19478892\n",
            "   -0.23004696]\n",
            "  [-0.37143025  0.34037519 -0.08855836 ... -0.22453043  0.19478892\n",
            "   -0.23004696]\n",
            "  [-0.37143025  0.34037519 -0.08855836 ... -0.22453043  0.19478892\n",
            "   -0.23004696]]\n",
            "\n",
            " [[-0.37143025  0.34037519 -0.08855836 ... -0.22453043  0.19478892\n",
            "   -0.23004696]\n",
            "  [-0.37143025  0.34037519 -0.08855836 ... -0.22453043  0.19478892\n",
            "   -0.23004696]\n",
            "  [-0.37143025  0.34037519 -0.08855836 ... -0.22453043  0.19478892\n",
            "   -0.23004696]\n",
            "  ...\n",
            "  [-0.37143025  0.34037519 -0.08855836 ... -0.22453043  0.19478892\n",
            "   -0.23004696]\n",
            "  [-0.37143025  0.34037519 -0.08855836 ... -0.22453043  0.19478892\n",
            "   -0.23004696]\n",
            "  [-0.37143025  0.34037519 -0.08855836 ... -0.22453043  0.19478892\n",
            "   -0.23004696]]\n",
            "\n",
            " [[-0.37143025  0.34037519 -0.08855836 ... -0.22453043  0.19478892\n",
            "   -0.23004696]\n",
            "  [-0.37143025  0.34037519 -0.08855836 ... -0.22453043  0.19478892\n",
            "   -0.23004696]\n",
            "  [-0.37143025  0.34037519 -0.08855836 ... -0.22453043  0.19478892\n",
            "   -0.23004696]\n",
            "  ...\n",
            "  [-0.37143025  0.34037519 -0.08855836 ... -0.22453043  0.19478892\n",
            "   -0.23004696]\n",
            "  [-0.37143025  0.34037519 -0.08855836 ... -0.22453043  0.19478892\n",
            "   -0.23004696]\n",
            "  [-0.37143025  0.34037519 -0.08855836 ... -0.22453043  0.19478892\n",
            "   -0.23004696]]], shape=(128, 764, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[0.01180905 0.01180905 0.01180905 ... 0.01180905 0.01180905 0.01180905]\n",
            " [0.01180905 0.01180905 0.01180905 ... 0.01180905 0.01180905 0.01180905]\n",
            " [0.01180905 0.01180905 0.01180905 ... 0.01180905 0.01180905 0.01180905]\n",
            " ...\n",
            " [0.01180905 0.01180905 0.01180905 ... 0.01180905 0.01180905 0.01180905]\n",
            " [0.01180905 0.01180905 0.01180905 ... 0.01180905 0.01180905 0.01180905]\n",
            " [0.01180905 0.01180905 0.01180905 ... 0.01180905 0.01180905 0.01180905]], shape=(512, 128), dtype=float32) tf.Tensor(\n",
            "[[0.01180905 0.01180905 0.01180905 ... 0.01180905 0.01180905 0.01180905]\n",
            " [0.01180905 0.01180905 0.01180905 ... 0.01180905 0.01180905 0.01180905]\n",
            " [0.01180905 0.01180905 0.01180905 ... 0.01180905 0.01180905 0.01180905]\n",
            " ...\n",
            " [0.01180905 0.01180905 0.01180905 ... 0.01180905 0.01180905 0.01180905]\n",
            " [0.01180905 0.01180905 0.01180905 ... 0.01180905 0.01180905 0.01180905]\n",
            " [0.01180905 0.01180905 0.01180905 ... 0.01180905 0.01180905 0.01180905]], shape=(252, 128), dtype=float32)\n",
            "(128, 764) (512, 1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_15/kernel:0', 'dense_15/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_15/kernel:0', 'dense_15/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch 1, Batch 95/100, Loss=4.12781e-04\n",
            "(1, 764, 1)\n",
            "tf.Tensor(\n",
            "[[[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " [[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " [[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]], shape=(128, 764, 1), dtype=float32) tf.Tensor(\n",
            "[[[-0.37177247  0.3404231  -0.08881777 ... -0.22438344  0.19502087\n",
            "   -0.23021975]\n",
            "  [-0.37177247  0.3404231  -0.08881777 ... -0.22438344  0.19502087\n",
            "   -0.23021975]\n",
            "  [-0.37177247  0.3404231  -0.08881777 ... -0.22438344  0.19502087\n",
            "   -0.23021975]\n",
            "  ...\n",
            "  [-0.37177247  0.3404231  -0.08881777 ... -0.22438344  0.19502087\n",
            "   -0.23021975]\n",
            "  [-0.37177247  0.3404231  -0.08881777 ... -0.22438344  0.19502087\n",
            "   -0.23021975]\n",
            "  [-0.37177247  0.3404231  -0.08881777 ... -0.22438344  0.19502087\n",
            "   -0.23021975]]\n",
            "\n",
            " [[-0.37177247  0.3404231  -0.08881777 ... -0.22438344  0.19502087\n",
            "   -0.23021975]\n",
            "  [-0.37177247  0.3404231  -0.08881777 ... -0.22438344  0.19502087\n",
            "   -0.23021975]\n",
            "  [-0.37177247  0.3404231  -0.08881777 ... -0.22438344  0.19502087\n",
            "   -0.23021975]\n",
            "  ...\n",
            "  [-0.37177247  0.3404231  -0.08881777 ... -0.22438344  0.19502087\n",
            "   -0.23021975]\n",
            "  [-0.37177247  0.3404231  -0.08881777 ... -0.22438344  0.19502087\n",
            "   -0.23021975]\n",
            "  [-0.37177247  0.3404231  -0.08881777 ... -0.22438344  0.19502087\n",
            "   -0.23021975]]\n",
            "\n",
            " [[-0.37177247  0.3404231  -0.08881777 ... -0.22438344  0.19502087\n",
            "   -0.23021975]\n",
            "  [-0.37177247  0.3404231  -0.08881777 ... -0.22438344  0.19502087\n",
            "   -0.23021975]\n",
            "  [-0.37177247  0.3404231  -0.08881777 ... -0.22438344  0.19502087\n",
            "   -0.23021975]\n",
            "  ...\n",
            "  [-0.37177247  0.3404231  -0.08881777 ... -0.22438344  0.19502087\n",
            "   -0.23021975]\n",
            "  [-0.37177247  0.3404231  -0.08881777 ... -0.22438344  0.19502087\n",
            "   -0.23021975]\n",
            "  [-0.37177247  0.3404231  -0.08881777 ... -0.22438344  0.19502087\n",
            "   -0.23021975]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[-0.37177247  0.3404231  -0.08881777 ... -0.22438344  0.19502087\n",
            "   -0.23021975]\n",
            "  [-0.37177247  0.3404231  -0.08881777 ... -0.22438344  0.19502087\n",
            "   -0.23021975]\n",
            "  [-0.37177247  0.3404231  -0.08881777 ... -0.22438344  0.19502087\n",
            "   -0.23021975]\n",
            "  ...\n",
            "  [-0.37177247  0.3404231  -0.08881777 ... -0.22438344  0.19502087\n",
            "   -0.23021975]\n",
            "  [-0.37177247  0.3404231  -0.08881777 ... -0.22438344  0.19502087\n",
            "   -0.23021975]\n",
            "  [-0.37177247  0.3404231  -0.08881777 ... -0.22438344  0.19502087\n",
            "   -0.23021975]]\n",
            "\n",
            " [[-0.37177247  0.3404231  -0.08881777 ... -0.22438344  0.19502087\n",
            "   -0.23021975]\n",
            "  [-0.37177247  0.3404231  -0.08881777 ... -0.22438344  0.19502087\n",
            "   -0.23021975]\n",
            "  [-0.37177247  0.3404231  -0.08881777 ... -0.22438344  0.19502087\n",
            "   -0.23021975]\n",
            "  ...\n",
            "  [-0.37177247  0.3404231  -0.08881777 ... -0.22438344  0.19502087\n",
            "   -0.23021975]\n",
            "  [-0.37177247  0.3404231  -0.08881777 ... -0.22438344  0.19502087\n",
            "   -0.23021975]\n",
            "  [-0.37177247  0.3404231  -0.08881777 ... -0.22438344  0.19502087\n",
            "   -0.23021975]]\n",
            "\n",
            " [[-0.37177247  0.3404231  -0.08881777 ... -0.22438344  0.19502087\n",
            "   -0.23021975]\n",
            "  [-0.37177247  0.3404231  -0.08881777 ... -0.22438344  0.19502087\n",
            "   -0.23021975]\n",
            "  [-0.37177247  0.3404231  -0.08881777 ... -0.22438344  0.19502087\n",
            "   -0.23021975]\n",
            "  ...\n",
            "  [-0.37177247  0.3404231  -0.08881777 ... -0.22438344  0.19502087\n",
            "   -0.23021975]\n",
            "  [-0.37177247  0.3404231  -0.08881777 ... -0.22438344  0.19502087\n",
            "   -0.23021975]\n",
            "  [-0.37177247  0.3404231  -0.08881777 ... -0.22438344  0.19502087\n",
            "   -0.23021975]]], shape=(128, 764, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[0.01007053 0.01007053 0.01007053 ... 0.01007053 0.01007053 0.01007053]\n",
            " [0.01007053 0.01007053 0.01007053 ... 0.01007053 0.01007053 0.01007053]\n",
            " [0.01007053 0.01007053 0.01007053 ... 0.01007053 0.01007053 0.01007053]\n",
            " ...\n",
            " [0.01007053 0.01007053 0.01007053 ... 0.01007053 0.01007053 0.01007053]\n",
            " [0.01007053 0.01007053 0.01007053 ... 0.01007053 0.01007053 0.01007053]\n",
            " [0.01007053 0.01007053 0.01007053 ... 0.01007053 0.01007053 0.01007053]], shape=(512, 128), dtype=float32) tf.Tensor(\n",
            "[[0.01007053 0.01007053 0.01007053 ... 0.01007053 0.01007053 0.01007053]\n",
            " [0.01007053 0.01007053 0.01007053 ... 0.01007053 0.01007053 0.01007053]\n",
            " [0.01007053 0.01007053 0.01007053 ... 0.01007053 0.01007053 0.01007053]\n",
            " ...\n",
            " [0.01007053 0.01007053 0.01007053 ... 0.01007053 0.01007053 0.01007053]\n",
            " [0.01007053 0.01007053 0.01007053 ... 0.01007053 0.01007053 0.01007053]\n",
            " [0.01007053 0.01007053 0.01007053 ... 0.01007053 0.01007053 0.01007053]], shape=(252, 128), dtype=float32)\n",
            "(128, 764) (512, 1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_15/kernel:0', 'dense_15/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_15/kernel:0', 'dense_15/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch 1, Batch 96/100, Loss=3.68598e-04\n",
            "(1, 764, 1)\n",
            "tf.Tensor(\n",
            "[[[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " [[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " [[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]], shape=(128, 764, 1), dtype=float32) tf.Tensor(\n",
            "[[[-0.37243855  0.34051955 -0.08935297 ... -0.22403358  0.19550994\n",
            "   -0.23061465]\n",
            "  [-0.37243855  0.34051955 -0.08935297 ... -0.22403358  0.19550994\n",
            "   -0.23061465]\n",
            "  [-0.37243855  0.34051955 -0.08935297 ... -0.22403358  0.19550994\n",
            "   -0.23061465]\n",
            "  ...\n",
            "  [-0.37243855  0.34051955 -0.08935297 ... -0.22403358  0.19550994\n",
            "   -0.23061465]\n",
            "  [-0.37243855  0.34051955 -0.08935297 ... -0.22403358  0.19550994\n",
            "   -0.23061465]\n",
            "  [-0.37243855  0.34051955 -0.08935297 ... -0.22403358  0.19550994\n",
            "   -0.23061465]]\n",
            "\n",
            " [[-0.37243855  0.34051955 -0.08935297 ... -0.22403358  0.19550994\n",
            "   -0.23061465]\n",
            "  [-0.37243855  0.34051955 -0.08935297 ... -0.22403358  0.19550994\n",
            "   -0.23061465]\n",
            "  [-0.37243855  0.34051955 -0.08935297 ... -0.22403358  0.19550994\n",
            "   -0.23061465]\n",
            "  ...\n",
            "  [-0.37243855  0.34051955 -0.08935297 ... -0.22403358  0.19550994\n",
            "   -0.23061465]\n",
            "  [-0.37243855  0.34051955 -0.08935297 ... -0.22403358  0.19550994\n",
            "   -0.23061465]\n",
            "  [-0.37243855  0.34051955 -0.08935297 ... -0.22403358  0.19550994\n",
            "   -0.23061465]]\n",
            "\n",
            " [[-0.37243855  0.34051955 -0.08935297 ... -0.22403358  0.19550994\n",
            "   -0.23061465]\n",
            "  [-0.37243855  0.34051955 -0.08935297 ... -0.22403358  0.19550994\n",
            "   -0.23061465]\n",
            "  [-0.37243855  0.34051955 -0.08935297 ... -0.22403358  0.19550994\n",
            "   -0.23061465]\n",
            "  ...\n",
            "  [-0.37243855  0.34051955 -0.08935297 ... -0.22403358  0.19550994\n",
            "   -0.23061465]\n",
            "  [-0.37243855  0.34051955 -0.08935297 ... -0.22403358  0.19550994\n",
            "   -0.23061465]\n",
            "  [-0.37243855  0.34051955 -0.08935297 ... -0.22403358  0.19550994\n",
            "   -0.23061465]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[-0.37243855  0.34051955 -0.08935297 ... -0.22403358  0.19550994\n",
            "   -0.23061465]\n",
            "  [-0.37243855  0.34051955 -0.08935297 ... -0.22403358  0.19550994\n",
            "   -0.23061465]\n",
            "  [-0.37243855  0.34051955 -0.08935297 ... -0.22403358  0.19550994\n",
            "   -0.23061465]\n",
            "  ...\n",
            "  [-0.37243855  0.34051955 -0.08935297 ... -0.22403358  0.19550994\n",
            "   -0.23061465]\n",
            "  [-0.37243855  0.34051955 -0.08935297 ... -0.22403358  0.19550994\n",
            "   -0.23061465]\n",
            "  [-0.37243855  0.34051955 -0.08935297 ... -0.22403358  0.19550994\n",
            "   -0.23061465]]\n",
            "\n",
            " [[-0.37243855  0.34051955 -0.08935297 ... -0.22403358  0.19550994\n",
            "   -0.23061465]\n",
            "  [-0.37243855  0.34051955 -0.08935297 ... -0.22403358  0.19550994\n",
            "   -0.23061465]\n",
            "  [-0.37243855  0.34051955 -0.08935297 ... -0.22403358  0.19550994\n",
            "   -0.23061465]\n",
            "  ...\n",
            "  [-0.37243855  0.34051955 -0.08935297 ... -0.22403358  0.19550994\n",
            "   -0.23061465]\n",
            "  [-0.37243855  0.34051955 -0.08935297 ... -0.22403358  0.19550994\n",
            "   -0.23061465]\n",
            "  [-0.37243855  0.34051955 -0.08935297 ... -0.22403358  0.19550994\n",
            "   -0.23061465]]\n",
            "\n",
            " [[-0.37243855  0.34051955 -0.08935297 ... -0.22403358  0.19550994\n",
            "   -0.23061465]\n",
            "  [-0.37243855  0.34051955 -0.08935297 ... -0.22403358  0.19550994\n",
            "   -0.23061465]\n",
            "  [-0.37243855  0.34051955 -0.08935297 ... -0.22403358  0.19550994\n",
            "   -0.23061465]\n",
            "  ...\n",
            "  [-0.37243855  0.34051955 -0.08935297 ... -0.22403358  0.19550994\n",
            "   -0.23061465]\n",
            "  [-0.37243855  0.34051955 -0.08935297 ... -0.22403358  0.19550994\n",
            "   -0.23061465]\n",
            "  [-0.37243855  0.34051955 -0.08935297 ... -0.22403358  0.19550994\n",
            "   -0.23061465]]], shape=(128, 764, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[0.00654555 0.00654555 0.00654555 ... 0.00654555 0.00654555 0.00654555]\n",
            " [0.00654555 0.00654555 0.00654555 ... 0.00654555 0.00654555 0.00654555]\n",
            " [0.00654555 0.00654555 0.00654555 ... 0.00654555 0.00654555 0.00654555]\n",
            " ...\n",
            " [0.00654555 0.00654555 0.00654555 ... 0.00654555 0.00654555 0.00654555]\n",
            " [0.00654555 0.00654555 0.00654555 ... 0.00654555 0.00654555 0.00654555]\n",
            " [0.00654555 0.00654555 0.00654555 ... 0.00654555 0.00654555 0.00654555]], shape=(512, 128), dtype=float32) tf.Tensor(\n",
            "[[0.00654555 0.00654555 0.00654555 ... 0.00654555 0.00654555 0.00654555]\n",
            " [0.00654555 0.00654555 0.00654555 ... 0.00654555 0.00654555 0.00654555]\n",
            " [0.00654555 0.00654555 0.00654555 ... 0.00654555 0.00654555 0.00654555]\n",
            " ...\n",
            " [0.00654555 0.00654555 0.00654555 ... 0.00654555 0.00654555 0.00654555]\n",
            " [0.00654555 0.00654555 0.00654555 ... 0.00654555 0.00654555 0.00654555]\n",
            " [0.00654555 0.00654555 0.00654555 ... 0.00654555 0.00654555 0.00654555]], shape=(252, 128), dtype=float32)\n",
            "(128, 764) (512, 1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_15/kernel:0', 'dense_15/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_15/kernel:0', 'dense_15/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch 1, Batch 97/100, Loss=2.13889e-04\n",
            "(1, 764, 1)\n",
            "tf.Tensor(\n",
            "[[[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]], shape=(128, 764, 1), dtype=float32) tf.Tensor(\n",
            "[[[-0.37326583  0.3406416  -0.09002879 ... -0.22357787  0.19612816\n",
            "   -0.23112273]\n",
            "  [-0.37326583  0.3406416  -0.09002879 ... -0.22357787  0.19612816\n",
            "   -0.23112273]\n",
            "  [-0.37326583  0.3406416  -0.09002879 ... -0.22357787  0.19612816\n",
            "   -0.23112273]\n",
            "  ...\n",
            "  [-0.37326583  0.3406416  -0.09002879 ... -0.22357787  0.19612816\n",
            "   -0.23112273]\n",
            "  [-0.37326583  0.3406416  -0.09002879 ... -0.22357787  0.19612816\n",
            "   -0.23112273]\n",
            "  [-0.37326583  0.3406416  -0.09002879 ... -0.22357787  0.19612816\n",
            "   -0.23112273]]\n",
            "\n",
            " [[-0.37326583  0.3406416  -0.09002879 ... -0.22357787  0.19612816\n",
            "   -0.23112273]\n",
            "  [-0.37326583  0.3406416  -0.09002879 ... -0.22357787  0.19612816\n",
            "   -0.23112273]\n",
            "  [-0.37326583  0.3406416  -0.09002879 ... -0.22357787  0.19612816\n",
            "   -0.23112273]\n",
            "  ...\n",
            "  [-0.37326583  0.3406416  -0.09002879 ... -0.22357787  0.19612816\n",
            "   -0.23112273]\n",
            "  [-0.37326583  0.3406416  -0.09002879 ... -0.22357787  0.19612816\n",
            "   -0.23112273]\n",
            "  [-0.37326583  0.3406416  -0.09002879 ... -0.22357787  0.19612816\n",
            "   -0.23112273]]\n",
            "\n",
            " [[-0.37326583  0.3406416  -0.09002879 ... -0.22357787  0.19612816\n",
            "   -0.23112273]\n",
            "  [-0.37326583  0.3406416  -0.09002879 ... -0.22357787  0.19612816\n",
            "   -0.23112273]\n",
            "  [-0.37326583  0.3406416  -0.09002879 ... -0.22357787  0.19612816\n",
            "   -0.23112273]\n",
            "  ...\n",
            "  [-0.37326583  0.3406416  -0.09002879 ... -0.22357787  0.19612816\n",
            "   -0.23112273]\n",
            "  [-0.37326583  0.3406416  -0.09002879 ... -0.22357787  0.19612816\n",
            "   -0.23112273]\n",
            "  [-0.37326583  0.3406416  -0.09002879 ... -0.22357787  0.19612816\n",
            "   -0.23112273]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[-0.37326583  0.3406416  -0.09002879 ... -0.22357787  0.19612816\n",
            "   -0.23112273]\n",
            "  [-0.37326583  0.3406416  -0.09002879 ... -0.22357787  0.19612816\n",
            "   -0.23112273]\n",
            "  [-0.37326583  0.3406416  -0.09002879 ... -0.22357787  0.19612816\n",
            "   -0.23112273]\n",
            "  ...\n",
            "  [-0.37326583  0.3406416  -0.09002879 ... -0.22357787  0.19612816\n",
            "   -0.23112273]\n",
            "  [-0.37326583  0.3406416  -0.09002879 ... -0.22357787  0.19612816\n",
            "   -0.23112273]\n",
            "  [-0.37326583  0.3406416  -0.09002879 ... -0.22357787  0.19612816\n",
            "   -0.23112273]]\n",
            "\n",
            " [[-0.37326583  0.3406416  -0.09002879 ... -0.22357787  0.19612816\n",
            "   -0.23112273]\n",
            "  [-0.37326583  0.3406416  -0.09002879 ... -0.22357787  0.19612816\n",
            "   -0.23112273]\n",
            "  [-0.37326583  0.3406416  -0.09002879 ... -0.22357787  0.19612816\n",
            "   -0.23112273]\n",
            "  ...\n",
            "  [-0.37326583  0.3406416  -0.09002879 ... -0.22357787  0.19612816\n",
            "   -0.23112273]\n",
            "  [-0.37326583  0.3406416  -0.09002879 ... -0.22357787  0.19612816\n",
            "   -0.23112273]\n",
            "  [-0.37326583  0.3406416  -0.09002879 ... -0.22357787  0.19612816\n",
            "   -0.23112273]]\n",
            "\n",
            " [[-0.37326583  0.3406416  -0.09002879 ... -0.22357787  0.19612816\n",
            "   -0.23112273]\n",
            "  [-0.37326583  0.3406416  -0.09002879 ... -0.22357787  0.19612816\n",
            "   -0.23112273]\n",
            "  [-0.37326583  0.3406416  -0.09002879 ... -0.22357787  0.19612816\n",
            "   -0.23112273]\n",
            "  ...\n",
            "  [-0.37326583  0.3406416  -0.09002879 ... -0.22357787  0.19612816\n",
            "   -0.23112273]\n",
            "  [-0.37326583  0.3406416  -0.09002879 ... -0.22357787  0.19612816\n",
            "   -0.23112273]\n",
            "  [-0.37326583  0.3406416  -0.09002879 ... -0.22357787  0.19612816\n",
            "   -0.23112273]]], shape=(128, 764, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[0.00212763 0.00212763 0.00212763 ... 0.00212763 0.00212763 0.00212763]\n",
            " [0.00212763 0.00212763 0.00212763 ... 0.00212763 0.00212763 0.00212763]\n",
            " [0.00212763 0.00212763 0.00212763 ... 0.00212763 0.00212763 0.00212763]\n",
            " ...\n",
            " [0.00212763 0.00212763 0.00212763 ... 0.00212763 0.00212763 0.00212763]\n",
            " [0.00212763 0.00212763 0.00212763 ... 0.00212763 0.00212763 0.00212763]\n",
            " [0.00212763 0.00212763 0.00212763 ... 0.00212763 0.00212763 0.00212763]], shape=(512, 128), dtype=float32) tf.Tensor(\n",
            "[[0.00212763 0.00212763 0.00212763 ... 0.00212763 0.00212763 0.00212763]\n",
            " [0.00212763 0.00212763 0.00212763 ... 0.00212763 0.00212763 0.00212763]\n",
            " [0.00212763 0.00212763 0.00212763 ... 0.00212763 0.00212763 0.00212763]\n",
            " ...\n",
            " [0.00212763 0.00212763 0.00212763 ... 0.00212763 0.00212763 0.00212763]\n",
            " [0.00212763 0.00212763 0.00212763 ... 0.00212763 0.00212763 0.00212763]\n",
            " [0.00212763 0.00212763 0.00212763 ... 0.00212763 0.00212763 0.00212763]], shape=(252, 128), dtype=float32)\n",
            "(128, 764) (512, 1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_15/kernel:0', 'dense_15/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_15/kernel:0', 'dense_15/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch 1, Batch 98/100, Loss=1.84018e-04\n",
            "(1, 764, 1)\n",
            "tf.Tensor(\n",
            "[[[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " [[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " [[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " [[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]], shape=(128, 764, 1), dtype=float32) tf.Tensor(\n",
            "[[[-0.37411618  0.34076694 -0.09073316 ... -0.22309943  0.19677027\n",
            "   -0.23165336]\n",
            "  [-0.37411618  0.34076694 -0.09073316 ... -0.22309943  0.19677027\n",
            "   -0.23165336]\n",
            "  [-0.37411618  0.34076694 -0.09073316 ... -0.22309943  0.19677027\n",
            "   -0.23165336]\n",
            "  ...\n",
            "  [-0.37411618  0.34076694 -0.09073316 ... -0.22309943  0.19677027\n",
            "   -0.23165336]\n",
            "  [-0.37411618  0.34076694 -0.09073316 ... -0.22309943  0.19677027\n",
            "   -0.23165336]\n",
            "  [-0.37411618  0.34076694 -0.09073316 ... -0.22309943  0.19677027\n",
            "   -0.23165336]]\n",
            "\n",
            " [[-0.37411618  0.34076694 -0.09073316 ... -0.22309943  0.19677027\n",
            "   -0.23165336]\n",
            "  [-0.37411618  0.34076694 -0.09073316 ... -0.22309943  0.19677027\n",
            "   -0.23165336]\n",
            "  [-0.37411618  0.34076694 -0.09073316 ... -0.22309943  0.19677027\n",
            "   -0.23165336]\n",
            "  ...\n",
            "  [-0.37411618  0.34076694 -0.09073316 ... -0.22309943  0.19677027\n",
            "   -0.23165336]\n",
            "  [-0.37411618  0.34076694 -0.09073316 ... -0.22309943  0.19677027\n",
            "   -0.23165336]\n",
            "  [-0.37411618  0.34076694 -0.09073316 ... -0.22309943  0.19677027\n",
            "   -0.23165336]]\n",
            "\n",
            " [[-0.37411618  0.34076694 -0.09073316 ... -0.22309943  0.19677027\n",
            "   -0.23165336]\n",
            "  [-0.37411618  0.34076694 -0.09073316 ... -0.22309943  0.19677027\n",
            "   -0.23165336]\n",
            "  [-0.37411618  0.34076694 -0.09073316 ... -0.22309943  0.19677027\n",
            "   -0.23165336]\n",
            "  ...\n",
            "  [-0.37411618  0.34076694 -0.09073316 ... -0.22309943  0.19677027\n",
            "   -0.23165336]\n",
            "  [-0.37411618  0.34076694 -0.09073316 ... -0.22309943  0.19677027\n",
            "   -0.23165336]\n",
            "  [-0.37411618  0.34076694 -0.09073316 ... -0.22309943  0.19677027\n",
            "   -0.23165336]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[-0.37411618  0.34076694 -0.09073316 ... -0.22309943  0.19677027\n",
            "   -0.23165336]\n",
            "  [-0.37411618  0.34076694 -0.09073316 ... -0.22309943  0.19677027\n",
            "   -0.23165336]\n",
            "  [-0.37411618  0.34076694 -0.09073316 ... -0.22309943  0.19677027\n",
            "   -0.23165336]\n",
            "  ...\n",
            "  [-0.37411618  0.34076694 -0.09073316 ... -0.22309943  0.19677027\n",
            "   -0.23165336]\n",
            "  [-0.37411618  0.34076694 -0.09073316 ... -0.22309943  0.19677027\n",
            "   -0.23165336]\n",
            "  [-0.37411618  0.34076694 -0.09073316 ... -0.22309943  0.19677027\n",
            "   -0.23165336]]\n",
            "\n",
            " [[-0.37411618  0.34076694 -0.09073316 ... -0.22309943  0.19677027\n",
            "   -0.23165336]\n",
            "  [-0.37411618  0.34076694 -0.09073316 ... -0.22309943  0.19677027\n",
            "   -0.23165336]\n",
            "  [-0.37411618  0.34076694 -0.09073316 ... -0.22309943  0.19677027\n",
            "   -0.23165336]\n",
            "  ...\n",
            "  [-0.37411618  0.34076694 -0.09073316 ... -0.22309943  0.19677027\n",
            "   -0.23165336]\n",
            "  [-0.37411618  0.34076694 -0.09073316 ... -0.22309943  0.19677027\n",
            "   -0.23165336]\n",
            "  [-0.37411618  0.34076694 -0.09073316 ... -0.22309943  0.19677027\n",
            "   -0.23165336]]\n",
            "\n",
            " [[-0.37411618  0.34076694 -0.09073316 ... -0.22309943  0.19677027\n",
            "   -0.23165336]\n",
            "  [-0.37411618  0.34076694 -0.09073316 ... -0.22309943  0.19677027\n",
            "   -0.23165336]\n",
            "  [-0.37411618  0.34076694 -0.09073316 ... -0.22309943  0.19677027\n",
            "   -0.23165336]\n",
            "  ...\n",
            "  [-0.37411618  0.34076694 -0.09073316 ... -0.22309943  0.19677027\n",
            "   -0.23165336]\n",
            "  [-0.37411618  0.34076694 -0.09073316 ... -0.22309943  0.19677027\n",
            "   -0.23165336]\n",
            "  [-0.37411618  0.34076694 -0.09073316 ... -0.22309943  0.19677027\n",
            "   -0.23165336]]], shape=(128, 764, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.00243879 -0.00243879 -0.00243879 ... -0.00243879 -0.00243879\n",
            "  -0.00243879]\n",
            " [-0.00243879 -0.00243879 -0.00243879 ... -0.00243879 -0.00243879\n",
            "  -0.00243879]\n",
            " [-0.00243879 -0.00243879 -0.00243879 ... -0.00243879 -0.00243879\n",
            "  -0.00243879]\n",
            " ...\n",
            " [-0.00243879 -0.00243879 -0.00243879 ... -0.00243879 -0.00243879\n",
            "  -0.00243879]\n",
            " [-0.00243879 -0.00243879 -0.00243879 ... -0.00243879 -0.00243879\n",
            "  -0.00243879]\n",
            " [-0.00243879 -0.00243879 -0.00243879 ... -0.00243879 -0.00243879\n",
            "  -0.00243879]], shape=(512, 128), dtype=float32) tf.Tensor(\n",
            "[[-0.00243879 -0.00243879 -0.00243879 ... -0.00243879 -0.00243879\n",
            "  -0.00243879]\n",
            " [-0.00243879 -0.00243879 -0.00243879 ... -0.00243879 -0.00243879\n",
            "  -0.00243879]\n",
            " [-0.00243879 -0.00243879 -0.00243879 ... -0.00243879 -0.00243879\n",
            "  -0.00243879]\n",
            " ...\n",
            " [-0.00243879 -0.00243879 -0.00243879 ... -0.00243879 -0.00243879\n",
            "  -0.00243879]\n",
            " [-0.00243879 -0.00243879 -0.00243879 ... -0.00243879 -0.00243879\n",
            "  -0.00243879]\n",
            " [-0.00243879 -0.00243879 -0.00243879 ... -0.00243879 -0.00243879\n",
            "  -0.00243879]], shape=(252, 128), dtype=float32)\n",
            "(128, 764) (512, 1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_15/kernel:0', 'dense_15/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_15/kernel:0', 'dense_15/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch 1, Batch 99/100, Loss=1.50720e-04\n",
            "(1, 764, 1)\n",
            "tf.Tensor(\n",
            "[[[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " [[ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  ...\n",
            "  [ 0.]\n",
            "  [ 0.]\n",
            "  [ 0.]]\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]\n",
            "\n",
            " [[-0.]\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  ...\n",
            "  [-0.]\n",
            "  [-0.]\n",
            "  [-0.]]], shape=(128, 764, 1), dtype=float32) tf.Tensor(\n",
            "[[[-0.37484917  0.3408751  -0.09134496 ... -0.22268628  0.19732493\n",
            "   -0.23211044]\n",
            "  [-0.37484917  0.3408751  -0.09134496 ... -0.22268628  0.19732493\n",
            "   -0.23211044]\n",
            "  [-0.37484917  0.3408751  -0.09134496 ... -0.22268628  0.19732493\n",
            "   -0.23211044]\n",
            "  ...\n",
            "  [-0.37484917  0.3408751  -0.09134496 ... -0.22268628  0.19732493\n",
            "   -0.23211044]\n",
            "  [-0.37484917  0.3408751  -0.09134496 ... -0.22268628  0.19732493\n",
            "   -0.23211044]\n",
            "  [-0.37484917  0.3408751  -0.09134496 ... -0.22268628  0.19732493\n",
            "   -0.23211044]]\n",
            "\n",
            " [[-0.37484917  0.3408751  -0.09134496 ... -0.22268628  0.19732493\n",
            "   -0.23211044]\n",
            "  [-0.37484917  0.3408751  -0.09134496 ... -0.22268628  0.19732493\n",
            "   -0.23211044]\n",
            "  [-0.37484917  0.3408751  -0.09134496 ... -0.22268628  0.19732493\n",
            "   -0.23211044]\n",
            "  ...\n",
            "  [-0.37484917  0.3408751  -0.09134496 ... -0.22268628  0.19732493\n",
            "   -0.23211044]\n",
            "  [-0.37484917  0.3408751  -0.09134496 ... -0.22268628  0.19732493\n",
            "   -0.23211044]\n",
            "  [-0.37484917  0.3408751  -0.09134496 ... -0.22268628  0.19732493\n",
            "   -0.23211044]]\n",
            "\n",
            " [[-0.37484917  0.3408751  -0.09134496 ... -0.22268628  0.19732493\n",
            "   -0.23211044]\n",
            "  [-0.37484917  0.3408751  -0.09134496 ... -0.22268628  0.19732493\n",
            "   -0.23211044]\n",
            "  [-0.37484917  0.3408751  -0.09134496 ... -0.22268628  0.19732493\n",
            "   -0.23211044]\n",
            "  ...\n",
            "  [-0.37484917  0.3408751  -0.09134496 ... -0.22268628  0.19732493\n",
            "   -0.23211044]\n",
            "  [-0.37484917  0.3408751  -0.09134496 ... -0.22268628  0.19732493\n",
            "   -0.23211044]\n",
            "  [-0.37484917  0.3408751  -0.09134496 ... -0.22268628  0.19732493\n",
            "   -0.23211044]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[-0.37484917  0.3408751  -0.09134496 ... -0.22268628  0.19732493\n",
            "   -0.23211044]\n",
            "  [-0.37484917  0.3408751  -0.09134496 ... -0.22268628  0.19732493\n",
            "   -0.23211044]\n",
            "  [-0.37484917  0.3408751  -0.09134496 ... -0.22268628  0.19732493\n",
            "   -0.23211044]\n",
            "  ...\n",
            "  [-0.37484917  0.3408751  -0.09134496 ... -0.22268628  0.19732493\n",
            "   -0.23211044]\n",
            "  [-0.37484917  0.3408751  -0.09134496 ... -0.22268628  0.19732493\n",
            "   -0.23211044]\n",
            "  [-0.37484917  0.3408751  -0.09134496 ... -0.22268628  0.19732493\n",
            "   -0.23211044]]\n",
            "\n",
            " [[-0.37484917  0.3408751  -0.09134496 ... -0.22268628  0.19732493\n",
            "   -0.23211044]\n",
            "  [-0.37484917  0.3408751  -0.09134496 ... -0.22268628  0.19732493\n",
            "   -0.23211044]\n",
            "  [-0.37484917  0.3408751  -0.09134496 ... -0.22268628  0.19732493\n",
            "   -0.23211044]\n",
            "  ...\n",
            "  [-0.37484917  0.3408751  -0.09134496 ... -0.22268628  0.19732493\n",
            "   -0.23211044]\n",
            "  [-0.37484917  0.3408751  -0.09134496 ... -0.22268628  0.19732493\n",
            "   -0.23211044]\n",
            "  [-0.37484917  0.3408751  -0.09134496 ... -0.22268628  0.19732493\n",
            "   -0.23211044]]\n",
            "\n",
            " [[-0.37484917  0.3408751  -0.09134496 ... -0.22268628  0.19732493\n",
            "   -0.23211044]\n",
            "  [-0.37484917  0.3408751  -0.09134496 ... -0.22268628  0.19732493\n",
            "   -0.23211044]\n",
            "  [-0.37484917  0.3408751  -0.09134496 ... -0.22268628  0.19732493\n",
            "   -0.23211044]\n",
            "  ...\n",
            "  [-0.37484917  0.3408751  -0.09134496 ... -0.22268628  0.19732493\n",
            "   -0.23211044]\n",
            "  [-0.37484917  0.3408751  -0.09134496 ... -0.22268628  0.19732493\n",
            "   -0.23211044]\n",
            "  [-0.37484917  0.3408751  -0.09134496 ... -0.22268628  0.19732493\n",
            "   -0.23211044]]], shape=(128, 764, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.00637329 -0.00637329 -0.00637329 ... -0.00637329 -0.00637329\n",
            "  -0.00637329]\n",
            " [-0.00637329 -0.00637329 -0.00637329 ... -0.00637329 -0.00637329\n",
            "  -0.00637329]\n",
            " [-0.00637329 -0.00637329 -0.00637329 ... -0.00637329 -0.00637329\n",
            "  -0.00637329]\n",
            " ...\n",
            " [-0.00637329 -0.00637329 -0.00637329 ... -0.00637329 -0.00637329\n",
            "  -0.00637329]\n",
            " [-0.00637329 -0.00637329 -0.00637329 ... -0.00637329 -0.00637329\n",
            "  -0.00637329]\n",
            " [-0.00637329 -0.00637329 -0.00637329 ... -0.00637329 -0.00637329\n",
            "  -0.00637329]], shape=(512, 128), dtype=float32) tf.Tensor(\n",
            "[[-0.00637329 -0.00637329 -0.00637329 ... -0.00637329 -0.00637329\n",
            "  -0.00637329]\n",
            " [-0.00637329 -0.00637329 -0.00637329 ... -0.00637329 -0.00637329\n",
            "  -0.00637329]\n",
            " [-0.00637329 -0.00637329 -0.00637329 ... -0.00637329 -0.00637329\n",
            "  -0.00637329]\n",
            " ...\n",
            " [-0.00637329 -0.00637329 -0.00637329 ... -0.00637329 -0.00637329\n",
            "  -0.00637329]\n",
            " [-0.00637329 -0.00637329 -0.00637329 ... -0.00637329 -0.00637329\n",
            "  -0.00637329]\n",
            " [-0.00637329 -0.00637329 -0.00637329 ... -0.00637329 -0.00637329\n",
            "  -0.00637329]], shape=(252, 128), dtype=float32)\n",
            "(128, 764) (512, 1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_15/kernel:0', 'dense_15/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_15/kernel:0', 'dense_15/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch 1, Batch 100/100, Loss=2.18612e-04\n",
            "Epoch 1 Train Time 1836.7272102832794s\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9lp--i02sOlm"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cn_con, vn_con, vals = sp.sparse.find(dec5G.pcm)\n",
        "cn_con, vn_con\n",
        "\n",
        "H = [[1,0,1,1,1,0,0],\n",
        "     [0,1,0,1,1,1,0],\n",
        "     [0,0,1,0,1,1,1]]\n",
        "H = csr_matrix(H)\n",
        "\n",
        "def get_syndrome(pcm, r_t):\n",
        "        # Calculate syndrome (pcm @ r = 0) if r is correct in binary\n",
        "        r_t = tf.reshape(r_t, (pcm.shape[1], -1)) # (n,b)\n",
        "        return pcm.dot(llr_to_bin(r_t).numpy()) % 2\n",
        "\n",
        "get_syndrome(dec5G.pcm, llr_5g)"
      ],
      "metadata": {
        "id": "kPTCo3dbFsJy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## DATA ###\n",
        "EbNo_range_train = range(2, 8)\n",
        "EbNo_range_test = range(5, 14)\n",
        "# Standard deviation for train/test\n",
        "std_train = [EbN0_to_std(ii, args.k / args.n) for ii in EbNo_range_train]\n",
        "std_test = [EbN0_to_std(ii, args.k / args.n) for ii in EbNo_range_test]\n",
        "\n",
        "scheduler = tf.keras.optimizers.schedules.CosineDecay(initial_learning_rate=args.lr, decay_steps=args.epochs) # 1000 is size of trainloader\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=scheduler)\n",
        "\n",
        "train_loader = FEC_Dataset(args.code, sigma=std_test, zero_cw=True, length=args.traindata_len).batch(args.batch_size).shuffle(buffer_size=args.batch_size)\n",
        "\n",
        "#                         z_cw   m 1s   1-cw     Should use zero codeword by default\n",
        "dataset_types = {\n",
        "              \"bin_bits\":(False, False, False), # Binary bits sent and recieved with some awgn\n",
        "              \"flip_cw\": (True, False, True),   # Zero codeword flipped to a all ones vector [1,1,...,1]\n",
        "              \"zero_cw\": (True, False, False),  # Standard zero codeword used for training\n",
        "              \"ones_m\":  (False, True, False),  # Makes the message all ones vector and passes it to generator matrix producing codeword and pcm\n",
        "              }\n",
        "\n",
        "test_ebnos_datasets = [ [FEC_Dataset(args.code, sigma=std_test, zero_cw=zero_cw, ones_m=ones_m, flip_cw=flip_cw)\n",
        "                                 for ii in range(len(std_test))]\n",
        "                                 for (zero_cw, ones_m, flip_cw) in dataset_types.values() ]"
      ],
      "metadata": {
        "id": "j7E0LIaj0YrS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "for epoch in range(1, args.epochs + 1):\n",
        "    print(\"Training Linear Transformer Diffusion Model...\")\n",
        "    # train_dec(dec, train_loader, optimizer, epoch,\n",
        "    #           LR=scheduler(tf.Variable(0, dtype=tf.float32)).numpy(),\n",
        "    #           traindata_len=args.traindata_len)\n",
        "\n",
        "    # print comparison\n",
        "    if epoch % 1 == 0:\n",
        "        data = test_models(dec, test_ebnos_datasets, EbNo_range_test)\n",
        "    break # from for loop\n",
        "\n",
        "data"
      ],
      "metadata": {
        "id": "tO8H1C_U2XDj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t9mzuvXAlGLX"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "def plot_comparison(title, EbNo_range, ber, fer, diff_iters):\n",
        "    plt.figure(figsize=(12, 6))\n",
        "\n",
        "    # Plot diff_iters to decoding\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(EbNo_range, diff_iters, marker='o', label='diff_iters to decode', color='blue')\n",
        "    plt.yscale('log')\n",
        "    plt.xlabel('Eb/No (dB)')\n",
        "    plt.ylabel('diff_iters to decode')\n",
        "    plt.title('diff_iters to decode vs Eb/No')\n",
        "    plt.grid(True, which=\"both\", ls=\"--\")\n",
        "    plt.legend()\n",
        "\n",
        "    # Plot BER for both models\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(EbNo_range, ber, marker='x', label='BER', color='green')\n",
        "    plt.yscale('log')\n",
        "    plt.xlabel('Eb/No (dB)')\n",
        "    plt.ylabel('BER')\n",
        "    plt.title('BER vs Eb/No')\n",
        "    plt.grid(True, which=\"both\", ls=\"--\")\n",
        "    plt.legend()\n",
        "\n",
        "    # Plot FER for both models\n",
        "    plt.subplot(1, 2, 3)\n",
        "    plt.plot(EbNo_range, fer, marker='o', label='FER', color='red')\n",
        "    plt.yscale('log')\n",
        "    plt.xlabel('Eb/No (dB)')\n",
        "    plt.ylabel('FER')\n",
        "    plt.title('FER vs Eb/No')\n",
        "    plt.grid(True, which=\"both\", ls=\"--\")\n",
        "    plt.legend()\n",
        "\n",
        "    # Set the overall title for the figure\n",
        "    plt.suptitle(title)\n",
        "\n",
        "    plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "for ix, dataset_type in enumerate(dataset_types.keys()):\n",
        "    ber = data['LTDM'][ix]['ber']\n",
        "    fer = data['LTDM'][ix]['bler']\n",
        "    diff_iters = data['LTDM'][ix]['diff_iters']\n",
        "\n",
        "    plot_comparison(dataset_type.upper(), EbNo_range_test, ber, fer, diff_iters)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNc2eyx3hf0ngj44UslHkvk",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
