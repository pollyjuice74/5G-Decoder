{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOv28pfcpiLfVruQnL/TtKb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pollyjuice74/5G-Decoder/blob/main/LTD_model_reg_LDPC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "collapsed": true,
        "id": "5q1VAmIeUKIn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d0b741f-50cd-4034-b232-2f5bb4e5645d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into '5G-Decoder'...\n",
            "remote: Enumerating objects: 1467, done.\u001b[K\n",
            "remote: Counting objects: 100% (1467/1467), done.\u001b[K\n",
            "remote: Compressing objects: 100% (527/527), done.\u001b[K\n",
            "remote: Total 1467 (delta 929), reused 1462 (delta 926), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (1467/1467), 1.65 MiB | 6.94 MiB/s, done.\n",
            "Resolving deltas: 100% (929/929), done.\n",
            "Collecting sionna\n",
            "  Downloading sionna-0.19.1-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting tensorflow<2.16.0,>=2.13.0 (from sionna)\n",
            "  Downloading tensorflow-2.15.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from sionna) (1.26.4)\n",
            "Requirement already satisfied: matplotlib>=3.5.3 in /usr/local/lib/python3.10/dist-packages (from sionna) (3.8.0)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from sionna) (1.13.1)\n",
            "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.10/dist-packages (from sionna) (6.4.5)\n",
            "Collecting mitsuba<3.6.0,>=3.2.0 (from sionna)\n",
            "  Downloading mitsuba-3.5.2-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (5.1 kB)\n",
            "Collecting pythreejs>=2.4.2 (from sionna)\n",
            "  Downloading pythreejs-2.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
            "Collecting ipywidgets>=8.0.4 (from sionna)\n",
            "  Downloading ipywidgets-8.1.5-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting ipydatawidgets==4.3.2 (from sionna)\n",
            "  Downloading ipydatawidgets-4.3.2-py2.py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting jupyterlab-widgets==3.0.5 (from sionna)\n",
            "  Downloading jupyterlab_widgets-3.0.5-py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: traittypes>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from ipydatawidgets==4.3.2->sionna) (0.2.1)\n",
            "Collecting comm>=0.1.3 (from ipywidgets>=8.0.4->sionna)\n",
            "  Downloading comm-0.2.2-py3-none-any.whl.metadata (3.7 kB)\n",
            "Requirement already satisfied: ipython>=6.1.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=8.0.4->sionna) (7.34.0)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=8.0.4->sionna) (5.7.1)\n",
            "Collecting widgetsnbextension~=4.0.12 (from ipywidgets>=8.0.4->sionna)\n",
            "  Downloading widgetsnbextension-4.0.13-py3-none-any.whl.metadata (1.6 kB)\n",
            "INFO: pip is looking at multiple versions of ipywidgets to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting ipywidgets>=8.0.4 (from sionna)\n",
            "  Downloading ipywidgets-8.1.4-py3-none-any.whl.metadata (2.3 kB)\n",
            "  Downloading ipywidgets-8.1.3-py3-none-any.whl.metadata (2.4 kB)\n",
            "  Downloading ipywidgets-8.1.2-py3-none-any.whl.metadata (2.4 kB)\n",
            "  Downloading ipywidgets-8.1.1-py3-none-any.whl.metadata (2.4 kB)\n",
            "  Downloading ipywidgets-8.1.0-py3-none-any.whl.metadata (2.4 kB)\n",
            "  Downloading ipywidgets-8.0.7-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=8.0.4->sionna) (5.5.6)\n",
            "  Downloading ipywidgets-8.0.6-py3-none-any.whl.metadata (2.4 kB)\n",
            "INFO: pip is still looking at multiple versions of ipywidgets to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading ipywidgets-8.0.5-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.3->sionna) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.3->sionna) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.3->sionna) (4.55.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.3->sionna) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.3->sionna) (24.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.3->sionna) (11.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.3->sionna) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.3->sionna) (2.8.2)\n",
            "Collecting drjit==0.4.6 (from mitsuba<3.6.0,>=3.2.0->sionna)\n",
            "  Downloading drjit-0.4.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16.0,>=2.13.0->sionna) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16.0,>=2.13.0->sionna) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16.0,>=2.13.0->sionna) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16.0,>=2.13.0->sionna) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16.0,>=2.13.0->sionna) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16.0,>=2.13.0->sionna) (3.12.1)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16.0,>=2.13.0->sionna) (18.1.1)\n",
            "Collecting ml-dtypes~=0.3.1 (from tensorflow<2.16.0,>=2.13.0->sionna)\n",
            "  Downloading ml_dtypes-0.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16.0,>=2.13.0->sionna) (3.4.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16.0,>=2.13.0->sionna) (4.25.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16.0,>=2.13.0->sionna) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16.0,>=2.13.0->sionna) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16.0,>=2.13.0->sionna) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16.0,>=2.13.0->sionna) (4.12.2)\n",
            "Collecting wrapt<1.15,>=1.11.0 (from tensorflow<2.16.0,>=2.13.0->sionna)\n",
            "  Downloading wrapt-1.14.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16.0,>=2.13.0->sionna) (0.37.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16.0,>=2.13.0->sionna) (1.68.1)\n",
            "Collecting tensorboard<2.16,>=2.15 (from tensorflow<2.16.0,>=2.13.0->sionna)\n",
            "  Downloading tensorboard-2.15.2-py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting tensorflow-estimator<2.16,>=2.15.0 (from tensorflow<2.16.0,>=2.13.0->sionna)\n",
            "  Downloading tensorflow_estimator-2.15.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting keras<2.16,>=2.15.0 (from tensorflow<2.16.0,>=2.13.0->sionna)\n",
            "  Downloading keras-2.15.0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow<2.16.0,>=2.13.0->sionna) (0.45.1)\n",
            "Collecting jedi>=0.16 (from ipython>=6.1.0->ipywidgets>=8.0.4->sionna)\n",
            "  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->sionna) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->sionna) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->sionna) (3.0.48)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->sionna) (2.18.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->sionna) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->sionna) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->sionna) (4.9.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16.0,>=2.13.0->sionna) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16.0,>=2.13.0->sionna) (1.2.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16.0,>=2.13.0->sionna) (3.7)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16.0,>=2.13.0->sionna) (2.32.3)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16.0,>=2.13.0->sionna) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16.0,>=2.13.0->sionna) (3.1.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow<2.16.0,>=2.13.0->sionna) (5.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow<2.16.0,>=2.13.0->sionna) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow<2.16.0,>=2.13.0->sionna) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow<2.16.0,>=2.13.0->sionna) (1.3.1)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets>=8.0.4->sionna) (0.8.4)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets>=8.0.4->sionna) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=6.1.0->ipywidgets>=8.0.4->sionna) (0.2.13)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow<2.16.0,>=2.13.0->sionna) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow<2.16.0,>=2.13.0->sionna) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow<2.16.0,>=2.13.0->sionna) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow<2.16.0,>=2.13.0->sionna) (2024.12.14)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow<2.16.0,>=2.13.0->sionna) (3.0.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow<2.16.0,>=2.13.0->sionna) (0.6.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow<2.16.0,>=2.13.0->sionna) (3.2.2)\n",
            "Downloading sionna-0.19.1-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m27.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ipydatawidgets-4.3.2-py2.py3-none-any.whl (271 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m271.6/271.6 kB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jupyterlab_widgets-3.0.5-py3-none-any.whl (384 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m384.3/384.3 kB\u001b[0m \u001b[31m29.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ipywidgets-8.0.5-py3-none-any.whl (138 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.3/138.3 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mitsuba-3.5.2-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (40.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.4/40.4 MB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading drjit-0.4.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m87.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pythreejs-2.4.2-py3-none-any.whl (3.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m77.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow-2.15.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (475.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m475.2/475.2 MB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading keras-2.15.0-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m34.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ml_dtypes-0.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m38.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboard-2.15.2-py3-none-any.whl (5.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m55.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow_estimator-2.15.0-py2.py3-none-any.whl (441 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m442.0/442.0 kB\u001b[0m \u001b[31m27.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading widgetsnbextension-4.0.13-py3-none-any.whl (2.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m58.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading wrapt-1.14.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (77 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m40.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: wrapt, widgetsnbextension, tensorflow-estimator, ml-dtypes, keras, jupyterlab-widgets, jedi, drjit, mitsuba, ipywidgets, tensorboard, ipydatawidgets, tensorflow, pythreejs, sionna\n",
            "  Attempting uninstall: wrapt\n",
            "    Found existing installation: wrapt 1.17.0\n",
            "    Uninstalling wrapt-1.17.0:\n",
            "      Successfully uninstalled wrapt-1.17.0\n",
            "  Attempting uninstall: widgetsnbextension\n",
            "    Found existing installation: widgetsnbextension 3.6.10\n",
            "    Uninstalling widgetsnbextension-3.6.10:\n",
            "      Successfully uninstalled widgetsnbextension-3.6.10\n",
            "  Attempting uninstall: ml-dtypes\n",
            "    Found existing installation: ml-dtypes 0.4.1\n",
            "    Uninstalling ml-dtypes-0.4.1:\n",
            "      Successfully uninstalled ml-dtypes-0.4.1\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 3.5.0\n",
            "    Uninstalling keras-3.5.0:\n",
            "      Successfully uninstalled keras-3.5.0\n",
            "  Attempting uninstall: jupyterlab-widgets\n",
            "    Found existing installation: jupyterlab_widgets 3.0.13\n",
            "    Uninstalling jupyterlab_widgets-3.0.13:\n",
            "      Successfully uninstalled jupyterlab_widgets-3.0.13\n",
            "  Attempting uninstall: ipywidgets\n",
            "    Found existing installation: ipywidgets 7.7.1\n",
            "    Uninstalling ipywidgets-7.7.1:\n",
            "      Successfully uninstalled ipywidgets-7.7.1\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.17.1\n",
            "    Uninstalling tensorboard-2.17.1:\n",
            "      Successfully uninstalled tensorboard-2.17.1\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.17.1\n",
            "    Uninstalling tensorflow-2.17.1:\n",
            "      Successfully uninstalled tensorflow-2.17.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tf-keras 2.17.0 requires tensorflow<2.18,>=2.17, but you have tensorflow 2.15.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed drjit-0.4.6 ipydatawidgets-4.3.2 ipywidgets-8.0.5 jedi-0.19.2 jupyterlab-widgets-3.0.5 keras-2.15.0 mitsuba-3.5.2 ml-dtypes-0.3.2 pythreejs-2.4.2 sionna-0.19.1 tensorboard-2.15.2 tensorflow-2.15.1 tensorflow-estimator-2.15.0 widgetsnbextension-4.0.13 wrapt-1.14.1\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/pollyjuice74/5G-Decoder\n",
        "!pip install sionna"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import tensorflow as tf\n",
        "import random\n",
        "import numpy as np\n",
        "import time\n",
        "from scipy.sparse import issparse, csr_matrix\n",
        "\n",
        "from sionna.fec.utils import generate_reg_ldpc, load_parity_check_examples, LinearEncoder, gm2pcm\n",
        "from sionna.utils.plotting import PlotBER\n",
        "from sionna.fec.ldpc import LDPCBPDecoder\n",
        "\n",
        "import os\n",
        "# os.chdir('../..')\n",
        "if os.path.exists('5G-Decoder'):\n",
        "  os.rename('5G-Decoder', '5G_Decoder')\n",
        "os.chdir('5G_Decoder/adv_nn')\n",
        "\n",
        "from dataset import *\n",
        "from attention import *\n",
        "from channel import *\n",
        "from args import *\n",
        "from model_functs import *\n",
        "from models import *"
      ],
      "metadata": {
        "id": "U5U5qUUVUeRm"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Loading LDPC code\")\n",
        "pcm, k, n, coderate = generate_reg_ldpc(v=3,\n",
        "                                        c=6,\n",
        "                                        n=10,\n",
        "                                        allow_flex_len=True,\n",
        "                                        verbose=True)\n",
        "\n",
        "# pcm = tf.cast(pcm, dtype=tf.int32)\n",
        "encoder = LinearEncoder(pcm, is_pcm=True, dtype=tf.int32)\n",
        "\n",
        "batch_size = 2  # For multiple codewords\n",
        "b = tf.random.uniform((batch_size, k), minval=0, maxval=2, dtype=tf.int32)\n",
        "c = encoder(b)\n",
        "print(pcm.shape, c.shape)\n",
        "pcm @ tf.transpose(c) % 2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 556
        },
        "id": "6RF7dBDwWg0L",
        "outputId": "73078a55-5a5b-40e3-a80f-38c68066edc9"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading LDPC code\n",
            "Setting n to:  10\n",
            "Number of edges (VN perspective):  30\n",
            "Number of edges (CN perspective):  30\n",
            "Generated regular (3,6) LDPC code of length n=10\n",
            "Code rate is r=0.500.\n",
            "Warning: The alias fec.utils.LinearEncoder will not be included in Sionna 1.0. Please use fec.linear.LinearEncoder instead.\n",
            "(5, 10) (2, 10)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(5, 2), dtype=int32, numpy=\n",
              "array([[0, 0],\n",
              "       [0, 0],\n",
              "       [0, 0],\n",
              "       [0, 0],\n",
              "       [0, 0]], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 39
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhYAAAEoCAYAAAAE37iTAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAAASy0lEQVR4nO3da4xUd/nA8Wd2kYXUnUmhgUpYLPYNthR64RJKUi9d25DaWGO8JBgRfaNZECQxgkbRaLtUoyEpiFBNfWFJ6yW02gQbggHElEBBDPXSxmh0tXJpYmZgTYZm5/jG7l/+hcLs/pYze+bzSSYNszNznu3vzM43Z87OlrIsywIAIIGOvAcAAIpDWAAAyQgLACAZYQEAJCMsAIBkhAUAkIywAACSERYAQDLCAgBIRlgAAMkULiy2bt0aN9xwQ0yaNCkWL14chw8fznukttPf3x8LFy6M7u7umDZtWjzwwAPx4osv5j0WEbFp06YolUqxdu3avEdpW//4xz/iox/9aEydOjUmT54ct9xySzz//PN5j9V2hoaG4ktf+lLMnj07Jk+eHDfeeGN87WtfC3/lYvQKFRZPPvlkrFu3LjZu3BjHjh2L+fPnx7333hunT5/Oe7S2sn///ujr64tDhw7Fnj174tVXX4177rknBgcH8x6trR05ciS2b98e8+bNy3uUtvWvf/0rli5dGm9605ti9+7d8fvf/z6+9a1vxbXXXpv3aG3n4Ycfjm3btsWWLVviD3/4Qzz88MPxjW98Ix555JG8Rxv3SkX6I2SLFy+OhQsXxpYtWyIiotFoRE9PT6xevTrWr1+f83Tt68yZMzFt2rTYv39/3HXXXXmP05bOnTsXt99+e3znO9+Jr3/963HrrbfG5s2b8x6r7axfvz5+/etfx69+9au8R2l7733ve2P69Onx/e9/f/i6D3zgAzF58uT44Q9/mONk419hjlicP38+jh49Gr29vcPXdXR0RG9vbzz33HM5Tka1Wo2IiClTpuQ8Sfvq6+uL++6774LnB1ffz372s1iwYEF88IMfjGnTpsVtt90Wjz76aN5jtaU777wz9u7dGy+99FJERPz2t7+NgwcPxrJly3KebPybkPcAqbzyyisxNDQU06dPv+D66dOnxx//+MecpqLRaMTatWtj6dKlMXfu3LzHaUtPPPFEHDt2LI4cOZL3KG3vz3/+c2zbti3WrVsXX/jCF+LIkSPxmc98JiZOnBgrVqzIe7y2sn79+qjVajFnzpzo7OyMoaGhePDBB2P58uV5jzbuFSYsaE19fX3xwgsvxMGDB/MepS0NDAzEmjVrYs+ePTFp0qS8x2l7jUYjFixYEA899FBERNx2223xwgsvxHe/+11hcZX96Ec/iscffzx27twZN998cxw/fjzWrl0bM2bMsBajVJiwuO6666KzszNOnTp1wfWnTp2K66+/Pqep2tuqVavimWeeiQMHDsTMmTPzHqctHT16NE6fPh2333778HVDQ0Nx4MCB2LJlS9Tr9ejs7Mxxwvbylre8JW666aYLrnv7298eP/3pT3OaqH197nOfi/Xr18dHPvKRiIi45ZZb4q9//Wv09/cLi1EqzDkWEydOjDvuuCP27t07fF2j0Yi9e/fGkiVLcpys/WRZFqtWrYpdu3bFL3/5y5g9e3beI7Wtu+++O06cOBHHjx8fvixYsCCWL18ex48fFxVX2dKlS1/3q9cvvfRSvPWtb81povb173//Ozo6LnwJ7OzsjEajkdNExVGYIxYREevWrYsVK1bEggULYtGiRbF58+YYHByMlStX5j1aW+nr64udO3fG008/Hd3d3XHy5MmIiKhUKjF58uScp2sv3d3drzu35ZprrompU6c65yUHn/3sZ+POO++Mhx56KD70oQ/F4cOHY8eOHbFjx468R2s7999/fzz44IMxa9asuPnmm+M3v/lNfPvb345PfOITeY82/mUF88gjj2SzZs3KJk6cmC1atCg7dOhQ3iO1nYi46OWxxx7LezSyLHvHO96RrVmzJu8x2tbPf/7zbO7cuVlXV1c2Z86cbMeOHXmP1JZqtVq2Zs2abNasWdmkSZOyt73tbdkXv/jFrF6v5z3auFeoz7EAAPJVmHMsAID8CQsAIBlhAQAkIywAgGSEBQCQjLAAAJIpXFjU6/X4yle+EvV6Pe9RCOvRSqxF67AWrcNapFe4z7Go1WpRqVSiWq1GuVzOe5y2Zz1ah7VoHdaidViL9Ap3xAIAyI+wAACSuep/hKzRaMTLL78c3d3dUSqVkj9+rVa74L/ky3q0DmvROqxF67AWVy7Lsjh79mzMmDHjdX8Z9n9d9XMs/v73v0dPT8/V3CQAkMjAwEDMnDnzkl+/6kcsuru7r/YmeQPVajXvESiYSqWS9wijVpTnRRHWgtZzudfxqx4WY/H2ByPnLGh4Pc8LuLTLvY47eRMASEZYAADJCAsAIBlhAQAkIywAgGSEBQCQjLAAAJIRFgBAMsICAEhGWAAAyQgLACAZYQEAJCMsAIBkhAUAkIywAACSERYAQDLCAgBIRlgAAMmMKCy2bt0aN9xwQ0yaNCkWL14chw8fTj0XADAONR0WTz75ZKxbty42btwYx44di/nz58e9994bp0+fHov5AIBxpJRlWdbMHRYvXhwLFy6MLVu2REREo9GInp6eWL16daxfv/6y96/ValGpVEY2Lck1ufxwWaVSKe8RRq0oz4sirAWtp1qtRrlcvuTXmzpicf78+Th69Gj09vb+3wN0dERvb28899xzF71PvV6PWq12wQUAKKamwuKVV16JoaGhmD59+gXXT58+PU6ePHnR+/T390elUhm+9PT0jHxaAKCljflvhWzYsCGq1erwZWBgYKw3CQDkZEIzN77uuuuis7MzTp06dcH1p06diuuvv/6i9+nq6oqurq6RTwgAjBtNHbGYOHFi3HHHHbF3797h6xqNRuzduzeWLFmSfDgAYHxp6ohFRMS6detixYoVsWDBgli0aFFs3rw5BgcHY+XKlWMxHwAwjjQdFh/+8IfjzJkz8eUvfzlOnjwZt956a/ziF7943QmdAED7afpzLEbL51i0lqL8vj6towifnVCU50UR1oLWk/RzLAAA3oiwAACSERYAQDLCAgBIRlgAAMkICwAgGWEBACQjLACAZIQFAJCMsAAAkhEWAEAywgIASEZYAADJCAsAIBlhAQAkIywAgGSEBQCQzIS8NlytVqNcLue1+VErlUp5j5BEUb6PLMvyHmHUrEXrKMpaFIV9anxxxAIASEZYAADJCAsAIBlhAQAkIywAgGSEBQCQjLAAAJIRFgBAMsICAEhGWAAAyQgLACAZYQEAJCMsAIBkhAUAkIywAACSERYAQDLCAgBIRlgAAMkICwAgGWEBACQjLACAZJoOiwMHDsT9998fM2bMiFKpFE899dQYjAUAjEdNh8Xg4GDMnz8/tm7dOhbzAADj2IRm77Bs2bJYtmzZWMwCAIxzTYdFs+r1etTr9eF/12q1sd4kAJCTMT95s7+/PyqVyvClp6dnrDcJAORkzMNiw4YNUa1Why8DAwNjvUkAICdj/lZIV1dXdHV1jfVmAIAW4HMsAIBkmj5ice7cufjTn/40/O+//OUvcfz48ZgyZUrMmjUr6XAAwPhSyrIsa+YO+/bti3e9612vu37FihXxgx/84LL3r9VqUalUolqtRrlcbmbTLaVUKuU9Av+jyd24JRVln7IWpGafai2Xe/1u+ojFO9/5zkIsMgCQnnMsAIBkhAUAkIywAACSERYAQDLCAgBIRlgAAMkICwAgGWEBACQjLACAZIQFAJCMsAAAkhEWAEAywgIASEZYAADJCAsAIBlhAQAkIywAgGQm5LXhSqWS16aTyLIs7xGSKJVKeY+QRBG+D/sUFFcRnt+1Wu2KXrsdsQAAkhEWAEAywgIASEZYAADJCAsAIBlhAQAkIywAgGSEBQCQjLAAAJIRFgBAMsICAEhGWAAAyQgLACAZYQEAJCMsAIBkhAUAkIywAACSERYAQDLCAgBIRlgAAMk0FRb9/f2xcOHC6O7ujmnTpsUDDzwQL7744ljNBgCMM02Fxf79+6Ovry8OHToUe/bsiVdffTXuueeeGBwcHKv5AIBxpJRlWTbSO585cyamTZsW+/fvj7vuuuuK7lOr1aJSqYx0ky1jFP/bWkqpVMp7BP7LPgUXV5Tnxnj32ut3tVqNcrl8ydtNGM1GqtVqRERMmTLlkrep1+tRr9cvGAwAKKYRn7zZaDRi7dq1sXTp0pg7d+4lb9ff3x+VSmX40tPTM9JNAgAtbsRvhXz605+O3bt3x8GDB2PmzJmXvN3FjlgUIS6KcmjOYevWYZ+CiyvKc2O8G9O3QlatWhXPPPNMHDhw4A2jIiKiq6srurq6RrIZAGCcaSossiyL1atXx65du2Lfvn0xe/bssZoLABiHmgqLvr6+2LlzZzz99NPR3d0dJ0+ejIiISqUSkydPHpMBAYDxo6lzLC713uljjz0WH//4x6/oMfy6aWvxfnjrsE/BxRXluTHejck5FhYXAHgj/lYIAJCMsAAAkhEWAEAywgIASEZYAADJCAsAIBlhAQAkIywAgGSEBQCQjLAAAJIRFgBAMsICAEhGWAAAyQgLACAZYQEAJCMsAIBkhAUAkMyEvAcgX1mW5T1CEqVSKe8RRq0I30NEMfYpa9FairIe7cIRCwAgGWEBACQjLACAZIQFAJCMsAAAkhEWAEAywgIASEZYAADJCAsAIBlhAQAkIywAgGSEBQCQjLAAAJIRFgBAMsICAEhGWAAAyQgLACAZYQEAJCMsAIBkhAUAkIywAACSaSostm3bFvPmzYtyuRzlcjmWLFkSu3fvHqvZAIBxpqmwmDlzZmzatCmOHj0azz//fLz73e+O973vffG73/1urOYDAMaRUpZl2WgeYMqUKfHNb34zPvnJT17R7Wu1WlQqldFssiWM8n8biZVKpbxH4L+K8Nwoyv5UhLWIKM56FEW1Wo1yuXzJr08Y6QMPDQ3Fj3/84xgcHIwlS5Zc8nb1ej3q9frwv2u12kg3CQC0uKZP3jxx4kS8+c1vjq6urvjUpz4Vu3btiptuuumSt+/v749KpTJ86enpGdXAAEDravqtkPPnz8ff/va3qFar8ZOf/CS+973vxf79+y8ZFxc7YlGEuCjKIcaicKi0dRThuVGU/akIaxFRnPUoisu9FTLqcyx6e3vjxhtvjO3bt1/R7Z1jwVjwg6d1FOG5UZT9qQhrEVGc9SiKy4XFqD/HotFoXHBEAgBoX02dvLlhw4ZYtmxZzJo1K86ePRs7d+6Mffv2xbPPPjtW8wEA40hTYXH69On42Mc+Fv/85z+jUqnEvHnz4tlnn433vOc9YzUfADCOjPoci2Y5x4Kx4D3Y1lGE50ZR9qcirEVEcdajKMb8HAsAgNcICwAgGWEBACQjLACAZIQFAJCMsAAAkhEWAEAywgIASEZYAADJCAsAIBlhAQAkIywAgGSEBQCQjLAAAJIRFgBAMsICAEhGWAAAyUzIa8PVajXK5XJemx+1UqmU9wjQkorw3MiyLO8RKJgi7FO1Wi0qlcplb+eIBQCQjLAAAJIRFgBAMsICAEhGWAAAyQgLACAZYQEAJCMsAIBkhAUAkIywAACSERYAQDLCAgBIRlgAAMkICwAgGWEBACQjLACAZIQFAJCMsAAAkhEWAEAywgIASGZUYbFp06YolUqxdu3aROMAAOPZiMPiyJEjsX379pg3b17KeQCAcWxEYXHu3LlYvnx5PProo3HttdemngkAGKdGFBZ9fX1x3333RW9v72VvW6/Xo1arXXABAIppQrN3eOKJJ+LYsWNx5MiRK7p9f39/fPWrX216MABg/GnqiMXAwECsWbMmHn/88Zg0adIV3WfDhg1RrVaHLwMDAyMaFABofaUsy7IrvfFTTz0V73//+6Ozs3P4uqGhoSiVStHR0RH1ev2Cr11MrVaLSqUS1Wo1yuXyyCfPWalUynsEYIw08WORq6AIP2+LsE9d6et3U2+F3H333XHixIkLrlu5cmXMmTMnPv/5z182KgCAYmsqLLq7u2Pu3LkXXHfNNdfE1KlTX3c9ANB+fPImAJBM078V8v/t27cvwRgAQBE4YgEAJCMsAIBkhAUAkIywAACSERYAQDLCAgBIRlgAAMkICwAgGWEBACQjLACAZIQFAJCMsAAAkhEWAEAywgIASEZYAADJCAsAIBlhAQAkM+FqbzDLsoiIqNVqV3vTAFfEzydSK8I+9dr38Nrr+KVc9bA4e/ZsRET09PRc7U0DXJFKpZL3CBRMkfaps2fPvuH3U8oulx6JNRqNePnll6O7uztKpVLyx6/VatHT0xMDAwNRLpeTPz7NsR6tw1q0DmvROqzFlcuyLM6ePRszZsyIjo5Ln0lx1Y9YdHR0xMyZM8d8O+Vy2U7SQqxH67AWrcNatA5rcWWu5MiLkzcBgGSEBQCQTOHCoqurKzZu3BhdXV15j0JYj1ZiLVqHtWgd1iK9q37yJgBQXIU7YgEA5EdYAADJCAsAIBlhAQAkIywAgGSEBQCQjLAAAJIRFgBAMv8B0GwTcre1HfQAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# for e2e model\n",
        "from sionna.utils import BinarySource, ebnodb2no\n",
        "from sionna.mapping import Mapper, Demapper\n",
        "from sionna.channel import AWGN\n",
        "# from sionna.fec.ldpc import LDPC5GDecoder, LDPC5GEncoder\n",
        "from tensorflow.keras.layers import Layer, Dense, Dropout\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "class Args():\n",
        "    def __init__(self, model_type, code_type='LDPC', n_look_up=121, k_look_up=80, n=400, k=200,\n",
        "                       n_rings=2, ls_active=True, split_diff=True, sigma=0.1,\n",
        "                       t_layers=1, d_model=512, heads=8, lr=5e-4,\n",
        "                       batch_size=160, batch_size_eval = 150,\n",
        "                       eval_train_iter=50, save_weights_iter=100,\n",
        "                       ebno_db_eval=2.5,\n",
        "                       ebno_db_min=0., ebno_db_max=4., ebno_db_stepsize=0.25,\n",
        "                       traindata_len=500, testdata_len=250, epochs=1000):\n",
        "        assert model_type in ['gen', 'dis'], \"Type must be: 'gen', Generator or 'dis', Discriminator.\"\n",
        "        assert code_type in ['POLAR', 'BCH', 'CCSDS', 'LDPC', 'MACKAY', 'LDPC5G', 'POLAR5G'], \"Invalid linear code type.\"\n",
        "\n",
        "\n",
        "        # model data\n",
        "        self.model_type = model_type\n",
        "\n",
        "        self.split_diff = split_diff\n",
        "        self.n_rings = n_rings # ring connectivity of mask\n",
        "        self.sigma = sigma\n",
        "        self.t_layers = t_layers\n",
        "        self.ls_active = ls_active\n",
        "\n",
        "        self.d_model = d_model\n",
        "        self.heads = heads\n",
        "\n",
        "        # training data\n",
        "        self.lr = lr\n",
        "        self.batch_size = batch_size\n",
        "        self.traindata_len = traindata_len\n",
        "        self.testdata_len = testdata_len\n",
        "        self.epochs = epochs\n",
        "\n",
        "        self.ebno_db_min = ebno_db_min\n",
        "        self.ebno_db_max = ebno_db_max\n",
        "        self.ebno_db_stepsize = ebno_db_stepsize\n",
        "\n",
        "        self.ebno_db_eval = ebno_db_eval\n",
        "        self.eval_train_iter = eval_train_iter\n",
        "        self.save_weights_iter = save_weights_iter\n",
        "        self.batch_size_eval = batch_size_eval\n",
        "\n",
        "        # code data\n",
        "        self.code_type = code_type\n",
        "        self.code = self.get_code(n_look_up, k_look_up) # n,k look up values in Get_Generator_and_Parity\n",
        "\n",
        "        # if self.code_type not in ['LDPC5G', 'POLAR5G']:\n",
        "        #     self.n, self.m, self.k = self.code.n, self.code.m, self.code.k\n",
        "        # else:\n",
        "        #     self.n, self.m, self.k = n, n-k, k\n",
        "\n",
        "        # self.n_steps = self.m + 5  # Number of diffusion steps\n",
        "\n",
        "    def get_code(self, n_look_up, k_look_up):\n",
        "        code = type('Code', (), {})() # class Code, no base class, no attributes/methods, () instantiate object\n",
        "        # code.n_look_up, code.k_look_up = n_look_up, k_look_up\n",
        "        # code.code_type = self.code_type\n",
        "\n",
        "        # if self.code_type not in ['LDPC5G', 'POLAR5G']:\n",
        "        #     G, H = Get_Generator_and_Parity(code)\n",
        "        #     code.G, code.H = tf.convert_to_tensor(G), csr_matrix( tf.convert_to_tensor(H) )\n",
        "\n",
        "        #     code.m, code.n = code.H.shape\n",
        "        #     code.k = code.n - code.m\n",
        "\n",
        "        return code\n",
        "\n",
        "\n",
        "class MHAttention(Layer):\n",
        "    def __init__(self, dims, heads, mask_length, linear=False, dropout=0.01):\n",
        "        super().__init__()\n",
        "        assert (dims % heads) == 0, 'dimension must be divisible by the number of heads'\n",
        "        self.linear = linear\n",
        "        self.dims = dims\n",
        "        self.heads = heads\n",
        "        self.dim_head = dims // heads\n",
        "\n",
        "        if linear:\n",
        "            self.k_proj = self.get_k_proj(mask_length) # n+m\n",
        "            self.proj_k = None\n",
        "            self.proj_v = None\n",
        "\n",
        "        self.to_q, self.to_k, self.to_v = [ Dense(self.dims, use_bias=False) for _ in range(3) ]\n",
        "        self.to_out = Dense(dims)\n",
        "        self.dropout = Dropout(dropout) # to d-dimentional embeddings\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        # Creates shape (n,k_proj) proj matrices for key and\n",
        "        n_value = input_shape[1]\n",
        "        if self.linear:\n",
        "            self.proj_k = self.add_weight(\"proj_k\", shape=[n_value, self.k_proj], initializer=GlorotUniform())\n",
        "            self.proj_v = self.add_weight(\"proj_v\", shape=[n_value, self.k_proj], initializer=GlorotUniform())\n",
        "\n",
        "    def call(self, x, mask=None):\n",
        "        out_att = self.lin_attention(x, mask) if self.linear else self.attention(x, mask)\n",
        "        return out_att\n",
        "\n",
        "    def get_k_proj(self, mask_length):\n",
        "        # gets dimention for linear tranformer vector projection\n",
        "        for k_proj in range(mask_length // 2, 0, -1): # starts at half the mask length TO 0\n",
        "            if mask_length % k_proj == 0:\n",
        "                return tf.cast(k_proj, tf.int32)\n",
        "\n",
        "    def lin_attention(self, x, mask): # O(n)\n",
        "        shape = tf.shape(x) # (b, n, d)\n",
        "        b = tf.cast(shape[0], tf.int32)\n",
        "        n = tf.cast(shape[1], tf.int32)\n",
        "\n",
        "        assert x.shape[-1] is not None, \"The last dimension of x is undefined.\"\n",
        "\n",
        "        query, key, val = self.to_q(x), self.to_k(x), self.to_v(x)\n",
        "\n",
        "        # Project key and val into k-dimentional space\n",
        "        key = tf.einsum('bnd,nk->bkd', key, self.proj_k)\n",
        "        val = tf.einsum('bnd,nk->bkd', val, self.proj_v)\n",
        "\n",
        "        # Reshape splitting for heads\n",
        "        query = tf.reshape(query, (b, n, self.heads, self.dim_head))\n",
        "        key = tf.reshape(key, (b, self.k_proj, self.heads, self.dim_head))\n",
        "        val = tf.reshape(val, (b, self.k_proj, self.heads, self.dim_head))\n",
        "        query, key, val = [ tf.transpose(x, [0, 2, 1, 3]) for x in [query, key, val] ]\n",
        "\n",
        "        # Low-rank mask (n,k_proj)\n",
        "        mask = tf.expand_dims(mask, axis=-1)\n",
        "        mask = tf.image.resize(mask, [n, self.k_proj], method='nearest')\n",
        "        mask = tf.reshape(mask, (1, 1, n, self.k_proj))\n",
        "\n",
        "        # Main attn logic: sftmx( q@k / d**0.5 ) @ v\n",
        "        scores = tf.einsum('bhnd,bhkd->bhnk', query, key) / (tf.sqrt( tf.cast(self.dim_head, dtype=tf.float32) ))\n",
        "        scores += (mask * -1e9) if mask is not None else 0.\n",
        "        attn = tf.nn.softmax(scores, axis=-1) # (b,h,n,k_proj)\n",
        "        attn = self.dropout(attn)\n",
        "        out = tf.einsum('bhnk,bhkd->bhnd', attn, val)\n",
        "\n",
        "        # Reshape and pass through out layer\n",
        "        out = tf.transpose(out, [0, 2, 1, 3])\n",
        "        out = tf.reshape(out, (b, n, -1))\n",
        "        return self.to_out(out)\n",
        "\n",
        "    def attention(self, x, mask): # O(n^2)\n",
        "        shape = tf.shape(x)\n",
        "        b = shape[0]\n",
        "        n = shape[1]\n",
        "        x = x[:, :, tf.newaxis] # (b,n,1)\n",
        "\n",
        "        query, key, val = self.to_q(x), self.to_k(x), self.to_v(x) # (b, n, d)\n",
        "        query, key, val = [ tf.reshape(x, (b, n, self.heads, self.dim_head)) for x in [query, key, val] ]\n",
        "        query, key, val = [ tf.cast( tf.transpose(x, [0, 2, 1, 3]), tf.float32 )\n",
        "                                                                            for x in [query, key, val] ]\n",
        "\n",
        "        scores = tf.einsum('bhqd,bhkd->bhqk', query, key) / (tf.sqrt( tf.cast(self.dim_head, tf.float32) ))\n",
        "        scores += (mask * -1e9) if mask is not None else 0. # apply mask non-edge connections\n",
        "        attn = tf.nn.softmax(scores, axis=-1) #-1\n",
        "        attn = self.dropout(attn)\n",
        "        out = tf.einsum('bhqk,bhkd->bhqd', attn, val)\n",
        "\n",
        "        out = tf.transpose(out, [0, 2, 1, 3])\n",
        "        out = tf.reshape(out, (b, n, -1))\n",
        "        return self.to_out(out)\n",
        "\n",
        "\n",
        "# class Decoder( TransformerDiffusion ):\n",
        "#     def __init__(self, args):\n",
        "#         super().__init__(args)\n",
        "#         self.transformer =\n",
        "\n",
        "#     # 'test' function\n",
        "#     def call(self, r_t):\n",
        "#         i = tf.constant(0)  # Initialize loop counter\n",
        "\n",
        "#         def condition(r_t, i):\n",
        "#             # Loop while i < self.m and syndrome sum is not zero\n",
        "#             return tf.logical_and(i < 5, tf.reduce_sum(self.get_syndrome(r_t)) != 0) # CHANGE 5 TO SELF.M\n",
        "\n",
        "#         def body(r_t, i):\n",
        "#             # Perform reverse or split diffusion\n",
        "#             r_t = tf.cond(\n",
        "#                 tf.logical_not(self.split_diff),\n",
        "#                 lambda: self.split_rdiff_call(r_t),\n",
        "#                 lambda: self.rev_diff_call(r_t),\n",
        "#             )\n",
        "#             return r_t, tf.add(i, 1)\n",
        "\n",
        "#         # Run tf.while_loop with the loop variables\n",
        "#         llr_hat, _ = tf.while_loop(\n",
        "#             condition,\n",
        "#             body,\n",
        "#             loop_vars=[r_t, i],\n",
        "#             maximum_iterations=self.m,\n",
        "#             shape_invariants=[tf.TensorShape([self.batch_size, self.n]), i.get_shape()]\n",
        "#         )\n",
        "\n",
        "#         # llr_hat, _ = self.tran_call(r_t)\n",
        "#         tf.print(\"llr_hat\", llr_hat)\n",
        "\n",
        "#         return llr_hat\n",
        "\n",
        "#     # Refines recieved codeword r at time t\n",
        "#     def rev_diff_call(self, r_t):\n",
        "#         tf.print(\"Rev def call with line-search...\")\n",
        "\n",
        "#         # Transformer error prediction\n",
        "#         z_hat_crude, t = self.tran_call(r_t) # (b,n)\n",
        "#         r_t1 = r_t - z_hat_crude*self.get_sigma(t)[:, tf.newaxis] # (b,n)\n",
        "#         # tf.print(r_t1)\n",
        "\n",
        "#         # # Refined estimate of the codeword for the ls diffusion step\n",
        "#         # r_t1, z_hat = self.line_search(r_t, sigma, err_hat) if self.ls_active else 1.\n",
        "#         # tf.print(\"After linesearch: \", r_t1)\n",
        "\n",
        "#         print(\"r_t1\", r_t1.shape, r_t1.dtype)\n",
        "#         return r_t1 # r at t-1, both (b,n)\n",
        "\n",
        "#     def split_rdiff_call(self, r_t):\n",
        "#         tf.print(\"Rev diff call with split diffusion...\")\n",
        "#         # First half-step condition subproblem\n",
        "#         z_hat_crude, t = self.tran_call(r_t)\n",
        "#         # tf.print(\"fc input: \", (z_hat_crude * self.get_sigma(t)[:, tf.newaxis]))\n",
        "#         r_t_half = r_t - 0.5 * self.fc( z_hat_crude * self.get_sigma(t)[:, tf.newaxis] )\n",
        "#         # tf.print(\"r_t_half\", r_t_half)\n",
        "\n",
        "#         # Full-step diffusion subproblem\n",
        "#         r_t1 = r_t_half + tf.random.normal(r_t_half.shape) * tf.sqrt(self.get_sigma(t)[:, tf.newaxis])\n",
        "\n",
        "#         # Second half-step condition subproblem\n",
        "#         z_hat_crude_half, t = self.tran_call(r_t1)  # Reuse the second `tran_call`\n",
        "#         r_t1 = r_t1 - 0.5 * self.fc(z_hat_crude_half * self.get_sigma(t)[:, tf.newaxis])\n",
        "#         print(\"r_t1\", r_t1.shape, r_t1.dtype)\n",
        "#         return r_t1  # r at t-1, both (b,n)\n",
        "\n",
        "\n",
        "from tensorflow.keras.layers import MultiHeadAttention, Dense, LayerNormalization, Dropout\n",
        "\n",
        "class TransformerDecoderBlock(tf.keras.layers.Layer):\n",
        "    def __init__(self, d_model, num_heads, dff, dropout_rate=0.1):\n",
        "        super(TransformerDecoderBlock, self).__init__()\n",
        "        self.mha = MultiHeadAttention(num_heads=num_heads, key_dim=d_model)\n",
        "        self.ffn = tf.keras.Sequential([\n",
        "            Dense(dff, activation='relu'),\n",
        "            Dense(d_model)\n",
        "        ])\n",
        "\n",
        "        self.layernorm1 = LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm2 = LayerNormalization(epsilon=1e-6)\n",
        "\n",
        "        self.dropout1 = Dropout(dropout_rate)\n",
        "        self.dropout2 = Dropout(dropout_rate)\n",
        "\n",
        "    def call(self, x, mask, training):\n",
        "        # Multi-Head Attention\n",
        "        attn_output = self.mha(x, x, attention_mask=mask)\n",
        "        tf.print(\"attn_output\", attn_output.shape)\n",
        "        attn_output = self.dropout1(attn_output, training=training)\n",
        "        out1 = self.layernorm1(x + attn_output)  # Add & Normalize\n",
        "\n",
        "        # Feedforward Network\n",
        "        ffn_output = self.ffn(out1)\n",
        "        tf.print(\"ffn_output\", ffn_output.shape)\n",
        "        ffn_output = self.dropout2(ffn_output, training=training)\n",
        "        out2 = self.layernorm2(out1 + ffn_output)  # Add & Normalize\n",
        "        return out2\n",
        "\n",
        "\n",
        "class Decoder( Layer ):\n",
        "    def __init__(self, args):\n",
        "        super().__init__()\n",
        "        code = args.code\n",
        "        self.pcm = tf.cast(code.H, dtype=tf.int32)\n",
        "\n",
        "        # shapes\n",
        "        self._m, self._n = self.pcm.shape\n",
        "        self._k = self._n - self._m\n",
        "        self.dims = args.d_model\n",
        "        self.batch_size = args.batch_size\n",
        "\n",
        "        # layers\n",
        "        self.node_embeddings = Dense(self.dims)\n",
        "        self.encoder_blocks = [\n",
        "            TransformerDecoderBlock(\n",
        "                d_model=args.d_model,\n",
        "                num_heads=args.heads,\n",
        "                dff=args.d_model * 4,\n",
        "                dropout_rate=0.1,\n",
        "            )\n",
        "            for _ in range(args.t_layers)\n",
        "        ]\n",
        "        self.forward_channel = Dense(1)\n",
        "        self.to_n = Dense(self._n)\n",
        "\n",
        "        # mask\n",
        "        self.mask = self.create_mask(self.pcm)\n",
        "        # for matrix, title in zip([self.pcm, self.mask], [\"PCM Matrix\", \"Mask Matrix\"]):\n",
        "        #     plt.imshow(matrix, cmap='viridis'); plt.colorbar(); plt.title(title); plt.show()\n",
        "        print(\"mask, pcm: \", self.mask, self.pcm)\n",
        "\n",
        "    def create_mask(self, H):\n",
        "        # Initialize diagonal identity mask\n",
        "        mask = tf.eye(2 * self._n - self._k, dtype=tf.float32)\n",
        "\n",
        "        # Get indices where H == 1\n",
        "        indices = tf.where(H == 1)  # Returns (row, col) pairs where H is 1\n",
        "        check_nodes, variable_nodes = indices[:, 0], indices[:, 1]\n",
        "\n",
        "        # Step 1: Update check node to variable node connections\n",
        "        mask = tf.tensor_scatter_nd_update(mask,\n",
        "                                          tf.stack([n + check_nodes, variable_nodes], axis=1),\n",
        "                                          tf.ones_like(check_nodes, dtype=tf.float32))\n",
        "        mask = tf.tensor_scatter_nd_update(mask,\n",
        "                                          tf.stack([variable_nodes, n + check_nodes], axis=1),\n",
        "                                          tf.ones_like(check_nodes, dtype=tf.float32))\n",
        "\n",
        "        # Step 2: Update variable node connections\n",
        "        for cn in tf.unique(check_nodes)[0]:  # Iterate over unique check nodes\n",
        "            related_vns = tf.boolean_mask(variable_nodes, check_nodes == cn)\n",
        "            indices = tf.stack(tf.meshgrid(related_vns, related_vns), axis=-1)\n",
        "            indices = tf.reshape(indices, [-1, 2])  # Flatten indices\n",
        "            mask = tf.tensor_scatter_nd_update(mask, indices, tf.ones_like(indices[:, 0], dtype=tf.float32))\n",
        "\n",
        "        # Tile mask across batch size for tf MHA\n",
        "        mask = tf.expand_dims(mask, axis=0)  # Shape: (1, n+m, n+m)\n",
        "        mask = tf.tile(mask, [self.batch_size, 1, 1])  # Shape: (b, n+m, n+m)\n",
        "        return mask\n",
        "\n",
        "    def get_syndrome(self, vn_vector, from_llr=True):\n",
        "        \"\"\" Calculate syndrome (pcm @ r = 0) if r is correct in binary \"\"\"\n",
        "        vn_vector = tf.transpose(vn_vector) # (n,b)\n",
        "        bin_vector = llr_to_bin(vn_vector) if from_llr else vn_vector\n",
        "        return tf.cast( (self.pcm @ bin_vector) % 2, dtype=tf.float32) # (m,n)@(n,b)->(m,b)\n",
        "\n",
        "    def call(self, x_nodes, training=False):\n",
        "        # tf.print(\"DECODER CALL\")\n",
        "        tf.print(\"x_nodes\", x_nodes.shape)\n",
        "        # Embed cn/vn nodes vector\n",
        "        x_nodes_embedded = self.node_embeddings( x_nodes ) # (b, n+m, hidden_dims)\n",
        "        # Pass through each encoder block\n",
        "        for block in self.encoder_blocks:\n",
        "            x_nodes = block(x_nodes_embedded,\n",
        "                            mask=self.mask,\n",
        "                            training=training)\n",
        "            tf.print(\"x_nodes\", x_nodes.shape)\n",
        "        x_nodes = tf.squeeze( self.forward_channel(x_nodes), axis=-1 ) # (b, n+m, hidden_dims)->(b, n+m)\n",
        "        # tf.print(\"x_nodes\", x_nodes, x_nodes.shape)\n",
        "        llr_hat = self.to_n(x_nodes) # (b, n+m)->(b,n)\n",
        "        # tf.print(\"Decoded output (llr_hat):\", llr_hat)\n",
        "        return llr_hat\n",
        "\n",
        "\n",
        "class E2EModel(tf.keras.Model):\n",
        "    def __init__(self, encoder, decoder, k, n, return_infobits=False, es_no=False):\n",
        "        super().__init__()\n",
        "\n",
        "        self._n = n\n",
        "        self._k = k\n",
        "        self._m = n - k\n",
        "\n",
        "        self._binary_source = BinarySource(dtype=tf.int32)\n",
        "        self._num_bits_per_symbol = 2\n",
        "        self._mapper = Mapper(\"qam\", self._num_bits_per_symbol)\n",
        "        self._demapper = Demapper(\"app\", \"qam\", self._num_bits_per_symbol)\n",
        "        self._channel = AWGN()\n",
        "        self._decoder = decoder\n",
        "        self._encoder = encoder\n",
        "        self._return_infobits = return_infobits\n",
        "        self._es_no = es_no\n",
        "\n",
        "    @tf.function(jit_compile=False)\n",
        "    def call(self, batch_size, ebno_db):\n",
        "\n",
        "        # no rate-adjustment for uncoded transmission or es_no scenario\n",
        "        if self._decoder is not None and self._es_no==False:\n",
        "            no = ebnodb2no(ebno_db, self._num_bits_per_symbol, self._k/self._n)\n",
        "        else: #for uncoded transmissions the rate is 1\n",
        "            no = ebnodb2no(ebno_db, self._num_bits_per_symbol, 1)\n",
        "\n",
        "        b = self._binary_source([batch_size, self._k])\n",
        "        if self._encoder is not None:\n",
        "            c = self._encoder(b)\n",
        "        else:\n",
        "            c = b\n",
        "\n",
        "        # check that rate calculations are correct\n",
        "        assert self._n==c.shape[-1], \"Invalid value of n.\"\n",
        "\n",
        "        # zero padding to support odd codeword lengths\n",
        "        if self._n%2==1:\n",
        "            c_pad = tf.concat([c, tf.zeros([batch_size, 1])], axis=1)\n",
        "        else: # no padding\n",
        "            c_pad = c\n",
        "        x = self._mapper(c_pad)\n",
        "\n",
        "        y = self._channel([x, no])\n",
        "        llr = self._demapper([y, no])\n",
        "\n",
        "        # remove zero padded bit at the end\n",
        "        if self._n%2==1:\n",
        "            llr = llr[:,:-1]\n",
        "        # tf.print('PCM @ CW: ', self._decoder.pcm @\n",
        "                #  tf.transpose(tf.cast(c, dtype=tf.int32)) % 2)\n",
        "\n",
        "        # decoder input nodes\n",
        "        syndrome = tf.reshape( self._decoder.get_syndrome(llr),\n",
        "                               (batch_size, self._m) ) # (m,n)@(n,b)->(m,b) check nodes\n",
        "        # tf.print(\"SYNDROME_CHECK\", self._decoder.get_syndrome(c, from_llr=False))\n",
        "        # tf.print(\"syndrome_sum\", tf.reduce_sum(syndrome))\n",
        "        x_nodes = tf.concat([llr, syndrome], axis=1)[:, :, tf.newaxis] # (b, n+m, 1)\n",
        "        # tf.print(\"syndrome, x_nodes.dtype\", syndrome, x_nodes.dtype)\n",
        "\n",
        "        # and run the decoder\n",
        "        if self._decoder is not None:\n",
        "            # tf.print('x_nodes input: ', x_nodes)\n",
        "            ############################\n",
        "            llr_hat = self._decoder(x_nodes)\n",
        "            ############################\n",
        "            # tf.print(llr_hat)\n",
        "            # c_check = llr_to_bin(bin_to_llr(c))\n",
        "            # tf.print(\"CHECK: \", c.dtype, c_check.dtype, c==c_check)\n",
        "\n",
        "        if self._return_infobits:\n",
        "            return b, llr_hat, llr\n",
        "        else:\n",
        "            return c, llr_hat, llr\n",
        "\n",
        "\n",
        "# args for decoder/discriminator\n",
        "args = Args(model_type='dis')\n",
        "args.code.H = pcm\n",
        "args.n, args.m = pcm.shape\n",
        "args.k = k\n",
        "args.n_steps = args.m + 5\n",
        "\n",
        "ltd_decoder = Decoder(args) # Linear Transformer Diffusion (LTD) Decoder\n",
        "\n",
        "e2e_ltd = E2EModel(encoder, ltd_decoder, k, n)"
      ],
      "metadata": {
        "id": "XOILyjSGXMdb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9084d01-f272-403c-dd76-9bfc8e209155"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mask, pcm:  tf.Tensor(\n",
            "[[[1. 1. 1. ... 1. 1. 0.]\n",
            "  [1. 1. 1. ... 0. 0. 1.]\n",
            "  [1. 1. 1. ... 1. 0. 1.]\n",
            "  ...\n",
            "  [1. 0. 1. ... 1. 0. 0.]\n",
            "  [1. 0. 0. ... 0. 1. 0.]\n",
            "  [0. 1. 1. ... 0. 0. 1.]]\n",
            "\n",
            " [[1. 1. 1. ... 1. 1. 0.]\n",
            "  [1. 1. 1. ... 0. 0. 1.]\n",
            "  [1. 1. 1. ... 1. 0. 1.]\n",
            "  ...\n",
            "  [1. 0. 1. ... 1. 0. 0.]\n",
            "  [1. 0. 0. ... 0. 1. 0.]\n",
            "  [0. 1. 1. ... 0. 0. 1.]]\n",
            "\n",
            " [[1. 1. 1. ... 1. 1. 0.]\n",
            "  [1. 1. 1. ... 0. 0. 1.]\n",
            "  [1. 1. 1. ... 1. 0. 1.]\n",
            "  ...\n",
            "  [1. 0. 1. ... 1. 0. 0.]\n",
            "  [1. 0. 0. ... 0. 1. 0.]\n",
            "  [0. 1. 1. ... 0. 0. 1.]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[1. 1. 1. ... 1. 1. 0.]\n",
            "  [1. 1. 1. ... 0. 0. 1.]\n",
            "  [1. 1. 1. ... 1. 0. 1.]\n",
            "  ...\n",
            "  [1. 0. 1. ... 1. 0. 0.]\n",
            "  [1. 0. 0. ... 0. 1. 0.]\n",
            "  [0. 1. 1. ... 0. 0. 1.]]\n",
            "\n",
            " [[1. 1. 1. ... 1. 1. 0.]\n",
            "  [1. 1. 1. ... 0. 0. 1.]\n",
            "  [1. 1. 1. ... 1. 0. 1.]\n",
            "  ...\n",
            "  [1. 0. 1. ... 1. 0. 0.]\n",
            "  [1. 0. 0. ... 0. 1. 0.]\n",
            "  [0. 1. 1. ... 0. 0. 1.]]\n",
            "\n",
            " [[1. 1. 1. ... 1. 1. 0.]\n",
            "  [1. 1. 1. ... 0. 0. 1.]\n",
            "  [1. 1. 1. ... 1. 0. 1.]\n",
            "  ...\n",
            "  [1. 0. 1. ... 1. 0. 0.]\n",
            "  [1. 0. 0. ... 0. 1. 0.]\n",
            "  [0. 1. 1. ... 0. 0. 1.]]], shape=(160, 15, 15), dtype=float32) tf.Tensor(\n",
            "[[1 1 0 0 0 1 0 1 1 1]\n",
            " [0 1 1 0 1 0 1 1 0 1]\n",
            " [1 0 1 1 0 1 1 1 0 0]\n",
            " [1 0 0 1 1 0 1 0 1 1]\n",
            " [0 1 1 1 1 1 0 0 1 0]], shape=(5, 10), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "@staticmethod\n",
        "def bin_to_llr(x):\n",
        "    \"\"\" Clip llrs to 20 for numerical stability \"\"\"\n",
        "    llr_vector = tf.where(x == 0, -20, 20)\n",
        "    return llr_vector\n",
        "\n",
        "@staticmethod\n",
        "def llr_to_bin(c):\n",
        "    return tf.cast(tf.greater(c, 0), tf.int32)\n",
        "\n",
        "def train_dec(model, args):\n",
        "    # loss\n",
        "    loss_fn = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
        "    # optimizer\n",
        "    scheduler = tf.keras.optimizers.schedules.CosineDecay(initial_learning_rate=args.lr, decay_steps=args.epochs) # 1000 is size of trainloader\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate=scheduler)\n",
        "    # time start\n",
        "    time_start = time.time()\n",
        "\n",
        "    # SGD update iteration\n",
        "    @tf.function(jit_compile=False)\n",
        "    def train_step(batch_size):\n",
        "        # train for random SNRs within a pre-defined interval\n",
        "        ebno_db = tf.random.uniform([batch_size, 1],\n",
        "                                    minval=args.ebno_db_min,\n",
        "                                    maxval=args.ebno_db_max)\n",
        "\n",
        "        with tf.GradientTape() as tape:\n",
        "            c, llr_hat, llr_channel = model(batch_size, ebno_db)\n",
        "            # tf.print(c, llr_hat)\n",
        "\n",
        "            llr_y = bin_to_llr(c)\n",
        "            # tf.print(\"llrs\", llr_y, llr_hat)\n",
        "            loss_value = loss_fn(llr_y, llr_hat)\n",
        "\n",
        "        # and apply the SGD updates\n",
        "        weights = model.trainable_weights\n",
        "        grads = tape.gradient(loss_value, weights) # variables\n",
        "        optimizer.apply_gradients(zip(grads, weights))\n",
        "        return c, llr_hat\n",
        "\n",
        "    print(\"Training Linear Transformer Model...\")\n",
        "    for epoch in range(1, args.epochs + 1):\n",
        "        train_step(args.batch_size)\n",
        "\n",
        "        # eval train iter\n",
        "        if True: #epoch % args.eval_train_iter == 0:\n",
        "            ebno_db = tf.random.uniform([args.batch_size, 1],\n",
        "                                          minval=args.ebno_db_eval,\n",
        "                                          maxval=args.ebno_db_eval)\n",
        "\n",
        "            c, llr_hat, llr_channel = model(args.batch_size, ebno_db)\n",
        "\n",
        "            # loss\n",
        "            llr_y = bin_to_llr(c)\n",
        "            loss_value = loss_fn(llr_y, llr_hat)\n",
        "\n",
        "            # ber\n",
        "            c_hat = llr_to_bin(llr_hat)\n",
        "            ber = compute_ber(c, c_hat).numpy()\n",
        "\n",
        "            c_channel = llr_to_bin(llr_channel)\n",
        "            channel_ber = compute_ber(c, c_channel).numpy()\n",
        "\n",
        "            # measure required time since last evaluation\n",
        "            duration = time.time() - time_start # in s\n",
        "            time_start = time.time() # reset counter\n",
        "\n",
        "            print(f'Training epoch {epoch}/{args.epochs}, LR={optimizer.learning_rate.numpy():.2e}, Loss={loss_value.numpy():.5e}, channel_BER={channel_ber}, BER={ber}, duration: {duration:.2f}s')\n",
        "            # break\n",
        "\n",
        "        # save weights iter\n",
        "        if epoch % args.save_weights_iter == 0:\n",
        "            save_path = '/content/drive/My Drive/ECC_weights/'\n",
        "            checkpoint = tf.train.Checkpoint(decoder=e2e_ltd._decoder)\n",
        "            # Save the checkpoint\n",
        "            checkpoint.save(os.path.join(save_path,(os.path.join(save_path, 'ECCT_dims512.h5'))))\n",
        "\n",
        "        # heat-map visualization of the model's weights\n",
        "        # for var in self.trainable_variables:\n",
        "        #     var_name = var.name\n",
        "        #     var_value = var.numpy()\n",
        "\n",
        "        #     # Check if the variable is at least 2D (suitable for heatmap)\n",
        "        #     if len(var_value.shape) > 1:\n",
        "        #         plt.figure(figsize=(8, 6))\n",
        "        #         sns.heatmap(var_value, cmap='viridis')\n",
        "        #         plt.title(f'Heatmap of {var_name}')\n",
        "        #         plt.show()\n",
        "        #     else:\n",
        "        #         print(f\"{var_name} has shape {var_value.shape} which is not suitable for a heatmap.\")\n",
        "\n",
        "\n",
        "train_dec(e2e_ltd, args)"
      ],
      "metadata": {
        "id": "oHhDtIq64gjg",
        "outputId": "29228063-d585-44c1-b6d3-4f227795afb5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Linear Transformer Model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:You are casting an input of type complex64 to an incompatible dtype float32.  This will discard the imaginary part and may not be what you intended.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "Training epoch 1/1000, LR=5.00e-04, Loss=-5.58276e+01, channel_BER=0.08875, BER=0.435625, duration: 11.86s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "Training epoch 2/1000, LR=5.00e-04, Loss=-4.65857e+01, channel_BER=0.099375, BER=0.448125, duration: 4.91s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "Training epoch 3/1000, LR=5.00e-04, Loss=-5.40837e+01, channel_BER=0.10125, BER=0.444375, duration: 6.34s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "Training epoch 4/1000, LR=5.00e-04, Loss=-8.18421e+01, channel_BER=0.088125, BER=0.45125, duration: 11.74s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "Training epoch 5/1000, LR=5.00e-04, Loss=-7.38299e+01, channel_BER=0.09375, BER=0.455, duration: 6.25s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "Training epoch 6/1000, LR=5.00e-04, Loss=-9.98669e+01, channel_BER=0.079375, BER=0.44, duration: 6.63s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "Training epoch 7/1000, LR=5.00e-04, Loss=-1.29822e+02, channel_BER=0.0825, BER=0.419375, duration: 5.06s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "Training epoch 8/1000, LR=5.00e-04, Loss=-1.15384e+02, channel_BER=0.08875, BER=0.420625, duration: 6.81s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "Training epoch 9/1000, LR=5.00e-04, Loss=-1.19801e+02, channel_BER=0.10125, BER=0.42, duration: 5.47s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "Training epoch 10/1000, LR=5.00e-04, Loss=-1.00753e+02, channel_BER=0.088125, BER=0.434375, duration: 5.21s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "Training epoch 11/1000, LR=5.00e-04, Loss=-7.38414e+01, channel_BER=0.088125, BER=0.4525, duration: 7.44s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "Training epoch 12/1000, LR=5.00e-04, Loss=-1.11165e+02, channel_BER=0.091875, BER=0.423125, duration: 5.17s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "Training epoch 13/1000, LR=5.00e-04, Loss=-7.51948e+01, channel_BER=0.08625, BER=0.458125, duration: 5.28s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "Training epoch 14/1000, LR=5.00e-04, Loss=-1.42775e+02, channel_BER=0.08625, BER=0.410625, duration: 7.56s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "Training epoch 15/1000, LR=5.00e-04, Loss=-1.02520e+02, channel_BER=0.085, BER=0.44, duration: 5.25s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "Training epoch 16/1000, LR=5.00e-04, Loss=-7.24377e+01, channel_BER=0.10375, BER=0.45375, duration: 5.91s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "Training epoch 17/1000, LR=5.00e-04, Loss=-1.13057e+02, channel_BER=0.091875, BER=0.43875, duration: 6.57s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "Training epoch 18/1000, LR=5.00e-04, Loss=-1.05663e+02, channel_BER=0.09, BER=0.4375, duration: 5.01s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "Training epoch 19/1000, LR=5.00e-04, Loss=-9.57326e+01, channel_BER=0.11, BER=0.44875, duration: 6.79s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "Training epoch 20/1000, LR=5.00e-04, Loss=-1.05799e+02, channel_BER=0.085, BER=0.458125, duration: 5.82s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "Training epoch 21/1000, LR=5.00e-04, Loss=-9.86498e+01, channel_BER=0.0925, BER=0.448125, duration: 4.95s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "Training epoch 22/1000, LR=4.99e-04, Loss=-1.01697e+02, channel_BER=0.095625, BER=0.43875, duration: 7.40s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "Training epoch 23/1000, LR=4.99e-04, Loss=-1.30169e+02, channel_BER=0.085, BER=0.441875, duration: 5.01s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "Training epoch 24/1000, LR=4.99e-04, Loss=-1.43892e+02, channel_BER=0.088125, BER=0.414375, duration: 5.37s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "Training epoch 25/1000, LR=4.99e-04, Loss=-1.10855e+02, channel_BER=0.08375, BER=0.435625, duration: 7.45s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "Training epoch 26/1000, LR=4.99e-04, Loss=-1.39961e+02, channel_BER=0.08375, BER=0.419375, duration: 5.05s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "Training epoch 27/1000, LR=4.99e-04, Loss=-9.00980e+01, channel_BER=0.088125, BER=0.464375, duration: 6.04s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "Training epoch 28/1000, LR=4.99e-04, Loss=-1.57943e+02, channel_BER=0.09125, BER=0.41875, duration: 6.57s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "Training epoch 29/1000, LR=4.99e-04, Loss=-6.50400e+01, channel_BER=0.090625, BER=0.46, duration: 5.17s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "Training epoch 30/1000, LR=4.99e-04, Loss=-1.38628e+02, channel_BER=0.075, BER=0.430625, duration: 6.51s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "Training epoch 31/1000, LR=4.99e-04, Loss=-1.34204e+02, channel_BER=0.10125, BER=0.4225, duration: 6.29s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "Training epoch 32/1000, LR=4.99e-04, Loss=-1.08393e+02, channel_BER=0.08375, BER=0.441875, duration: 5.03s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "Training epoch 33/1000, LR=4.99e-04, Loss=-1.00926e+02, channel_BER=0.100625, BER=0.420625, duration: 7.31s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "Training epoch 34/1000, LR=4.99e-04, Loss=-1.81529e+02, channel_BER=0.083125, BER=0.405625, duration: 5.62s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "Training epoch 35/1000, LR=4.99e-04, Loss=-1.33688e+02, channel_BER=0.084375, BER=0.4175, duration: 5.04s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "Training epoch 36/1000, LR=4.98e-04, Loss=-1.41175e+02, channel_BER=0.089375, BER=0.406875, duration: 7.55s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "Training epoch 37/1000, LR=4.98e-04, Loss=-1.46985e+02, channel_BER=0.08625, BER=0.43125, duration: 5.10s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "Training epoch 38/1000, LR=4.98e-04, Loss=-1.42668e+02, channel_BER=0.09625, BER=0.411875, duration: 5.79s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "Training epoch 39/1000, LR=4.98e-04, Loss=-1.34126e+02, channel_BER=0.1, BER=0.413125, duration: 7.06s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "Training epoch 40/1000, LR=4.98e-04, Loss=-1.37670e+02, channel_BER=0.11125, BER=0.421875, duration: 5.00s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "Training epoch 41/1000, LR=4.98e-04, Loss=-1.45171e+02, channel_BER=0.084375, BER=0.438125, duration: 6.54s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "Training epoch 42/1000, LR=4.98e-04, Loss=-1.24762e+02, channel_BER=0.084375, BER=0.43, duration: 6.04s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "Training epoch 43/1000, LR=4.98e-04, Loss=-1.70756e+02, channel_BER=0.093125, BER=0.420625, duration: 5.22s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "Training epoch 44/1000, LR=4.98e-04, Loss=-1.53173e+02, channel_BER=0.10625, BER=0.42375, duration: 7.34s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "Training epoch 45/1000, LR=4.98e-04, Loss=-1.51146e+02, channel_BER=0.098125, BER=0.42375, duration: 5.36s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "Training epoch 46/1000, LR=4.98e-04, Loss=-1.62802e+02, channel_BER=0.08875, BER=0.415, duration: 5.22s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "Training epoch 47/1000, LR=4.97e-04, Loss=-1.26563e+02, channel_BER=0.091875, BER=0.443125, duration: 7.47s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "Training epoch 48/1000, LR=4.97e-04, Loss=-1.12131e+02, channel_BER=0.101875, BER=0.43875, duration: 5.26s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "Training epoch 49/1000, LR=4.97e-04, Loss=-1.10521e+02, channel_BER=0.095625, BER=0.44125, duration: 5.27s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "Training epoch 50/1000, LR=4.97e-04, Loss=-1.06452e+02, channel_BER=0.0925, BER=0.44125, duration: 7.37s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "Training epoch 51/1000, LR=4.97e-04, Loss=-1.29078e+02, channel_BER=0.085625, BER=0.44875, duration: 5.22s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "Training epoch 52/1000, LR=4.97e-04, Loss=-1.48258e+02, channel_BER=0.08375, BER=0.444375, duration: 5.92s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "Training epoch 53/1000, LR=4.97e-04, Loss=-1.22415e+02, channel_BER=0.09875, BER=0.440625, duration: 6.80s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "Training epoch 54/1000, LR=4.97e-04, Loss=-1.79050e+02, channel_BER=0.0925, BER=0.405625, duration: 4.95s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "Training epoch 55/1000, LR=4.96e-04, Loss=-1.66659e+02, channel_BER=0.088125, BER=0.4325, duration: 6.85s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "Training epoch 56/1000, LR=4.96e-04, Loss=-1.34229e+02, channel_BER=0.098125, BER=0.455625, duration: 5.69s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "Training epoch 57/1000, LR=4.96e-04, Loss=-1.57256e+02, channel_BER=0.095625, BER=0.421875, duration: 4.98s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "Training epoch 58/1000, LR=4.96e-04, Loss=-1.05424e+02, channel_BER=0.09875, BER=0.45875, duration: 7.57s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "Training epoch 59/1000, LR=4.96e-04, Loss=-1.67627e+02, channel_BER=0.08625, BER=0.405625, duration: 4.97s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "Training epoch 60/1000, LR=4.96e-04, Loss=-1.78322e+02, channel_BER=0.0925, BER=0.40625, duration: 5.30s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "Training epoch 61/1000, LR=4.96e-04, Loss=-1.38200e+02, channel_BER=0.09125, BER=0.436875, duration: 7.34s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "Training epoch 62/1000, LR=4.95e-04, Loss=-1.37514e+02, channel_BER=0.1, BER=0.4425, duration: 4.93s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "Training epoch 63/1000, LR=4.95e-04, Loss=-1.32391e+02, channel_BER=0.095, BER=0.42, duration: 5.40s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "Training epoch 64/1000, LR=4.95e-04, Loss=-1.61325e+02, channel_BER=0.088125, BER=0.424375, duration: 6.84s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "Training epoch 65/1000, LR=4.95e-04, Loss=-1.69460e+02, channel_BER=0.085625, BER=0.421875, duration: 4.95s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "Training epoch 66/1000, LR=4.95e-04, Loss=-1.65083e+02, channel_BER=0.093125, BER=0.425, duration: 6.38s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "Training epoch 67/1000, LR=4.95e-04, Loss=-1.60310e+02, channel_BER=0.075, BER=0.43, duration: 6.36s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "Training epoch 68/1000, LR=4.94e-04, Loss=-1.19878e+02, channel_BER=0.099375, BER=0.455625, duration: 4.98s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "Training epoch 69/1000, LR=4.94e-04, Loss=-1.70364e+02, channel_BER=0.080625, BER=0.434375, duration: 6.89s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "Training epoch 70/1000, LR=4.94e-04, Loss=-1.33691e+02, channel_BER=0.110625, BER=0.4525, duration: 5.67s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "Training epoch 71/1000, LR=4.94e-04, Loss=-1.64990e+02, channel_BER=0.095625, BER=0.42, duration: 5.12s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "Training epoch 72/1000, LR=4.94e-04, Loss=-1.51208e+02, channel_BER=0.091875, BER=0.4225, duration: 7.16s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "Training epoch 73/1000, LR=4.94e-04, Loss=-2.31221e+02, channel_BER=0.1025, BER=0.413125, duration: 5.41s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "Training epoch 74/1000, LR=4.93e-04, Loss=-1.66615e+02, channel_BER=0.080625, BER=0.44, duration: 5.02s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "Training epoch 75/1000, LR=4.93e-04, Loss=-1.92165e+02, channel_BER=0.100625, BER=0.424375, duration: 7.44s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "Training epoch 76/1000, LR=4.93e-04, Loss=-1.77236e+02, channel_BER=0.09625, BER=0.435625, duration: 5.15s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "Training epoch 77/1000, LR=4.93e-04, Loss=-1.89923e+02, channel_BER=0.08875, BER=0.40375, duration: 5.22s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "Training epoch 78/1000, LR=4.93e-04, Loss=-1.58163e+02, channel_BER=0.09125, BER=0.425625, duration: 7.06s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "Training epoch 79/1000, LR=4.93e-04, Loss=-1.81731e+02, channel_BER=0.084375, BER=0.43375, duration: 5.04s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "Training epoch 80/1000, LR=4.92e-04, Loss=-1.97093e+02, channel_BER=0.09, BER=0.406875, duration: 6.32s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "Training epoch 81/1000, LR=4.92e-04, Loss=-1.74162e+02, channel_BER=0.085625, BER=0.42125, duration: 6.29s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "Training epoch 82/1000, LR=4.92e-04, Loss=-2.95481e+02, channel_BER=0.08625, BER=0.38125, duration: 4.90s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "Training epoch 83/1000, LR=4.92e-04, Loss=-2.12524e+02, channel_BER=0.085625, BER=0.399375, duration: 7.20s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "Training epoch 84/1000, LR=4.92e-04, Loss=-1.86899e+02, channel_BER=0.094375, BER=0.41375, duration: 5.60s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "Training epoch 85/1000, LR=4.91e-04, Loss=-2.09552e+02, channel_BER=0.10125, BER=0.41375, duration: 5.09s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "Training epoch 86/1000, LR=4.91e-04, Loss=-2.12463e+02, channel_BER=0.076875, BER=0.415, duration: 7.57s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "Training epoch 87/1000, LR=4.91e-04, Loss=-2.67234e+02, channel_BER=0.086875, BER=0.39875, duration: 5.08s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "Training epoch 88/1000, LR=4.91e-04, Loss=-2.21584e+02, channel_BER=0.088125, BER=0.405625, duration: 5.26s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "Training epoch 89/1000, LR=4.91e-04, Loss=-1.96324e+02, channel_BER=0.0875, BER=0.40875, duration: 7.39s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "Training epoch 90/1000, LR=4.90e-04, Loss=-2.28237e+02, channel_BER=0.089375, BER=0.40625, duration: 5.24s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "Training epoch 91/1000, LR=4.90e-04, Loss=-2.89538e+02, channel_BER=0.0925, BER=0.3925, duration: 5.97s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "Training epoch 92/1000, LR=4.90e-04, Loss=-3.00657e+02, channel_BER=0.096875, BER=0.37125, duration: 6.99s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "Training epoch 93/1000, LR=4.90e-04, Loss=-2.24378e+02, channel_BER=0.090625, BER=0.41625, duration: 5.42s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "Training epoch 94/1000, LR=4.89e-04, Loss=-2.62603e+02, channel_BER=0.086875, BER=0.405, duration: 6.77s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "Training epoch 95/1000, LR=4.89e-04, Loss=-1.98140e+02, channel_BER=0.081875, BER=0.41375, duration: 5.94s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "Training epoch 96/1000, LR=4.89e-04, Loss=-2.38021e+02, channel_BER=0.108125, BER=0.398125, duration: 5.03s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "Training epoch 97/1000, LR=4.89e-04, Loss=-2.64475e+02, channel_BER=0.098125, BER=0.400625, duration: 7.63s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "Training epoch 98/1000, LR=4.88e-04, Loss=-2.52261e+02, channel_BER=0.090625, BER=0.39875, duration: 5.14s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "Training epoch 99/1000, LR=4.88e-04, Loss=-2.76501e+02, channel_BER=0.109375, BER=0.386875, duration: 5.22s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "Training epoch 100/1000, LR=4.88e-04, Loss=-3.13647e+02, channel_BER=0.09, BER=0.38125, duration: 7.43s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "Training epoch 101/1000, LR=4.88e-04, Loss=-2.69739e+02, channel_BER=0.095625, BER=0.3925, duration: 5.21s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "Training epoch 102/1000, LR=4.88e-04, Loss=-3.04630e+02, channel_BER=0.076875, BER=0.373125, duration: 6.56s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "Training epoch 103/1000, LR=4.87e-04, Loss=-3.01695e+02, channel_BER=0.091875, BER=0.395625, duration: 6.42s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "Training epoch 104/1000, LR=4.87e-04, Loss=-2.73746e+02, channel_BER=0.083125, BER=0.395, duration: 5.29s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "Training epoch 105/1000, LR=4.87e-04, Loss=-2.55354e+02, channel_BER=0.100625, BER=0.394375, duration: 7.13s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "Training epoch 106/1000, LR=4.87e-04, Loss=-2.39092e+02, channel_BER=0.100625, BER=0.41125, duration: 5.57s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "Training epoch 107/1000, LR=4.86e-04, Loss=-2.57240e+02, channel_BER=0.090625, BER=0.40875, duration: 5.28s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "Training epoch 108/1000, LR=4.86e-04, Loss=-3.07422e+02, channel_BER=0.090625, BER=0.4, duration: 7.54s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "Training epoch 109/1000, LR=4.86e-04, Loss=-2.45284e+02, channel_BER=0.103125, BER=0.41375, duration: 5.19s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "Training epoch 110/1000, LR=4.85e-04, Loss=-3.41484e+02, channel_BER=0.10125, BER=0.39875, duration: 5.22s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "Training epoch 111/1000, LR=4.85e-04, Loss=-3.25060e+02, channel_BER=0.090625, BER=0.388125, duration: 7.24s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "Training epoch 112/1000, LR=4.85e-04, Loss=-3.03810e+02, channel_BER=0.09125, BER=0.39625, duration: 5.17s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "Training epoch 113/1000, LR=4.85e-04, Loss=-3.49322e+02, channel_BER=0.1025, BER=0.3825, duration: 6.02s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "Training epoch 114/1000, LR=4.84e-04, Loss=-2.64765e+02, channel_BER=0.089375, BER=0.403125, duration: 6.65s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "Training epoch 115/1000, LR=4.84e-04, Loss=-3.04462e+02, channel_BER=0.09, BER=0.39625, duration: 4.98s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "Training epoch 116/1000, LR=4.84e-04, Loss=-2.54043e+02, channel_BER=0.08875, BER=0.41125, duration: 6.49s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "Training epoch 117/1000, LR=4.84e-04, Loss=-2.38124e+02, channel_BER=0.0825, BER=0.413125, duration: 5.66s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "Training epoch 118/1000, LR=4.83e-04, Loss=-3.44898e+02, channel_BER=0.08375, BER=0.398125, duration: 5.19s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "Training epoch 119/1000, LR=4.83e-04, Loss=-3.03475e+02, channel_BER=0.089375, BER=0.400625, duration: 7.27s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "Training epoch 120/1000, LR=4.83e-04, Loss=-3.30400e+02, channel_BER=0.101875, BER=0.38, duration: 5.16s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "Training epoch 121/1000, LR=4.82e-04, Loss=-3.39255e+02, channel_BER=0.09, BER=0.39625, duration: 5.09s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "Training epoch 122/1000, LR=4.82e-04, Loss=-3.76962e+02, channel_BER=0.095, BER=0.37375, duration: 7.31s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "Training epoch 123/1000, LR=4.82e-04, Loss=-3.33164e+02, channel_BER=0.09625, BER=0.39375, duration: 5.19s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "Training epoch 124/1000, LR=4.82e-04, Loss=-2.69602e+02, channel_BER=0.09, BER=0.3975, duration: 5.80s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "Training epoch 125/1000, LR=4.81e-04, Loss=-2.94434e+02, channel_BER=0.08625, BER=0.40875, duration: 6.90s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "Training epoch 126/1000, LR=4.81e-04, Loss=-3.81026e+02, channel_BER=0.088125, BER=0.395625, duration: 4.98s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "Training epoch 127/1000, LR=4.81e-04, Loss=-2.90468e+02, channel_BER=0.0975, BER=0.39875, duration: 6.47s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "Training epoch 128/1000, LR=4.80e-04, Loss=-3.46584e+02, channel_BER=0.08875, BER=0.395, duration: 6.45s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "Training epoch 129/1000, LR=4.80e-04, Loss=-3.06148e+02, channel_BER=0.09125, BER=0.4075, duration: 5.01s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "Training epoch 130/1000, LR=4.80e-04, Loss=-2.60333e+02, channel_BER=0.0975, BER=0.416875, duration: 7.33s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "Training epoch 131/1000, LR=4.79e-04, Loss=-3.87630e+02, channel_BER=0.09, BER=0.378125, duration: 5.25s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "Training epoch 132/1000, LR=4.79e-04, Loss=-3.20001e+02, channel_BER=0.0775, BER=0.398125, duration: 5.07s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "Training epoch 133/1000, LR=4.79e-04, Loss=-3.57867e+02, channel_BER=0.106875, BER=0.393125, duration: 7.56s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "Training epoch 134/1000, LR=4.78e-04, Loss=-3.14059e+02, channel_BER=0.085, BER=0.405, duration: 4.99s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "Training epoch 135/1000, LR=4.78e-04, Loss=-3.35152e+02, channel_BER=0.0825, BER=0.398125, duration: 5.55s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "Training epoch 136/1000, LR=4.78e-04, Loss=-3.88234e+02, channel_BER=0.08375, BER=0.378125, duration: 7.09s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "Training epoch 137/1000, LR=4.78e-04, Loss=-4.53275e+02, channel_BER=0.083125, BER=0.37625, duration: 5.16s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "Training epoch 138/1000, LR=4.77e-04, Loss=-4.03337e+02, channel_BER=0.081875, BER=0.384375, duration: 5.96s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "Training epoch 139/1000, LR=4.77e-04, Loss=-3.02439e+02, channel_BER=0.0775, BER=0.42, duration: 6.61s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "Training epoch 140/1000, LR=4.77e-04, Loss=-3.66680e+02, channel_BER=0.090625, BER=0.38, duration: 4.98s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "Training epoch 141/1000, LR=4.76e-04, Loss=-4.69276e+02, channel_BER=0.08125, BER=0.3675, duration: 6.88s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "Training epoch 142/1000, LR=4.76e-04, Loss=-3.98965e+02, channel_BER=0.089375, BER=0.370625, duration: 5.92s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "Training epoch 143/1000, LR=4.76e-04, Loss=-3.03857e+02, channel_BER=0.10375, BER=0.399375, duration: 5.01s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "Training epoch 144/1000, LR=4.75e-04, Loss=-3.56709e+02, channel_BER=0.095625, BER=0.418125, duration: 7.49s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "Training epoch 145/1000, LR=4.75e-04, Loss=-3.61745e+02, channel_BER=0.079375, BER=0.391875, duration: 4.99s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "Training epoch 146/1000, LR=4.75e-04, Loss=-3.72536e+02, channel_BER=0.0975, BER=0.394375, duration: 5.22s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "Training epoch 147/1000, LR=4.74e-04, Loss=-4.01018e+02, channel_BER=0.093125, BER=0.3825, duration: 7.62s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "Training epoch 148/1000, LR=4.74e-04, Loss=-4.67904e+02, channel_BER=0.09125, BER=0.36, duration: 5.08s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "Training epoch 149/1000, LR=4.73e-04, Loss=-2.97280e+02, channel_BER=0.094375, BER=0.405, duration: 5.72s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "Training epoch 150/1000, LR=4.73e-04, Loss=-3.84927e+02, channel_BER=0.090625, BER=0.38125, duration: 6.94s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "Training epoch 151/1000, LR=4.73e-04, Loss=-4.64986e+02, channel_BER=0.085625, BER=0.383125, duration: 5.18s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "Training epoch 152/1000, LR=4.72e-04, Loss=-4.14690e+02, channel_BER=0.081875, BER=0.38375, duration: 6.17s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "Training epoch 153/1000, LR=4.72e-04, Loss=-4.35081e+02, channel_BER=0.088125, BER=0.376875, duration: 6.43s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "Training epoch 154/1000, LR=4.72e-04, Loss=-4.51553e+02, channel_BER=0.104375, BER=0.3725, duration: 5.22s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "Training epoch 155/1000, LR=4.71e-04, Loss=-4.38175e+02, channel_BER=0.096875, BER=0.374375, duration: 6.91s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "Training epoch 156/1000, LR=4.71e-04, Loss=-4.03358e+02, channel_BER=0.08625, BER=0.383125, duration: 5.70s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "Training epoch 157/1000, LR=4.71e-04, Loss=-4.64820e+02, channel_BER=0.09125, BER=0.360625, duration: 5.05s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "Training epoch 158/1000, LR=4.70e-04, Loss=-4.18303e+02, channel_BER=0.1, BER=0.384375, duration: 7.52s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "Training epoch 159/1000, LR=4.70e-04, Loss=-4.99539e+02, channel_BER=0.081875, BER=0.353125, duration: 5.17s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "Training epoch 160/1000, LR=4.69e-04, Loss=-4.25831e+02, channel_BER=0.090625, BER=0.38375, duration: 5.54s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "Training epoch 161/1000, LR=4.69e-04, Loss=-3.34518e+02, channel_BER=0.098125, BER=0.409375, duration: 6.99s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "Training epoch 162/1000, LR=4.69e-04, Loss=-4.61062e+02, channel_BER=0.0825, BER=0.36375, duration: 4.99s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "Training epoch 163/1000, LR=4.68e-04, Loss=-4.71117e+02, channel_BER=0.09, BER=0.366875, duration: 6.52s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "Training epoch 164/1000, LR=4.68e-04, Loss=-4.73008e+02, channel_BER=0.0925, BER=0.3625, duration: 6.21s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "Training epoch 165/1000, LR=4.68e-04, Loss=-4.38115e+02, channel_BER=0.0925, BER=0.39375, duration: 5.22s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "Training epoch 166/1000, LR=4.67e-04, Loss=-5.29816e+02, channel_BER=0.098125, BER=0.37125, duration: 7.38s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "Training epoch 167/1000, LR=4.67e-04, Loss=-4.03863e+02, channel_BER=0.081875, BER=0.390625, duration: 5.40s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "Training epoch 168/1000, LR=4.66e-04, Loss=-5.05131e+02, channel_BER=0.095, BER=0.365625, duration: 5.34s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "Training epoch 169/1000, LR=4.66e-04, Loss=-5.11536e+02, channel_BER=0.100625, BER=0.374375, duration: 7.31s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "Training epoch 170/1000, LR=4.66e-04, Loss=-5.05034e+02, channel_BER=0.07875, BER=0.348125, duration: 5.03s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "Training epoch 171/1000, LR=4.65e-04, Loss=-4.49792e+02, channel_BER=0.08625, BER=0.38375, duration: 5.57s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "Training epoch 172/1000, LR=4.65e-04, Loss=-5.92412e+02, channel_BER=0.094375, BER=0.35375, duration: 6.93s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "Training epoch 173/1000, LR=4.64e-04, Loss=-4.55843e+02, channel_BER=0.091875, BER=0.375, duration: 5.01s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "Training epoch 174/1000, LR=4.64e-04, Loss=-5.61226e+02, channel_BER=0.09625, BER=0.36125, duration: 6.31s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "Training epoch 175/1000, LR=4.64e-04, Loss=-5.11307e+02, channel_BER=0.08375, BER=0.360625, duration: 6.21s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "Training epoch 176/1000, LR=4.63e-04, Loss=-4.88563e+02, channel_BER=0.09875, BER=0.38375, duration: 4.98s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "Training epoch 177/1000, LR=4.63e-04, Loss=-5.10270e+02, channel_BER=0.090625, BER=0.35125, duration: 6.73s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "Training epoch 178/1000, LR=4.62e-04, Loss=-4.89562e+02, channel_BER=0.083125, BER=0.38, duration: 5.79s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "Training epoch 179/1000, LR=4.62e-04, Loss=-4.31884e+02, channel_BER=0.09, BER=0.388125, duration: 5.01s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "Training epoch 180/1000, LR=4.62e-04, Loss=-5.35291e+02, channel_BER=0.086875, BER=0.370625, duration: 7.25s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "Training epoch 181/1000, LR=4.61e-04, Loss=-4.23479e+02, channel_BER=0.091875, BER=0.39625, duration: 5.09s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "Training epoch 182/1000, LR=4.61e-04, Loss=-5.54179e+02, channel_BER=0.098125, BER=0.37375, duration: 5.00s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "Training epoch 183/1000, LR=4.60e-04, Loss=-5.53610e+02, channel_BER=0.088125, BER=0.373125, duration: 7.21s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "Training epoch 184/1000, LR=4.60e-04, Loss=-4.90802e+02, channel_BER=0.07875, BER=0.375625, duration: 5.03s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "Training epoch 185/1000, LR=4.59e-04, Loss=-5.25675e+02, channel_BER=0.096875, BER=0.371875, duration: 5.49s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "Training epoch 186/1000, LR=4.59e-04, Loss=-4.67179e+02, channel_BER=0.0975, BER=0.403125, duration: 6.98s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "Training epoch 187/1000, LR=4.59e-04, Loss=-5.10122e+02, channel_BER=0.105625, BER=0.38125, duration: 5.04s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "Training epoch 188/1000, LR=4.58e-04, Loss=-4.98513e+02, channel_BER=0.094375, BER=0.394375, duration: 6.09s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "Training epoch 189/1000, LR=4.58e-04, Loss=-6.32380e+02, channel_BER=0.10625, BER=0.36625, duration: 6.24s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "Training epoch 190/1000, LR=4.57e-04, Loss=-6.17108e+02, channel_BER=0.095625, BER=0.350625, duration: 5.04s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "Training epoch 191/1000, LR=4.57e-04, Loss=-6.11657e+02, channel_BER=0.1, BER=0.37625, duration: 6.93s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "Training epoch 192/1000, LR=4.56e-04, Loss=-5.55629e+02, channel_BER=0.095, BER=0.37625, duration: 5.51s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "Training epoch 193/1000, LR=4.56e-04, Loss=-6.02700e+02, channel_BER=0.09125, BER=0.370625, duration: 5.02s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "Training epoch 194/1000, LR=4.55e-04, Loss=-7.08066e+02, channel_BER=0.0775, BER=0.330625, duration: 7.35s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "Training epoch 195/1000, LR=4.55e-04, Loss=-5.82972e+02, channel_BER=0.09375, BER=0.36, duration: 5.01s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "Training epoch 196/1000, LR=4.55e-04, Loss=-5.27546e+02, channel_BER=0.08875, BER=0.359375, duration: 5.31s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "Training epoch 197/1000, LR=4.54e-04, Loss=-5.22908e+02, channel_BER=0.093125, BER=0.3575, duration: 7.16s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "Training epoch 198/1000, LR=4.54e-04, Loss=-9.95082e+01, channel_BER=0.103125, BER=0.434375, duration: 5.05s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "Training epoch 199/1000, LR=4.53e-04, Loss=3.51112e+01, channel_BER=0.089375, BER=0.48875, duration: 5.82s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "Training epoch 200/1000, LR=4.53e-04, Loss=1.00305e+02, channel_BER=0.085, BER=0.493125, duration: 6.51s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "Training epoch 201/1000, LR=4.52e-04, Loss=1.43222e+02, channel_BER=0.095625, BER=0.49875, duration: 5.29s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n",
            "Training epoch 202/1000, LR=4.52e-04, Loss=8.45705e+01, channel_BER=0.088125, BER=0.500625, duration: 6.79s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 512])\n",
            "ffn_output TensorShape([160, 15, 512])\n",
            "x_nodes TensorShape([160, 15, 512])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "4vZxtXOf4c1k",
        "outputId": "4dfb26e2-5da8-4e4d-9952-601378b4c150",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "save_path = '/content/drive/My Drive/ECC_weights/'\n",
        "checkpoint = tf.train.Checkpoint(decoder=e2e_ltd._decoder)\n",
        "# Save the checkpoint\n",
        "checkpoint.save(os.path.join(save_path,(os.path.join(save_path, 'ECCT_dims128.h5'))))"
      ],
      "metadata": {
        "id": "vWxADRdv5w7G",
        "outputId": "b1f7ff71-8f2b-4b8b-8162-317750507ee3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/My Drive/ECC_weights/ECCT_dims128.h5-1'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    }
  ]
}