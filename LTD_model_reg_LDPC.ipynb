{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMZtgNrwQ/QiJU5j7VZ1wSG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pollyjuice74/5G-Decoder/blob/main/LTD_model_reg_LDPC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "collapsed": true,
        "id": "5q1VAmIeUKIn",
        "outputId": "3ccd6e8c-b13b-450d-834e-cacd8dcfc530",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into '5G-Decoder'...\n",
            "remote: Enumerating objects: 1464, done.\u001b[K\n",
            "remote: Counting objects: 100% (1464/1464), done.\u001b[K\n",
            "remote: Compressing objects: 100% (524/524), done.\u001b[K\n",
            "remote: Total 1464 (delta 926), reused 1464 (delta 926), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (1464/1464), 1.61 MiB | 16.16 MiB/s, done.\n",
            "Resolving deltas: 100% (926/926), done.\n",
            "Collecting sionna\n",
            "  Downloading sionna-0.19.1-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting tensorflow<2.16.0,>=2.13.0 (from sionna)\n",
            "  Downloading tensorflow-2.15.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from sionna) (1.26.4)\n",
            "Requirement already satisfied: matplotlib>=3.5.3 in /usr/local/lib/python3.10/dist-packages (from sionna) (3.8.0)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from sionna) (1.13.1)\n",
            "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.10/dist-packages (from sionna) (6.4.5)\n",
            "Collecting mitsuba<3.6.0,>=3.2.0 (from sionna)\n",
            "  Downloading mitsuba-3.5.2-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (5.1 kB)\n",
            "Collecting pythreejs>=2.4.2 (from sionna)\n",
            "  Downloading pythreejs-2.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
            "Collecting ipywidgets>=8.0.4 (from sionna)\n",
            "  Downloading ipywidgets-8.1.5-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting ipydatawidgets==4.3.2 (from sionna)\n",
            "  Downloading ipydatawidgets-4.3.2-py2.py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting jupyterlab-widgets==3.0.5 (from sionna)\n",
            "  Downloading jupyterlab_widgets-3.0.5-py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: traittypes>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from ipydatawidgets==4.3.2->sionna) (0.2.1)\n",
            "Collecting comm>=0.1.3 (from ipywidgets>=8.0.4->sionna)\n",
            "  Downloading comm-0.2.2-py3-none-any.whl.metadata (3.7 kB)\n",
            "Requirement already satisfied: ipython>=6.1.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=8.0.4->sionna) (7.34.0)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=8.0.4->sionna) (5.7.1)\n",
            "Collecting widgetsnbextension~=4.0.12 (from ipywidgets>=8.0.4->sionna)\n",
            "  Downloading widgetsnbextension-4.0.13-py3-none-any.whl.metadata (1.6 kB)\n",
            "INFO: pip is looking at multiple versions of ipywidgets to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting ipywidgets>=8.0.4 (from sionna)\n",
            "  Downloading ipywidgets-8.1.4-py3-none-any.whl.metadata (2.3 kB)\n",
            "  Downloading ipywidgets-8.1.3-py3-none-any.whl.metadata (2.4 kB)\n",
            "  Downloading ipywidgets-8.1.2-py3-none-any.whl.metadata (2.4 kB)\n",
            "  Downloading ipywidgets-8.1.1-py3-none-any.whl.metadata (2.4 kB)\n",
            "  Downloading ipywidgets-8.1.0-py3-none-any.whl.metadata (2.4 kB)\n",
            "  Downloading ipywidgets-8.0.7-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=8.0.4->sionna) (5.5.6)\n",
            "  Downloading ipywidgets-8.0.6-py3-none-any.whl.metadata (2.4 kB)\n",
            "INFO: pip is still looking at multiple versions of ipywidgets to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading ipywidgets-8.0.5-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.3->sionna) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.3->sionna) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.3->sionna) (4.55.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.3->sionna) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.3->sionna) (24.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.3->sionna) (11.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.3->sionna) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.3->sionna) (2.8.2)\n",
            "Collecting drjit==0.4.6 (from mitsuba<3.6.0,>=3.2.0->sionna)\n",
            "  Downloading drjit-0.4.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16.0,>=2.13.0->sionna) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16.0,>=2.13.0->sionna) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16.0,>=2.13.0->sionna) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16.0,>=2.13.0->sionna) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16.0,>=2.13.0->sionna) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16.0,>=2.13.0->sionna) (3.12.1)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16.0,>=2.13.0->sionna) (18.1.1)\n",
            "Collecting ml-dtypes~=0.3.1 (from tensorflow<2.16.0,>=2.13.0->sionna)\n",
            "  Downloading ml_dtypes-0.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16.0,>=2.13.0->sionna) (3.4.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16.0,>=2.13.0->sionna) (4.25.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16.0,>=2.13.0->sionna) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16.0,>=2.13.0->sionna) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16.0,>=2.13.0->sionna) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16.0,>=2.13.0->sionna) (4.12.2)\n",
            "Collecting wrapt<1.15,>=1.11.0 (from tensorflow<2.16.0,>=2.13.0->sionna)\n",
            "  Downloading wrapt-1.14.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16.0,>=2.13.0->sionna) (0.37.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16.0,>=2.13.0->sionna) (1.68.1)\n",
            "Collecting tensorboard<2.16,>=2.15 (from tensorflow<2.16.0,>=2.13.0->sionna)\n",
            "  Downloading tensorboard-2.15.2-py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting tensorflow-estimator<2.16,>=2.15.0 (from tensorflow<2.16.0,>=2.13.0->sionna)\n",
            "  Downloading tensorflow_estimator-2.15.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting keras<2.16,>=2.15.0 (from tensorflow<2.16.0,>=2.13.0->sionna)\n",
            "  Downloading keras-2.15.0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow<2.16.0,>=2.13.0->sionna) (0.45.1)\n",
            "Collecting jedi>=0.16 (from ipython>=6.1.0->ipywidgets>=8.0.4->sionna)\n",
            "  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->sionna) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->sionna) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->sionna) (3.0.48)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->sionna) (2.18.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->sionna) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->sionna) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->sionna) (4.9.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16.0,>=2.13.0->sionna) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16.0,>=2.13.0->sionna) (1.2.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16.0,>=2.13.0->sionna) (3.7)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16.0,>=2.13.0->sionna) (2.32.3)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16.0,>=2.13.0->sionna) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16.0,>=2.13.0->sionna) (3.1.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow<2.16.0,>=2.13.0->sionna) (5.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow<2.16.0,>=2.13.0->sionna) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow<2.16.0,>=2.13.0->sionna) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow<2.16.0,>=2.13.0->sionna) (1.3.1)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets>=8.0.4->sionna) (0.8.4)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets>=8.0.4->sionna) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=6.1.0->ipywidgets>=8.0.4->sionna) (0.2.13)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow<2.16.0,>=2.13.0->sionna) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow<2.16.0,>=2.13.0->sionna) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow<2.16.0,>=2.13.0->sionna) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow<2.16.0,>=2.13.0->sionna) (2024.12.14)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow<2.16.0,>=2.13.0->sionna) (3.0.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow<2.16.0,>=2.13.0->sionna) (0.6.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow<2.16.0,>=2.13.0->sionna) (3.2.2)\n",
            "Downloading sionna-0.19.1-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m28.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ipydatawidgets-4.3.2-py2.py3-none-any.whl (271 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m271.6/271.6 kB\u001b[0m \u001b[31m22.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jupyterlab_widgets-3.0.5-py3-none-any.whl (384 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m384.3/384.3 kB\u001b[0m \u001b[31m26.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ipywidgets-8.0.5-py3-none-any.whl (138 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.3/138.3 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mitsuba-3.5.2-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (40.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.4/40.4 MB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading drjit-0.4.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m68.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pythreejs-2.4.2-py3-none-any.whl (3.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow-2.15.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (475.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m475.2/475.2 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading keras-2.15.0-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m72.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ml_dtypes-0.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m84.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboard-2.15.2-py3-none-any.whl (5.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m107.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow_estimator-2.15.0-py2.py3-none-any.whl (441 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m442.0/442.0 kB\u001b[0m \u001b[31m36.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading widgetsnbextension-4.0.13-py3-none-any.whl (2.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m93.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading wrapt-1.14.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (77 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m76.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: wrapt, widgetsnbextension, tensorflow-estimator, ml-dtypes, keras, jupyterlab-widgets, jedi, drjit, mitsuba, ipywidgets, tensorboard, ipydatawidgets, tensorflow, pythreejs, sionna\n",
            "  Attempting uninstall: wrapt\n",
            "    Found existing installation: wrapt 1.17.0\n",
            "    Uninstalling wrapt-1.17.0:\n",
            "      Successfully uninstalled wrapt-1.17.0\n",
            "  Attempting uninstall: widgetsnbextension\n",
            "    Found existing installation: widgetsnbextension 3.6.10\n",
            "    Uninstalling widgetsnbextension-3.6.10:\n",
            "      Successfully uninstalled widgetsnbextension-3.6.10\n",
            "  Attempting uninstall: ml-dtypes\n",
            "    Found existing installation: ml-dtypes 0.4.1\n",
            "    Uninstalling ml-dtypes-0.4.1:\n",
            "      Successfully uninstalled ml-dtypes-0.4.1\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 3.5.0\n",
            "    Uninstalling keras-3.5.0:\n",
            "      Successfully uninstalled keras-3.5.0\n",
            "  Attempting uninstall: jupyterlab-widgets\n",
            "    Found existing installation: jupyterlab_widgets 3.0.13\n",
            "    Uninstalling jupyterlab_widgets-3.0.13:\n",
            "      Successfully uninstalled jupyterlab_widgets-3.0.13\n",
            "  Attempting uninstall: ipywidgets\n",
            "    Found existing installation: ipywidgets 7.7.1\n",
            "    Uninstalling ipywidgets-7.7.1:\n",
            "      Successfully uninstalled ipywidgets-7.7.1\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.17.1\n",
            "    Uninstalling tensorboard-2.17.1:\n",
            "      Successfully uninstalled tensorboard-2.17.1\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.17.1\n",
            "    Uninstalling tensorflow-2.17.1:\n",
            "      Successfully uninstalled tensorflow-2.17.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tf-keras 2.17.0 requires tensorflow<2.18,>=2.17, but you have tensorflow 2.15.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed drjit-0.4.6 ipydatawidgets-4.3.2 ipywidgets-8.0.5 jedi-0.19.2 jupyterlab-widgets-3.0.5 keras-2.15.0 mitsuba-3.5.2 ml-dtypes-0.3.2 pythreejs-2.4.2 sionna-0.19.1 tensorboard-2.15.2 tensorflow-2.15.1 tensorflow-estimator-2.15.0 widgetsnbextension-4.0.13 wrapt-1.14.1\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/pollyjuice74/5G-Decoder\n",
        "!pip install sionna"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import tensorflow as tf\n",
        "import random\n",
        "import numpy as np\n",
        "import time\n",
        "from scipy.sparse import issparse, csr_matrix\n",
        "\n",
        "from sionna.fec.utils import generate_reg_ldpc, load_parity_check_examples, LinearEncoder, gm2pcm\n",
        "from sionna.utils.plotting import PlotBER\n",
        "from sionna.fec.ldpc import LDPCBPDecoder\n",
        "\n",
        "import os\n",
        "# os.chdir('../..')\n",
        "if os.path.exists('5G-Decoder'):\n",
        "  os.rename('5G-Decoder', '5G_Decoder')\n",
        "os.chdir('5G_Decoder/adv_nn')\n",
        "\n",
        "from dataset import *\n",
        "from attention import *\n",
        "from channel import *\n",
        "from args import *\n",
        "from model_functs import *\n",
        "from models import *"
      ],
      "metadata": {
        "id": "U5U5qUUVUeRm"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Loading LDPC code\")\n",
        "pcm, k, n, coderate = generate_reg_ldpc(v=3,\n",
        "                                        c=6,\n",
        "                                        n=10,\n",
        "                                        allow_flex_len=True,\n",
        "                                        verbose=True)\n",
        "\n",
        "encoder = LinearEncoder(pcm, is_pcm=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 435
        },
        "id": "6RF7dBDwWg0L",
        "outputId": "cdb862ca-bb4a-4f50-8555-d8c1b5bce27c"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading LDPC code\n",
            "Setting n to:  10\n",
            "Number of edges (VN perspective):  30\n",
            "Number of edges (CN perspective):  30\n",
            "Generated regular (3,6) LDPC code of length n=10\n",
            "Code rate is r=0.500.\n",
            "Warning: The alias fec.utils.LinearEncoder will not be included in Sionna 1.0. Please use fec.linear.LinearEncoder instead.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# for e2e model\n",
        "from sionna.utils import BinarySource, ebnodb2no\n",
        "from sionna.mapping import Mapper, Demapper\n",
        "from sionna.channel import AWGN\n",
        "# from sionna.fec.ldpc import LDPC5GDecoder, LDPC5GEncoder\n",
        "from tensorflow.keras.layers import Layer, Dense, Dropout\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "class Args():\n",
        "    def __init__(self, model_type, code_type='LDPC', n_look_up=121, k_look_up=80, n=400, k=200,\n",
        "                       n_rings=2, ls_active=True, split_diff=True, sigma=0.1,\n",
        "                       t_layers=1, d_model=128, heads=8, lr=5e-4,\n",
        "                       batch_size=160, batch_size_eval = 150,\n",
        "                       eval_train_iter=10, save_weights_iter=100,\n",
        "                       ebno_db_eval=2.5,\n",
        "                       ebno_db_min=0., ebno_db_max=4., ebno_db_stepsize=0.25,\n",
        "                       traindata_len=500, testdata_len=250, epochs=1000):\n",
        "        assert model_type in ['gen', 'dis'], \"Type must be: 'gen', Generator or 'dis', Discriminator.\"\n",
        "        assert code_type in ['POLAR', 'BCH', 'CCSDS', 'LDPC', 'MACKAY', 'LDPC5G', 'POLAR5G'], \"Invalid linear code type.\"\n",
        "\n",
        "\n",
        "        # model data\n",
        "        self.model_type = model_type\n",
        "\n",
        "        self.split_diff = split_diff\n",
        "        self.n_rings = n_rings # ring connectivity of mask\n",
        "        self.sigma = sigma\n",
        "        self.t_layers = t_layers\n",
        "        self.ls_active = ls_active\n",
        "\n",
        "        self.d_model = d_model\n",
        "        self.heads = heads\n",
        "\n",
        "        # training data\n",
        "        self.lr = lr\n",
        "        self.batch_size = batch_size\n",
        "        self.traindata_len = traindata_len\n",
        "        self.testdata_len = testdata_len\n",
        "        self.epochs = epochs\n",
        "\n",
        "        self.ebno_db_min = ebno_db_min\n",
        "        self.ebno_db_max = ebno_db_max\n",
        "        self.ebno_db_stepsize = ebno_db_stepsize\n",
        "\n",
        "        self.ebno_db_eval = ebno_db_eval\n",
        "        self.eval_train_iter = eval_train_iter\n",
        "        self.save_weights_iter = save_weights_iter\n",
        "        self.batch_size_eval = batch_size_eval\n",
        "\n",
        "        # code data\n",
        "        self.code_type = code_type\n",
        "        self.code = self.get_code(n_look_up, k_look_up) # n,k look up values in Get_Generator_and_Parity\n",
        "\n",
        "        # if self.code_type not in ['LDPC5G', 'POLAR5G']:\n",
        "        #     self.n, self.m, self.k = self.code.n, self.code.m, self.code.k\n",
        "        # else:\n",
        "        #     self.n, self.m, self.k = n, n-k, k\n",
        "\n",
        "        # self.n_steps = self.m + 5  # Number of diffusion steps\n",
        "\n",
        "    def get_code(self, n_look_up, k_look_up):\n",
        "        code = type('Code', (), {})() # class Code, no base class, no attributes/methods, () instantiate object\n",
        "        # code.n_look_up, code.k_look_up = n_look_up, k_look_up\n",
        "        # code.code_type = self.code_type\n",
        "\n",
        "        # if self.code_type not in ['LDPC5G', 'POLAR5G']:\n",
        "        #     G, H = Get_Generator_and_Parity(code)\n",
        "        #     code.G, code.H = tf.convert_to_tensor(G), csr_matrix( tf.convert_to_tensor(H) )\n",
        "\n",
        "        #     code.m, code.n = code.H.shape\n",
        "        #     code.k = code.n - code.m\n",
        "\n",
        "        return code\n",
        "\n",
        "\n",
        "class MHAttention(Layer):\n",
        "    def __init__(self, dims, heads, mask_length, linear=False, dropout=0.01):\n",
        "        super().__init__()\n",
        "        assert (dims % heads) == 0, 'dimension must be divisible by the number of heads'\n",
        "        self.linear = linear\n",
        "        self.dims = dims\n",
        "        self.heads = heads\n",
        "        self.dim_head = dims // heads\n",
        "\n",
        "        if linear:\n",
        "            self.k_proj = self.get_k_proj(mask_length) # n+m\n",
        "            self.proj_k = None\n",
        "            self.proj_v = None\n",
        "\n",
        "        self.to_q, self.to_k, self.to_v = [ Dense(self.dims, use_bias=False) for _ in range(3) ]\n",
        "        self.to_out = Dense(dims)\n",
        "        self.dropout = Dropout(dropout) # to d-dimentional embeddings\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        # Creates shape (n,k_proj) proj matrices for key and\n",
        "        n_value = input_shape[1]\n",
        "        if self.linear:\n",
        "            self.proj_k = self.add_weight(\"proj_k\", shape=[n_value, self.k_proj], initializer=GlorotUniform())\n",
        "            self.proj_v = self.add_weight(\"proj_v\", shape=[n_value, self.k_proj], initializer=GlorotUniform())\n",
        "\n",
        "    def call(self, x, mask=None):\n",
        "        out_att = self.lin_attention(x, mask) if self.linear else self.attention(x, mask)\n",
        "        return out_att\n",
        "\n",
        "    def get_k_proj(self, mask_length):\n",
        "        # gets dimention for linear tranformer vector projection\n",
        "        for k_proj in range(mask_length // 2, 0, -1): # starts at half the mask length TO 0\n",
        "            if mask_length % k_proj == 0:\n",
        "                return tf.cast(k_proj, tf.int32)\n",
        "\n",
        "    def lin_attention(self, x, mask): # O(n)\n",
        "        shape = tf.shape(x) # (b, n, d)\n",
        "        b = tf.cast(shape[0], tf.int32)\n",
        "        n = tf.cast(shape[1], tf.int32)\n",
        "\n",
        "        assert x.shape[-1] is not None, \"The last dimension of x is undefined.\"\n",
        "\n",
        "        query, key, val = self.to_q(x), self.to_k(x), self.to_v(x)\n",
        "\n",
        "        # Project key and val into k-dimentional space\n",
        "        key = tf.einsum('bnd,nk->bkd', key, self.proj_k)\n",
        "        val = tf.einsum('bnd,nk->bkd', val, self.proj_v)\n",
        "\n",
        "        # Reshape splitting for heads\n",
        "        query = tf.reshape(query, (b, n, self.heads, self.dim_head))\n",
        "        key = tf.reshape(key, (b, self.k_proj, self.heads, self.dim_head))\n",
        "        val = tf.reshape(val, (b, self.k_proj, self.heads, self.dim_head))\n",
        "        query, key, val = [ tf.transpose(x, [0, 2, 1, 3]) for x in [query, key, val] ]\n",
        "\n",
        "        # Low-rank mask (n,k_proj)\n",
        "        mask = tf.expand_dims(mask, axis=-1)\n",
        "        mask = tf.image.resize(mask, [n, self.k_proj], method='nearest')\n",
        "        mask = tf.reshape(mask, (1, 1, n, self.k_proj))\n",
        "\n",
        "        # Main attn logic: sftmx( q@k / d**0.5 ) @ v\n",
        "        scores = tf.einsum('bhnd,bhkd->bhnk', query, key) / (tf.sqrt( tf.cast(self.dim_head, dtype=tf.float32) ))\n",
        "        scores += (mask * -1e9) if mask is not None else 0.\n",
        "        attn = tf.nn.softmax(scores, axis=-1) # (b,h,n,k_proj)\n",
        "        attn = self.dropout(attn)\n",
        "        out = tf.einsum('bhnk,bhkd->bhnd', attn, val)\n",
        "\n",
        "        # Reshape and pass through out layer\n",
        "        out = tf.transpose(out, [0, 2, 1, 3])\n",
        "        out = tf.reshape(out, (b, n, -1))\n",
        "        return self.to_out(out)\n",
        "\n",
        "    def attention(self, x, mask): # O(n^2)\n",
        "        shape = tf.shape(x)\n",
        "        b = shape[0]\n",
        "        n = shape[1]\n",
        "        x = x[:, :, tf.newaxis] # (b,n,1)\n",
        "\n",
        "        query, key, val = self.to_q(x), self.to_k(x), self.to_v(x) # (b, n, d)\n",
        "        query, key, val = [ tf.reshape(x, (b, n, self.heads, self.dim_head)) for x in [query, key, val] ]\n",
        "        query, key, val = [ tf.cast( tf.transpose(x, [0, 2, 1, 3]), tf.float32 )\n",
        "                                                                            for x in [query, key, val] ]\n",
        "\n",
        "        scores = tf.einsum('bhqd,bhkd->bhqk', query, key) / (tf.sqrt( tf.cast(self.dim_head, tf.float32) ))\n",
        "        scores += (mask * -1e9) if mask is not None else 0. # apply mask non-edge connections\n",
        "        attn = tf.nn.softmax(scores, axis=-1) #-1\n",
        "        attn = self.dropout(attn)\n",
        "        out = tf.einsum('bhqk,bhkd->bhqd', attn, val)\n",
        "\n",
        "        out = tf.transpose(out, [0, 2, 1, 3])\n",
        "        out = tf.reshape(out, (b, n, -1))\n",
        "        return self.to_out(out)\n",
        "\n",
        "\n",
        "\n",
        "class TransformerLayer(Layer):\n",
        "    def __init__(self, attn, ff, norm):\n",
        "        super().__init__()\n",
        "        self.attn, self.ff = attn, ff\n",
        "        self.norm1, self.norm2 = c(norm), c(norm)\n",
        "\n",
        "    def call(self, x, mask):\n",
        "        out = self.norm1( self.attn(x, mask) )\n",
        "        return self.norm2( self.ff(out) )\n",
        "\n",
        "\n",
        "class Transformer(Layer):\n",
        "    def __init__(self, d_model, heads, mask, N):\n",
        "        super().__init__()\n",
        "        self.transformer_layers = [ TransformerLayer( MHAttention(d_model, heads, mask_length=mask.shape[0]),\n",
        "                                                      FeedForward(d_model),\n",
        "                                                      PreNorm() ) for _ in range(N) ]\n",
        "        self.mask = mask\n",
        "\n",
        "    def call(self, x):\n",
        "        for transformer in self.transformer_layers:\n",
        "            x = transformer(x, self.mask)\n",
        "        return x\n",
        "\n",
        "\n",
        "class TransformerDiffusion( Layer ):\n",
        "    def __init__(self, args):\n",
        "        super().__init__()\n",
        "        self.model_type = args.model_type\n",
        "        self.n_steps = args.n_steps\n",
        "\n",
        "        code = args.code\n",
        "        # assert isinstance(code.H, tf.sparse.SparseTensor), \"Code's pcm must be sparse.\"\n",
        "        self.pcm = tf.cast(code.H, dtype=tf.int32)\n",
        "        # shapes\n",
        "        self.m, self.n = self.pcm.shape\n",
        "        self.k = self.n - self.m\n",
        "        self.dims = args.d_model\n",
        "        self.batch_size = args.batch_size\n",
        "\n",
        "        self.mask = self.create_mask(self.pcm)\n",
        "        for matrix, title in zip([self.pcm, self.mask], [\"PCM Matrix\", \"Mask Matrix\"]):\n",
        "            plt.imshow(matrix, cmap='viridis'); plt.colorbar(); plt.title(title); plt.show()\n",
        "        print(\"mask, pcm: \", self.mask, self.pcm)\n",
        "\n",
        "        # trans_call layers\n",
        "        self.src_embed = tf.Variable( tf.random.uniform([1, self.n + self.m, self.dims]), trainable=True ) # (b,n+m,d)\n",
        "        self.decoder = Transformer(args.d_model, args.heads, self.mask, args.t_layers) # (b,n)\n",
        "        self.time_embed = Embedding(self.m//2, args.d_model)\n",
        "        self.to_out = Dense(1)\n",
        "        self.to_n = Dense(self.n)\n",
        "        # diff layers\n",
        "        self.fc = Dense(1) ###\n",
        "\n",
        "        self.betas = tf.constant( tf.linspace(1e-3, 1e-2, args.n_steps)*0 + args.sigma )\n",
        "        self.betas_bar = tf.constant( tf.math.cumsum(self.betas, 0) )\n",
        "\n",
        "        self.split_diff = args.split_diff\n",
        "        self.ls_active = args.ls_active\n",
        "\n",
        "    def create_mask(self, H):\n",
        "        l, n = H.shape  # l: number of rows (check nodes), n: columns (variable nodes)\n",
        "        k = n - l  # Code dimension\n",
        "        mask = tf.eye(2 * n - k, dtype=tf.float32)  # Initialize diagonal identity mask\n",
        "\n",
        "        # Get indices where H == 1\n",
        "        indices = tf.where(H == 1)  # Returns (row, col) pairs where H is 1\n",
        "        check_nodes, variable_nodes = indices[:, 0], indices[:, 1]\n",
        "\n",
        "        # Step 1: Update check node to variable node connections\n",
        "        mask = tf.tensor_scatter_nd_update(mask,\n",
        "                                          tf.stack([n + check_nodes, variable_nodes], axis=1),\n",
        "                                          tf.ones_like(check_nodes, dtype=tf.float32))\n",
        "        mask = tf.tensor_scatter_nd_update(mask,\n",
        "                                          tf.stack([variable_nodes, n + check_nodes], axis=1),\n",
        "                                          tf.ones_like(check_nodes, dtype=tf.float32))\n",
        "\n",
        "        # Step 2: Update variable node connections\n",
        "        for cn in tf.unique(check_nodes)[0]:  # Iterate over unique check nodes\n",
        "            related_vns = tf.boolean_mask(variable_nodes, check_nodes == cn)\n",
        "            indices = tf.stack(tf.meshgrid(related_vns, related_vns), axis=-1)\n",
        "            indices = tf.reshape(indices, [-1, 2])  # Flatten indices\n",
        "            mask = tf.tensor_scatter_nd_update(mask, indices, tf.ones_like(indices[:, 0], dtype=tf.float32))\n",
        "\n",
        "        # Step 3: Logical inversion and scale\n",
        "        mask = -tf.cast(tf.logical_not(mask > 0), dtype=tf.float32) * 1e9\n",
        "        return mask\n",
        "\n",
        "    def get_sigma(self, t):\n",
        "        # make sure t is a positive int\n",
        "        t = tf.cast( tf.abs(t), tf.int32 )\n",
        "        # gather betas\n",
        "        betas_t = tf.gather(self.betas, t)\n",
        "        betas_bar_t = tf.gather(self.betas_bar, t)\n",
        "        sigma = betas_bar_t * betas_t / (betas_bar_t + betas_t)\n",
        "        return tf.cast(sigma, tf.float32)\n",
        "\n",
        "    def get_syndrome(self, r_t):\n",
        "        # Calculate syndrome (pcm @ r = 0) if r is correct in binary\n",
        "        r_t = tf.reshape(r_t, (self.n, -1)) # (n,b)\n",
        "        r_t_bin = tf.cast(llr_to_bin(r_t), dtype=tf.int32)\n",
        "        return (self.pcm @ r_t_bin) % 2 # (m,n)@(n,b)->(m,b)\n",
        "\n",
        "    def get_t_error(self, r_t):\n",
        "        t = tf.reduce_sum( self.get_syndrome(llr_to_bin(r_t)), axis=0 ) # (m,n)@(n,b)->(m,b)->(1,b)\n",
        "        t = tf.cast(tf.abs(t), dtype=tf.int32)\n",
        "        return t\n",
        "\n",
        "    # Extracts noise estimate z_hat from r\n",
        "    def tran_call(self, r_t):\n",
        "        # Compute synd and magn\n",
        "        syndrome = tf.reshape( self.get_syndrome(r_t), (self.batch_size, self.m) ) # (m,n)@(n,b)->(m,b) check nodes\n",
        "        magnitude = tf.reshape( tf.abs(r_t), (self.batch_size, self.n) ) #(n,b) variable nodes\n",
        "        # make sure their the same dtype\n",
        "        magnitude, syndrome = [ tf.cast(tensor, dtype=tf.float32) for tensor in [magnitude, syndrome] ]\n",
        "\n",
        "        # Concatenate synd and magn\n",
        "        nodes = tf.concat([magnitude, syndrome], axis=1)[:, :, tf.newaxis] # (b, n+m, 1)\n",
        "\n",
        "        # Embedding nodes w/ attn and 'time' (sum syn errs) dims\n",
        "        t = self.get_t_error(r_t)\n",
        "        nodes_emb = self.src_embed * nodes # (b, n+m, d)\n",
        "        time_emb = tf.reshape( self.time_embed(t), (self.batch_size, 1, self.dims) ) # (b,1,d)\n",
        "\n",
        "        # Applying embeds\n",
        "        emb_t = time_emb * nodes_emb # (b, n+m, d)\n",
        "        logits = self.decoder(emb_t) # (b, n+m, d)\n",
        "\n",
        "        # Converting to output shape\n",
        "        emb = tf.squeeze( self.to_out(logits), axis=-1 ) # (b,n+m,d)->(b, n+m)\n",
        "        z_hat = self.to_n(emb) # (b, n+m)->(b, n)\n",
        "        print(\"z_hat: \", z_hat.shape, z_hat.dtype, t.dtype)\n",
        "        return z_hat, t\n",
        "\n",
        "    # # optimal lambda l for theoretical and for error prediction\n",
        "    # def line_search(self, r_t, sigma, err_hat, lin_splits=20):\n",
        "    #     l_values =  tf.reshape( tf.linspace(1., 20., lin_splits), (1, 1, lin_splits) )\n",
        "    #     r_t, sigma, err_hat = [ tf.expand_dims(tensor, axis=-1) for tensor in [r_t, sigma, err_hat] ]# (n,b, 1)\n",
        "    #     # print(f\"sigma: {sigma}, err_hat: {err_hat}\")\n",
        "\n",
        "    #     # Compute theoretical step size w/ ls splits\n",
        "    #     z_hat_values = l_values*(sigma*err_hat) # (n,b, l), l is lin_splits\n",
        "    #     r_values = llr_to_bin(r_t - z_hat_values) # (n,b, l)\n",
        "    #     r_values = tf.reshape(r_values, [r_values.shape[0], -1]) # (n,b*l)\n",
        "    #     tf.print(\"r_values\", r_values.shape)\n",
        "\n",
        "    #     # sum of synds (m,n)@(n,b*l)->(m,b*l)->(b*l, 1)\n",
        "    #     sum_synds = tf.reduce_sum( tf.abs( (self.pcm @ r_values) % 2 ),\n",
        "    #                                axis=0 )\n",
        "    #     sum_synds = tf.reshape(sum_synds, (-1, lin_splits)) # (b, l)\n",
        "    #     tf.print(\"In linesearch Sum Syndromes: \", sum_synds)\n",
        "\n",
        "    #     # Pick optimal ls value\n",
        "    #     if self.model_type=='dis':\n",
        "    #          ixs = tf.math.argmin(sum_synds, axis=1, output_type=tf.int32)[:, tf.newaxis] # (b,1) w/ ixs of optimal line search for batch b\n",
        "    #     elif self.model_type=='gen':\n",
        "    #          ixs = tf.math.argmax(sum_synds, axis=1, output_type=tf.int32)[:, tf.newaxis] # (b,1)\n",
        "    #     # print(r_values.shape, z_hat_values.shape, ixs.shape)\n",
        "\n",
        "    #     r_values = r_t - z_hat_values\n",
        "    #     # (b, l, n) for indexing on l\n",
        "    #     r_values, z_hat_values = [ tf.reshape(tensor, [-1, lin_splits, r_values.shape[0]])\n",
        "    #                                         for tensor in [r_values, z_hat_values] ]\n",
        "\n",
        "    #     # concat range of batch ixs [0,...,n-1] and optimal line search ixs for gather_nd\n",
        "    #     indices = tf.concat([ tf.range(ixs.shape[0])[:, tf.newaxis], ixs ],\n",
        "    #                                                         axis=-1) # (b,2)\n",
        "\n",
        "    #     # print(r_values, z_hat_values, indices)\n",
        "    #     # ix on lin_splits w/ gather_nd st. ix,(b, l, n)->(n,b)\n",
        "    #     r_t1, z_hat = [ tf.reshape( tf.gather_nd(tensor, indices), (self.n, -1) )\n",
        "    #                                          for tensor in [r_values, z_hat_values] ]\n",
        "    #     # print(r_t1, z_hat_values)\n",
        "    #     return r_t1, z_hat # r at t-1\n",
        "\n",
        "    # def loss_fn(self, synd):\n",
        "    #     return tf.reduce_mean(tf.square(synd))\n",
        "\n",
        "    # def train_step(self, llr_ch):\n",
        "    #     with tf.GradientTape() as tape:\n",
        "    #         _, synd = self.tran_call(llr_ch,\n",
        "    #                                  tf.reduce_sum( self.get_syndrome(llr_ch) ))\n",
        "    #         loss = self.loss_fn(synd)\n",
        "    #     gradients = tape.gradient(loss, self.trainable_variables)\n",
        "    #     self.optimizer.apply_gradients(zip(gradients, self.trainable_variables))\n",
        "    #     return loss\n",
        "\n",
        "\n",
        "\n",
        "# class Decoder( TransformerDiffusion ):\n",
        "#     def __init__(self, args):\n",
        "#         super().__init__(args)\n",
        "#         self.transformer =\n",
        "\n",
        "#     # 'test' function\n",
        "#     def call(self, r_t):\n",
        "#         i = tf.constant(0)  # Initialize loop counter\n",
        "\n",
        "#         def condition(r_t, i):\n",
        "#             # Loop while i < self.m and syndrome sum is not zero\n",
        "#             return tf.logical_and(i < 5, tf.reduce_sum(self.get_syndrome(r_t)) != 0) # CHANGE 5 TO SELF.M\n",
        "\n",
        "#         def body(r_t, i):\n",
        "#             # Perform reverse or split diffusion\n",
        "#             r_t = tf.cond(\n",
        "#                 tf.logical_not(self.split_diff),\n",
        "#                 lambda: self.split_rdiff_call(r_t),\n",
        "#                 lambda: self.rev_diff_call(r_t),\n",
        "#             )\n",
        "#             return r_t, tf.add(i, 1)\n",
        "\n",
        "#         # Run tf.while_loop with the loop variables\n",
        "#         llr_hat, _ = tf.while_loop(\n",
        "#             condition,\n",
        "#             body,\n",
        "#             loop_vars=[r_t, i],\n",
        "#             maximum_iterations=self.m,\n",
        "#             shape_invariants=[tf.TensorShape([self.batch_size, self.n]), i.get_shape()]\n",
        "#         )\n",
        "\n",
        "#         # llr_hat, _ = self.tran_call(r_t)\n",
        "#         tf.print(\"llr_hat\", llr_hat)\n",
        "\n",
        "#         return llr_hat\n",
        "\n",
        "#     # Refines recieved codeword r at time t\n",
        "#     def rev_diff_call(self, r_t):\n",
        "#         tf.print(\"Rev def call with line-search...\")\n",
        "\n",
        "#         # Transformer error prediction\n",
        "#         z_hat_crude, t = self.tran_call(r_t) # (b,n)\n",
        "#         r_t1 = r_t - z_hat_crude*self.get_sigma(t)[:, tf.newaxis] # (b,n)\n",
        "#         # tf.print(r_t1)\n",
        "\n",
        "#         # # Refined estimate of the codeword for the ls diffusion step\n",
        "#         # r_t1, z_hat = self.line_search(r_t, sigma, err_hat) if self.ls_active else 1.\n",
        "#         # tf.print(\"After linesearch: \", r_t1)\n",
        "\n",
        "#         print(\"r_t1\", r_t1.shape, r_t1.dtype)\n",
        "#         return r_t1 # r at t-1, both (b,n)\n",
        "\n",
        "#     def split_rdiff_call(self, r_t):\n",
        "#         tf.print(\"Rev diff call with split diffusion...\")\n",
        "#         # First half-step condition subproblem\n",
        "#         z_hat_crude, t = self.tran_call(r_t)\n",
        "#         # tf.print(\"fc input: \", (z_hat_crude * self.get_sigma(t)[:, tf.newaxis]))\n",
        "#         r_t_half = r_t - 0.5 * self.fc( z_hat_crude * self.get_sigma(t)[:, tf.newaxis] )\n",
        "#         # tf.print(\"r_t_half\", r_t_half)\n",
        "\n",
        "#         # Full-step diffusion subproblem\n",
        "#         r_t1 = r_t_half + tf.random.normal(r_t_half.shape) * tf.sqrt(self.get_sigma(t)[:, tf.newaxis])\n",
        "\n",
        "#         # Second half-step condition subproblem\n",
        "#         z_hat_crude_half, t = self.tran_call(r_t1)  # Reuse the second `tran_call`\n",
        "#         r_t1 = r_t1 - 0.5 * self.fc(z_hat_crude_half * self.get_sigma(t)[:, tf.newaxis])\n",
        "#         print(\"r_t1\", r_t1.shape, r_t1.dtype)\n",
        "#         return r_t1  # r at t-1, both (b,n)\n",
        "\n",
        "\n",
        "from tensorflow.keras.layers import MultiHeadAttention, Dense, LayerNormalization, Dropout\n",
        "\n",
        "class TransformerEncoderBlock(tf.keras.layers.Layer):\n",
        "    def __init__(self, d_model, num_heads, dff, dropout_rate=0.1):\n",
        "        super(TransformerEncoderBlock, self).__init__()\n",
        "        self.mha = MultiHeadAttention(num_heads=num_heads, key_dim=d_model)\n",
        "        self.ffn = tf.keras.Sequential([\n",
        "            Dense(dff, activation='relu'),\n",
        "            Dense(d_model)\n",
        "        ])\n",
        "\n",
        "        self.layernorm1 = LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm2 = LayerNormalization(epsilon=1e-6)\n",
        "\n",
        "        self.dropout1 = Dropout(dropout_rate)\n",
        "        self.dropout2 = Dropout(dropout_rate)\n",
        "\n",
        "    def call(self, x, training):\n",
        "        # Ensure input is 3D\n",
        "        if len(tf.shape(x)) == 2:  # Shape: (batch_size, d_model)\n",
        "            x = tf.expand_dims(x, axis=1)  # Convert to (batch_size, 1, d_model)\n",
        "\n",
        "        # Multi-Head Attention\n",
        "        attn_output = self.mha(x, x)\n",
        "        attn_output = self.dropout1(attn_output, training=training)\n",
        "        out1 = self.layernorm1(x + attn_output)  # Add & Normalize\n",
        "\n",
        "        # Feedforward Network\n",
        "        ffn_output = self.ffn(out1)\n",
        "        ffn_output = self.dropout2(ffn_output, training=training)\n",
        "        out2 = self.layernorm2(out1 + ffn_output)  # Add & Normalize\n",
        "\n",
        "        return out2\n",
        "\n",
        "\n",
        "\n",
        "class Decoder(TransformerDiffusion):\n",
        "    def __init__(self, args):\n",
        "        super().__init__(args)\n",
        "\n",
        "        self.encoder_blocks = [\n",
        "            TransformerEncoderBlock(\n",
        "                d_model=args.d_model,\n",
        "                num_heads=args.heads,\n",
        "                dff=args.d_model * 4,\n",
        "                dropout_rate=0.1,\n",
        "            )\n",
        "            for _ in range(args.t_layers)\n",
        "        ]\n",
        "\n",
        "    def call(self, r_t, training=False):\n",
        "        # Ensure r_t is 3D\n",
        "        if len(tf.shape(r_t)) == 2:\n",
        "            r_t = tf.expand_dims(r_t, axis=1)\n",
        "\n",
        "        # Pass through each encoder block\n",
        "        for block in self.encoder_blocks:\n",
        "            r_t = block(r_t, training=training)\n",
        "\n",
        "        tf.print(\"Decoded output (llr_hat):\", r_t)\n",
        "        return r_t\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class E2EModel(tf.keras.Model):\n",
        "    def __init__(self, encoder, decoder, k, n, return_infobits=False, es_no=False):\n",
        "        super().__init__()\n",
        "\n",
        "        self._n = n\n",
        "        self._k = k\n",
        "\n",
        "        self._binary_source = BinarySource()\n",
        "        self._num_bits_per_symbol = 2\n",
        "        self._mapper = Mapper(\"qam\", self._num_bits_per_symbol)\n",
        "        self._demapper = Demapper(\"app\", \"qam\", self._num_bits_per_symbol)\n",
        "        self._channel = AWGN()\n",
        "        self._decoder = decoder\n",
        "        self._encoder = encoder\n",
        "        self._return_infobits = return_infobits\n",
        "        self._es_no = es_no\n",
        "\n",
        "    @tf.function(jit_compile=False)\n",
        "    def call(self, batch_size, ebno_db):\n",
        "\n",
        "        # no rate-adjustment for uncoded transmission or es_no scenario\n",
        "        if self._decoder is not None and self._es_no==False:\n",
        "            no = ebnodb2no(ebno_db, self._num_bits_per_symbol, self._k/self._n)\n",
        "        else: #for uncoded transmissions the rate is 1\n",
        "            no = ebnodb2no(ebno_db, self._num_bits_per_symbol, 1)\n",
        "\n",
        "        b = self._binary_source([batch_size, self._k])\n",
        "        if self._encoder is not None:\n",
        "            c = self._encoder(b)\n",
        "        else:\n",
        "            c = b\n",
        "\n",
        "        # check that rate calculations are correct\n",
        "        assert self._n==c.shape[-1], \"Invalid value of n.\"\n",
        "\n",
        "        # zero padding to support odd codeword lengths\n",
        "        if self._n%2==1:\n",
        "            c_pad = tf.concat([c, tf.zeros([batch_size, 1])], axis=1)\n",
        "        else: # no padding\n",
        "            c_pad = c\n",
        "        x = self._mapper(c_pad)\n",
        "\n",
        "        y = self._channel([x, no])\n",
        "        llr = self._demapper([y, no])\n",
        "\n",
        "        # remove zero padded bit at the end\n",
        "        if self._n%2==1:\n",
        "            llr = llr[:,:-1]\n",
        "\n",
        "        # and run the decoder\n",
        "        if self._decoder is not None:\n",
        "            tf.print('llr: ', llr)\n",
        "            ############################\n",
        "            llr_hat = self._decoder(llr)\n",
        "            ############################\n",
        "            # tf.print(\"llr_hat: \", llr_hat)\n",
        "\n",
        "        if self._return_infobits:\n",
        "            return b, llr_hat\n",
        "        else:\n",
        "            return c, llr_hat\n",
        "\n",
        "\n",
        "# args for decoder/discriminator\n",
        "args = Args(model_type='dis')\n",
        "args.code.H = pcm\n",
        "args.n, args.m = pcm.shape\n",
        "args.k = k\n",
        "args.n_steps = args.m + 5\n",
        "\n",
        "ltd_decoder = Decoder(args) # Linear Transformer Diffusion (LTD) Decoder\n",
        "\n",
        "e2e_ltd = E2EModel(encoder, ltd_decoder, k, n)"
      ],
      "metadata": {
        "id": "XOILyjSGXMdb",
        "outputId": "973c77e3-9c33-4ca7-d869-d3d18aa671dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mask, pcm:  tf.Tensor(\n",
            "[[-0.e+00 -0.e+00 -0.e+00 -0.e+00 -0.e+00 -0.e+00 -0.e+00 -0.e+00 -0.e+00\n",
            "  -0.e+00 -0.e+00 -1.e+09 -1.e+09 -0.e+00 -0.e+00]\n",
            " [-0.e+00 -0.e+00 -0.e+00 -0.e+00 -0.e+00 -0.e+00 -0.e+00 -0.e+00 -0.e+00\n",
            "  -0.e+00 -0.e+00 -0.e+00 -1.e+09 -1.e+09 -0.e+00]\n",
            " [-0.e+00 -0.e+00 -0.e+00 -0.e+00 -0.e+00 -0.e+00 -0.e+00 -0.e+00 -0.e+00\n",
            "  -0.e+00 -1.e+09 -0.e+00 -0.e+00 -1.e+09 -0.e+00]\n",
            " [-0.e+00 -0.e+00 -0.e+00 -0.e+00 -0.e+00 -0.e+00 -0.e+00 -0.e+00 -0.e+00\n",
            "  -0.e+00 -0.e+00 -1.e+09 -1.e+09 -0.e+00 -0.e+00]\n",
            " [-0.e+00 -0.e+00 -0.e+00 -0.e+00 -0.e+00 -0.e+00 -0.e+00 -0.e+00 -0.e+00\n",
            "  -0.e+00 -0.e+00 -1.e+09 -0.e+00 -0.e+00 -1.e+09]\n",
            " [-0.e+00 -0.e+00 -0.e+00 -0.e+00 -0.e+00 -0.e+00 -0.e+00 -0.e+00 -0.e+00\n",
            "  -0.e+00 -0.e+00 -1.e+09 -0.e+00 -0.e+00 -1.e+09]\n",
            " [-0.e+00 -0.e+00 -0.e+00 -0.e+00 -0.e+00 -0.e+00 -0.e+00 -0.e+00 -0.e+00\n",
            "  -0.e+00 -1.e+09 -0.e+00 -0.e+00 -0.e+00 -1.e+09]\n",
            " [-0.e+00 -0.e+00 -0.e+00 -0.e+00 -0.e+00 -0.e+00 -0.e+00 -0.e+00 -0.e+00\n",
            "  -0.e+00 -1.e+09 -0.e+00 -1.e+09 -0.e+00 -0.e+00]\n",
            " [-0.e+00 -0.e+00 -0.e+00 -0.e+00 -0.e+00 -0.e+00 -0.e+00 -0.e+00 -0.e+00\n",
            "  -0.e+00 -1.e+09 -0.e+00 -0.e+00 -1.e+09 -0.e+00]\n",
            " [-0.e+00 -0.e+00 -0.e+00 -0.e+00 -0.e+00 -0.e+00 -0.e+00 -0.e+00 -0.e+00\n",
            "  -0.e+00 -0.e+00 -0.e+00 -0.e+00 -1.e+09 -1.e+09]\n",
            " [-0.e+00 -0.e+00 -1.e+09 -0.e+00 -0.e+00 -0.e+00 -1.e+09 -1.e+09 -1.e+09\n",
            "  -0.e+00 -0.e+00 -1.e+09 -1.e+09 -1.e+09 -1.e+09]\n",
            " [-1.e+09 -0.e+00 -0.e+00 -1.e+09 -1.e+09 -1.e+09 -0.e+00 -0.e+00 -0.e+00\n",
            "  -0.e+00 -1.e+09 -0.e+00 -1.e+09 -1.e+09 -1.e+09]\n",
            " [-1.e+09 -1.e+09 -0.e+00 -1.e+09 -0.e+00 -0.e+00 -0.e+00 -1.e+09 -0.e+00\n",
            "  -0.e+00 -1.e+09 -1.e+09 -0.e+00 -1.e+09 -1.e+09]\n",
            " [-0.e+00 -1.e+09 -1.e+09 -0.e+00 -0.e+00 -0.e+00 -0.e+00 -0.e+00 -1.e+09\n",
            "  -1.e+09 -1.e+09 -1.e+09 -1.e+09 -0.e+00 -1.e+09]\n",
            " [-0.e+00 -0.e+00 -0.e+00 -0.e+00 -1.e+09 -1.e+09 -1.e+09 -0.e+00 -0.e+00\n",
            "  -1.e+09 -1.e+09 -1.e+09 -1.e+09 -1.e+09 -0.e+00]], shape=(15, 15), dtype=float32) tf.Tensor(\n",
            "[[1 1 0 1 1 1 0 0 0 1]\n",
            " [0 1 1 0 0 0 1 1 1 1]\n",
            " [0 0 1 0 1 1 1 0 1 1]\n",
            " [1 0 0 1 1 1 1 1 0 0]\n",
            " [1 1 1 1 0 0 0 1 1 0]], shape=(5, 10), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def bin_to_llr(x):\n",
        "    \"\"\" Clip llrs to 20 for numerical stability \"\"\"\n",
        "    llr_vector = tf.where(x == 0, -20, 20)\n",
        "    return llr_vector\n",
        "\n",
        "\n",
        "def train_dec(model, args):\n",
        "    # loss\n",
        "    loss_fn = tf.keras.losses.MeanSquaredError()\n",
        "    # optimizer\n",
        "    scheduler = tf.keras.optimizers.schedules.CosineDecay(initial_learning_rate=args.lr, decay_steps=args.epochs) # 1000 is size of trainloader\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate=scheduler)\n",
        "    # time start\n",
        "    time_start = time.time()\n",
        "\n",
        "    # SGD update iteration\n",
        "    @tf.function(jit_compile=False)\n",
        "    def train_step(batch_size):\n",
        "        # train for random SNRs within a pre-defined interval\n",
        "        ebno_db = tf.random.uniform([batch_size, 1],\n",
        "                                    minval=args.ebno_db_min,\n",
        "                                    maxval=args.ebno_db_max)\n",
        "\n",
        "        with tf.GradientTape() as tape:\n",
        "            c, llr_hat = model(batch_size, ebno_db)\n",
        "            # tf.print(c, llr_hat)\n",
        "\n",
        "            llr_y = bin_to_llr(c)\n",
        "            print(\"llr_hat\", llr_hat.shape, llr_hat.dtype)\n",
        "            loss_value = loss_fn(llr_y, llr_hat)\n",
        "\n",
        "        # and apply the SGD updates\n",
        "        weights = model.trainable_weights\n",
        "        grads = tape.gradient(loss_value, weights) # variables\n",
        "        optimizer.apply_gradients(zip(grads, weights))\n",
        "        return c, llr_hat\n",
        "\n",
        "    print(\"Training Linear Transformer Diffusion Model...\")\n",
        "    for epoch in range(1, args.epochs + 1):\n",
        "        train_step(args.batch_size)\n",
        "\n",
        "        # eval train iter\n",
        "        if True:#epoch % args.eval_train_iter == 0:\n",
        "            ebno_db = tf.random.uniform([args.batch_size, 1],\n",
        "                                          minval=args.ebno_db_eval,\n",
        "                                          maxval=args.ebno_db_eval)\n",
        "\n",
        "            c, llr_hat = model(args.batch_size, ebno_db)\n",
        "\n",
        "            # loss\n",
        "            llr_y = bin_to_llr(c)\n",
        "            loss_value = loss_fn(llr_y, llr_hat)\n",
        "\n",
        "            # ber\n",
        "            c_hat = llr_to_bin(llr_hat)\n",
        "            ber = compute_ber(c, c_hat).numpy()\n",
        "\n",
        "            # measure required time since last evaluation\n",
        "            duration = time.time() - time_start # in s\n",
        "            time_start = time.time() # reset counter\n",
        "\n",
        "            print(f'Training epoch {epoch}/{args.epochs}, LR={optimizer.learning_rate.numpy():.2e}, Loss={loss_value.numpy():.5e}, BER={ber}, duration: {duration:.2f}s')\n",
        "\n",
        "        # save weights iter\n",
        "        if epoch % args.save_weights_iter == 0:\n",
        "            pass\n",
        "\n",
        "        # heat-map visualization of the model's weights\n",
        "        # for var in self.trainable_variables:\n",
        "        #     var_name = var.name\n",
        "        #     var_value = var.numpy()\n",
        "\n",
        "        #     # Check if the variable is at least 2D (suitable for heatmap)\n",
        "        #     if len(var_value.shape) > 1:\n",
        "        #         plt.figure(figsize=(8, 6))\n",
        "        #         sns.heatmap(var_value, cmap='viridis')\n",
        "        #         plt.title(f'Heatmap of {var_name}')\n",
        "        #         plt.show()\n",
        "        #     else:\n",
        "        #         print(f\"{var_name} has shape {var_value.shape} which is not suitable for a heatmap.\")\n",
        "\n",
        "\n",
        "train_dec(e2e_ltd, args)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "NhZncoEEpgNv",
        "outputId": "8a47cb5e-64ab-4b8a-efaf-e03677a46f29"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Linear Transformer Diffusion Model...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "in user code:\n\n    File \"<ipython-input-16-820b27f9dc89>\", line 25, in train_step  *\n        c, llr_hat = model(batch_size, ebno_db)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler  **\n        raise e.with_traceback(filtered_tb) from None\n    File \"/tmp/__autograph_generated_filed_73g01n.py\", line 99, in tf__call\n        ag__.if_stmt(ag__.ld(self)._decoder is not None, if_body_4, else_body_4, get_state_4, set_state_4, ('llr_hat',), 1)\n    File \"/tmp/__autograph_generated_filed_73g01n.py\", line 93, in if_body_4\n        llr_hat = ag__.converted_call(ag__.ld(self)._decoder, (ag__.ld(llr),), None, fscope)\n    File \"/tmp/__autograph_generated_file18q4mr8e.py\", line 39, in tf__call\n        ag__.for_stmt(ag__.ld(self).encoder_blocks, None, loop_body, get_state_1, set_state_1, ('r_t',), {'iterate_names': 'block'})\n    File \"/tmp/__autograph_generated_file18q4mr8e.py\", line 37, in loop_body\n        r_t = ag__.converted_call(ag__.ld(block), (ag__.ld(r_t),), dict(training=ag__.ld(training)), fscope)\n    File \"/tmp/__autograph_generated_file3bumf56h.py\", line 31, in tf__call\n        out2 = ag__.converted_call(ag__.ld(self).layernorm2, (ag__.ld(out1) + ag__.ld(ffn_output),), None, fscope)\n\n    ValueError: Exception encountered when calling layer 'e2e_model_13' (type E2EModel).\n    \n    in user code:\n    \n        File \"<ipython-input-35-e1ed9ad7eadb>\", line 548, in call  *\n            llr_hat = self._decoder(llr)\n        File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler  **\n            raise e.with_traceback(filtered_tb) from None\n        File \"/tmp/__autograph_generated_file18q4mr8e.py\", line 39, in tf__call\n            ag__.for_stmt(ag__.ld(self).encoder_blocks, None, loop_body, get_state_1, set_state_1, ('r_t',), {'iterate_names': 'block'})\n        File \"/tmp/__autograph_generated_file18q4mr8e.py\", line 37, in loop_body\n            r_t = ag__.converted_call(ag__.ld(block), (ag__.ld(r_t),), dict(training=ag__.ld(training)), fscope)\n        File \"/tmp/__autograph_generated_file3bumf56h.py\", line 31, in tf__call\n            out2 = ag__.converted_call(ag__.ld(self).layernorm2, (ag__.ld(out1) + ag__.ld(ffn_output),), None, fscope)\n    \n        ValueError: Exception encountered when calling layer 'decoder_14' (type Decoder).\n        \n        in user code:\n        \n            File \"<ipython-input-35-e1ed9ad7eadb>\", line 487, in call  *\n                r_t = block(r_t, training=training)\n            File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler  **\n                raise e.with_traceback(filtered_tb) from None\n            File \"/tmp/__autograph_generated_file3bumf56h.py\", line 31, in tf__call\n                out2 = ag__.converted_call(ag__.ld(self).layernorm2, (ag__.ld(out1) + ag__.ld(ffn_output),), None, fscope)\n        \n            ValueError: Exception encountered when calling layer 'transformer_encoder_block_1' (type TransformerEncoderBlock).\n            \n            in user code:\n            \n                File \"<ipython-input-35-e1ed9ad7eadb>\", line 460, in call  *\n                    out2 = self.layernorm2(out1 + ffn_output)  # Add & Normalize\n            \n                ValueError: Dimensions must be equal, but are 10 and 128 for '{{node decoder_14/transformer_encoder_block_1/add_1}} = AddV2[T=DT_FLOAT](decoder_14/transformer_encoder_block_1/layer_normalization_16/batchnorm/add_1, decoder_14/transformer_encoder_block_1/dropout_45/Identity)' with input shapes: [160,1,10], [160,1,128].\n            \n            \n            Call arguments received by layer 'transformer_encoder_block_1' (type TransformerEncoderBlock):\n              • x=tf.Tensor(shape=(160, 1, 10), dtype=float32)\n              • training=False\n        \n        \n        Call arguments received by layer 'decoder_14' (type Decoder):\n          • r_t=tf.Tensor(shape=(160, 10), dtype=float32)\n          • training=False\n    \n    \n    Call arguments received by layer 'e2e_model_13' (type E2EModel):\n      • batch_size=tf.Tensor(shape=(), dtype=int32)\n      • ebno_db=tf.Tensor(shape=(160, 1), dtype=float32)\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-820b27f9dc89>\u001b[0m in \u001b[0;36m<cell line: 83>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m \u001b[0mtrain_dec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me2e_ltd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-36-820b27f9dc89>\u001b[0m in \u001b[0;36mtrain_dec\u001b[0;34m(model, args)\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Training Linear Transformer Diffusion Model...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0;31m# eval train iter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/__autograph_generated_filezg2gjmwd.py\u001b[0m in \u001b[0;36mtf__train_step\u001b[0;34m(batch_size)\u001b[0m\n\u001b[1;32m     14\u001b[0m                 \u001b[0mebno_db\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muniform\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mminval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mebno_db_min\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mebno_db_max\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGradientTape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m                     \u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mllr_hat\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mebno_db\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m                     \u001b[0mllr_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbin_to_llr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m                     \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'llr_hat'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mllr_hat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mllr_hat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/__autograph_generated_filed_73g01n.py\u001b[0m in \u001b[0;36mtf__call\u001b[0;34m(self, batch_size, ebno_db)\u001b[0m\n\u001b[1;32m     97\u001b[0m                     \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m                 \u001b[0mllr_hat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUndefined\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'llr_hat'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m                 \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mif_stmt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_decoder\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mif_body_4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0melse_body_4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_state_4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset_state_4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'llr_hat'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m                 \u001b[0;32mdef\u001b[0m \u001b[0mget_state_5\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/__autograph_generated_filed_73g01n.py\u001b[0m in \u001b[0;36mif_body_4\u001b[0;34m()\u001b[0m\n\u001b[1;32m     91\u001b[0m                     \u001b[0;32mnonlocal\u001b[0m \u001b[0mllr_hat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m                     \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'llr: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mllr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m                     \u001b[0mllr_hat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_decoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mllr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m                 \u001b[0;32mdef\u001b[0m \u001b[0melse_body_4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/__autograph_generated_file18q4mr8e.py\u001b[0m in \u001b[0;36mtf__call\u001b[0;34m(self, r_t, training)\u001b[0m\n\u001b[1;32m     37\u001b[0m                     \u001b[0mr_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m                 \u001b[0mblock\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUndefined\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'block'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m                 \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_stmt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder_blocks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloop_body\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_state_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset_state_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'r_t'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'iterate_names'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'block'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m                 \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'Decoded output (llr_hat):'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/__autograph_generated_file18q4mr8e.py\u001b[0m in \u001b[0;36mloop_body\u001b[0;34m(itr)\u001b[0m\n\u001b[1;32m     35\u001b[0m                     \u001b[0;32mnonlocal\u001b[0m \u001b[0mr_t\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m                     \u001b[0mblock\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mitr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m                     \u001b[0mr_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m                 \u001b[0mblock\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUndefined\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'block'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m                 \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_stmt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder_blocks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloop_body\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_state_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset_state_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'r_t'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'iterate_names'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'block'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/__autograph_generated_file3bumf56h.py\u001b[0m in \u001b[0;36mtf__call\u001b[0;34m(self, x, training)\u001b[0m\n\u001b[1;32m     29\u001b[0m                 \u001b[0mffn_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mffn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m                 \u001b[0mffn_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mffn_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m                 \u001b[0mout2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayernorm2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mffn_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"<ipython-input-16-820b27f9dc89>\", line 25, in train_step  *\n        c, llr_hat = model(batch_size, ebno_db)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler  **\n        raise e.with_traceback(filtered_tb) from None\n    File \"/tmp/__autograph_generated_filed_73g01n.py\", line 99, in tf__call\n        ag__.if_stmt(ag__.ld(self)._decoder is not None, if_body_4, else_body_4, get_state_4, set_state_4, ('llr_hat',), 1)\n    File \"/tmp/__autograph_generated_filed_73g01n.py\", line 93, in if_body_4\n        llr_hat = ag__.converted_call(ag__.ld(self)._decoder, (ag__.ld(llr),), None, fscope)\n    File \"/tmp/__autograph_generated_file18q4mr8e.py\", line 39, in tf__call\n        ag__.for_stmt(ag__.ld(self).encoder_blocks, None, loop_body, get_state_1, set_state_1, ('r_t',), {'iterate_names': 'block'})\n    File \"/tmp/__autograph_generated_file18q4mr8e.py\", line 37, in loop_body\n        r_t = ag__.converted_call(ag__.ld(block), (ag__.ld(r_t),), dict(training=ag__.ld(training)), fscope)\n    File \"/tmp/__autograph_generated_file3bumf56h.py\", line 31, in tf__call\n        out2 = ag__.converted_call(ag__.ld(self).layernorm2, (ag__.ld(out1) + ag__.ld(ffn_output),), None, fscope)\n\n    ValueError: Exception encountered when calling layer 'e2e_model_13' (type E2EModel).\n    \n    in user code:\n    \n        File \"<ipython-input-35-e1ed9ad7eadb>\", line 548, in call  *\n            llr_hat = self._decoder(llr)\n        File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler  **\n            raise e.with_traceback(filtered_tb) from None\n        File \"/tmp/__autograph_generated_file18q4mr8e.py\", line 39, in tf__call\n            ag__.for_stmt(ag__.ld(self).encoder_blocks, None, loop_body, get_state_1, set_state_1, ('r_t',), {'iterate_names': 'block'})\n        File \"/tmp/__autograph_generated_file18q4mr8e.py\", line 37, in loop_body\n            r_t = ag__.converted_call(ag__.ld(block), (ag__.ld(r_t),), dict(training=ag__.ld(training)), fscope)\n        File \"/tmp/__autograph_generated_file3bumf56h.py\", line 31, in tf__call\n            out2 = ag__.converted_call(ag__.ld(self).layernorm2, (ag__.ld(out1) + ag__.ld(ffn_output),), None, fscope)\n    \n        ValueError: Exception encountered when calling layer 'decoder_14' (type Decoder).\n        \n        in user code:\n        \n            File \"<ipython-input-35-e1ed9ad7eadb>\", line 487, in call  *\n                r_t = block(r_t, training=training)\n            File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler  **\n                raise e.with_traceback(filtered_tb) from None\n            File \"/tmp/__autograph_generated_file3bumf56h.py\", line 31, in tf__call\n                out2 = ag__.converted_call(ag__.ld(self).layernorm2, (ag__.ld(out1) + ag__.ld(ffn_output),), None, fscope)\n        \n            ValueError: Exception encountered when calling layer 'transformer_encoder_block_1' (type TransformerEncoderBlock).\n            \n            in user code:\n            \n                File \"<ipython-input-35-e1ed9ad7eadb>\", line 460, in call  *\n                    out2 = self.layernorm2(out1 + ffn_output)  # Add & Normalize\n            \n                ValueError: Dimensions must be equal, but are 10 and 128 for '{{node decoder_14/transformer_encoder_block_1/add_1}} = AddV2[T=DT_FLOAT](decoder_14/transformer_encoder_block_1/layer_normalization_16/batchnorm/add_1, decoder_14/transformer_encoder_block_1/dropout_45/Identity)' with input shapes: [160,1,10], [160,1,128].\n            \n            \n            Call arguments received by layer 'transformer_encoder_block_1' (type TransformerEncoderBlock):\n              • x=tf.Tensor(shape=(160, 1, 10), dtype=float32)\n              • training=False\n        \n        \n        Call arguments received by layer 'decoder_14' (type Decoder):\n          • r_t=tf.Tensor(shape=(160, 10), dtype=float32)\n          • training=False\n    \n    \n    Call arguments received by layer 'e2e_model_13' (type E2EModel):\n      • batch_size=tf.Tensor(shape=(), dtype=int32)\n      • ebno_db=tf.Tensor(shape=(160, 1), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ltd_decoder.summary()\n",
        "# tf.keras.utils.plot_model(ltd_decoder, show_shapes=True, to_file=\"model.png\")\n"
      ],
      "metadata": {
        "id": "OuPmknHQuxFw",
        "outputId": "e539ac52-069c-4277-c8e4-abdd92287438",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'Decoder' object has no attribute 'layers'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-b0c447741219>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# ltd_decoder.summary()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mltd_decoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"model.png\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/vis_utils.py\u001b[0m in \u001b[0;36mplot_model\u001b[0;34m(model, to_file, show_shapes, show_dtype, show_layer_names, rankdir, expand_nested, dpi, layer_range, show_layer_activations, show_trainable)\u001b[0m\n\u001b[1;32m    464\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 466\u001b[0;31m     dot = model_to_dot(\n\u001b[0m\u001b[1;32m    467\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    468\u001b[0m         \u001b[0mshow_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshow_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/vis_utils.py\u001b[0m in \u001b[0;36mmodel_to_dot\u001b[0;34m(model, show_shapes, show_dtype, show_layer_names, rankdir, expand_nested, dpi, subgraph, layer_range, show_layer_activations, show_trainable)\u001b[0m\n\u001b[1;32m    182\u001b[0m     \u001b[0msub_w_last_node\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 184\u001b[0;31m     \u001b[0mlayers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    185\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_graph_network\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m         \u001b[0mnode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpydot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'Decoder' object has no attribute 'layers'"
          ]
        }
      ]
    }
  ]
}