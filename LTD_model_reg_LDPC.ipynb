{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPmBrrJTEK0DN7NVnzqHVU+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pollyjuice74/5G-Decoder/blob/main/LTD_model_reg_LDPC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "collapsed": true,
        "id": "5q1VAmIeUKIn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "410e8b3c-8ca0-41ef-831b-d09e2f763bf0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into '5G-Decoder'...\n",
            "remote: Enumerating objects: 1476, done.\u001b[K\n",
            "remote: Counting objects: 100% (1476/1476), done.\u001b[K\n",
            "remote: Compressing objects: 100% (536/536), done.\u001b[K\n",
            "remote: Total 1476 (delta 936), reused 1461 (delta 926), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (1476/1476), 1.69 MiB | 4.18 MiB/s, done.\n",
            "Resolving deltas: 100% (936/936), done.\n",
            "Collecting sionna\n",
            "  Downloading sionna-0.19.1-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting tensorflow<2.16.0,>=2.13.0 (from sionna)\n",
            "  Downloading tensorflow-2.15.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from sionna) (1.26.4)\n",
            "Requirement already satisfied: matplotlib>=3.5.3 in /usr/local/lib/python3.10/dist-packages (from sionna) (3.8.0)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from sionna) (1.13.1)\n",
            "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.10/dist-packages (from sionna) (6.4.5)\n",
            "Collecting mitsuba<3.6.0,>=3.2.0 (from sionna)\n",
            "  Downloading mitsuba-3.5.2-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (5.1 kB)\n",
            "Collecting pythreejs>=2.4.2 (from sionna)\n",
            "  Downloading pythreejs-2.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
            "Collecting ipywidgets>=8.0.4 (from sionna)\n",
            "  Downloading ipywidgets-8.1.5-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting ipydatawidgets==4.3.2 (from sionna)\n",
            "  Downloading ipydatawidgets-4.3.2-py2.py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting jupyterlab-widgets==3.0.5 (from sionna)\n",
            "  Downloading jupyterlab_widgets-3.0.5-py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: traittypes>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from ipydatawidgets==4.3.2->sionna) (0.2.1)\n",
            "Collecting comm>=0.1.3 (from ipywidgets>=8.0.4->sionna)\n",
            "  Downloading comm-0.2.2-py3-none-any.whl.metadata (3.7 kB)\n",
            "Requirement already satisfied: ipython>=6.1.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=8.0.4->sionna) (7.34.0)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=8.0.4->sionna) (5.7.1)\n",
            "Collecting widgetsnbextension~=4.0.12 (from ipywidgets>=8.0.4->sionna)\n",
            "  Downloading widgetsnbextension-4.0.13-py3-none-any.whl.metadata (1.6 kB)\n",
            "INFO: pip is looking at multiple versions of ipywidgets to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting ipywidgets>=8.0.4 (from sionna)\n",
            "  Downloading ipywidgets-8.1.4-py3-none-any.whl.metadata (2.3 kB)\n",
            "  Downloading ipywidgets-8.1.3-py3-none-any.whl.metadata (2.4 kB)\n",
            "  Downloading ipywidgets-8.1.2-py3-none-any.whl.metadata (2.4 kB)\n",
            "  Downloading ipywidgets-8.1.1-py3-none-any.whl.metadata (2.4 kB)\n",
            "  Downloading ipywidgets-8.1.0-py3-none-any.whl.metadata (2.4 kB)\n",
            "  Downloading ipywidgets-8.0.7-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=8.0.4->sionna) (5.5.6)\n",
            "  Downloading ipywidgets-8.0.6-py3-none-any.whl.metadata (2.4 kB)\n",
            "INFO: pip is still looking at multiple versions of ipywidgets to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading ipywidgets-8.0.5-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.3->sionna) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.3->sionna) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.3->sionna) (4.55.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.3->sionna) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.3->sionna) (24.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.3->sionna) (11.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.3->sionna) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.3->sionna) (2.8.2)\n",
            "Collecting drjit==0.4.6 (from mitsuba<3.6.0,>=3.2.0->sionna)\n",
            "  Downloading drjit-0.4.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16.0,>=2.13.0->sionna) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16.0,>=2.13.0->sionna) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16.0,>=2.13.0->sionna) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16.0,>=2.13.0->sionna) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16.0,>=2.13.0->sionna) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16.0,>=2.13.0->sionna) (3.12.1)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16.0,>=2.13.0->sionna) (18.1.1)\n",
            "Collecting ml-dtypes~=0.3.1 (from tensorflow<2.16.0,>=2.13.0->sionna)\n",
            "  Downloading ml_dtypes-0.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16.0,>=2.13.0->sionna) (3.4.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16.0,>=2.13.0->sionna) (4.25.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16.0,>=2.13.0->sionna) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16.0,>=2.13.0->sionna) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16.0,>=2.13.0->sionna) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16.0,>=2.13.0->sionna) (4.12.2)\n",
            "Collecting wrapt<1.15,>=1.11.0 (from tensorflow<2.16.0,>=2.13.0->sionna)\n",
            "  Downloading wrapt-1.14.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16.0,>=2.13.0->sionna) (0.37.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16.0,>=2.13.0->sionna) (1.68.1)\n",
            "Collecting tensorboard<2.16,>=2.15 (from tensorflow<2.16.0,>=2.13.0->sionna)\n",
            "  Downloading tensorboard-2.15.2-py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting tensorflow-estimator<2.16,>=2.15.0 (from tensorflow<2.16.0,>=2.13.0->sionna)\n",
            "  Downloading tensorflow_estimator-2.15.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting keras<2.16,>=2.15.0 (from tensorflow<2.16.0,>=2.13.0->sionna)\n",
            "  Downloading keras-2.15.0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow<2.16.0,>=2.13.0->sionna) (0.45.1)\n",
            "Collecting jedi>=0.16 (from ipython>=6.1.0->ipywidgets>=8.0.4->sionna)\n",
            "  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->sionna) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->sionna) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->sionna) (3.0.48)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->sionna) (2.18.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->sionna) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->sionna) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->sionna) (4.9.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16.0,>=2.13.0->sionna) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16.0,>=2.13.0->sionna) (1.2.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16.0,>=2.13.0->sionna) (3.7)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16.0,>=2.13.0->sionna) (2.32.3)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16.0,>=2.13.0->sionna) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16.0,>=2.13.0->sionna) (3.1.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow<2.16.0,>=2.13.0->sionna) (5.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow<2.16.0,>=2.13.0->sionna) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow<2.16.0,>=2.13.0->sionna) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow<2.16.0,>=2.13.0->sionna) (1.3.1)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets>=8.0.4->sionna) (0.8.4)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets>=8.0.4->sionna) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=6.1.0->ipywidgets>=8.0.4->sionna) (0.2.13)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow<2.16.0,>=2.13.0->sionna) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow<2.16.0,>=2.13.0->sionna) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow<2.16.0,>=2.13.0->sionna) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow<2.16.0,>=2.13.0->sionna) (2024.12.14)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow<2.16.0,>=2.13.0->sionna) (3.0.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow<2.16.0,>=2.13.0->sionna) (0.6.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow<2.16.0,>=2.13.0->sionna) (3.2.2)\n",
            "Downloading sionna-0.19.1-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m24.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ipydatawidgets-4.3.2-py2.py3-none-any.whl (271 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m271.6/271.6 kB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jupyterlab_widgets-3.0.5-py3-none-any.whl (384 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m384.3/384.3 kB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ipywidgets-8.0.5-py3-none-any.whl (138 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.3/138.3 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mitsuba-3.5.2-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (40.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.4/40.4 MB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading drjit-0.4.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m22.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pythreejs-2.4.2-py3-none-any.whl (3.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m29.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow-2.15.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (475.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m475.2/475.2 MB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading keras-2.15.0-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m71.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ml_dtypes-0.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m75.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboard-2.15.2-py3-none-any.whl (5.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m90.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow_estimator-2.15.0-py2.py3-none-any.whl (441 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m442.0/442.0 kB\u001b[0m \u001b[31m35.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading widgetsnbextension-4.0.13-py3-none-any.whl (2.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m83.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading wrapt-1.14.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (77 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m61.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: wrapt, widgetsnbextension, tensorflow-estimator, ml-dtypes, keras, jupyterlab-widgets, jedi, drjit, mitsuba, ipywidgets, tensorboard, ipydatawidgets, tensorflow, pythreejs, sionna\n",
            "  Attempting uninstall: wrapt\n",
            "    Found existing installation: wrapt 1.17.0\n",
            "    Uninstalling wrapt-1.17.0:\n",
            "      Successfully uninstalled wrapt-1.17.0\n",
            "  Attempting uninstall: widgetsnbextension\n",
            "    Found existing installation: widgetsnbextension 3.6.10\n",
            "    Uninstalling widgetsnbextension-3.6.10:\n",
            "      Successfully uninstalled widgetsnbextension-3.6.10\n",
            "  Attempting uninstall: ml-dtypes\n",
            "    Found existing installation: ml-dtypes 0.4.1\n",
            "    Uninstalling ml-dtypes-0.4.1:\n",
            "      Successfully uninstalled ml-dtypes-0.4.1\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 3.5.0\n",
            "    Uninstalling keras-3.5.0:\n",
            "      Successfully uninstalled keras-3.5.0\n",
            "  Attempting uninstall: jupyterlab-widgets\n",
            "    Found existing installation: jupyterlab_widgets 3.0.13\n",
            "    Uninstalling jupyterlab_widgets-3.0.13:\n",
            "      Successfully uninstalled jupyterlab_widgets-3.0.13\n",
            "  Attempting uninstall: ipywidgets\n",
            "    Found existing installation: ipywidgets 7.7.1\n",
            "    Uninstalling ipywidgets-7.7.1:\n",
            "      Successfully uninstalled ipywidgets-7.7.1\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.17.1\n",
            "    Uninstalling tensorboard-2.17.1:\n",
            "      Successfully uninstalled tensorboard-2.17.1\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.17.1\n",
            "    Uninstalling tensorflow-2.17.1:\n",
            "      Successfully uninstalled tensorflow-2.17.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tf-keras 2.17.0 requires tensorflow<2.18,>=2.17, but you have tensorflow 2.15.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed drjit-0.4.6 ipydatawidgets-4.3.2 ipywidgets-8.0.5 jedi-0.19.2 jupyterlab-widgets-3.0.5 keras-2.15.0 mitsuba-3.5.2 ml-dtypes-0.3.2 pythreejs-2.4.2 sionna-0.19.1 tensorboard-2.15.2 tensorflow-2.15.1 tensorflow-estimator-2.15.0 widgetsnbextension-4.0.13 wrapt-1.14.1\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/pollyjuice74/5G-Decoder\n",
        "!pip install sionna"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import tensorflow as tf\n",
        "import random\n",
        "import numpy as np\n",
        "import time\n",
        "from scipy.sparse import issparse, csr_matrix\n",
        "\n",
        "from sionna.fec.utils import generate_reg_ldpc, load_parity_check_examples, LinearEncoder, gm2pcm\n",
        "from sionna.utils.plotting import PlotBER\n",
        "from sionna.fec.ldpc import LDPCBPDecoder\n",
        "\n",
        "import os\n",
        "# os.chdir('../..')\n",
        "if os.path.exists('5G-Decoder'):\n",
        "  os.rename('5G-Decoder', '5G_Decoder')\n",
        "os.chdir('5G_Decoder/adv_nn')\n",
        "\n",
        "from dataset import *\n",
        "from attention import *\n",
        "from channel import *\n",
        "from args import *\n",
        "from model_functs import *\n",
        "from models import *"
      ],
      "metadata": {
        "id": "U5U5qUUVUeRm"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Loading LDPC code\")\n",
        "pcm, k, n, coderate = generate_reg_ldpc(v=3,\n",
        "                                        c=6,\n",
        "                                        n=10,\n",
        "                                        allow_flex_len=True,\n",
        "                                        verbose=True)\n",
        "\n",
        "# pcm = tf.cast(pcm, dtype=tf.int32)\n",
        "encoder = LinearEncoder(pcm, is_pcm=True, dtype=tf.int32)\n",
        "\n",
        "batch_size = 2  # For multiple codewords\n",
        "b = tf.random.uniform((batch_size, k), minval=0, maxval=2, dtype=tf.int32)\n",
        "c = encoder(b)\n",
        "print(pcm.shape, c.shape)\n",
        "pcm @ tf.transpose(c) % 2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 556
        },
        "id": "6RF7dBDwWg0L",
        "outputId": "e4be3d03-798e-48aa-e7ed-3002d3cf7377"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading LDPC code\n",
            "Setting n to:  10\n",
            "Number of edges (VN perspective):  30\n",
            "Number of edges (CN perspective):  30\n",
            "Generated regular (3,6) LDPC code of length n=10\n",
            "Code rate is r=0.500.\n",
            "Warning: The alias fec.utils.LinearEncoder will not be included in Sionna 1.0. Please use fec.linear.LinearEncoder instead.\n",
            "(5, 10) (2, 10)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(5, 2), dtype=int32, numpy=\n",
              "array([[0, 0],\n",
              "       [0, 0],\n",
              "       [0, 0],\n",
              "       [0, 0],\n",
              "       [0, 0]], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# for e2e model\n",
        "from sionna.utils import BinarySource, ebnodb2no\n",
        "from sionna.mapping import Mapper, Demapper\n",
        "from sionna.channel import AWGN\n",
        "# from sionna.fec.ldpc import LDPC5GDecoder, LDPC5GEncoder\n",
        "from tensorflow.keras.layers import Layer, Dense, Dropout\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "class Args():\n",
        "    def __init__(self, model_type, code_type='LDPC', n_look_up=121, k_look_up=80, n=400, k=200,\n",
        "                       n_rings=2, ls_active=True, split_diff=True, sigma=0.1,\n",
        "                       t_layers=1, d_model=128, heads=8, lr=5e-4,\n",
        "                       batch_size=160, batch_size_eval = 150,\n",
        "                       eval_train_iter=50, save_weights_iter=100,\n",
        "                       ebno_db_eval=2.5,\n",
        "                       ebno_db_min=0., ebno_db_max=4., ebno_db_stepsize=0.25,\n",
        "                       traindata_len=500, testdata_len=250, epochs=10000):\n",
        "        assert model_type in ['gen', 'dis'], \"Type must be: 'gen', Generator or 'dis', Discriminator.\"\n",
        "        assert code_type in ['POLAR', 'BCH', 'CCSDS', 'LDPC', 'MACKAY', 'LDPC5G', 'POLAR5G'], \"Invalid linear code type.\"\n",
        "\n",
        "\n",
        "        # model data\n",
        "        self.model_type = model_type\n",
        "\n",
        "        self.split_diff = split_diff\n",
        "        self.n_rings = n_rings # ring connectivity of mask\n",
        "        self.sigma = sigma\n",
        "        self.t_layers = t_layers\n",
        "        self.ls_active = ls_active\n",
        "\n",
        "        self.d_model = d_model\n",
        "        self.heads = heads\n",
        "\n",
        "        # training data\n",
        "        self.lr = lr\n",
        "        self.batch_size = batch_size\n",
        "        self.traindata_len = traindata_len\n",
        "        self.testdata_len = testdata_len\n",
        "        self.epochs = epochs\n",
        "\n",
        "        self.ebno_db_min = ebno_db_min\n",
        "        self.ebno_db_max = ebno_db_max\n",
        "        self.ebno_db_stepsize = ebno_db_stepsize\n",
        "\n",
        "        self.ebno_db_eval = ebno_db_eval\n",
        "        self.eval_train_iter = eval_train_iter\n",
        "        self.save_weights_iter = save_weights_iter\n",
        "        self.batch_size_eval = batch_size_eval\n",
        "\n",
        "        # code data\n",
        "        self.code_type = code_type\n",
        "        self.code = self.get_code(n_look_up, k_look_up) # n,k look up values in Get_Generator_and_Parity\n",
        "\n",
        "        # if self.code_type not in ['LDPC5G', 'POLAR5G']:\n",
        "        #     self.n, self.m, self.k = self.code.n, self.code.m, self.code.k\n",
        "        # else:\n",
        "        #     self.n, self.m, self.k = n, n-k, k\n",
        "\n",
        "        # self.n_steps = self.m + 5  # Number of diffusion steps\n",
        "\n",
        "    def get_code(self, n_look_up, k_look_up):\n",
        "        code = type('Code', (), {})() # class Code, no base class, no attributes/methods, () instantiate object\n",
        "        # code.n_look_up, code.k_look_up = n_look_up, k_look_up\n",
        "        # code.code_type = self.code_type\n",
        "\n",
        "        # if self.code_type not in ['LDPC5G', 'POLAR5G']:\n",
        "        #     G, H = Get_Generator_and_Parity(code)\n",
        "        #     code.G, code.H = tf.convert_to_tensor(G), csr_matrix( tf.convert_to_tensor(H) )\n",
        "\n",
        "        #     code.m, code.n = code.H.shape\n",
        "        #     code.k = code.n - code.m\n",
        "\n",
        "        return code\n",
        "\n",
        "\n",
        "class MHAttention(Layer):\n",
        "    def __init__(self, dims, heads, mask_length, linear=False, dropout=0.01):\n",
        "        super().__init__()\n",
        "        assert (dims % heads) == 0, 'dimension must be divisible by the number of heads'\n",
        "        self.linear = linear\n",
        "        self.dims = dims\n",
        "        self.heads = heads\n",
        "        self.dim_head = dims // heads\n",
        "\n",
        "        if linear:\n",
        "            self.k_proj = self.get_k_proj(mask_length) # n+m\n",
        "            self.proj_k = None\n",
        "            self.proj_v = None\n",
        "\n",
        "        self.to_q, self.to_k, self.to_v = [ Dense(self.dims, use_bias=False) for _ in range(3) ]\n",
        "        self.to_out = Dense(dims)\n",
        "        self.dropout = Dropout(dropout) # to d-dimentional embeddings\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        # Creates shape (n,k_proj) proj matrices for key and\n",
        "        n_value = input_shape[1]\n",
        "        if self.linear:\n",
        "            self.proj_k = self.add_weight(\"proj_k\", shape=[n_value, self.k_proj], initializer=GlorotUniform())\n",
        "            self.proj_v = self.add_weight(\"proj_v\", shape=[n_value, self.k_proj], initializer=GlorotUniform())\n",
        "\n",
        "    def call(self, x, mask=None):\n",
        "        out_att = self.lin_attention(x, mask) if self.linear else self.attention(x, mask)\n",
        "        return out_att\n",
        "\n",
        "    def get_k_proj(self, mask_length):\n",
        "        # gets dimention for linear tranformer vector projection\n",
        "        for k_proj in range(mask_length // 2, 0, -1): # starts at half the mask length TO 0\n",
        "            if mask_length % k_proj == 0:\n",
        "                return tf.cast(k_proj, tf.int32)\n",
        "\n",
        "    def lin_attention(self, x, mask): # O(n)\n",
        "        shape = tf.shape(x) # (b, n, d)\n",
        "        b = tf.cast(shape[0], tf.int32)\n",
        "        n = tf.cast(shape[1], tf.int32)\n",
        "\n",
        "        assert x.shape[-1] is not None, \"The last dimension of x is undefined.\"\n",
        "\n",
        "        query, key, val = self.to_q(x), self.to_k(x), self.to_v(x)\n",
        "\n",
        "        # Project key and val into k-dimentional space\n",
        "        key = tf.einsum('bnd,nk->bkd', key, self.proj_k)\n",
        "        val = tf.einsum('bnd,nk->bkd', val, self.proj_v)\n",
        "\n",
        "        # Reshape splitting for heads\n",
        "        query = tf.reshape(query, (b, n, self.heads, self.dim_head))\n",
        "        key = tf.reshape(key, (b, self.k_proj, self.heads, self.dim_head))\n",
        "        val = tf.reshape(val, (b, self.k_proj, self.heads, self.dim_head))\n",
        "        query, key, val = [ tf.transpose(x, [0, 2, 1, 3]) for x in [query, key, val] ]\n",
        "\n",
        "        # Low-rank mask (n,k_proj)\n",
        "        mask = tf.expand_dims(mask, axis=-1)\n",
        "        mask = tf.image.resize(mask, [n, self.k_proj], method='nearest')\n",
        "        mask = tf.reshape(mask, (1, 1, n, self.k_proj))\n",
        "\n",
        "        # Main attn logic: sftmx( q@k / d**0.5 ) @ v\n",
        "        scores = tf.einsum('bhnd,bhkd->bhnk', query, key) / (tf.sqrt( tf.cast(self.dim_head, dtype=tf.float32) ))\n",
        "        scores += (mask * -1e9) if mask is not None else 0.\n",
        "        attn = tf.nn.softmax(scores, axis=-1) # (b,h,n,k_proj)\n",
        "        attn = self.dropout(attn)\n",
        "        out = tf.einsum('bhnk,bhkd->bhnd', attn, val)\n",
        "\n",
        "        # Reshape and pass through out layer\n",
        "        out = tf.transpose(out, [0, 2, 1, 3])\n",
        "        out = tf.reshape(out, (b, n, -1))\n",
        "        return self.to_out(out)\n",
        "\n",
        "    def attention(self, x, mask): # O(n^2)\n",
        "        shape = tf.shape(x)\n",
        "        b = shape[0]\n",
        "        n = shape[1]\n",
        "        x = x[:, :, tf.newaxis] # (b,n,1)\n",
        "\n",
        "        query, key, val = self.to_q(x), self.to_k(x), self.to_v(x) # (b, n, d)\n",
        "        query, key, val = [ tf.reshape(x, (b, n, self.heads, self.dim_head)) for x in [query, key, val] ]\n",
        "        query, key, val = [ tf.cast( tf.transpose(x, [0, 2, 1, 3]), tf.float32 )\n",
        "                                                                            for x in [query, key, val] ]\n",
        "\n",
        "        scores = tf.einsum('bhqd,bhkd->bhqk', query, key) / (tf.sqrt( tf.cast(self.dim_head, tf.float32) ))\n",
        "        scores += (mask * -1e9) if mask is not None else 0. # apply mask non-edge connections\n",
        "        attn = tf.nn.softmax(scores, axis=-1) #-1\n",
        "        attn = self.dropout(attn)\n",
        "        out = tf.einsum('bhqk,bhkd->bhqd', attn, val)\n",
        "\n",
        "        out = tf.transpose(out, [0, 2, 1, 3])\n",
        "        out = tf.reshape(out, (b, n, -1))\n",
        "        return self.to_out(out)\n",
        "\n",
        "\n",
        "# class Decoder( TransformerDiffusion ):\n",
        "#     def __init__(self, args):\n",
        "#         super().__init__(args)\n",
        "#         self.transformer =\n",
        "\n",
        "#     # 'test' function\n",
        "#     def call(self, r_t):\n",
        "#         i = tf.constant(0)  # Initialize loop counter\n",
        "\n",
        "#         def condition(r_t, i):\n",
        "#             # Loop while i < self.m and syndrome sum is not zero\n",
        "#             return tf.logical_and(i < 5, tf.reduce_sum(self.get_syndrome(r_t)) != 0) # CHANGE 5 TO SELF.M\n",
        "\n",
        "#         def body(r_t, i):\n",
        "#             # Perform reverse or split diffusion\n",
        "#             r_t = tf.cond(\n",
        "#                 tf.logical_not(self.split_diff),\n",
        "#                 lambda: self.split_rdiff_call(r_t),\n",
        "#                 lambda: self.rev_diff_call(r_t),\n",
        "#             )\n",
        "#             return r_t, tf.add(i, 1)\n",
        "\n",
        "#         # Run tf.while_loop with the loop variables\n",
        "#         llr_hat, _ = tf.while_loop(\n",
        "#             condition,\n",
        "#             body,\n",
        "#             loop_vars=[r_t, i],\n",
        "#             maximum_iterations=self.m,\n",
        "#             shape_invariants=[tf.TensorShape([self.batch_size, self.n]), i.get_shape()]\n",
        "#         )\n",
        "\n",
        "#         # llr_hat, _ = self.tran_call(r_t)\n",
        "#         tf.print(\"llr_hat\", llr_hat)\n",
        "\n",
        "#         return llr_hat\n",
        "\n",
        "#     # Refines recieved codeword r at time t\n",
        "#     def rev_diff_call(self, r_t):\n",
        "#         tf.print(\"Rev def call with line-search...\")\n",
        "\n",
        "#         # Transformer error prediction\n",
        "#         z_hat_crude, t = self.tran_call(r_t) # (b,n)\n",
        "#         r_t1 = r_t - z_hat_crude*self.get_sigma(t)[:, tf.newaxis] # (b,n)\n",
        "#         # tf.print(r_t1)\n",
        "\n",
        "#         # # Refined estimate of the codeword for the ls diffusion step\n",
        "#         # r_t1, z_hat = self.line_search(r_t, sigma, err_hat) if self.ls_active else 1.\n",
        "#         # tf.print(\"After linesearch: \", r_t1)\n",
        "\n",
        "#         print(\"r_t1\", r_t1.shape, r_t1.dtype)\n",
        "#         return r_t1 # r at t-1, both (b,n)\n",
        "\n",
        "#     def split_rdiff_call(self, r_t):\n",
        "#         tf.print(\"Rev diff call with split diffusion...\")\n",
        "#         # First half-step condition subproblem\n",
        "#         z_hat_crude, t = self.tran_call(r_t)\n",
        "#         # tf.print(\"fc input: \", (z_hat_crude * self.get_sigma(t)[:, tf.newaxis]))\n",
        "#         r_t_half = r_t - 0.5 * self.fc( z_hat_crude * self.get_sigma(t)[:, tf.newaxis] )\n",
        "#         # tf.print(\"r_t_half\", r_t_half)\n",
        "\n",
        "#         # Full-step diffusion subproblem\n",
        "#         r_t1 = r_t_half + tf.random.normal(r_t_half.shape) * tf.sqrt(self.get_sigma(t)[:, tf.newaxis])\n",
        "\n",
        "#         # Second half-step condition subproblem\n",
        "#         z_hat_crude_half, t = self.tran_call(r_t1)  # Reuse the second `tran_call`\n",
        "#         r_t1 = r_t1 - 0.5 * self.fc(z_hat_crude_half * self.get_sigma(t)[:, tf.newaxis])\n",
        "#         print(\"r_t1\", r_t1.shape, r_t1.dtype)\n",
        "#         return r_t1  # r at t-1, both (b,n)\n",
        "\n",
        "\n",
        "from tensorflow.keras.layers import MultiHeadAttention, Dense, LayerNormalization, Dropout\n",
        "\n",
        "class TransformerEncoderBlock(tf.keras.layers.Layer):\n",
        "    def __init__(self, d_model, num_heads, dff, dropout_rate=0.1):\n",
        "        super(TransformerEncoderBlock, self).__init__()\n",
        "        self.mha = MultiHeadAttention(num_heads=num_heads, key_dim=d_model)\n",
        "        self.ffn = tf.keras.Sequential([\n",
        "            Dense(dff, activation='relu'),\n",
        "            Dense(d_model)\n",
        "        ])\n",
        "\n",
        "        self.layernorm1 = LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm2 = LayerNormalization(epsilon=1e-6)\n",
        "\n",
        "        self.dropout1 = Dropout(dropout_rate)\n",
        "        self.dropout2 = Dropout(dropout_rate)\n",
        "\n",
        "    def call(self, x, mask, training):\n",
        "        # Multi-Head Attention\n",
        "        attn_output = self.mha(x, x, attention_mask=mask)\n",
        "        tf.print(\"attn_output\", attn_output.shape)\n",
        "        attn_output = self.dropout1(attn_output, training=training)\n",
        "        out1 = self.layernorm1(x + attn_output)  # Add & Normalize\n",
        "\n",
        "        # Feedforward Network\n",
        "        ffn_output = self.ffn(out1)\n",
        "        tf.print(\"ffn_output\", ffn_output.shape)\n",
        "        ffn_output = self.dropout2(ffn_output, training=training)\n",
        "        out2 = self.layernorm2(out1 + ffn_output)  # Add & Normalize\n",
        "        return out2\n",
        "\n",
        "\n",
        "class Decoder( Layer ):\n",
        "    def __init__(self, args):\n",
        "        super().__init__()\n",
        "        code = args.code\n",
        "        self.pcm = tf.cast(code.H, dtype=tf.int32)\n",
        "\n",
        "        # shapes\n",
        "        self._m, self._n = self.pcm.shape\n",
        "        self._k = self._n - self._m\n",
        "        self.dims = args.d_model\n",
        "        self.batch_size = args.batch_size\n",
        "\n",
        "        # layers\n",
        "        self.node_embeddings = Dense(self.dims)\n",
        "        self.encoder_blocks = [\n",
        "            TransformerEncoderBlock(\n",
        "                d_model=args.d_model,\n",
        "                num_heads=args.heads,\n",
        "                dff=args.d_model * 4,\n",
        "                dropout_rate=0.1,\n",
        "            )\n",
        "            for _ in range(args.t_layers)\n",
        "        ]\n",
        "        self.forward_channel = Dense(1)\n",
        "        self.to_n = Dense(self._n)\n",
        "\n",
        "        # mask\n",
        "        self.mask = self.create_mask(self.pcm)\n",
        "        # for matrix, title in zip([self.pcm, self.mask], [\"PCM Matrix\", \"Mask Matrix\"]):\n",
        "        #     plt.imshow(matrix, cmap='viridis'); plt.colorbar(); plt.title(title); plt.show()\n",
        "        print(\"mask, pcm: \", self.mask, self.pcm)\n",
        "\n",
        "    def create_mask(self, H):\n",
        "        # Initialize diagonal identity mask\n",
        "        mask = tf.eye(2 * self._n - self._k, dtype=tf.float32)\n",
        "\n",
        "        # Get indices where H == 1\n",
        "        indices = tf.where(H == 1)  # Returns (row, col) pairs where H is 1\n",
        "        check_nodes, variable_nodes = indices[:, 0], indices[:, 1]\n",
        "\n",
        "        # Step 1: Update check node to variable node connections\n",
        "        mask = tf.tensor_scatter_nd_update(mask,\n",
        "                                          tf.stack([n + check_nodes, variable_nodes], axis=1),\n",
        "                                          tf.ones_like(check_nodes, dtype=tf.float32))\n",
        "        mask = tf.tensor_scatter_nd_update(mask,\n",
        "                                          tf.stack([variable_nodes, n + check_nodes], axis=1),\n",
        "                                          tf.ones_like(check_nodes, dtype=tf.float32))\n",
        "\n",
        "        # Step 2: Update variable node connections\n",
        "        for cn in tf.unique(check_nodes)[0]:  # Iterate over unique check nodes\n",
        "            related_vns = tf.boolean_mask(variable_nodes, check_nodes == cn)\n",
        "            indices = tf.stack(tf.meshgrid(related_vns, related_vns), axis=-1)\n",
        "            indices = tf.reshape(indices, [-1, 2])  # Flatten indices\n",
        "            mask = tf.tensor_scatter_nd_update(mask, indices, tf.ones_like(indices[:, 0], dtype=tf.float32))\n",
        "\n",
        "        # Tile mask across batch size for tf MHA\n",
        "        mask = tf.expand_dims(mask, axis=0)  # Shape: (1, n+m, n+m)\n",
        "        mask = tf.tile(mask, [self.batch_size, 1, 1])  # Shape: (b, n+m, n+m)\n",
        "        return mask\n",
        "\n",
        "    def get_syndrome(self, vn_vector, from_llr=True):\n",
        "        \"\"\" Calculate syndrome (pcm @ r = 0) if r is correct in binary \"\"\"\n",
        "        vn_vector = tf.transpose(vn_vector) # (n,b)\n",
        "        bin_vector = llr_to_bin(vn_vector) if from_llr else vn_vector\n",
        "        return tf.cast( (self.pcm @ bin_vector) % 2, dtype=tf.float32) # (m,n)@(n,b)->(m,b)\n",
        "\n",
        "    def call(self, x_nodes, training=False):\n",
        "        # tf.print(\"DECODER CALL\")\n",
        "        tf.print(\"x_nodes\", x_nodes.shape)\n",
        "        # Embed cn/vn nodes vector\n",
        "        x_nodes_embedded = self.node_embeddings( x_nodes ) # (b, n+m, hidden_dims)\n",
        "        # Pass through each encoder block\n",
        "        for block in self.encoder_blocks:\n",
        "            x_nodes = block(x_nodes_embedded,\n",
        "                            mask=self.mask,\n",
        "                            training=training)\n",
        "            tf.print(\"x_nodes\", x_nodes.shape)\n",
        "        x_nodes = tf.squeeze( self.forward_channel(x_nodes), axis=-1 ) # (b, n+m, hidden_dims)->(b, n+m)\n",
        "        # tf.print(\"x_nodes\", x_nodes, x_nodes.shape)\n",
        "        llr_hat = self.to_n(x_nodes) # (b, n+m)->(b,n)\n",
        "        # tf.print(\"Decoded output (llr_hat):\", llr_hat)\n",
        "        return llr_hat\n",
        "\n",
        "\n",
        "class E2EModel(tf.keras.Model):\n",
        "    def __init__(self, encoder, decoder, k, n, return_infobits=False, es_no=False):\n",
        "        super().__init__()\n",
        "\n",
        "        self._n = n\n",
        "        self._k = k\n",
        "        self._m = n - k\n",
        "\n",
        "        self._binary_source = BinarySource(dtype=tf.int32)\n",
        "        self._num_bits_per_symbol = 2\n",
        "        self._mapper = Mapper(\"qam\", self._num_bits_per_symbol)\n",
        "        self._demapper = Demapper(\"app\", \"qam\", self._num_bits_per_symbol)\n",
        "        self._channel = AWGN()\n",
        "        self._decoder = decoder\n",
        "        self._encoder = encoder\n",
        "        self._return_infobits = return_infobits\n",
        "        self._es_no = es_no\n",
        "\n",
        "    @tf.function(jit_compile=False)\n",
        "    def call(self, batch_size, ebno_db):\n",
        "\n",
        "        # no rate-adjustment for uncoded transmission or es_no scenario\n",
        "        if self._decoder is not None and self._es_no==False:\n",
        "            no = ebnodb2no(ebno_db, self._num_bits_per_symbol, self._k/self._n)\n",
        "        else: #for uncoded transmissions the rate is 1\n",
        "            no = ebnodb2no(ebno_db, self._num_bits_per_symbol, 1)\n",
        "\n",
        "        b = self._binary_source([batch_size, self._k])\n",
        "        if self._encoder is not None:\n",
        "            c = self._encoder(b)\n",
        "        else:\n",
        "            c = b\n",
        "\n",
        "        # check that rate calculations are correct\n",
        "        assert self._n==c.shape[-1], \"Invalid value of n.\"\n",
        "\n",
        "        # zero padding to support odd codeword lengths\n",
        "        if self._n%2==1:\n",
        "            c_pad = tf.concat([c, tf.zeros([batch_size, 1])], axis=1)\n",
        "        else: # no padding\n",
        "            c_pad = c\n",
        "        x = self._mapper(c_pad)\n",
        "\n",
        "        y = self._channel([x, no])\n",
        "        llr = self._demapper([y, no])\n",
        "\n",
        "        # remove zero padded bit at the end\n",
        "        if self._n%2==1:\n",
        "            llr = llr[:,:-1]\n",
        "        # tf.print('PCM @ CW: ', self._decoder.pcm @\n",
        "                #  tf.transpose(tf.cast(c, dtype=tf.int32)) % 2)\n",
        "\n",
        "        # decoder input nodes\n",
        "        syndrome = tf.reshape( self._decoder.get_syndrome(llr),\n",
        "                               (batch_size, self._m) ) # (m,n)@(n,b)->(m,b) check nodes\n",
        "        # tf.print(\"SYNDROME_CHECK\", self._decoder.get_syndrome(bin_to_llr(c)))\n",
        "        # tf.print(\"syndrome_sum\", tf.reduce_sum(syndrome))\n",
        "        x_nodes = tf.concat([llr, syndrome], axis=1)[:, :, tf.newaxis] # (b, n+m, 1)\n",
        "        # tf.print(\"syndrome, x_nodes.dtype\", syndrome, x_nodes.dtype)\n",
        "\n",
        "        # and run the decoder\n",
        "        if self._decoder is not None:\n",
        "            # tf.print('x_nodes input: ', x_nodes)\n",
        "            ############################\n",
        "            llr_hat = self._decoder(x_nodes)\n",
        "            ############################\n",
        "            # tf.print(llr_hat)\n",
        "            # c_check = llr_to_bin(bin_to_llr(c))\n",
        "            # tf.print(\"CHECK: \", c.dtype, c_check.dtype, c==c_check)\n",
        "\n",
        "        if self._return_infobits:\n",
        "            return b, llr_hat, llr\n",
        "        else:\n",
        "            return c, llr_hat, llr\n",
        "\n",
        "\n",
        "# args for decoder/discriminator\n",
        "args = Args(model_type='dis')\n",
        "args.code.H = pcm\n",
        "args.n, args.m = pcm.shape\n",
        "args.k = k\n",
        "args.n_steps = args.m + 5\n",
        "\n",
        "ltd_decoder = Decoder(args) # Linear Transformer Diffusion (LTD) Decoder\n",
        "\n",
        "e2e_ltd = E2EModel(encoder, ltd_decoder, k, n)"
      ],
      "metadata": {
        "id": "XOILyjSGXMdb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8593eff4-c981-466e-f767-7a7ea2dafc46"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mask, pcm:  tf.Tensor(\n",
            "[[[1. 1. 1. ... 1. 1. 1.]\n",
            "  [1. 1. 1. ... 1. 0. 0.]\n",
            "  [1. 1. 1. ... 1. 1. 0.]\n",
            "  ...\n",
            "  [1. 1. 1. ... 1. 0. 0.]\n",
            "  [1. 0. 1. ... 0. 1. 0.]\n",
            "  [1. 0. 0. ... 0. 0. 1.]]\n",
            "\n",
            " [[1. 1. 1. ... 1. 1. 1.]\n",
            "  [1. 1. 1. ... 1. 0. 0.]\n",
            "  [1. 1. 1. ... 1. 1. 0.]\n",
            "  ...\n",
            "  [1. 1. 1. ... 1. 0. 0.]\n",
            "  [1. 0. 1. ... 0. 1. 0.]\n",
            "  [1. 0. 0. ... 0. 0. 1.]]\n",
            "\n",
            " [[1. 1. 1. ... 1. 1. 1.]\n",
            "  [1. 1. 1. ... 1. 0. 0.]\n",
            "  [1. 1. 1. ... 1. 1. 0.]\n",
            "  ...\n",
            "  [1. 1. 1. ... 1. 0. 0.]\n",
            "  [1. 0. 1. ... 0. 1. 0.]\n",
            "  [1. 0. 0. ... 0. 0. 1.]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[1. 1. 1. ... 1. 1. 1.]\n",
            "  [1. 1. 1. ... 1. 0. 0.]\n",
            "  [1. 1. 1. ... 1. 1. 0.]\n",
            "  ...\n",
            "  [1. 1. 1. ... 1. 0. 0.]\n",
            "  [1. 0. 1. ... 0. 1. 0.]\n",
            "  [1. 0. 0. ... 0. 0. 1.]]\n",
            "\n",
            " [[1. 1. 1. ... 1. 1. 1.]\n",
            "  [1. 1. 1. ... 1. 0. 0.]\n",
            "  [1. 1. 1. ... 1. 1. 0.]\n",
            "  ...\n",
            "  [1. 1. 1. ... 1. 0. 0.]\n",
            "  [1. 0. 1. ... 0. 1. 0.]\n",
            "  [1. 0. 0. ... 0. 0. 1.]]\n",
            "\n",
            " [[1. 1. 1. ... 1. 1. 1.]\n",
            "  [1. 1. 1. ... 1. 0. 0.]\n",
            "  [1. 1. 1. ... 1. 1. 0.]\n",
            "  ...\n",
            "  [1. 1. 1. ... 1. 0. 0.]\n",
            "  [1. 0. 1. ... 0. 1. 0.]\n",
            "  [1. 0. 0. ... 0. 0. 1.]]], shape=(160, 15, 15), dtype=float32) tf.Tensor(\n",
            "[[0 1 0 1 1 1 1 1 0 0]\n",
            " [0 1 1 1 0 0 1 1 0 1]\n",
            " [1 1 1 0 0 1 0 1 1 0]\n",
            " [1 0 1 0 1 1 0 0 1 1]\n",
            " [1 0 0 1 1 0 1 0 1 1]], shape=(5, 10), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "4vZxtXOf4c1k",
        "outputId": "a0cbfaa9-46eb-414b-e4a0-098eb0527da6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "@staticmethod\n",
        "def bin_to_llr(x):\n",
        "    \"\"\"\n",
        "    Converts binary values (0 or 1) to log-likelihood ratios (LLRs), clipping values to ±20 for numerical stability.\n",
        "    Args:\n",
        "        x (Tensor): Binary input tensor with values 0 or 1.\n",
        "    Returns:\n",
        "        Tensor: Tensor of LLR values with clipped range.\n",
        "    \"\"\"\n",
        "    llr_vector = tf.where(x == 0, -20, 20)\n",
        "    return llr_vector\n",
        "\n",
        "@staticmethod\n",
        "def llr_to_bin(c):\n",
        "    \"\"\"\n",
        "    Converts log-likelihood ratios (LLRs) to binary values based on their sign.\n",
        "    Args:\n",
        "        c (Tensor): Tensor of LLR values.\n",
        "    Returns:\n",
        "        Tensor: Binary tensor with values 0 or 1.\n",
        "    \"\"\"\n",
        "    return tf.cast(tf.greater(c, 0), tf.int32)\n",
        "\n",
        "def load_weights(model, checkpoint_path):\n",
        "    \"\"\"\n",
        "    Loads the model's weights from a specified checkpoint directory.\n",
        "    Args:\n",
        "        model (tf.keras.Model): The model whose weights need to be restored.\n",
        "        checkpoint_path (str): File path where checkpoint files are stored.\n",
        "    \"\"\"\n",
        "    checkpoint = tf.train.Checkpoint(decoder=model._decoder)\n",
        "    try:\n",
        "        checkpoint.restore(checkpoint_path).assert_existing_objects_matched()\n",
        "        print(f\"Successfully restored weights from {checkpoint_path}\")\n",
        "    except AssertionError:\n",
        "        print(\"No checkpoint found. Starting training from scratch.\")\n",
        "\n",
        "def save_weights(model, checkpoint_dir):\n",
        "    \"\"\"\n",
        "    Saves the model's current weights to a specified checkpoint directory.\n",
        "    Args:\n",
        "        model (tf.keras.Model): The model whose weights need to be saved.\n",
        "        checkpoint_dir (str): Directory path where checkpoint files will be saved.\n",
        "    \"\"\"\n",
        "    checkpoint = tf.train.Checkpoint(decoder=model._decoder)\n",
        "    checkpoint.save(checkpoint_dir)\n",
        "    print(f\"Saved weights to {checkpoint_dir}\")\n",
        "\n",
        "def visualize_weights(model):\n",
        "    \"\"\"\n",
        "    Visualizes the trainable weights of the model as heatmaps, updating them in place during training.\n",
        "    Args:\n",
        "        model (tf.keras.Model): The model whose weights are visualized.\n",
        "    \"\"\"\n",
        "    import seaborn as sns\n",
        "    plt.ion()  # Turn on interactive mode\n",
        "    fig, axs = plt.subplots(1, len(model.trainable_weights), figsize=(15, 5))\n",
        "\n",
        "    for epoch in range(1, args.epochs + 1):\n",
        "        for i, var in enumerate(model.trainable_weights):\n",
        "            var_name = var.name\n",
        "            var_value = var.numpy()\n",
        "\n",
        "            if len(var_value.shape) > 1:  # Ensure the weights are at least 2D\n",
        "                axs[i].clear()  # Clear the axis to avoid overlapping\n",
        "                sns.heatmap(var_value, cmap=\"viridis\", ax=axs[i], cbar=True)\n",
        "                axs[i].set_title(f'{var_name}')\n",
        "            else:\n",
        "                axs[i].text(0.5, 0.5, f\"{var_name}: Not 2D\", ha='center')\n",
        "\n",
        "        plt.draw()  # Update the figure with new data\n",
        "        plt.pause(0.5)  # Pause briefly to allow visualization updates\n",
        "\n",
        "    plt.ioff()  # Turn off interactive mode\n",
        "\n",
        "# SGD update iteration\n",
        "@tf.function(jit_compile=False)\n",
        "def train_step(model, loss_fn, optimizer, batch_size):\n",
        "    \"\"\"\n",
        "    Performs one training step with a batch of data, applying SGD updates to the model.\n",
        "    Args:\n",
        "        model (tf.keras.Model): The model to be trained.\n",
        "        loss_fn (tf.keras.losses.Loss): Loss function to calculate the error.\n",
        "        optimizer (tf.keras.optimizers.Optimizer): Optimizer to update the model weights.\n",
        "        batch_size (int): Number of samples in the training batch.\n",
        "    Returns:\n",
        "        Tuple: Ground truth binary labels and predicted LLR values.\n",
        "    \"\"\"\n",
        "    # train for random SNRs within a pre-defined interval\n",
        "    ebno_db = tf.random.uniform([batch_size, 1],\n",
        "                                minval=args.ebno_db_min,\n",
        "                                maxval=args.ebno_db_max)\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "        c, llr_hat, llr_channel = model(batch_size, ebno_db)\n",
        "        # tf.print(c, llr_hat)\n",
        "\n",
        "        llr_y = bin_to_llr(c)\n",
        "        tf.print(\"llrs\", llr_y, llr_hat)\n",
        "        loss_value = loss_fn(llr_y, llr_hat)\n",
        "\n",
        "    # and apply the SGD updates\n",
        "    weights = model.trainable_weights\n",
        "    grads = tape.gradient(loss_value, weights) # variables\n",
        "    optimizer.apply_gradients(zip(grads, weights))\n",
        "    return c, llr_hat\n",
        "\n",
        "def test_step(model, args, loss_fn, learning_rate, epoch):\n",
        "    \"\"\"\n",
        "    Evaluates the model on a batch of data, calculating loss, bit error rate (BER), and timing.\n",
        "    Args:\n",
        "        model (tf.keras.Model): The model to be evaluated.\n",
        "        args (Namespace): Arguments containing evaluation parameters.\n",
        "        loss_fn (tf.keras.losses.Loss): Loss function to calculate the error.\n",
        "        learning_rate (float): Current learning rate of the optimizer.\n",
        "        epoch (int): Current epoch of training.\n",
        "    \"\"\"\n",
        "    ebno_db = tf.random.uniform([args.batch_size, 1],\n",
        "                                 minval=args.ebno_db_eval,\n",
        "                                 maxval=args.ebno_db_eval)\n",
        "    # measure time for call\n",
        "    time_start = time.time()\n",
        "    c, llr_hat, llr_channel = model(args.batch_size, ebno_db)\n",
        "    duration = time.time() - time_start # in s\n",
        "\n",
        "    # clip llr_hat for numerical stability\n",
        "    llr_hat = tf.clip_by_value(llr_hat, -20.0, 20.0)\n",
        "    # loss\n",
        "    llr_y = bin_to_llr(c)\n",
        "    loss_value = loss_fn(llr_y, llr_hat)\n",
        "    # ber pred\n",
        "    c_hat = llr_to_bin(llr_hat)\n",
        "    ber = compute_ber(c, c_hat).numpy()\n",
        "    # ber original\n",
        "    c_channel = llr_to_bin(llr_channel)\n",
        "    channel_ber = compute_ber(c, c_channel).numpy()\n",
        "\n",
        "    print(f'Training epoch {epoch}/{args.epochs}, LR={learning_rate:.2e}, Loss={loss_value.numpy():.5e}, channel_BER={channel_ber}, BER={ber}, duration per call: {duration:.2f}s')\n",
        "\n",
        "def train_dec(model, args, file_name, save_path='/content/drive/My Drive/ECC_weights/', visualize_decoder_weights=False):\n",
        "    \"\"\"\n",
        "    Trains the model using a specified training process, evaluates periodically, and saves weights at intervals.\n",
        "    Args:\n",
        "        model (tf.keras.Model): The model to be trained.\n",
        "        args (Namespace): Training arguments including batch size, epochs, learning rate, etc.\n",
        "        file_name (str): Name of the file to save weights.\n",
        "        save_path (str): Directory path to save model checkpoints.\n",
        "        visualize_decoder_weights (bool): Whether to visualize model weights during training.\n",
        "    \"\"\"\n",
        "    # loss\n",
        "    loss_fn = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
        "    # optimizer\n",
        "    scheduler = tf.keras.optimizers.schedules.CosineDecay(initial_learning_rate=args.lr, decay_steps=args.epochs) # 1000 is size of trainloader\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate=scheduler)\n",
        "\n",
        "    # Load weights if available\n",
        "    weights_path = os.path.join(save_path, file_name)\n",
        "    load_weights(model, weights_path)\n",
        "\n",
        "    print(\"Training Model...\")\n",
        "    for epoch in range(1, args.epochs + 1):\n",
        "        train_step(model,\n",
        "                   loss_fn,\n",
        "                   optimizer,\n",
        "                   args.batch_size)\n",
        "\n",
        "        # eval train iter\n",
        "        if True: #epoch % args.eval_train_iter == 0:\n",
        "            test_step(model,\n",
        "                      args,\n",
        "                      loss_fn,\n",
        "                      learning_rate=optimizer.learning_rate.numpy(),\n",
        "                      epoch=epoch)\n",
        "            # break\n",
        "\n",
        "        # save weights iter\n",
        "        if epoch % args.save_weights_iter == 0:\n",
        "            save_weights(model, weights_path)\n",
        "\n",
        "        # visualize decoder weights\n",
        "        if visualize_decoder_weights:\n",
        "            visualize_weights(model)\n",
        "\n",
        "\n",
        "train_dec(e2e_ltd, args, file_name='ECCT_dims128.h5-1', visualize_decoder_weights=False)"
      ],
      "metadata": {
        "id": "oHhDtIq64gjg",
        "outputId": "d28a77df-ca20-4258-e21a-af159d359ff2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully restored weights from /content/drive/My Drive/ECC_weights/ECCT_dims128.h5-1\n",
            "Training Model...\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "llrs [[20 20 20 ... 20 20 20]\n",
            " [20 20 -20 ... -20 20 -20]\n",
            " [-20 -20 -20 ... -20 -20 -20]\n",
            " ...\n",
            " [-20 20 -20 ... 20 -20 -20]\n",
            " [20 -20 -20 ... -20 20 -20]\n",
            " [-20 -20 20 ... 20 -20 20]] [[666.484497 875.710266 549.902771 ... 464.596619 776.546753 685.599915]\n",
            " [278.742767 -333.528412 -680.124939 ... -591.804443 -221.343582 -324.261261]\n",
            " [-830.087341 -620.54126 -785.826111 ... -277.013275 -693.15509 -999.440796]\n",
            " ...\n",
            " [-232.181671 -189.03656 -840.318604 ... -130.737213 -589.926392 -711.501404]\n",
            " [-771.788452 -1061.02954 -312.659058 ... -916.527161 -690.609558 -897.488037]\n",
            " [-129.585617 -38.166256 -106.687759 ... 218.916458 -416.851318 -38.9228516]]\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "Training epoch 1/10000, LR=5.00e-04, Loss=-1.60673e+02, channel_BER=0.098125, BER=0.291875, duration per call: 0.01s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "llrs [[-20 -20 20 ... -20 -20 20]\n",
            " [-20 -20 -20 ... -20 -20 -20]\n",
            " [-20 -20 -20 ... -20 -20 -20]\n",
            " ...\n",
            " [20 20 -20 ... -20 20 -20]\n",
            " [-20 20 -20 ... 20 -20 -20]\n",
            " [-20 -20 20 ... 20 -20 20]] [[-375.580872 9.36843395 -252.833664 ... -786.116272 -76.3205795 253.218]\n",
            " [-1063.36035 -1397.20874 -877.9328 ... -741.753 -1238.7738 -1096.03735]\n",
            " [-651.904724 -797.811523 -382.498535 ... -218.369 -516.940125 -241.444397]\n",
            " ...\n",
            " [-237.46759 -695.639 -3.24722958 ... -455.743622 134.896362 -166.818985]\n",
            " [-1063.7616 -1397.98486 -878.12 ... -742.158691 -1239.47864 -1094.52136]\n",
            " [-638.883 45.8607941 61.9202805 ... 99.7083359 -905.15448 142.820358]]\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "Training epoch 2/10000, LR=5.00e-04, Loss=-1.45152e+02, channel_BER=0.085, BER=0.31, duration per call: 0.01s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "llrs [[20 -20 -20 ... 20 20 -20]\n",
            " [20 20 -20 ... 20 20 -20]\n",
            " [20 -20 20 ... 20 20 20]\n",
            " ...\n",
            " [-20 -20 20 ... -20 -20 20]\n",
            " [20 -20 -20 ... -20 20 -20]\n",
            " [-20 20 -20 ... -20 -20 -20]] [[-465.557343 -768.909668 -743.663574 ... -229.098572 15.9881639 -952.167236]\n",
            " [199.469162 -296.246155 -244.897903 ... 714.645081 -143.803589 -536.102417]\n",
            " [251.000183 -638.585449 -34.3029022 ... 148.392029 -690.92981 320.713226]\n",
            " ...\n",
            " [289.533478 718.975037 328.756165 ... -9.62915802 739.061 553.519592]\n",
            " [71.1945343 -1255.703 -77.4623 ... 142.615784 -192.710693 -171.498871]\n",
            " [193.835144 216.431885 -187.82785 ... 164.703629 -148.554565 -482.542206]]\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "Training epoch 3/10000, LR=5.00e-04, Loss=-1.54920e+02, channel_BER=0.110625, BER=0.2975, duration per call: 0.02s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "llrs [[20 -20 20 ... 20 20 20]\n",
            " [-20 -20 20 ... 20 -20 20]\n",
            " [-20 -20 -20 ... -20 -20 -20]\n",
            " ...\n",
            " [20 -20 -20 ... -20 20 -20]\n",
            " [-20 -20 -20 ... 20 -20 -20]\n",
            " [-20 -20 -20 ... 20 -20 -20]] [[-351.118195 -178.588852 473.432 ... -277.977417 8.84013557 413.855682]\n",
            " [-500.389984 -272.363129 69.323494 ... 121.461411 -761.408875 388.769104]\n",
            " [-1067.73962 -1403.43628 -882.588684 ... -745.403564 -1243.60657 -1098.97534]\n",
            " ...\n",
            " [-1068.13977 -1403.89905 -882.246155 ... -745.77594 -1244.02673 -1099.1759]\n",
            " [589.079834 -347.028503 -303.393219 ... 629.059387 296.750153 -80.6161957]\n",
            " [-208.170731 -406.852661 -628.619263 ... -90.5988388 -416.960052 -505.729797]]\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "Training epoch 4/10000, LR=5.00e-04, Loss=-1.59418e+02, channel_BER=0.091875, BER=0.293125, duration per call: 0.03s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "llrs [[-20 20 -20 ... 20 -20 -20]\n",
            " [-20 20 20 ... -20 -20 20]\n",
            " [-20 20 -20 ... -20 -20 -20]\n",
            " ...\n",
            " [-20 -20 -20 ... 20 -20 -20]\n",
            " [-20 20 -20 ... 20 -20 -20]\n",
            " [-20 20 20 ... -20 -20 20]] [[-50.8965492 -117.840355 -808.147827 ... 170.687546 -337.91983 -488.601349]\n",
            " [-517.247559 -796.170837 -459.765198 ... -788.140442 -951.137817 -509.576294]\n",
            " [-525.05835 -484.820282 -978.549866 ... -151.22374 -442.950378 -911.101624]\n",
            " ...\n",
            " [-168.981827 -283.188629 -402.933228 ... 190.49202 -152.648285 -390.293701]\n",
            " [-289.463562 256.655762 -579.322 ... 243.419571 -358.589386 -208.630554]\n",
            " [-381.796417 -249.828629 286.680481 ... -40.1738739 -421.423859 -85.6313705]]\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "Training epoch 5/10000, LR=5.00e-04, Loss=-1.53354e+02, channel_BER=0.093125, BER=0.299375, duration per call: 0.02s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "llrs [[20 -20 20 ... -20 20 20]\n",
            " [-20 -20 -20 ... 20 -20 -20]\n",
            " [-20 -20 20 ... 20 -20 20]\n",
            " ...\n",
            " [-20 20 -20 ... -20 -20 -20]\n",
            " [-20 20 -20 ... -20 -20 -20]\n",
            " [-20 -20 -20 ... 20 -20 -20]] [[194.895096 -121.415199 -140.186691 ... -90.2751923 664.040405 -64.1491]\n",
            " [-170.86525 -283.47522 -405.602386 ... 190.538818 -154.133636 -393.110931]\n",
            " [67.9673386 225.206284 -59.6910591 ... 741.390137 7.43498516 728.653076]\n",
            " ...\n",
            " [-484.260406 123.373116 -264.922791 ... -487.986 -112.534073 -256.057831]\n",
            " [-237.86702 -757.607056 -1144.28589 ... -48.5849457 -359.940918 -994.414551]\n",
            " [-780.260559 -1111.03467 -752.797852 ... -728.660156 -1402.75049 -910.854675]]\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "Training epoch 6/10000, LR=5.00e-04, Loss=-1.40154e+02, channel_BER=0.08625, BER=0.31625, duration per call: 0.02s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "llrs [[20 20 20 ... 20 20 20]\n",
            " [20 -20 20 ... -20 20 20]\n",
            " [20 -20 20 ... -20 20 20]\n",
            " ...\n",
            " [20 -20 20 ... -20 20 20]\n",
            " [-20 -20 -20 ... 20 -20 -20]\n",
            " [20 20 -20 ... -20 20 -20]] [[672.277161 882.934387 555.388733 ... 469.703278 782.748169 691.56958]\n",
            " [672.147461 882.939331 555.361755 ... 469.649689 782.655823 691.528076]\n",
            " [-181.775787 -847.842834 -53.3767815 ... -336.845825 294.45932 -272.071747]\n",
            " ...\n",
            " [-137.594208 -1276.49744 -67.1399918 ... -313.113525 -138.467407 -219.523743]\n",
            " [583.901855 -653.009827 -508.613892 ... 217.941788 -83.443634 -460.191376]\n",
            " [714.895508 649.638245 197.401154 ... 158.17099 680.559509 62.0630417]]\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "Training epoch 7/10000, LR=5.00e-04, Loss=-1.59980e+02, channel_BER=0.08875, BER=0.289375, duration per call: 0.02s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "llrs [[20 20 -20 ... -20 20 -20]\n",
            " [-20 -20 20 ... -20 -20 20]\n",
            " [-20 -20 20 ... -20 -20 20]\n",
            " ...\n",
            " [20 -20 20 ... 20 20 20]\n",
            " [-20 -20 20 ... -20 -20 20]\n",
            " [20 20 20 ... -20 20 20]] [[215.243561 -356.79538 -614.354614 ... -423.607086 266.520844 -771.004761]\n",
            " [-123.908661 820.779114 225.963318 ... -256.480835 69.3390732 268.608704]\n",
            " [-340.342468 131.471863 -27.9887028 ... -512.398 185.005081 370.509705]\n",
            " ...\n",
            " [260.368439 -98.5714798 227.690704 ... 409.475189 -394.033752 287.41864]\n",
            " [-571.646851 -1686.91589 -731.012634 ... -611.952332 -589.783264 -457.27597]\n",
            " [-175.767059 -424.071381 211.946274 ... -584.642212 -129.832886 -207.423264]]\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "Training epoch 8/10000, LR=5.00e-04, Loss=-1.37402e+02, channel_BER=0.1025, BER=0.318125, duration per call: 0.01s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "llrs [[20 -20 20 ... 20 20 20]\n",
            " [20 20 -20 ... -20 20 -20]\n",
            " [20 20 -20 ... -20 20 -20]\n",
            " ...\n",
            " [20 20 -20 ... 20 20 -20]\n",
            " [-20 -20 20 ... 20 -20 20]\n",
            " [20 20 -20 ... -20 20 -20]] [[-511.340912 -585.520264 -134.829758 ... -294.06012 -1146.57129 8.91075]\n",
            " [-98.3116837 -110.373833 -86.0721207 ... -262.72345 -83.1968231 -859.865845]\n",
            " [843.984924 602.828125 484.624237 ... 340.418365 938.201111 541.032288]\n",
            " ...\n",
            " [550.436768 305.597717 351.032867 ... 321.640625 1094.35913 345.315796]\n",
            " [-1099.82825 -579.512756 -515.864685 ... -463.860413 -1431.18518 -555.087769]\n",
            " [994.115967 321.963257 299.282623 ... 189.449951 794.794 315.670654]]\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "Training epoch 9/10000, LR=5.00e-04, Loss=-1.48122e+02, channel_BER=0.101875, BER=0.30375, duration per call: 0.01s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "llrs [[20 -20 -20 ... 20 20 -20]\n",
            " [-20 -20 20 ... 20 -20 20]\n",
            " [-20 20 -20 ... -20 -20 -20]\n",
            " ...\n",
            " [20 -20 20 ... 20 20 20]\n",
            " [-20 -20 -20 ... 20 -20 -20]\n",
            " [20 20 20 ... 20 20 20]] [[991.19635 329.522614 304.558044 ... 193.862183 799.905457 321.944366]\n",
            " [25.2572212 99.5918732 -289.804535 ... 462.567749 -262.056244 612.638428]\n",
            " [-254.245529 -741.766602 -1119.14795 ... -395.180542 -907.488464 -694.349915]\n",
            " ...\n",
            " [-292.201782 -197.941071 278.253967 ... 166.969742 -36.3701859 -82.3049698]\n",
            " [-215.02948 -413.084076 -638.636536 ... -91.7521439 -425.361145 -515.039246]\n",
            " [675.222778 886.230469 558.027039 ... 472.441925 786.037781 694.527649]]\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "Training epoch 10/10000, LR=5.00e-04, Loss=-1.38060e+02, channel_BER=0.081875, BER=0.31625, duration per call: 0.02s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "llrs [[20 -20 20 ... -20 20 20]\n",
            " [20 20 20 ... -20 20 20]\n",
            " [-20 20 20 ... -20 -20 20]\n",
            " ...\n",
            " [-20 -20 -20 ... 20 -20 -20]\n",
            " [-20 20 20 ... -20 -20 20]\n",
            " [-20 -20 20 ... -20 -20 20]] [[368.111694 748.727173 748.477 ... 342.585449 526.121 602.155212]\n",
            " [-341.063416 157.474075 483.204224 ... -48.8144112 89.6292496 320.607208]\n",
            " [-1145.33533 -846.398926 -548.27655 ... -951.894714 -1197.78613 -713.512939]\n",
            " ...\n",
            " [-59.9083824 -390.208466 -621.659729 ... 172.097046 -188.89389 -362.527985]\n",
            " [719.409058 457.086182 545.225525 ... 496.687775 351.316071 748.345032]\n",
            " [-436.956665 -720.226562 75.830246 ... -750.278931 -355.284271 178.82048]]\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "Training epoch 11/10000, LR=5.00e-04, Loss=-1.50272e+02, channel_BER=0.083125, BER=0.303125, duration per call: 0.01s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "llrs [[20 20 -20 ... 20 20 -20]\n",
            " [-20 -20 -20 ... 20 -20 -20]\n",
            " [-20 -20 20 ... 20 -20 20]\n",
            " ...\n",
            " [20 -20 20 ... 20 20 20]\n",
            " [20 20 20 ... 20 20 20]\n",
            " [-20 20 -20 ... -20 -20 -20]] [[-796.442444 -1423.53687 -734.896057 ... -413.734497 -1293.37036 -1249.01025]\n",
            " [-336.647949 -554.116394 -486.270844 ... 81.2763748 -318.848206 -136.411514]\n",
            " [-909.668518 -1049.07605 -344.107544 ... -457.245209 -1078.66711 -460.278046]\n",
            " ...\n",
            " [-361.341766 -1252.97791 -434.365082 ... -1.52438486 -703.737549 -168.351334]\n",
            " [677.677246 888.774292 560.160156 ... 474.473785 788.577942 696.869568]\n",
            " [-526.440247 -756.263489 -558.618652 ... -673.948669 69.9036331 -461.264801]]\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "Training epoch 12/10000, LR=5.00e-04, Loss=-1.54926e+02, channel_BER=0.09375, BER=0.296875, duration per call: 0.01s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "llrs [[-20 20 20 ... 20 -20 20]\n",
            " [20 20 20 ... -20 20 20]\n",
            " [20 20 -20 ... 20 20 -20]\n",
            " ...\n",
            " [20 20 20 ... 20 20 20]\n",
            " [-20 -20 20 ... 20 -20 20]\n",
            " [20 -20 -20 ... 20 20 -20]] [[678.233887 889.000488 560.918823 ... 474.668365 789.33429 696.438232]\n",
            " [-115.023949 402.353149 320.280212 ... 170.213409 346.739227 454.73468]\n",
            " [202.480743 -299.547882 -251.877975 ... 723.398438 -142.869156 -545.854126]\n",
            " ...\n",
            " [279.569763 30.9033012 534.332092 ... -39.0341339 444.431763 446.715424]\n",
            " [-1159.40442 -972.623779 -757.899353 ... -489.219574 -1341.62878 -697.916504]\n",
            " [-181.341064 -484.284973 -626.622437 ... -214.66925 -145.757935 -774.900879]]\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "Training epoch 13/10000, LR=5.00e-04, Loss=-1.47766e+02, channel_BER=0.084375, BER=0.306875, duration per call: 0.01s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "llrs [[20 -20 -20 ... -20 20 -20]\n",
            " [-20 -20 20 ... 20 -20 20]\n",
            " [20 -20 -20 ... -20 20 -20]\n",
            " ...\n",
            " [-20 20 -20 ... 20 -20 -20]\n",
            " [-20 -20 -20 ... -20 -20 -20]\n",
            " [-20 -20 -20 ... -20 -20 -20]] [[306.347321 539.184692 200.37796 ... -63.533493 -114.886612 -93.2128296]\n",
            " [142.525284 -239.861206 386.218231 ... 587.49115 -287.511 673.778198]\n",
            " [-1090.01282 -1428.66626 -901.347473 ... -763.939636 -1267.8855 -1120.74451]\n",
            " ...\n",
            " [-470.947815 -433.04245 -676.168701 ... -259.165771 -836.636536 -841.138]\n",
            " [-1090.02429 -1428.67542 -901.382629 ... -763.976135 -1267.92627 -1120.75757]\n",
            " [-1089.94775 -1428.59802 -901.325684 ... -763.97644 -1267.89099 -1120.70178]]\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "Training epoch 14/10000, LR=5.00e-04, Loss=-1.41180e+02, channel_BER=0.08875, BER=0.3125, duration per call: 0.01s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "llrs [[20 -20 20 ... 20 20 20]\n",
            " [20 20 -20 ... 20 20 -20]\n",
            " [20 -20 20 ... -20 20 20]\n",
            " ...\n",
            " [-20 -20 20 ... 20 -20 20]\n",
            " [-20 20 -20 ... -20 -20 -20]\n",
            " [20 -20 20 ... -20 20 20]] [[-311.877808 -761.29364 19.0125027 ... -106.207214 -353.249054 -53.1377335]\n",
            " [-24.0510521 -542.062805 -81.5546112 ... 512.348755 -393.710297 -675.707947]\n",
            " [681.232605 892.510803 563.191101 ... 477.418945 792.253357 700.264038]\n",
            " ...\n",
            " [-1080.79834 -1334.74512 -595.235107 ... -334.84906 -1018.55304 -609.588501]\n",
            " [-598.114075 -474.282349 -800.955383 ... -599.402222 -395.976532 -425.25647]\n",
            " [-464.127441 -611.36853 -159.268524 ... -842.773315 253.533295 -563.776917]]\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "Training epoch 15/10000, LR=5.00e-04, Loss=-1.52996e+02, channel_BER=0.080625, BER=0.300625, duration per call: 0.02s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "llrs [[20 20 20 ... -20 20 20]\n",
            " [-20 20 20 ... 20 -20 20]\n",
            " [20 20 -20 ... -20 20 -20]\n",
            " ...\n",
            " [-20 20 -20 ... -20 -20 -20]\n",
            " [20 -20 -20 ... 20 20 -20]\n",
            " [20 -20 -20 ... -20 20 -20]] [[-498.709351 139.08255 476.199 ... -307.679016 -140.652786 174.485718]\n",
            " [652.906921 1106.4187 349.318176 ... 436.233 616.85321 492.439453]\n",
            " [527.60083 -426.679657 -579.760254 ... 88.3296661 347.738861 -482.570465]\n",
            " ...\n",
            " [360.342407 224.180664 -299.891174 ... -256.136597 253.21228 -353.945068]\n",
            " [582.30481 723.721497 495.402618 ... 337.216125 715.177063 432.819885]\n",
            " [-417.917694 -869.86908 -245.849686 ... -494.530212 36.8122902 -255.183945]]\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "Training epoch 16/10000, LR=5.00e-04, Loss=-1.39786e+02, channel_BER=0.10125, BER=0.31625, duration per call: 0.02s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "llrs [[-20 -20 -20 ... 20 -20 -20]\n",
            " [-20 20 20 ... -20 -20 20]\n",
            " [20 -20 20 ... -20 20 20]\n",
            " ...\n",
            " [-20 -20 -20 ... 20 -20 -20]\n",
            " [20 -20 20 ... -20 20 20]\n",
            " [-20 -20 -20 ... -20 -20 -20]] [[-1094.55029 -1434.59558 -907.077759 ... -769.324646 -1274.89221 -1126.55896]\n",
            " [-399.548 52.0011 150.969238 ... -387.111084 -856.136353 162.843521]\n",
            " [-309.252899 -933.259216 187.652802 ... -416.182556 126.922821 -134.748306]\n",
            " ...\n",
            " [-384.209381 -686.817322 -723.731812 ... -204.916168 -594.948547 -259.081421]\n",
            " [532.318665 -258.849426 -23.2092438 ... -48.1712494 73.5678864 183.130554]\n",
            " [-1096.38879 -1436.19116 -907.273499 ... -769.733521 -1274.87781 -1127.3551]]\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "Training epoch 17/10000, LR=5.00e-04, Loss=-1.53731e+02, channel_BER=0.106875, BER=0.2975, duration per call: 0.01s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "llrs [[20 20 -20 ... -20 20 -20]\n",
            " [20 -20 20 ... -20 20 20]\n",
            " [-20 20 20 ... -20 -20 20]\n",
            " ...\n",
            " [20 20 20 ... -20 20 20]\n",
            " [-20 -20 20 ... 20 -20 20]\n",
            " [20 20 20 ... -20 20 20]] [[560.169128 306.622498 355.31723 ... 325.607849 1110.80688 348.598541]\n",
            " [-698.629822 -1101.16345 -43.0724602 ... -904.878174 82.4229813 -275.727966]\n",
            " [45.1021614 471.044373 308.938599 ... 243.856155 -485.504822 355.6073]\n",
            " ...\n",
            " [-554.682739 140.610687 125.562157 ... -643.262451 -698.451965 16.7051125]\n",
            " [-995.450623 -613.911 -216.840622 ... -275.931366 -1185.10229 -58.82761]\n",
            " [205.040512 179.007446 474.195496 ... -185.013229 -12.9946985 489.800415]]\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "Training epoch 18/10000, LR=5.00e-04, Loss=-1.52209e+02, channel_BER=0.085, BER=0.3025, duration per call: 0.01s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "llrs [[-20 -20 20 ... 20 -20 20]\n",
            " [-20 -20 20 ... 20 -20 20]\n",
            " [20 -20 -20 ... -20 20 -20]\n",
            " ...\n",
            " [20 20 -20 ... 20 20 -20]\n",
            " [20 -20 20 ... -20 20 20]\n",
            " [-20 20 20 ... -20 -20 20]] [[-925.931335 -480.675659 148.408691 ... 120.240799 -592.474854 160.443619]\n",
            " [-410.000031 -922.15625 -49.0525513 ... -288.422394 -820.266296 -294.967529]\n",
            " [183.243073 -32.6004448 -26.0901222 ... -221.899963 188.353683 -464.295074]\n",
            " ...\n",
            " [-103.876869 -239.7155 -304.902557 ... 207.160828 -225.683487 -851.4599]\n",
            " [685.87738 898.178589 567.820679 ... 481.905975 797.458374 705.340332]\n",
            " [-500.829742 -121.633179 -435.545227 ... -199.823227 -1022.60205 -158.072128]]\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "Training epoch 19/10000, LR=5.00e-04, Loss=-1.64213e+02, channel_BER=0.0775, BER=0.288125, duration per call: 0.01s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "llrs [[20 -20 20 ... -20 20 20]\n",
            " [-20 -20 20 ... -20 -20 20]\n",
            " [-20 -20 20 ... 20 -20 20]\n",
            " ...\n",
            " [20 -20 -20 ... -20 20 -20]\n",
            " [-20 -20 20 ... 20 -20 20]\n",
            " [-20 20 -20 ... 20 -20 -20]] [[-518.713135 -658.835693 -428.891479 ... -754.375305 132.258194 -375.150696]\n",
            " [-412.3703 156.544815 221.169083 ... -618.906311 96.3560486 -17.1338978]\n",
            " [-349.248383 122.159119 464.648468 ... -610.256042 -116.527473 757.97168]\n",
            " ...\n",
            " [-226.143112 -995.385193 -289.566895 ... -634.996094 26.3763542 -400.069763]\n",
            " [-533.550293 -555.15979 -428.201019 ... -223.144943 -1174.54077 -347.127777]\n",
            " [-780.800964 -1135.72034 -643.411743 ... -642.967102 -1116.42249 -835.398315]]\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "Training epoch 20/10000, LR=5.00e-04, Loss=-1.77859e+02, channel_BER=0.099375, BER=0.2675, duration per call: 0.01s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "llrs [[20 -20 -20 ... 20 20 -20]\n",
            " [-20 20 20 ... -20 -20 20]\n",
            " [20 20 20 ... 20 20 20]\n",
            " ...\n",
            " [-20 -20 -20 ... 20 -20 -20]\n",
            " [20 -20 -20 ... -20 20 -20]\n",
            " [20 -20 -20 ... 20 20 -20]] [[152.096909 56.8150749 -327.778534 ... 797.729187 -306.411713 -76.4847565]\n",
            " [-825.127441 530.780212 530.101807 ... -471.97879 -525.649231 213.109695]\n",
            " [758.953 441.707458 424.934631 ... 206.651901 875.533325 281.434296]\n",
            " ...\n",
            " [632.934204 -311.268951 -592.044189 ... 478.697479 -194.570816 -13.2609949]\n",
            " [-496.802795 -507.580444 -149.174362 ... -278.327148 -719.183716 -1141.03528]\n",
            " [325.811035 -162.790131 -125.264084 ... 407.586121 489.107239 -268.759399]]\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "Training epoch 21/10000, LR=5.00e-04, Loss=-1.67967e+02, channel_BER=0.0925, BER=0.28125, duration per call: 0.02s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "llrs [[20 -20 20 ... 20 20 20]\n",
            " [20 20 -20 ... 20 20 -20]\n",
            " [20 -20 20 ... 20 20 20]\n",
            " ...\n",
            " [20 20 -20 ... -20 20 -20]\n",
            " [-20 20 20 ... -20 -20 20]\n",
            " [-20 20 -20 ... -20 -20 -20]] [[-39.8507843 -397.426849 80.4316254 ... 394.595978 170.436737 198.172867]\n",
            " [-1105.8 -1446.35364 -913.096619 ... -773.504456 -1281.47095 -1135.95447]\n",
            " [-1092.28821 -708.337646 -87.432991 ... -559.750183 -819.946228 -374.263855]\n",
            " ...\n",
            " [5.21766186 -192.141098 -790.819275 ... -628.769165 -546.928772 -730.229]\n",
            " [-628.826111 -713.257751 -133.358856 ... -689.510254 -630.21 -465.807922]\n",
            " [-454.616211 -472.378265 -809.058044 ... -320.274963 -175.346176 -292.638397]]\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "Training epoch 22/10000, LR=5.00e-04, Loss=-1.53259e+02, channel_BER=0.0925, BER=0.3, duration per call: 0.02s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "llrs [[20 20 -20 ... 20 20 -20]\n",
            " [-20 20 -20 ... 20 -20 -20]\n",
            " [-20 -20 20 ... -20 -20 20]\n",
            " ...\n",
            " [-20 20 -20 ... -20 -20 -20]\n",
            " [20 -20 20 ... -20 20 20]\n",
            " [20 -20 -20 ... 20 20 -20]] [[192.179306 413.362976 -186.196686 ... 1154.58472 108.920013 -75.0919418]\n",
            " [-9.25372505 564.373474 -467.149353 ... 270.353119 -534.004517 -25.6982021]\n",
            " [-1210.95837 -1366.72656 -494.565552 ... -578.517578 -970.337708 -677.354858]\n",
            " ...\n",
            " [10.9883184 119.77832 -581.672058 ... -205.457718 -161.73941 -343.24054]\n",
            " [85.3015747 -427.640472 90.059761 ... -93.4728928 545.257568 -272.423737]\n",
            " [-111.751175 -799.31189 -1048.91968 ... 29.3403378 -642.119873 -1314.16345]]\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "Training epoch 23/10000, LR=5.00e-04, Loss=-1.59203e+02, channel_BER=0.09875, BER=0.293125, duration per call: 0.02s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "llrs [[-20 20 -20 ... 20 -20 -20]\n",
            " [-20 -20 -20 ... -20 -20 -20]\n",
            " [20 20 -20 ... 20 20 -20]\n",
            " ...\n",
            " [-20 20 20 ... 20 -20 20]\n",
            " [20 -20 20 ... 20 20 20]\n",
            " [20 -20 20 ... -20 20 20]] [[-1110.58228 -1453.30273 -920.597778 ... -782.039673 -1290.61414 -1142.14209]\n",
            " [-1110.76611 -1453.53235 -920.657837 ... -782.100464 -1290.5741 -1142.29883]\n",
            " [-445.216125 -874.907104 -370.471436 ... 218.310425 -711.729126 -1080.69702]\n",
            " ...\n",
            " [461.098572 661.414368 748.328674 ... 271.47052 550.095154 582.984802]\n",
            " [573.789246 294.564209 80.2216263 ... 396.073 194.708374 69.7272949]\n",
            " [691.633057 905.203796 573.247559 ... 486.815247 803.782 711.323181]]\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "Training epoch 24/10000, LR=5.00e-04, Loss=-1.53625e+02, channel_BER=0.08, BER=0.29625, duration per call: 0.02s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "llrs [[-20 20 -20 ... -20 -20 -20]\n",
            " [20 -20 -20 ... 20 20 -20]\n",
            " [20 20 20 ... 20 20 20]\n",
            " ...\n",
            " [20 -20 -20 ... 20 20 -20]\n",
            " [-20 20 20 ... 20 -20 20]\n",
            " [-20 20 20 ... -20 -20 20]] [[-106.061455 224.343658 -369.761383 ... -186.996429 -131.991089 -380.59137]\n",
            " [144.988892 -578.497925 -716.829834 ... -384.472015 105.578362 -497.060944]\n",
            " [-139.937485 -877.125061 -14.7383804 ... 419.219849 22.7464409 -239.777344]\n",
            " ...\n",
            " [821.293213 612.254883 377.370972 ... 293.596222 626.044312 455.306213]\n",
            " [-62.9578667 316.378113 -131.896606 ... -384.047729 358.256348 163.784271]\n",
            " [-229.675919 255.452927 268.967682 ... -402.679718 -464.326904 691.211609]]\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "Training epoch 25/10000, LR=5.00e-04, Loss=-1.53303e+02, channel_BER=0.086875, BER=0.300625, duration per call: 0.01s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "llrs [[20 20 -20 ... -20 20 -20]\n",
            " [-20 -20 20 ... 20 -20 20]\n",
            " [20 20 -20 ... -20 20 -20]\n",
            " ...\n",
            " [-20 20 -20 ... -20 -20 -20]\n",
            " [20 20 20 ... -20 20 20]\n",
            " [-20 -20 20 ... 20 -20 20]] [[222.575851 -573.727661 -397.283539 ... -46.8649445 89.2659225 -584.689]\n",
            " [-1301.62598 -928.70105 -358.374 ... -302.178253 -1039.02283 -262.595154]\n",
            " [-1.5849328 -205.37236 -569.640503 ... 127.171417 -47.177166 -689.461365]\n",
            " ...\n",
            " [-506.587494 -133.603928 -616.258362 ... 48.3985977 -797.077393 -570.507263]\n",
            " [8.14217472 -73.8949814 614.217285 ... -40.7953072 305.554962 57.1937485]\n",
            " [-981.329346 -861.021912 -580.143066 ... -516.24054 -1285.33142 -691.681152]]\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "Training epoch 26/10000, LR=5.00e-04, Loss=-1.39813e+02, channel_BER=0.099375, BER=0.3175, duration per call: 0.01s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "llrs [[20 20 20 ... -20 20 20]\n",
            " [-20 -20 20 ... 20 -20 20]\n",
            " [20 20 -20 ... -20 20 -20]\n",
            " ...\n",
            " [-20 -20 -20 ... -20 -20 -20]\n",
            " [-20 20 20 ... -20 -20 20]\n",
            " [-20 -20 20 ... -20 -20 20]] [[-230.786697 -457.667511 -201.983414 ... 238.894165 -590.665771 143.813538]\n",
            " [-931.347229 -1082.4707 -351.259888 ... -471.701874 -1101.54211 -468.42514]\n",
            " [-342.124847 27.4939 -394.410797 ... -614.032776 482.063904 -470.849609]\n",
            " ...\n",
            " [-1130.672 -723.201782 -224.511108 ... -676.709473 -1155.19092 -478.873718]\n",
            " [-862.939453 -567.0672 -312.43634 ... -943.920776 -1092.14563 -459.166016]\n",
            " [-616.570679 -78.6444 379.017914 ... -1031.45264 -443.064392 335.136505]]\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "Training epoch 27/10000, LR=5.00e-04, Loss=-1.45131e+02, channel_BER=0.101875, BER=0.30875, duration per call: 0.02s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "llrs [[20 -20 20 ... 20 20 20]\n",
            " [20 -20 20 ... -20 20 20]\n",
            " [-20 20 -20 ... 20 -20 -20]\n",
            " ...\n",
            " [20 20 20 ... -20 20 20]\n",
            " [20 -20 -20 ... 20 20 -20]\n",
            " [20 20 20 ... -20 20 20]] [[27.0269642 -337.75116 398.755615 ... 204.87384 -243.472916 277.245]\n",
            " [510.16 183.153336 9.50431919 ... 20.6313896 552.611145 155.533981]\n",
            " [-1118.50085 -1463.25085 -927.915283 ... -789.237793 -1299.29578 -1150.15613]\n",
            " ...\n",
            " [638.000305 1130.90796 347.554688 ... 401.758484 583.611267 470.331116]\n",
            " [402.032318 -287.528137 -104.049614 ... 40.6549149 816.124817 -181.186859]\n",
            " [207.928101 -739.65564 -189.038361 ... -390.833832 -356.897 5.35957384]]\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "Training epoch 28/10000, LR=5.00e-04, Loss=-1.39568e+02, channel_BER=0.09875, BER=0.31625, duration per call: 0.01s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "llrs [[20 20 -20 ... 20 20 -20]\n",
            " [20 -20 -20 ... 20 20 -20]\n",
            " [-20 20 20 ... -20 -20 20]\n",
            " ...\n",
            " [20 -20 -20 ... -20 20 -20]\n",
            " [-20 20 20 ... -20 -20 20]\n",
            " [-20 20 20 ... 20 -20 20]] [[233.334839 344.604034 90.9126 ... 487.666687 -136.422943 -260.223663]\n",
            " [-170.218872 -323.198212 -552.66394 ... -502.271454 3.52547503 -429.670563]\n",
            " [-972.95 208.564346 214.483063 ... -925.569885 -900.772583 -196.803848]\n",
            " ...\n",
            " [-1249.77344 -1175.69482 -256.458221 ... -1319.35364 -720.403625 -887.277832]\n",
            " [-561.678101 -65.1096344 -153.66629 ... 77.2988129 -983.009033 179.10527]\n",
            " [697.585815 912.670166 578.64856 ... 492.484344 810.11615 717.355713]]\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "Training epoch 29/10000, LR=5.00e-04, Loss=-1.56644e+02, channel_BER=0.10125, BER=0.295625, duration per call: 0.02s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "llrs [[-20 20 -20 ... 20 -20 -20]\n",
            " [-20 -20 -20 ... 20 -20 -20]\n",
            " [20 -20 20 ... -20 20 20]\n",
            " ...\n",
            " [-20 20 -20 ... -20 -20 -20]\n",
            " [20 -20 20 ... -20 20 20]\n",
            " [-20 -20 -20 ... 20 -20 -20]] [[-463.27298 754.119446 -138.928146 ... -327.667206 41.3276978 -161.753601]\n",
            " [-1199.61658 -1269.39282 -277.293091 ... -298.787231 -699.36377 -578.130859]\n",
            " [292.026581 -266.218292 -281.299 ... -583.860291 689.526062 -136.63118]\n",
            " ...\n",
            " [-808.805664 -1159.25684 -790.068542 ... -737.490356 -1437.0437 -932.774]\n",
            " [537.131104 887.03186 558.057739 ... 221.998352 566.979553 559.3255]\n",
            " [90.4077225 -302.32724 -274.512 ... 528.798218 -204.241104 -541.417053]]\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "Training epoch 30/10000, LR=5.00e-04, Loss=-1.68967e+02, channel_BER=0.089375, BER=0.27875, duration per call: 0.02s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "llrs [[-20 -20 -20 ... -20 -20 -20]\n",
            " [20 -20 20 ... 20 20 20]\n",
            " [20 -20 -20 ... -20 20 -20]\n",
            " ...\n",
            " [-20 20 -20 ... 20 -20 -20]\n",
            " [-20 20 20 ... -20 -20 20]\n",
            " [-20 -20 20 ... -20 -20 20]] [[-1124.63391 -1471.06616 -933.690796 ... -794.899231 -1305.73962 -1156.66736]\n",
            " [218.542297 497.549774 702.378174 ... 243.009323 381.053 896.803345]\n",
            " [-881.657959 -457.888519 -558.428528 ... -1038.26575 -463.275909 -1222.62415]\n",
            " ...\n",
            " [-136.022598 -1064.39294 -1112.87537 ... 168.429092 -581.675476 -909.82135]\n",
            " [-476.992096 -102.348755 -94.0951 ... -693.044373 -1141.25146 26.5440216]\n",
            " [-477.131195 -549.312378 -154.490921 ... -1180.58582 -207.167526 -37.237545]]\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "Training epoch 31/10000, LR=5.00e-04, Loss=-1.40830e+02, channel_BER=0.09375, BER=0.314375, duration per call: 0.02s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "llrs [[20 20 20 ... 20 20 20]\n",
            " [20 20 -20 ... 20 20 -20]\n",
            " [20 20 -20 ... 20 20 -20]\n",
            " ...\n",
            " [20 20 -20 ... -20 20 -20]\n",
            " [-20 20 -20 ... -20 -20 -20]\n",
            " [20 -20 20 ... 20 20 20]] [[58.8601265 -273.760956 -29.4526672 ... 241.919586 -78.8930206 641.311523]\n",
            " [166.266357 -437.54837 -505.668671 ... 445.037415 -418.328949 -688.604797]\n",
            " [116.117149 -265.944733 19.4209404 ... 274.008545 -803.319275 -645.702942]\n",
            " ...\n",
            " [166.365128 -438.581635 -508.028961 ... 444.674469 -418.032318 -689.924133]\n",
            " [5.5235157 120.152306 -593.452576 ... -210.437714 -168.83934 -353.088]\n",
            " [-24.161438 -553.492798 -89.1688 ... 517.9151 -400.320862 -692.562866]]\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "Training epoch 32/10000, LR=5.00e-04, Loss=-1.48002e+02, channel_BER=0.104375, BER=0.3075, duration per call: 0.02s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "llrs [[-20 -20 -20 ... -20 -20 -20]\n",
            " [-20 -20 -20 ... 20 -20 -20]\n",
            " [20 -20 -20 ... 20 20 -20]\n",
            " ...\n",
            " [-20 -20 -20 ... -20 -20 -20]\n",
            " [20 -20 20 ... 20 20 20]\n",
            " [20 20 20 ... -20 20 20]] [[-1129.02124 -1476.42334 -937.262451 ... -798.883728 -1310.53943 -1160.97681]\n",
            " [-473.371033 -684.459839 -496.720764 ... -317.670227 -711.679199 -673.953796]\n",
            " [600.798218 -360.912415 -321.013031 ... 654.775757 299.366974 -92.2841873]\n",
            " ...\n",
            " [-1128.84497 -1476.18604 -937.220154 ... -798.78186 -1310.43127 -1161.12158]\n",
            " [425.013184 588.611145 276.353424 ... 560.981506 343.07019 305.782562]\n",
            " [-981.595154 -64.8966827 204.612518 ... -664.145874 -517.434 -221.917114]]\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "Training epoch 33/10000, LR=5.00e-04, Loss=-1.55876e+02, channel_BER=0.079375, BER=0.29625, duration per call: 0.01s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "llrs [[-20 -20 20 ... -20 -20 20]\n",
            " [20 20 20 ... 20 20 20]\n",
            " [20 20 -20 ... 20 20 -20]\n",
            " ...\n",
            " [-20 -20 20 ... 20 -20 20]\n",
            " [20 -20 -20 ... 20 20 -20]\n",
            " [20 -20 20 ... -20 20 20]] [[30.686533 570.657 358.713867 ... -287.767517 385.493042 933.449036]\n",
            " [703.279053 919.57782 583.807068 ... 497.809174 816.338318 723.054443]\n",
            " [35.6390381 -14.6685791 -189.460052 ... 875.394043 -301.123657 -407.488586]\n",
            " ...\n",
            " [-1302.84741 -1183.24414 -859.262878 ... -661.047485 -1468.5896 -1000.01471]\n",
            " [528.993591 -321.279053 -295.008026 ... 270.873077 534.142578 -188.237534]\n",
            " [656.901794 786.490906 344.97229 ... 204.329544 538.237427 597.610474]]\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "Training epoch 34/10000, LR=5.00e-04, Loss=-1.41740e+02, channel_BER=0.094375, BER=0.313125, duration per call: 0.02s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "llrs [[-20 -20 20 ... -20 -20 20]\n",
            " [-20 -20 20 ... -20 -20 20]\n",
            " [-20 20 -20 ... -20 -20 -20]\n",
            " ...\n",
            " [20 -20 -20 ... 20 20 -20]\n",
            " [-20 -20 -20 ... -20 -20 -20]\n",
            " [-20 20 -20 ... -20 -20 -20]] [[-158.282684 371.352631 500.314301 ... -464.740204 178.055725 834.794312]\n",
            " [-638.97821 -253.066132 -88.1176 ... -1042.0896 -353.69635 126.887329]\n",
            " [-274.465179 249.468536 -473.348145 ... -596.022461 -37.3351326 193.14743]\n",
            " ...\n",
            " [-276.174469 -396.056976 -305.170349 ... -91.5011444 209.946564 -743.745544]\n",
            " [-1012.39563 -946.714233 -406.963318 ... -1108.94727 -438.226807 -756.142273]\n",
            " [-228.028564 -77.7017136 -667.420898 ... 146.868439 -366.423553 -647.746765]]\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "Training epoch 35/10000, LR=5.00e-04, Loss=-1.42322e+02, channel_BER=0.099375, BER=0.31, duration per call: 0.01s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "llrs [[20 -20 20 ... -20 20 20]\n",
            " [-20 20 20 ... -20 -20 20]\n",
            " [-20 -20 -20 ... -20 -20 -20]\n",
            " ...\n",
            " [20 20 20 ... -20 20 20]\n",
            " [-20 -20 -20 ... -20 -20 -20]\n",
            " [20 -20 -20 ... 20 20 -20]] [[705.571 922.310608 585.829041 ... 499.839813 818.791748 725.350098]\n",
            " [-302.481079 -59.3032417 -65.7144775 ... -424.646729 -914.806152 198.037369]\n",
            " [-1135.44507 -1484.21069 -942.846558 ... -804.569763 -1317.55676 -1167.26477]\n",
            " ...\n",
            " [34.6888885 146.340576 157.700333 ... 25.9065933 227.366089 256.496368]\n",
            " [-1135.45178 -1484.20935 -942.837952 ... -804.566406 -1317.54932 -1167.24963]\n",
            " [150.798401 -200.108032 240.760269 ... 29.9709702 -356.159546 -113.875908]]\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "Training epoch 36/10000, LR=5.00e-04, Loss=-1.51765e+02, channel_BER=0.090625, BER=0.300625, duration per call: 0.01s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "llrs [[-20 20 -20 ... -20 -20 -20]\n",
            " [20 20 20 ... -20 20 20]\n",
            " [20 -20 -20 ... 20 20 -20]\n",
            " ...\n",
            " [-20 -20 -20 ... 20 -20 -20]\n",
            " [20 -20 -20 ... 20 20 -20]\n",
            " [20 20 20 ... -20 20 20]] [[-1137.60852 -1486.82617 -944.809875 ... -806.433899 -1319.92615 -1169.42676]\n",
            " [-394.38443 -22.1985817 79.0418625 ... -1097.37976 -665.315491 201.572189]\n",
            " [-270.432739 -797.984924 -658.196716 ... -396.027649 301.838745 -753.201782]\n",
            " ...\n",
            " [-653.246216 -1065.9115 -1069.46521 ... -551.906738 -885.472778 -1347.94421]\n",
            " [204.975281 -601.253723 7.08536386 ... 233.279984 421.483704 -504.937134]\n",
            " [-345.846771 168.570404 518.070129 ... -46.4482803 103.104034 348.202]]\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "Training epoch 37/10000, LR=5.00e-04, Loss=-1.59812e+02, channel_BER=0.086875, BER=0.29, duration per call: 0.02s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "llrs [[-20 20 -20 ... 20 -20 -20]\n",
            " [-20 20 -20 ... 20 -20 -20]\n",
            " [-20 20 20 ... 20 -20 20]\n",
            " ...\n",
            " [-20 20 -20 ... 20 -20 -20]\n",
            " [-20 -20 20 ... 20 -20 20]\n",
            " [-20 -20 -20 ... 20 -20 -20]] [[-347.991608 258.531281 -759.711548 ... 138.355545 -724.509705 -340.720856]\n",
            " [-314.322632 263.724213 -624.713257 ... 251.488861 -386.379364 -241.370377]\n",
            " [707.654602 924.752747 587.792114 ... 501.737701 821.142761 727.534302]\n",
            " ...\n",
            " [-1084.78101 -1431.93079 -920.177124 ... -803.528809 -1352.11292 -1133.17236]\n",
            " [-723.667419 -279.680115 -47.4102058 ... 313.720612 -1170.15381 -289.910095]\n",
            " [-384.375641 -1045.74548 -1020.67761 ... -284.658 -438.664978 -999.463928]]\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "Training epoch 38/10000, LR=5.00e-04, Loss=-1.39726e+02, channel_BER=0.095625, BER=0.31625, duration per call: 0.01s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "llrs [[-20 -20 -20 ... 20 -20 -20]\n",
            " [20 -20 20 ... 20 20 20]\n",
            " [20 20 20 ... 20 20 20]\n",
            " ...\n",
            " [-20 -20 -20 ... 20 -20 -20]\n",
            " [-20 20 20 ... 20 -20 20]\n",
            " [-20 20 20 ... 20 -20 20]] [[-385.013794 -188.84523 -326.961792 ... 243.064056 -546.162415 -83.0701675]\n",
            " [-13.5324402 252.798187 893.487122 ... 26.1760349 126.985542 781.774902]\n",
            " [709.052917 926.469055 588.853943 ... 503.13678 822.548279 728.68927]\n",
            " ...\n",
            " [-196.99202 -306.316833 -442.561 ... 195.645447 -180.592056 -430.126343]\n",
            " [709.069031 926.57312 589.023499 ... 503.086395 822.62439 728.902954]\n",
            " [-74.259 172.486984 -148.943558 ... 846.043945 -487.10318 -308.670074]]\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "Training epoch 39/10000, LR=5.00e-04, Loss=-1.39079e+02, channel_BER=0.08, BER=0.318125, duration per call: 0.02s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "llrs [[-20 -20 20 ... -20 -20 20]\n",
            " [-20 20 20 ... -20 -20 20]\n",
            " [-20 20 -20 ... 20 -20 -20]\n",
            " ...\n",
            " [20 -20 20 ... 20 20 20]\n",
            " [20 -20 -20 ... 20 20 -20]\n",
            " [20 20 20 ... 20 20 20]] [[-1144.33826 -818.397888 -301.633606 ... -439.162445 -1318.18347 -344.771027]\n",
            " [-725.607178 31.5155849 -23.452795 ... -812.225403 -484.314087 251.9758]\n",
            " [-1143.78296 -1494.38928 -950.528137 ... -812.147461 -1327.07544 -1175.82776]\n",
            " ...\n",
            " [-331.981689 -525.614868 420.494904 ... 266.742096 152.402 229.330353]\n",
            " [192.136948 -774.398254 -470.178253 ... 235.050842 520.463196 -722.934937]\n",
            " [545.235901 899.082397 566.575317 ... 227.682922 574.994629 567.473389]]\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "Training epoch 40/10000, LR=5.00e-04, Loss=-1.58809e+02, channel_BER=0.075, BER=0.2925, duration per call: 0.02s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "llrs [[-20 -20 -20 ... 20 -20 -20]\n",
            " [20 -20 20 ... 20 20 20]\n",
            " [-20 20 20 ... 20 -20 20]\n",
            " ...\n",
            " [20 -20 20 ... -20 20 20]\n",
            " [-20 -20 -20 ... 20 -20 -20]\n",
            " [20 20 -20 ... -20 20 -20]] [[-827.983398 -1348.91602 -1152.25439 ... -673.652832 -1059.48096 -1085.57983]\n",
            " [20.1646919 -413.370789 523.594055 ... -463.087708 221.306519 -248.32338]\n",
            " [-330.042877 -513.562683 -170.621246 ... 275.509796 -745.865 -103.700745]\n",
            " ...\n",
            " [711.34729 929.259338 591.156372 ... 505.163239 825.117188 731.200928]\n",
            " [-282.141754 -214.37352 -918.321045 ... -149.34375 -654.074341 -785.514771]\n",
            " [238.113052 662.8255 6.41202259 ... 169.705658 378.190887 -81.4166107]]\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "Training epoch 41/10000, LR=5.00e-04, Loss=-1.47000e+02, channel_BER=0.105, BER=0.306875, duration per call: 0.02s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "llrs [[20 20 -20 ... 20 20 -20]\n",
            " [-20 -20 20 ... -20 -20 20]\n",
            " [-20 -20 20 ... -20 -20 20]\n",
            " ...\n",
            " [-20 20 -20 ... 20 -20 -20]\n",
            " [20 20 -20 ... -20 20 -20]\n",
            " [-20 -20 -20 ... 20 -20 -20]] [[550.957458 -395.052277 -346.266602 ... 575.587097 120.539124 -272.808807]\n",
            " [-884.745 -1383.41589 -356.055939 ... -476.514923 -449.646881 -285.359497]\n",
            " [140.791611 723.60614 324.291016 ... -277.403442 523.202 417.345825]\n",
            " ...\n",
            " [-694.080872 -1186.65173 -468.577301 ... -12.2354755 -996.075867 -900.735962]\n",
            " [1012.05292 564.274658 86.8469238 ... 156.463989 652.594543 109.309464]\n",
            " [-543.448 -764.529846 -836.451355 ... -130.048218 -301.333862 -774.684937]]\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "Training epoch 42/10000, LR=5.00e-04, Loss=-1.52820e+02, channel_BER=0.08625, BER=0.300625, duration per call: 0.02s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "llrs [[-20 -20 -20 ... 20 -20 -20]\n",
            " [-20 20 20 ... 20 -20 20]\n",
            " [-20 -20 -20 ... -20 -20 -20]\n",
            " ...\n",
            " [20 -20 -20 ... -20 20 -20]\n",
            " [-20 -20 -20 ... -20 -20 -20]\n",
            " [20 -20 -20 ... 20 20 -20]] [[260.820343 -280.224976 -256.464813 ... 826.683105 34.9141693 -398.124207]\n",
            " [-198.115311 -63.0650902 -251.076691 ... -287.358 -219.488129 374.001434]\n",
            " [-1150.35681 -1501.97424 -956.438965 ... -817.738708 -1333.85583 -1182.51624]\n",
            " ...\n",
            " [-421.704376 -202.746368 7.78758526 ... -725.127136 -26.87257 -436.657471]\n",
            " [-1150.35706 -1501.97644 -956.439636 ... -817.73468 -1333.85486 -1182.51428]\n",
            " [713.336426 931.537903 593.075378 ... 506.847565 827.11969 733.072571]]\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "Training epoch 43/10000, LR=5.00e-04, Loss=-1.50832e+02, channel_BER=0.095625, BER=0.30375, duration per call: 0.01s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "llrs [[-20 20 -20 ... 20 -20 -20]\n",
            " [-20 20 -20 ... -20 -20 -20]\n",
            " [-20 -20 20 ... 20 -20 20]\n",
            " ...\n",
            " [-20 -20 -20 ... -20 -20 -20]\n",
            " [-20 -20 -20 ... 20 -20 -20]\n",
            " [-20 -20 20 ... -20 -20 20]] [[-1152.42651 -1504.34839 -958.324097 ... -819.586548 -1336.11853 -1184.62427]\n",
            " [-981.512634 -1226.72595 -887.28 ... -700.843506 -1166.70129 -1456.05762]\n",
            " [-612.727661 -1777.2196 -786.984863 ... -662.796204 -639.118896 -503.398834]\n",
            " ...\n",
            " [-1152.40479 -1504.28125 -958.202698 ... -819.441345 -1335.98181 -1184.56726]\n",
            " [-131.552734 -760.385315 -1171.0874 ... -152.818939 -722.286316 -593.212952]\n",
            " [-116.695656 183.760651 385.739197 ... -429.305817 259.185394 692.048462]]\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "Training epoch 44/10000, LR=5.00e-04, Loss=-1.42470e+02, channel_BER=0.09875, BER=0.31125, duration per call: 0.02s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "llrs [[20 -20 20 ... -20 20 20]\n",
            " [-20 20 -20 ... -20 -20 -20]\n",
            " [-20 20 -20 ... -20 -20 -20]\n",
            " ...\n",
            " [-20 -20 -20 ... 20 -20 -20]\n",
            " [-20 -20 20 ... -20 -20 20]\n",
            " [-20 20 -20 ... 20 -20 -20]] [[436.939301 -120.366196 373.222382 ... 40.2154961 742.654602 32.9538536]\n",
            " [39.3091545 -279.094238 -828.034912 ... -409.00058 253.80336 -274.617371]\n",
            " [-169.938232 90.0830536 -636.295593 ... -496.368225 -431.639893 -532.715759]\n",
            " ...\n",
            " [-835.761841 -1356.65308 -1159.44678 ... -680.603 -1069.6145 -1093.78223]\n",
            " [199.867447 0.90360564 32.6451111 ... -187.145126 -338.794434 187.084183]\n",
            " [-1154.57288 -1506.81421 -960.233887 ... -821.435425 -1338.46472 -1186.79541]]\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "Training epoch 45/10000, LR=5.00e-04, Loss=-1.52050e+02, channel_BER=0.098125, BER=0.299375, duration per call: 0.02s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "llrs [[20 20 -20 ... 20 20 -20]\n",
            " [20 -20 -20 ... 20 20 -20]\n",
            " [20 20 -20 ... -20 20 -20]\n",
            " ...\n",
            " [20 -20 -20 ... 20 20 -20]\n",
            " [-20 -20 -20 ... -20 -20 -20]\n",
            " [20 20 20 ... 20 20 20]] [[164.028366 -448.409485 -519.990234 ... 446.605103 -428.409515 -708.896423]\n",
            " [-290.00528 -959.589355 -299.740936 ... -182.557678 4.76028872 -985.827576]\n",
            " [498.954254 -576.455872 -858.122192 ... -214.734116 79.8499756 -642.687317]\n",
            " ...\n",
            " [103.226624 -298.889252 -153.294418 ... 176.955261 165.047348 112.715912]\n",
            " [-1156.70984 -1509.2196 -962.113 ... -823.266846 -1340.79626 -1188.88416]\n",
            " [717.1922 935.79425 596.408325 ... 510.49649 831.402344 737.077148]]\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "Training epoch 46/10000, LR=5.00e-04, Loss=-1.34871e+02, channel_BER=0.106875, BER=0.321875, duration per call: 0.01s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "llrs [[-20 20 20 ... -20 -20 20]\n",
            " [-20 20 -20 ... -20 -20 -20]\n",
            " [20 -20 -20 ... 20 20 -20]\n",
            " ...\n",
            " [20 -20 -20 ... -20 20 -20]\n",
            " [-20 20 -20 ... -20 -20 -20]\n",
            " [20 -20 20 ... -20 20 20]] [[-480.934479 224.987488 712.729797 ... -612.141846 -92.0570374 758.340454]\n",
            " [-53.083107 339.255 -270.538727 ... -609.130066 317.431519 -282.932587]\n",
            " [718.410522 936.959229 597.387268 ... 511.255066 832.57605 738.101929]\n",
            " ...\n",
            " [-708.533508 -680.258 -156.922989 ... -983.34491 -293.681519 -458.01944]\n",
            " [-811.11676 -1078.22 -969.427124 ... -266.588745 -699.127747 -728.830505]\n",
            " [718.383057 937.102173 597.485 ... 511.387756 832.712891 738.249573]]\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "Training epoch 47/10000, LR=5.00e-04, Loss=-1.46643e+02, channel_BER=0.080625, BER=0.306875, duration per call: 0.01s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "llrs [[-20 20 20 ... 20 -20 20]\n",
            " [20 20 20 ... -20 20 20]\n",
            " [20 -20 -20 ... -20 20 -20]\n",
            " ...\n",
            " [20 20 -20 ... 20 20 -20]\n",
            " [20 20 20 ... 20 20 20]\n",
            " [-20 20 20 ... 20 -20 20]] [[393.317047 163.496231 -483.092438 ... 760.723816 -51.8215714 -162.317307]\n",
            " [-465.49823 -994.783508 -401.516083 ... -382.126648 -806.70929 -611.229492]\n",
            " [-1226.68433 -1272.11194 -463.195465 ... -901.670105 -783.39856 -1418.92065]\n",
            " ...\n",
            " [372.64 1015.01453 655.643616 ... 659.374634 546.455811 424.029541]\n",
            " [719.545837 938.349426 598.452393 ... 512.359375 833.967224 739.327332]\n",
            " [683.262451 1168.97742 365.083038 ... 462.409729 641.568359 512.427185]]\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "Training epoch 48/10000, LR=5.00e-04, Loss=-1.36122e+02, channel_BER=0.100625, BER=0.31875, duration per call: 0.02s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "llrs [[20 -20 20 ... -20 20 20]\n",
            " [20 20 20 ... 20 20 20]\n",
            " [-20 20 20 ... 20 -20 20]\n",
            " ...\n",
            " [20 20 -20 ... -20 20 -20]\n",
            " [-20 -20 20 ... 20 -20 20]\n",
            " [-20 20 20 ... -20 -20 20]] [[1058.3783 342.270538 318.059418 ... 207.906235 850.479675 334.276245]\n",
            " [720.798584 939.689758 599.465332 ... 513.374 835.304504 740.45166]\n",
            " [715.057861 938.583557 598.566162 ... 503.771057 826.645813 734.762085]\n",
            " ...\n",
            " [41.1644325 -73.1901169 -599.317871 ... -365.526855 -290.809784 -646.13562]\n",
            " [-1163.33887 -1516.65808 -967.681274 ... -828.585 -1347.99316 -1195.11926]\n",
            " [-756.924072 -101.467247 -182.224548 ... -205.743927 -1271.6792 16.3139248]]\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "Training epoch 49/10000, LR=5.00e-04, Loss=-1.49635e+02, channel_BER=0.09625, BER=0.3025, duration per call: 0.02s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "llrs [[-20 -20 20 ... 20 -20 20]\n",
            " [20 -20 -20 ... -20 20 -20]\n",
            " [-20 20 20 ... 20 -20 20]\n",
            " ...\n",
            " [-20 20 -20 ... -20 -20 -20]\n",
            " [-20 -20 20 ... 20 -20 20]\n",
            " [20 20 20 ... -20 20 20]] [[-1067.57397 -632.294067 -262.009613 ... -302.890472 -1276.66162 -100.066589]\n",
            " [-1165.62659 -1519.22522 -969.51355 ... -830.475159 -1350.46985 -1197.25623]\n",
            " [702.983887 154.898163 39.4794159 ... 981.544067 232.911057 940.441162]\n",
            " ...\n",
            " [-13.9514408 -207.593918 -843.863953 ... -663.732 -581.705505 -781.997498]\n",
            " [-324.058472 -220.922852 -586.489 ... 358.109 -467.908112 315.560577]\n",
            " [-178.684158 -458.091522 224.932083 ... -637.162903 -131.677078 -212.658279]]\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "Training epoch 50/10000, LR=5.00e-04, Loss=-1.58452e+02, channel_BER=0.08375, BER=0.29125, duration per call: 0.01s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "llrs [[20 -20 20 ... -20 20 20]\n",
            " [-20 -20 20 ... 20 -20 20]\n",
            " [-20 -20 -20 ... 20 -20 -20]\n",
            " ...\n",
            " [20 20 20 ... 20 20 20]\n",
            " [20 20 -20 ... -20 20 -20]\n",
            " [20 -20 -20 ... 20 20 -20]] [[723.147766 942.369 601.44696 ... 515.351929 837.889404 742.691895]\n",
            " [-673.203613 -197.009949 298.606781 ... 144.972839 -796.016 375.78183]\n",
            " [-361.052856 -223.122269 -478.76947 ... -65.2497635 -21.3612957 -591.024048]\n",
            " ...\n",
            " [723.277771 942.500061 601.574 ... 515.449768 837.994385 742.809509]\n",
            " [-904.662903 -138.900711 -179.037628 ... -893.284 -333.120026 -434.837372]\n",
            " [92.6356888 288.867279 39.7288132 ... -409.803375 598.847107 225.890106]]\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "Training epoch 51/10000, LR=5.00e-04, Loss=-1.47105e+02, channel_BER=0.08875, BER=0.306875, duration per call: 0.02s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "llrs [[20 -20 -20 ... -20 20 -20]\n",
            " [20 -20 20 ... -20 20 20]\n",
            " [-20 20 -20 ... 20 -20 -20]\n",
            " ...\n",
            " [20 20 20 ... -20 20 20]\n",
            " [-20 20 -20 ... 20 -20 -20]\n",
            " [-20 20 -20 ... 20 -20 -20]] [[-1169.91382 -1523.89197 -973.173157 ... -833.966 -1355.16699 -1201.50964]\n",
            " [281.988861 175.71907 577.081116 ... 203.930588 898.354065 276.059875]\n",
            " [-676.34906 -1091.84167 -1104.09082 ... -570.87677 -912.209778 -1388.15173]\n",
            " ...\n",
            " [-5.7247324 808.544861 47.1081772 ... 306.538 259.243805 -134.285782]\n",
            " [-1169.96655 -1523.90515 -973.14856 ... -833.939697 -1355.19751 -1201.24548]\n",
            " [-1170.00586 -1524.03577 -973.215332 ... -834.037109 -1355.26257 -1201.40137]]\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "Training epoch 52/10000, LR=5.00e-04, Loss=-1.55957e+02, channel_BER=0.085, BER=0.295625, duration per call: 0.02s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "llrs [[-20 20 20 ... -20 -20 20]\n",
            " [-20 20 -20 ... -20 -20 -20]\n",
            " [20 20 -20 ... -20 20 -20]\n",
            " ...\n",
            " [20 20 20 ... -20 20 20]\n",
            " [20 -20 20 ... 20 20 20]\n",
            " [-20 20 20 ... 20 -20 20]] [[-732.957092 -689.370239 -505.332855 ... -117.573143 -1000.45703 -272.838135]\n",
            " [-842.683533 -1044.69141 -952.725586 ... -246.342361 -686.851074 -702.61731]\n",
            " [258.004791 -327.626556 -136.729568 ... -240.574142 596.94519 -357.111145]\n",
            " ...\n",
            " [178.148544 85.7668686 718.872681 ... -29.3020687 242.467163 180.610947]\n",
            " [-601.983643 -1009.06982 -140.805847 ... -716.880737 -487.052521 -220.049774]\n",
            " [879.164 437.023163 110.869301 ... 1110.36 405.153778 663.709717]]\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "Training epoch 53/10000, LR=5.00e-04, Loss=-1.32910e+02, channel_BER=0.09625, BER=0.32625, duration per call: 0.02s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "llrs [[-20 20 20 ... -20 -20 20]\n",
            " [-20 20 20 ... -20 -20 20]\n",
            " [-20 20 -20 ... -20 -20 -20]\n",
            " ...\n",
            " [20 20 -20 ... -20 20 -20]\n",
            " [20 20 20 ... -20 20 20]\n",
            " [-20 20 -20 ... -20 -20 -20]] [[-1174.35901 -1528.54846 -976.729675 ... -837.379578 -1359.96167 -1205.36938]\n",
            " [-289.922272 347.623352 530.729919 ... 108.422958 -790.866577 284.398254]\n",
            " [176.972992 230.388824 -229.848602 ... 161.965607 -184.261719 -541.396545]\n",
            " ...\n",
            " [268.151367 4.96274233 92.4215851 ... 206.71022 998.029114 55.1397781]\n",
            " [293.578979 1128.03381 193.918823 ... 334.442841 89.6469 77.0284119]\n",
            " [725.589661 945.791687 602.859436 ... 517.727051 841.000916 744.286865]]\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "Training epoch 54/10000, LR=5.00e-04, Loss=-1.44246e+02, channel_BER=0.0875, BER=0.31, duration per call: 0.02s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "llrs [[20 20 20 ... 20 20 20]\n",
            " [-20 20 -20 ... 20 -20 -20]\n",
            " [20 -20 20 ... 20 20 20]\n",
            " ...\n",
            " [20 -20 20 ... -20 20 20]\n",
            " [-20 20 20 ... 20 -20 20]\n",
            " [-20 -20 -20 ... -20 -20 -20]] [[728.61853 948.022278 605.87854 ... 519.685669 843.772217 747.656921]\n",
            " [-989.927795 -437.951416 -277.122437 ... 84.210083 -1003.00897 -284.237732]\n",
            " [356.799194 658.198 562.770752 ... 73.8675156 284.565369 525.762329]\n",
            " ...\n",
            " [-309.388123 -988.203735 205.732864 ... -450.826538 142.385269 -129.21965]\n",
            " [391.665649 620.989075 320.23053 ... 376.395844 668.459961 431.214661]\n",
            " [-1176.57837 -1530.88208 -978.561401 ... -839.099121 -1362.39331 -1207.41821]]\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "Training epoch 55/10000, LR=5.00e-04, Loss=-1.45270e+02, channel_BER=0.090625, BER=0.309375, duration per call: 0.02s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "llrs [[-20 20 -20 ... 20 -20 -20]\n",
            " [20 20 20 ... -20 20 20]\n",
            " [20 -20 -20 ... 20 20 -20]\n",
            " ...\n",
            " [20 -20 -20 ... -20 20 -20]\n",
            " [20 -20 20 ... 20 20 20]\n",
            " [20 -20 20 ... -20 20 20]] [[-536.585876 -0.338488549 160.265808 ... 551.76709 -683.640869 -474.538452]\n",
            " [270.377533 177.991608 461.269867 ... 183.745392 599.713 200.154434]\n",
            " [609.854492 637.256104 311.557129 ... 870.709656 610.920593 483.659912]\n",
            " ...\n",
            " [670.876282 478.533112 130.300049 ... -230.380753 157.368881 204.771942]\n",
            " [-304.213745 -226.407043 304.221863 ... 171.368423 -42.1420364 -78.4636841]\n",
            " [220.743317 -527.67511 561.245667 ... -433.942413 61.1598625 115.193367]]\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "Training epoch 56/10000, LR=5.00e-04, Loss=-1.46356e+02, channel_BER=0.10375, BER=0.305625, duration per call: 0.01s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "llrs [[-20 20 20 ... -20 -20 20]\n",
            " [-20 20 20 ... -20 -20 20]\n",
            " [-20 20 -20 ... -20 -20 -20]\n",
            " ...\n",
            " [-20 20 -20 ... 20 -20 -20]\n",
            " [-20 -20 -20 ... 20 -20 -20]\n",
            " [20 -20 -20 ... 20 20 -20]] [[-556.123962 -266.041687 -139.06189 ... -71.5144958 -1145.422 -96.9954]\n",
            " [-268.91687 208.736359 -144.637863 ... -285.590363 -614.686279 253.973129]\n",
            " [-504.477142 -718.960388 -513.306702 ... -750.399475 -156.744888 -170.816452]\n",
            " ...\n",
            " [-63.0944099 266.322754 -614.223267 ... 507.43573 -781.906372 -489.499481]\n",
            " [-495.175201 -497.589142 -259.541138 ... -716.764221 511.810425 7.04761219]\n",
            " [731.173157 949.688599 606.630249 ... 520.016907 845.112305 749.063843]]\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "Training epoch 57/10000, LR=5.00e-04, Loss=-1.40795e+02, channel_BER=0.09125, BER=0.31625, duration per call: 0.01s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "llrs [[-20 20 -20 ... 20 -20 -20]\n",
            " [20 20 20 ... 20 20 20]\n",
            " [20 -20 -20 ... 20 20 -20]\n",
            " ...\n",
            " [-20 20 20 ... 20 -20 20]\n",
            " [20 20 -20 ... -20 20 -20]\n",
            " [-20 20 20 ... -20 -20 20]] [[-614.067688 -21.5725651 -495.936462 ... 7.45732117 -690.236389 -422.766]\n",
            " [732.447083 952.176331 609.121033 ... 522.660217 847.916748 751.246704]\n",
            " [6.57517672 -564.772156 -686.862366 ... 304.461578 -197.848648 -487.791351]\n",
            " ...\n",
            " [437.349091 556.432312 546.603333 ... -8.2011385 292.231659 491.778687]\n",
            " [1074.06335 347.392365 322.099792 ... 211.764664 864.109558 338.459381]\n",
            " [-1183.28894 -1538.19751 -984.146 ... -844.433 -1369.72009 -1213.69714]]\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "Training epoch 58/10000, LR=5.00e-04, Loss=-1.37458e+02, channel_BER=0.0725, BER=0.318125, duration per call: 0.01s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "llrs [[-20 20 20 ... -20 -20 20]\n",
            " [20 20 20 ... 20 20 20]\n",
            " [20 20 -20 ... 20 20 -20]\n",
            " ...\n",
            " [20 20 -20 ... -20 20 -20]\n",
            " [20 -20 -20 ... 20 20 -20]\n",
            " [20 -20 20 ... 20 20 20]] [[-1185.55615 -1540.61145 -986.031616 ... -846.30011 -1372.15063 -1215.81567]\n",
            " [733.749207 953.547485 610.201172 ... 523.750122 849.327881 752.464172]\n",
            " [-306.862427 -785.26062 -205.285187 ... 91.9240265 -756.124695 -1171.41418]\n",
            " ...\n",
            " [873.377 885.162842 287.786316 ... 325.823273 813.341064 352.771881]\n",
            " [392.798096 627.615967 323.463837 ... 381.401611 670.782471 435.634979]\n",
            " [-609.954651 -337.319489 397.417175 ... 194.743271 -428.148834 -670.93573]]\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "Training epoch 59/10000, LR=5.00e-04, Loss=-1.55681e+02, channel_BER=0.09125, BER=0.298125, duration per call: 0.02s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "llrs [[-20 20 20 ... 20 -20 20]\n",
            " [-20 -20 -20 ... 20 -20 -20]\n",
            " [20 20 20 ... 20 20 20]\n",
            " ...\n",
            " [20 20 -20 ... -20 20 -20]\n",
            " [20 20 -20 ... -20 20 -20]\n",
            " [-20 20 -20 ... 20 -20 -20]] [[839.459167 484.792755 342.093384 ... 653.837952 479.243256 1202.49292]\n",
            " [-267.444305 -459.805542 -717.090881 ... -103.927895 -488.336273 -588.930908]\n",
            " [734.98877 954.853943 611.255188 ... 524.801819 850.66095 753.628906]\n",
            " ...\n",
            " [287.516174 -243.017517 -426.260498 ... -164.093475 576.206604 -708.13562]\n",
            " [578.921875 620.91925 280.604309 ... 62.4057693 478.941742 329.212128]\n",
            " [-871.046814 -1209.79077 -584.065918 ... -32.6179962 -1002.81451 -932.628]]\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "Training epoch 60/10000, LR=5.00e-04, Loss=-1.26340e+02, channel_BER=0.0875, BER=0.3325, duration per call: 0.01s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "llrs [[-20 -20 -20 ... 20 -20 -20]\n",
            " [20 20 20 ... 20 20 20]\n",
            " [-20 20 -20 ... -20 -20 -20]\n",
            " ...\n",
            " [-20 -20 20 ... 20 -20 20]\n",
            " [20 20 20 ... 20 20 20]\n",
            " [-20 20 -20 ... -20 -20 -20]] [[-690.516724 -1106.56677 -1125.00244 ... -581.524353 -928.515259 -1411.83423]\n",
            " [736.235535 956.105591 612.323303 ... 525.855835 851.997375 754.813416]\n",
            " [-1068.34607 -1231.36084 -692.388611 ... -1202.73853 -1140.54797 -953.003357]\n",
            " ...\n",
            " [-1368.81213 -1240.67334 -905.088257 ... -704.085205 -1538.32129 -1051.47571]\n",
            " [736.234131 956.108521 612.330139 ... 525.854919 852.004639 754.831116]\n",
            " [-1189.73279 -1545.01392 -989.975586 ... -849.885315 -1376.75464 -1220.6698]]\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "Training epoch 61/10000, LR=5.00e-04, Loss=-1.45843e+02, channel_BER=0.090625, BER=0.30875, duration per call: 0.01s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "llrs [[-20 -20 20 ... 20 -20 20]\n",
            " [20 20 -20 ... 20 20 -20]\n",
            " [20 -20 20 ... 20 20 20]\n",
            " ...\n",
            " [-20 -20 20 ... 20 -20 20]\n",
            " [-20 -20 20 ... 20 -20 20]\n",
            " [20 20 -20 ... 20 20 -20]] [[-1194.20093 -854.504211 -313.641205 ... -456.685974 -1371.16638 -358.096039]\n",
            " [-128.112854 504.6138 -252.885132 ... 663.239258 27.0794964 -405.421]\n",
            " [-354.878357 -135.080612 -319.435669 ... 641.458923 -628.644165 -30.9084511]\n",
            " ...\n",
            " [-1372.24536 -1240.88892 -906.218323 ... -704.931763 -1540.8186 -1052.30713]\n",
            " [-1371.79895 -1242.901 -907.475281 ... -706.00708 -1541.54602 -1054.08887]\n",
            " [697.109924 1193.7041 373.729065 ... 473.816681 655.012939 522.217102]]\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "Training epoch 62/10000, LR=5.00e-04, Loss=-1.46678e+02, channel_BER=0.0975, BER=0.306875, duration per call: 0.02s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "llrs [[-20 -20 -20 ... 20 -20 -20]\n",
            " [20 20 20 ... -20 20 20]\n",
            " [20 -20 20 ... 20 20 20]\n",
            " ...\n",
            " [-20 20 20 ... 20 -20 20]\n",
            " [-20 20 20 ... -20 -20 20]\n",
            " [20 20 -20 ... 20 20 -20]] [[-516.296753 -721.393433 -535.003296 ... -334.288086 -761.998108 -720.971863]\n",
            " [237.906 416.397156 226.727264 ... 132.020386 410.396 -29.7372036]\n",
            " [238.940765 346.817841 272.017639 ... 428.88855 50.9765549 268.19519]\n",
            " ...\n",
            " [-366.312958 -979.162964 -328.649475 ... 251.375916 -354.847717 -207.904068]\n",
            " [-1194.84473 -1550.62952 -994.061218 ... -854.136475 -1382.64465 -1224.77759]\n",
            " [-353.950195 -1069.99438 -897.57373 ... 184.410904 -791.772644 -768.503479]]\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "Training epoch 63/10000, LR=5.00e-04, Loss=-1.58700e+02, channel_BER=0.078125, BER=0.29125, duration per call: 0.02s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "llrs [[-20 20 20 ... 20 -20 20]\n",
            " [20 20 20 ... 20 20 20]\n",
            " [-20 -20 20 ... 20 -20 20]\n",
            " ...\n",
            " [20 -20 -20 ... -20 20 -20]\n",
            " [-20 -20 20 ... -20 -20 20]\n",
            " [20 -20 -20 ... -20 20 -20]] [[-166.797928 -302.006073 -9.76525879 ... -233.986084 -40.7059822 611.983643]\n",
            " [902.232422 660.243164 413.101593 ... 363.533417 712.983704 514.113892]\n",
            " [-1197.3468 -1553.3562 -996.170776 ... -856.215393 -1385.41309 -1227.17139]\n",
            " ...\n",
            " [-1197.62073 -1553.62732 -996.324402 ... -856.253784 -1385.26355 -1227.38989]\n",
            " [-11.7619123 -759.994507 282.315491 ... -170.679428 -179.763412 229.331833]\n",
            " [-855.060364 -1226.57 -708.463806 ... -712.301147 -1205.67627 -909.286926]]\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "Training epoch 64/10000, LR=5.00e-04, Loss=-1.46530e+02, channel_BER=0.0825, BER=0.30625, duration per call: 0.01s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "llrs [[20 -20 20 ... 20 20 20]\n",
            " [-20 20 20 ... -20 -20 20]\n",
            " [-20 20 20 ... -20 -20 20]\n",
            " ...\n",
            " [-20 -20 20 ... 20 -20 20]\n",
            " [-20 20 -20 ... -20 -20 -20]\n",
            " [20 20 -20 ... -20 20 -20]] [[-433.83725 -380.141449 491.107208 ... 353.327423 70.8280182 340.068176]\n",
            " [-1035.76526 -291.464111 -87.9812 ... 63.0200844 -842.902832 -69.9825211]\n",
            " [-287.605927 79.0895309 -366.990265 ... 219.614273 -774.229309 274.441223]\n",
            " ...\n",
            " [-1128.09155 -437.240906 -477.12561 ... -358.536774 -1488.4635 -306.206543]\n",
            " [-1185.39014 -1548.78284 -1007.05273 ... -852.039124 -1376.02991 -1225.48047]\n",
            " [233.952942 -604.640564 -429.867462 ... -68.9522095 94.6590118 -626.638184]]\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "Training epoch 65/10000, LR=5.00e-04, Loss=-1.45282e+02, channel_BER=0.09375, BER=0.30875, duration per call: 0.01s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "llrs [[-20 -20 20 ... 20 -20 20]\n",
            " [-20 -20 20 ... 20 -20 20]\n",
            " [20 20 20 ... -20 20 20]\n",
            " ...\n",
            " [-20 20 20 ... 20 -20 20]\n",
            " [20 -20 20 ... -20 20 20]\n",
            " [20 -20 -20 ... 20 20 -20]] [[-963.456909 -760.341919 -666.935608 ... -523.514648 -1621.3313 -539.506958]\n",
            " [-879.963562 -641.030762 -73.4389572 ... 93.6538239 -683.735229 197.302124]\n",
            " [103.051773 -187.508392 484.814606 ... -446.787659 -301.192474 444.08844]\n",
            " ...\n",
            " [862.216797 815.013489 92.3549423 ... 568.875366 360.658783 418.309]\n",
            " [546.735596 185.437546 633.707092 ... -13.3026009 644.4776 196.226288]\n",
            " [-195.47525 -1068.00244 -415.914795 ... 514.859436 -216.696533 -970.313599]]\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "Training epoch 66/10000, LR=5.00e-04, Loss=-1.48675e+02, channel_BER=0.08125, BER=0.306875, duration per call: 0.01s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "llrs [[20 20 20 ... 20 20 20]\n",
            " [20 20 -20 ... -20 20 -20]\n",
            " [20 20 20 ... -20 20 20]\n",
            " ...\n",
            " [-20 20 -20 ... -20 -20 -20]\n",
            " [-20 -20 -20 ... -20 -20 -20]\n",
            " [-20 20 20 ... 20 -20 20]] [[970.139526 995.285583 177.989883 ... 719.721863 445.12854 705.761597]\n",
            " [-191.753052 -1155.04321 -315.535828 ... -425.598938 -353.373901 -471.63562]\n",
            " [-138.394348 -693.003845 -126.180313 ... -258.343842 -650.329224 -309.795929]\n",
            " ...\n",
            " [-236.862793 -677.387268 -859.202087 ... -32.4130783 -374.480591 -564.094543]\n",
            " [-1205.29749 -1561.97583 -1002.71533 ... -862.25061 -1393.65833 -1234.52]\n",
            " [-87.610672 -638.629517 -299.960297 ... 199.194504 -32.6035385 505.310059]]\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "Training epoch 67/10000, LR=5.00e-04, Loss=-1.45749e+02, channel_BER=0.0925, BER=0.3075, duration per call: 0.01s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "llrs [[20 -20 20 ... 20 20 20]\n",
            " [-20 20 20 ... 20 -20 20]\n",
            " [20 20 20 ... 20 20 20]\n",
            " ...\n",
            " [-20 20 20 ... 20 -20 20]\n",
            " [-20 20 20 ... 20 -20 20]\n",
            " [-20 -20 -20 ... -20 -20 -20]] [[-36.6786156 -892.212097 -54.634407 ... 317.295654 -637.159485 174.163727]\n",
            " [-237.080338 -63.2716789 4.69376 ... 178.115509 -502.800598 571.569702]\n",
            " [745.230164 965.629456 620.121643 ... 533.196045 861.647522 763.294434]\n",
            " ...\n",
            " [745.284912 965.694397 620.041931 ... 533.234314 861.717346 763.342468]\n",
            " [129.056366 -307.386 157.400269 ... 127.10688 -73.6225433 486.519073]\n",
            " [-1207.79236 -1564.8761 -1004.93237 ... -864.237122 -1396.2887 -1237.01306]]\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "Training epoch 68/10000, LR=5.00e-04, Loss=-1.50764e+02, channel_BER=0.085625, BER=0.303125, duration per call: 0.01s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "llrs [[-20 20 20 ... 20 -20 20]\n",
            " [20 -20 -20 ... 20 20 -20]\n",
            " [20 -20 20 ... 20 20 20]\n",
            " ...\n",
            " [20 20 -20 ... -20 20 -20]\n",
            " [20 -20 20 ... -20 20 20]\n",
            " [-20 20 20 ... -20 -20 20]] [[-205.997635 -3.1398375 -240.032394 ... 723.211792 -608.693848 -615.153503]\n",
            " [799.622131 -295.141571 -308.174713 ... 107.931892 254.707214 -354.08]\n",
            " [-6.36990738 260.239136 946.911316 ... 29.9798279 136.86351 832.780762]\n",
            " ...\n",
            " [-378.726227 -1014.49133 -675.844 ... -981.632324 -443.116699 -766.548645]\n",
            " [144.33992 -506.983124 -52.0878487 ... -623.361 -320.761383 193.347061]\n",
            " [-76.3522339 743.550537 566.152832 ... 293.037201 -66.5766373 369.943848]]\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "Training epoch 69/10000, LR=5.00e-04, Loss=-1.60052e+02, channel_BER=0.104375, BER=0.2925, duration per call: 0.01s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "llrs [[20 20 20 ... -20 20 20]\n",
            " [20 20 20 ... 20 20 20]\n",
            " [-20 20 -20 ... 20 -20 -20]\n",
            " ...\n",
            " [20 -20 20 ... -20 20 20]\n",
            " [-20 20 20 ... 20 -20 20]\n",
            " [20 20 -20 ... -20 20 -20]] [[243.918015 341.334656 317.716309 ... -378.74 -325.104828 -73.121582]\n",
            " [302.464142 -142.955032 13.647254 ... 763.029358 -39.5524712 228.08078]\n",
            " [126.94651 290.373749 -725.082825 ... 120.413155 -737.519226 -306.44873]\n",
            " ...\n",
            " [-120.687645 -31.1300316 211.258194 ... 76.7492676 -455.273682 459.067108]\n",
            " [72.1736526 515.495117 552.079773 ... -225.313 526.575867 473.281799]\n",
            " [285.596375 -250.26709 -439.067078 ... -172.725845 580.641541 -722.229065]]\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "Training epoch 70/10000, LR=5.00e-04, Loss=-1.55520e+02, channel_BER=0.084375, BER=0.2975, duration per call: 0.01s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "llrs [[20 20 -20 ... -20 20 -20]\n",
            " [-20 20 20 ... -20 -20 20]\n",
            " [20 20 -20 ... 20 20 -20]\n",
            " ...\n",
            " [-20 20 20 ... 20 -20 20]\n",
            " [20 20 -20 ... 20 20 -20]\n",
            " [-20 -20 -20 ... -20 -20 -20]] [[-612.086243 -987.92041 -1098.20337 ... -225.078125 -692.16217 -1230.53027]\n",
            " [-1380.14758 -1266.22253 -803.196289 ... -699.879 -1258.63403 -993.087646]\n",
            " [42.2610817 -139.415955 -582.166382 ... 64.3972321 -217.867233 -1007.56604]\n",
            " ...\n",
            " [28.6147156 911.878174 262.033173 ... 28.8449783 320.817017 442.325592]\n",
            " [-892.799561 -778.512878 -703.675842 ... -740.142334 -738.942383 -976.592346]\n",
            " [-1214.91394 -1573.09619 -1011.10913 ... -869.95166 -1404.01196 -1243.92456]]\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "Training epoch 71/10000, LR=5.00e-04, Loss=-1.42114e+02, channel_BER=0.08375, BER=0.3125, duration per call: 0.01s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "llrs [[-20 -20 -20 ... 20 -20 -20]\n",
            " [20 -20 20 ... 20 20 20]\n",
            " [-20 -20 20 ... 20 -20 20]\n",
            " ...\n",
            " [20 -20 -20 ... 20 20 -20]\n",
            " [-20 20 20 ... -20 -20 20]\n",
            " [20 -20 20 ... 20 20 20]] [[-1216.38135 -1574.76587 -1012.71564 ... -871.555542 -1406.64758 -1245.91309]\n",
            " [-238.338608 -680.286804 -33.3607101 ... 415.085724 -690.689941 -438.435181]\n",
            " [-834.024048 -1490.74231 -482.728302 ... -671.406921 -1024.24719 -691.707]\n",
            " ...\n",
            " [-488.220276 -1116.21606 -723.921692 ... -588.313538 -3.23885059 -860.079529]\n",
            " [-617.335144 350.815308 366.32428 ... -265.525757 -787.433411 420.614471]\n",
            " [326.808868 333.291016 174.312424 ... 861.550842 801.32074 282.9263]]\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "Training epoch 72/10000, LR=5.00e-04, Loss=-1.58392e+02, channel_BER=0.090625, BER=0.29375, duration per call: 0.01s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "llrs [[-20 20 -20 ... 20 -20 -20]\n",
            " [-20 20 -20 ... -20 -20 -20]\n",
            " [-20 20 20 ... -20 -20 20]\n",
            " ...\n",
            " [-20 -20 20 ... -20 -20 20]\n",
            " [20 20 -20 ... -20 20 -20]\n",
            " [20 -20 20 ... -20 20 20]] [[-305.1763 -262.736359 -610.176208 ... -238.726181 -1194.48267 -150.865692]\n",
            " [-588.640442 -1094.57727 -1072.84607 ... -693.406494 -1307.78076 -939.232605]\n",
            " [-1082.53394 -624.047546 -203.195297 ... 287.754791 -1064.479 -521.646179]\n",
            " ...\n",
            " [-671.626648 -1200.68066 -525.360168 ... -1075.15601 -574.273438 -509.643982]\n",
            " [135.373199 -110.126137 30.9571877 ... -465.37323 228.159515 -667.446594]\n",
            " [752.068176 973.126648 625.856445 ... 538.539185 869.048645 769.71344]]\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "Training epoch 73/10000, LR=5.00e-04, Loss=-1.35928e+02, channel_BER=0.1075, BER=0.323125, duration per call: 0.01s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "llrs [[20 20 -20 ... -20 20 -20]\n",
            " [-20 20 20 ... -20 -20 20]\n",
            " [-20 20 -20 ... 20 -20 -20]\n",
            " ...\n",
            " [-20 -20 20 ... -20 -20 20]\n",
            " [-20 -20 -20 ... -20 -20 -20]\n",
            " [-20 20 -20 ... -20 -20 -20]] [[564.372131 -453.764191 -650.018616 ... 76.0462 373.904938 -547.173096]\n",
            " [-615.549255 -897.994202 -529.699768 ... -912.121643 -1082.83386 -582.86084]\n",
            " [-1042.32935 -1293.48352 -947.134644 ... -749.667053 -1233.77295 -1533.08533]\n",
            " ...\n",
            " [-1333.43201 -1131.00171 -556.846313 ... -400.697662 -973.625488 -862.587952]\n",
            " [-1221.50525 -1580.63647 -1016.99072 ... -875.122314 -1411.21667 -1250.16455]\n",
            " [-343.385925 -825.917664 -1260.78674 ... -456.996704 -1032.46619 -807.896851]]\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "Training epoch 74/10000, LR=5.00e-04, Loss=-1.58082e+02, channel_BER=0.08375, BER=0.29375, duration per call: 0.01s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "llrs [[-20 20 -20 ... -20 -20 -20]\n",
            " [-20 20 20 ... 20 -20 20]\n",
            " [20 -20 20 ... 20 20 20]\n",
            " ...\n",
            " [20 -20 -20 ... 20 20 -20]\n",
            " [20 -20 -20 ... 20 20 -20]\n",
            " [20 -20 -20 ... -20 20 -20]] [[-1097.30798 -1261.74622 -714.907349 ... -1236.29285 -1170.8988 -980.824646]\n",
            " [750.442566 966.546265 611.008179 ... 519.751282 851.808594 762.79]\n",
            " [-1110.14697 -944.223267 -155.950989 ... -482.186 -715.216125 -525.040894]\n",
            " ...\n",
            " [-135.696732 -357.301575 96.1042557 ... -784.118408 457.822906 -304.841156]\n",
            " [-535.82251 -729.128052 -169.617813 ... 133.760269 -180.045227 -1051.94775]\n",
            " [-903.788 -999.690552 -567.04071 ... -1044.04504 -1037.19946 -613.591248]]\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "Training epoch 75/10000, LR=5.00e-04, Loss=-1.65146e+02, channel_BER=0.0775, BER=0.28625, duration per call: 0.01s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "llrs [[-20 -20 -20 ... -20 -20 -20]\n",
            " [-20 20 20 ... -20 -20 20]\n",
            " [20 -20 20 ... -20 20 20]\n",
            " ...\n",
            " [20 20 20 ... -20 20 20]\n",
            " [-20 -20 20 ... -20 -20 20]\n",
            " [20 20 -20 ... 20 20 -20]] [[-1226.22656 -1586.32556 -1021.0675 ... -879.175232 -1416.27808 -1255.04163]\n",
            " [-1336.96667 -1129.49182 -552.565857 ... -401.542358 -971.586914 -861.870789]\n",
            " [-412.042358 -608.701 412.326416 ... -331.845398 381.992798 -457.244904]\n",
            " ...\n",
            " [-361.858856 -166.501984 322.374969 ... -521.492676 -296.913513 -41.5788651]\n",
            " [-451.452332 150.716461 232.82991 ... -661.766235 85.2657471 -17.1652718]\n",
            " [691.005 -198.702713 -537.276 ... 847.575256 241.608871 -394.96521]]\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "Training epoch 76/10000, LR=5.00e-04, Loss=-1.61331e+02, channel_BER=0.08875, BER=0.289375, duration per call: 0.01s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "llrs [[20 20 20 ... 20 20 20]\n",
            " [20 -20 -20 ... 20 20 -20]\n",
            " [20 -20 20 ... -20 20 20]\n",
            " ...\n",
            " [20 20 20 ... -20 20 20]\n",
            " [-20 -20 -20 ... 20 -20 -20]\n",
            " [-20 20 -20 ... -20 -20 -20]] [[756.992 979.261536 630.467346 ... 542.831726 874.450439 774.803528]\n",
            " [-180.41098 -820.358276 -240.452255 ... -41.2630882 99.7514877 -735.943665]\n",
            " [202.287521 387.964844 667.177307 ... 277.188202 776.229065 426.886139]\n",
            " ...\n",
            " [-154.86467 294.011902 113.934357 ... -137.17923 90.0743332 373.366119]\n",
            " [224.472061 178.351883 -225.441406 ... 443.856445 148.86644 37.0561485]\n",
            " [-452.64093 -99.6610489 -587.898438 ... -240.93779 0.126210332 -667.131653]]\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "Training epoch 77/10000, LR=5.00e-04, Loss=-1.50384e+02, channel_BER=0.09375, BER=0.30125, duration per call: 0.01s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "llrs [[20 -20 20 ... -20 20 20]\n",
            " [20 -20 -20 ... 20 20 -20]\n",
            " [20 -20 -20 ... 20 20 -20]\n",
            " ...\n",
            " [20 -20 -20 ... -20 20 -20]\n",
            " [20 20 -20 ... -20 20 -20]\n",
            " [-20 20 -20 ... -20 -20 -20]] [[-652.235352 -740.625244 398.161163 ... -590.589 36.2154388 -55.7037315]\n",
            " [630.400208 -303.934906 -161.780838 ... -282.498352 679.106506 -306.103912]\n",
            " [-36.5452614 -673.599121 -819.607727 ... -705.70282 -165.473282 -733.885315]\n",
            " ...\n",
            " [-1170.28198 -1443.06226 -772.335205 ... -567.853088 -1119.18762 -1119.50916]\n",
            " [419.938812 41.4009323 -323.360657 ... -436.334442 146.19429 -687.517822]\n",
            " [-324.318451 -106.551849 -734.906311 ... -609.806824 -593.166 -392.104065]]\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "Training epoch 78/10000, LR=5.00e-04, Loss=-1.51110e+02, channel_BER=0.10125, BER=0.304375, duration per call: 0.01s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "llrs [[-20 20 -20 ... -20 -20 -20]\n",
            " [20 20 20 ... 20 20 20]\n",
            " [20 20 -20 ... -20 20 -20]\n",
            " ...\n",
            " [20 -20 -20 ... 20 20 -20]\n",
            " [-20 20 20 ... -20 -20 20]\n",
            " [20 -20 20 ... 20 20 20]] [[-1231.82153 -1593.94287 -1026.54297 ... -884.127258 -1422.11572 -1261.005]\n",
            " [412.367371 651.640503 341.089111 ... 397.273041 693.309326 454.824066]\n",
            " [346.419312 218.539185 -255.224319 ... -4.25030899 289.168823 -570.131165]\n",
            " ...\n",
            " [-179.135422 -1124.41821 -553.614685 ... -225.654709 -27.3108273 -994.88562]\n",
            " [-62.0206718 11.8360033 164.381165 ... -417.715088 -150.976898 -297.523651]\n",
            " [-999.072693 -760.683105 -72.5933533 ... -326.825775 -625.164734 -231.909012]]\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "Training epoch 79/10000, LR=5.00e-04, Loss=-1.60537e+02, channel_BER=0.09375, BER=0.291875, duration per call: 0.02s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "llrs [[-20 -20 20 ... -20 -20 20]\n",
            " [20 -20 20 ... -20 20 20]\n",
            " [-20 20 20 ... 20 -20 20]\n",
            " ...\n",
            " [-20 20 -20 ... 20 -20 -20]\n",
            " [20 20 20 ... 20 20 20]\n",
            " [-20 20 -20 ... 20 -20 -20]] [[-509.919952 13.0931473 -10.6726675 ... -966.188782 -203.245605 -152.371582]\n",
            " [-802.102234 -1367.96887 -304.806122 ... -1325.71484 -216.225098 -434.381958]\n",
            " [605.637939 -28.112339 -35.7627869 ... 870.465881 143.562851 678.429077]\n",
            " ...\n",
            " [-1234.37927 -1596.75549 -1028.69373 ... -886.535339 -1425.41516 -1263.37036]\n",
            " [760.770569 984.216797 633.88739 ... 546.371338 878.45 778.688477]\n",
            " [123.281509 293.037903 -739.967102 ... 123.154915 -749.605286 -317.318268]]\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "Training epoch 80/10000, LR=5.00e-04, Loss=-1.83549e+02, channel_BER=0.088125, BER=0.265, duration per call: 0.03s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "llrs [[-20 20 20 ... -20 -20 20]\n",
            " [20 20 -20 ... 20 20 -20]\n",
            " [20 20 20 ... 20 20 20]\n",
            " ...\n",
            " [20 -20 20 ... -20 20 20]\n",
            " [20 20 -20 ... 20 20 -20]\n",
            " [-20 20 20 ... 20 -20 20]] [[-506.306671 242.981934 145.258163 ... -290.233826 -833.280396 463.305298]\n",
            " [-96.3030548 -61.3667297 -250.750015 ... 272.089539 -172.411484 -600.868286]\n",
            " [761.838806 985.694153 634.951416 ... 547.450256 879.631409 779.875366]\n",
            " ...\n",
            " [-125.246666 229.440308 886.033752 ... 126.841164 501.970276 341.179443]\n",
            " [83.6601944 -35.6638298 -227.205826 ... 566.957336 86.2352 -433.048615]\n",
            " [761.710449 985.492432 634.782593 ... 547.213623 879.391418 779.673828]]\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "Training epoch 81/10000, LR=5.00e-04, Loss=-1.53762e+02, channel_BER=0.0825, BER=0.3, duration per call: 0.01s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "llrs [[20 -20 20 ... 20 20 20]\n",
            " [20 -20 20 ... 20 20 20]\n",
            " [-20 20 20 ... 20 -20 20]\n",
            " ...\n",
            " [-20 -20 20 ... -20 -20 20]\n",
            " [20 20 20 ... 20 20 20]\n",
            " [-20 -20 -20 ... 20 -20 -20]] [[-390.786407 -312.810242 -51.6568718 ... 392.884125 -855.695862 -745.907837]\n",
            " [231.363983 -252.827225 5.61177397 ... 140.585358 -273.491669 311.796448]\n",
            " [735.550537 755.891296 368.919281 ... 504.294067 181.561905 591.442]\n",
            " ...\n",
            " [-1237.02332 -1602.53027 -1032.57629 ... -887.873413 -1427.38208 -1266.51489]\n",
            " [762.90686 987.188904 636.019836 ... 548.592 880.835327 781.08374]\n",
            " [-589.913879 -505.101807 -809.241 ... -402.941223 -1002.20654 -992.210754]]\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "Training epoch 82/10000, LR=5.00e-04, Loss=-1.38564e+02, channel_BER=0.089375, BER=0.316875, duration per call: 0.02s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "llrs [[-20 -20 -20 ... -20 -20 -20]\n",
            " [-20 -20 -20 ... -20 -20 -20]\n",
            " [20 -20 20 ... 20 20 20]\n",
            " ...\n",
            " [20 20 -20 ... 20 20 -20]\n",
            " [-20 -20 20 ... -20 -20 20]\n",
            " [20 20 -20 ... 20 20 -20]] [[-1241.06067 -1605.82275 -1035.00232 ... -892.952332 -1432.51465 -1270.68054]\n",
            " [-1240.90662 -1605.67273 -1034.87048 ... -892.912903 -1432.44531 -1270.56494]\n",
            " [-1125.73621 -656.500916 153.743835 ... -308.997498 -594.740417 -270.25296]\n",
            " ...\n",
            " [-383.04 -930.580505 -407.726379 ... 383.579803 -612.917847 -1073.92786]\n",
            " [24.0111923 504.996094 94.7590103 ... -566.260559 157.241882 883.835754]\n",
            " [-566.286499 -1277.7655 -753.153198 ... -98.3117828 -1016.47784 -1504.13]]\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "Training epoch 83/10000, LR=5.00e-04, Loss=-1.50930e+02, channel_BER=0.093125, BER=0.30375, duration per call: 0.02s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "llrs [[-20 -20 20 ... -20 -20 20]\n",
            " [20 20 20 ... 20 20 20]\n",
            " [20 20 -20 ... 20 20 -20]\n",
            " ...\n",
            " [-20 20 -20 ... -20 -20 -20]\n",
            " [-20 -20 20 ... -20 -20 20]\n",
            " [-20 -20 -20 ... -20 -20 -20]] [[-867.640076 -914.243896 -326.784515 ... -946.94635 -460.695709 -278.345093]\n",
            " [354.18277 505.932312 81.5341873 ... 85.7864456 395.584 315.347687]\n",
            " [-866.680847 -1456.26355 -596.030151 ... -201.975098 -1159.71729 -1259.77612]\n",
            " ...\n",
            " [-542.425903 -678.645325 -615.190918 ... -660.859863 -424.801239 -1058.79858]\n",
            " [-396.393494 -938.073914 -148.843903 ... -874.93335 -468.189606 224.495499]\n",
            " [-1243.30969 -1608.72351 -1037.15 ... -895.09 -1435.04822 -1273.07495]]\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "Training epoch 84/10000, LR=5.00e-04, Loss=-1.36378e+02, channel_BER=0.086875, BER=0.3225, duration per call: 0.02s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "llrs [[20 20 20 ... -20 20 20]\n",
            " [20 20 -20 ... 20 20 -20]\n",
            " [-20 -20 20 ... -20 -20 20]\n",
            " ...\n",
            " [20 -20 -20 ... 20 20 -20]\n",
            " [20 -20 -20 ... 20 20 -20]\n",
            " [-20 -20 -20 ... 20 -20 -20]] [[-138.720566 -379.887451 609.391479 ... -177.550674 176.891556 380.879456]\n",
            " [27.8497543 183.438339 -627.662415 ... -282.159912 -377.026611 -681.641846]\n",
            " [-157.888199 -1440.71069 -84.1590347 ... -380.794617 -163.749725 -249.01825]\n",
            " ...\n",
            " [-260.686737 -689.263611 -212.414871 ... -435.114197 215.518036 -586.534]\n",
            " [636.791199 665.594666 330.556976 ... 916.042603 638.319275 506.898193]\n",
            " [-357.15625 -1043.84558 -507.16507 ... 293.789795 -379.792694 -929.421143]]\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "Training epoch 85/10000, LR=5.00e-04, Loss=-1.42931e+02, channel_BER=0.091875, BER=0.314375, duration per call: 0.02s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "llrs [[-20 -20 -20 ... 20 -20 -20]\n",
            " [-20 -20 -20 ... 20 -20 -20]\n",
            " [-20 -20 20 ... -20 -20 20]\n",
            " ...\n",
            " [-20 -20 20 ... 20 -20 20]\n",
            " [20 20 -20 ... 20 20 -20]\n",
            " [-20 -20 -20 ... 20 -20 -20]] [[-436.059326 -0.355567724 -768.505127 ... -125.125473 -248.862549 -877.756836]\n",
            " [-1066.97046 -1580.91553 -1005.24884 ... -602.765503 -1169.06409 -1096.14075]\n",
            " [-882.214294 -1309.2301 -332.816498 ... -1194.97437 -549.526184 -176.002579]\n",
            " ...\n",
            " [-252.919739 -77.3669 -236.492538 ... 31.3866596 -370.022552 170.641]\n",
            " [-433.858429 -231.658585 -12.6734457 ... -776.991089 -22.8456554 -476.199768]\n",
            " [-342.3255 -241.241241 -1011.82245 ... -168.199402 -731.522034 -873.945374]]\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "Training epoch 86/10000, LR=5.00e-04, Loss=-1.57562e+02, channel_BER=0.100625, BER=0.29375, duration per call: 0.01s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "llrs [[-20 20 -20 ... 20 -20 -20]\n",
            " [20 -20 -20 ... -20 20 -20]\n",
            " [20 -20 20 ... 20 20 20]\n",
            " ...\n",
            " [20 -20 20 ... -20 20 20]\n",
            " [-20 -20 -20 ... 20 -20 -20]\n",
            " [-20 20 -20 ... 20 -20 -20]] [[-1250.32153 -1617.44727 -1043.68237 ... -901.319641 -1442.68103 -1280.47205]\n",
            " [-1002.3941 -511.180511 -36.8515663 ... -496.735779 -715.01825 -705.426514]\n",
            " [-314.061737 -97.6398621 640.798462 ... 100.700035 -373.201752 408.603577]\n",
            " ...\n",
            " [36.3397598 238.576492 777.647461 ... 15.6332579 219.443115 643.34491]\n",
            " [-678.028809 -291.541168 -216.733932 ... 123.374268 -668.397095 -439.890106]\n",
            " [-303.711517 -14.8100548 -86.3098 ... 960.68689 -361.501801 86.8083038]]\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "Training epoch 87/10000, LR=5.00e-04, Loss=-1.61135e+02, channel_BER=0.08625, BER=0.288125, duration per call: 0.01s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "llrs [[20 20 20 ... -20 20 20]\n",
            " [20 -20 -20 ... -20 20 -20]\n",
            " [-20 20 20 ... -20 -20 20]\n",
            " ...\n",
            " [20 20 -20 ... -20 20 -20]\n",
            " [20 -20 20 ... -20 20 20]\n",
            " [20 20 -20 ... -20 20 -20]] [[123.342178 198.556793 520.691345 ... -204.346024 -209.998383 365.903351]\n",
            " [-1252.53406 -1620.65454 -1045.49585 ... -903.246094 -1444.84766 -1282.52051]\n",
            " [-949.312317 -932.855042 -763.763245 ... -419.060486 -1522.09717 -701.340393]\n",
            " ...\n",
            " [181.662766 -1013.5871 -255.958908 ... -404.598907 38.6872864 -625.9505]\n",
            " [647.179871 344.98056 393.57132 ... 366.785126 1233.94543 385.339264]\n",
            " [-71.5430222 -1039.98254 -517.603 ... -638.559814 -482.503174 -920.39]]\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "Training epoch 88/10000, LR=5.00e-04, Loss=-1.52005e+02, channel_BER=0.09875, BER=0.30125, duration per call: 0.01s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "llrs [[-20 -20 20 ... 20 -20 20]\n",
            " [20 20 -20 ... -20 20 -20]\n",
            " [-20 -20 20 ... 20 -20 20]\n",
            " ...\n",
            " [20 -20 20 ... -20 20 20]\n",
            " [-20 -20 20 ... -20 -20 20]\n",
            " [20 20 -20 ... -20 20 -20]] [[-393.141602 -58.534111 98.6092682 ... 305.683319 -572.085205 482.581116]\n",
            " [666.081848 1093.77698 130.49382 ... 177.106277 376.939331 399.668213]\n",
            " [-966.828186 -1021.70044 -463.161194 ... -494.565338 -1490.72 -338.597504]\n",
            " ...\n",
            " [-430.748657 -1236.12415 135.721542 ... -649.48291 58.5937576 -425.442749]\n",
            " [670.266541 329.206329 541.713196 ... 408.41452 295.569427 546.059]\n",
            " [12.7007256 -667.108826 8.59072304 ... -279.516846 523.876404 -593.358032]]\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "Training epoch 89/10000, LR=5.00e-04, Loss=-1.46928e+02, channel_BER=0.081875, BER=0.3075, duration per call: 0.02s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "llrs [[20 20 -20 ... 20 20 -20]\n",
            " [20 20 -20 ... 20 20 -20]\n",
            " [-20 20 -20 ... -20 -20 -20]\n",
            " ...\n",
            " [-20 20 20 ... -20 -20 20]\n",
            " [20 20 -20 ... -20 20 -20]\n",
            " [20 20 20 ... 20 20 20]] [[162.681808 511.834625 -356.155487 ... 254.354263 -568.336243 -635.001648]\n",
            " [-267.47 -780.764893 -412.42218 ... -75.1794128 -998.326477 -1075.20007]\n",
            " [709.310059 847.809631 379.750275 ... 238.036072 584.956177 645.033203]\n",
            " ...\n",
            " [-834.334717 -444.104614 -259.831482 ... -804.078 -1080.61938 -197.798874]\n",
            " [-202.529327 -1372.25989 -830.844238 ... -274.371552 -732.662537 -1203.63245]\n",
            " [772.024109 998.521362 645.056824 ... 557.211 890.699829 791.524048]]\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "Training epoch 90/10000, LR=5.00e-04, Loss=-1.39051e+02, channel_BER=0.10125, BER=0.318125, duration per call: 0.02s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "llrs [[20 20 -20 ... -20 20 -20]\n",
            " [-20 -20 -20 ... 20 -20 -20]\n",
            " [20 20 20 ... -20 20 20]\n",
            " ...\n",
            " [-20 20 -20 ... 20 -20 -20]\n",
            " [20 -20 20 ... -20 20 20]\n",
            " [20 -20 -20 ... -20 20 -20]] [[420.74762 -62.4466248 -372.726227 ... -20.7296619 695.868652 -449.137085]\n",
            " [200.277145 -447.712463 -553.012512 ... 568.501831 -285.581055 -585.54364]\n",
            " [75.3742065 134.088776 169.4039 ... 0.432884 254.475174 269.415314]\n",
            " ...\n",
            " [-937.041748 -1621.34241 -867.512268 ... -527.200928 -1476.29846 -1416.27881]\n",
            " [773.302734 1000.28546 646.262146 ... 558.489807 892.248901 792.275818]\n",
            " [-1027.53491 -1574.70325 -730.895935 ... -717.568115 -1056.90283 -1340.22144]]\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "Training epoch 91/10000, LR=5.00e-04, Loss=-1.42491e+02, channel_BER=0.09375, BER=0.31375, duration per call: 0.02s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "llrs [[-20 20 -20 ... -20 -20 -20]\n",
            " [-20 20 20 ... 20 -20 20]\n",
            " [20 -20 20 ... -20 20 20]\n",
            " ...\n",
            " [20 -20 -20 ... 20 20 -20]\n",
            " [20 20 -20 ... -20 20 -20]\n",
            " [-20 -20 -20 ... -20 -20 -20]] [[-240.579544 -46.4213715 -1061.47656 ... -28.7613087 -956.123 -665.696594]\n",
            " [774.618347 1001.90045 647.595398 ... 559.60083 893.479736 793.716858]\n",
            " [-728.907776 -1009.02264 -535.497559 ... -970.679626 -489.191772 -218.361084]\n",
            " ...\n",
            " [892.481812 526.252319 286.099487 ... 83.8503189 750.635742 465.233215]\n",
            " [102.552 32.2298546 -520.571045 ... -829.892273 170.320953 -579.668762]\n",
            " [-1261.6333 -1631.69153 -1054.72522 ... -911.520386 -1455.05432 -1292.75964]]\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "Training epoch 92/10000, LR=5.00e-04, Loss=-1.54344e+02, channel_BER=0.096875, BER=0.2975, duration per call: 0.03s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "llrs [[20 -20 -20 ... -20 20 -20]\n",
            " [-20 20 20 ... -20 -20 20]\n",
            " [-20 20 20 ... -20 -20 20]\n",
            " ...\n",
            " [20 -20 -20 ... 20 20 -20]\n",
            " [-20 20 20 ... -20 -20 20]\n",
            " [20 -20 20 ... 20 20 20]] [[-982.878357 -880.935547 -388.020569 ... -1071.97375 -399.521057 -521.292419]\n",
            " [-1263.98718 -1634.50623 -1056.89014 ... -913.697144 -1457.60693 -1295.19519]\n",
            " [-882.040588 -229.962402 -758.321472 ... -116.362572 -971.41 -688.391907]\n",
            " ...\n",
            " [-142.181595 -558.917908 -340.988434 ... 121.801163 433.99527 -709.943665]\n",
            " [-592.516357 -158.509933 71.2658691 ... -619.890198 -1062.90515 -132.038986]\n",
            " [-174.542633 -957.718262 59.6984482 ... 145.339966 -556.335449 110.064705]]\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "Training epoch 93/10000, LR=5.00e-04, Loss=-1.60186e+02, channel_BER=0.086875, BER=0.2925, duration per call: 0.02s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "llrs [[-20 -20 20 ... 20 -20 20]\n",
            " [20 -20 -20 ... 20 20 -20]\n",
            " [20 -20 20 ... -20 20 20]\n",
            " ...\n",
            " [20 20 20 ... -20 20 20]\n",
            " [20 -20 20 ... 20 20 20]\n",
            " [20 -20 20 ... -20 20 20]] [[-1405.61426 -1557.93921 -721.756104 ... -700.931335 -1423.2334 -880.144043]\n",
            " [420.30014 -5.05386782 -97.4270172 ... -232.27681 468.610291 -164.067856]\n",
            " [776.823059 1004.4317 649.74231 ... 561.810913 895.946411 796.352112]\n",
            " ...\n",
            " [-93.8891296 -124.16082 179.624039 ... -544.029114 -418.421112 109.869324]\n",
            " [559.790833 375.455933 390.477936 ... -89.04776 167.261414 306.476654]\n",
            " [776.243103 1003.94067 650.340454 ... 561.218079 895.274536 795.822632]]\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "Training epoch 94/10000, LR=5.00e-04, Loss=-1.46086e+02, channel_BER=0.086875, BER=0.308125, duration per call: 0.02s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "llrs [[-20 -20 -20 ... 20 -20 -20]\n",
            " [20 -20 20 ... 20 20 20]\n",
            " [20 20 -20 ... -20 20 -20]\n",
            " ...\n",
            " [-20 20 -20 ... -20 -20 -20]\n",
            " [20 -20 -20 ... 20 20 -20]\n",
            " [-20 -20 20 ... 20 -20 20]] [[-120.529404 592.583191 -59.1968193 ... 400.233917 67.3753815 154.809052]\n",
            " [53.1091728 236.072861 752.247 ... 533.597717 81.9635391 299.337769]\n",
            " [423.496735 -0.089996621 -96.3374405 ... -229.578278 469.722382 -159.210709]\n",
            " ...\n",
            " [376.930695 -174.437241 -739.384827 ... -579.829773 -49.0011368 -400.683777]\n",
            " [962.324768 684.592957 557.365723 ... 405.96405 1063.30347 616.606689]\n",
            " [3.57586956 531.48114 1033.11243 ... -134.60704 60.7059212 402.411163]]\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "Training epoch 95/10000, LR=5.00e-04, Loss=-1.46583e+02, channel_BER=0.089375, BER=0.3075, duration per call: 0.02s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "llrs [[20 -20 -20 ... 20 20 -20]\n",
            " [20 20 -20 ... -20 20 -20]\n",
            " [-20 -20 20 ... -20 -20 20]\n",
            " ...\n",
            " [-20 -20 -20 ... 20 -20 -20]\n",
            " [-20 -20 20 ... 20 -20 20]\n",
            " [-20 20 -20 ... 20 -20 -20]] [[626.050598 -390.811188 -361.736633 ... 714.754517 304.562469 -119.310181]\n",
            " [794.413086 738.562683 215.687622 ... 180.446365 755.304749 66.2787323]\n",
            " [-457.066376 -711.23761 -407.016174 ... -952.949768 -694.214905 -22.7294941]\n",
            " ...\n",
            " [260.027069 465.633942 238.733322 ... 200.202194 610.536926 173.75618]\n",
            " [-1194.76855 -1826.77771 -749.490479 ... -925.671 -1211.71045 -999.754517]\n",
            " [-1270.89465 -1642.63428 -1063.32825 ... -920.166931 -1465.16174 -1302.37439]]\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "Training epoch 96/10000, LR=5.00e-04, Loss=-1.53291e+02, channel_BER=0.084375, BER=0.3, duration per call: 0.02s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "llrs [[20 -20 20 ... 20 20 20]\n",
            " [20 -20 -20 ... 20 20 -20]\n",
            " [20 20 -20 ... 20 20 -20]\n",
            " ...\n",
            " [-20 -20 -20 ... -20 -20 -20]\n",
            " [-20 20 -20 ... 20 -20 -20]\n",
            " [20 20 -20 ... 20 20 -20]] [[-193.912888 -86.9558868 194.412918 ... 793.208618 -234.063644 -166.773804]\n",
            " [323.673981 -725.394165 -521.059631 ... 680.358765 486.133453 -346.82605]\n",
            " [-351.074585 -362.494751 -226.591049 ... 62.1839752 -301.952179 -1303.28723]\n",
            " ...\n",
            " [-1273.17993 -1645.27405 -1065.44592 ... -922.291565 -1467.65137 -1304.73535]\n",
            " [-956.676086 -1001.30164 -1268.94336 ... -778.293701 -682.455 -1273.26672]\n",
            " [-236.314957 239.79425 526.694824 ... 72.8111877 95.2519684 -288.740662]]\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "Training epoch 97/10000, LR=5.00e-04, Loss=-1.43884e+02, channel_BER=0.095, BER=0.31125, duration per call: 0.02s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "llrs [[20 -20 20 ... -20 20 20]\n",
            " [-20 20 -20 ... -20 -20 -20]\n",
            " [20 -20 20 ... 20 20 20]\n",
            " ...\n",
            " [-20 -20 -20 ... -20 -20 -20]\n",
            " [20 20 -20 ... 20 20 -20]\n",
            " [20 -20 -20 ... 20 20 -20]] [[14.0156631 -316.155182 462.223541 ... -84.2668457 682.367249 296.849915]\n",
            " [-41.975071 122.933746 -688.252502 ... -246.031311 -228.495102 -433.682281]\n",
            " [-761.482788 -516.575 -272.962982 ... -97.2583084 -356.430573 -111.047325]\n",
            " ...\n",
            " [-1275.01025 -1646.26331 -1066.00183 ... -926.236694 -1468.95679 -1305.8606]\n",
            " [-12.3024311 502.649109 -215.907013 ... -148.645248 -143.900146 -597.448303]\n",
            " [829.697205 -532.337646 -56.8764038 ... 534.643494 70.5250549 -134.851242]]\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "Training epoch 98/10000, LR=5.00e-04, Loss=-1.53907e+02, channel_BER=0.09875, BER=0.298125, duration per call: 0.02s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "llrs [[-20 -20 20 ... 20 -20 20]\n",
            " [-20 20 -20 ... -20 -20 -20]\n",
            " [-20 -20 -20 ... 20 -20 -20]\n",
            " ...\n",
            " [20 20 20 ... 20 20 20]\n",
            " [20 20 -20 ... 20 20 -20]\n",
            " [20 -20 20 ... 20 20 20]] [[-1146.79773 -679.76062 153.957016 ... -320.728424 -609.084351 -276.332916]\n",
            " [-1119.6488 -1166.5813 -1072.42 ... -590.372864 -1046.34583 -961.027527]\n",
            " [-313.208527 -138.670425 -656.278137 ... 345.79718 -436.689484 -289.313751]\n",
            " ...\n",
            " [554.145 599.251526 364.792328 ... 592.344177 647.028198 310.541504]\n",
            " [776.103 993.875671 638.677795 ... 587.996033 889.53717 787.260925]\n",
            " [-17.9091892 188.002197 757.186035 ... -258.37326 -117.08786 675.57135]]\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "Training epoch 99/10000, LR=5.00e-04, Loss=-1.52425e+02, channel_BER=0.089375, BER=0.30125, duration per call: 0.01s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "llrs [[-20 -20 20 ... -20 -20 20]\n",
            " [-20 -20 -20 ... 20 -20 -20]\n",
            " [-20 20 20 ... -20 -20 20]\n",
            " ...\n",
            " [-20 -20 20 ... 20 -20 20]\n",
            " [20 20 -20 ... 20 20 -20]\n",
            " [20 -20 -20 ... -20 20 -20]] [[-597.959351 -1003.82104 -186.513535 ... -1203.35364 -759.445557 45.2241325]\n",
            " [73.4834061 -341.57074 -333.650574 ... 596.370239 -259.557343 -635.89032]\n",
            " [-1148.9176 -321.079926 -240.889053 ... -65.1786041 -1273.72083 -185.518448]\n",
            " ...\n",
            " [-592.139832 -625.864746 -128.122086 ... 261.803101 -1064.047 -468.000214]\n",
            " [-30.4262314 -606.438843 -121.747719 ... 540.953613 -432.392395 -765.883728]\n",
            " [-1280.07556 -1652.8811 -1071.48633 ... -929.255554 -1475.01318 -1311.54834]]\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "Training epoch 100/10000, LR=5.00e-04, Loss=-1.44697e+02, channel_BER=0.08125, BER=0.31125, duration per call: 0.02s\n",
            "Saved weights to /content/drive/My Drive/ECC_weights/ECCT_dims128.h5-1\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "llrs [[20 -20 20 ... -20 20 20]\n",
            " [-20 20 -20 ... 20 -20 -20]\n",
            " [-20 20 -20 ... 20 -20 -20]\n",
            " ...\n",
            " [-20 20 -20 ... -20 -20 -20]\n",
            " [-20 20 -20 ... 20 -20 -20]\n",
            " [-20 -20 -20 ... 20 -20 -20]] [[-433.621613 -1260.87122 138.938843 ... -665.536194 61.2377167 -428.974243]\n",
            " [-324.58255 344.69455 -354.87262 ... 60.4173698 -919.736084 -206.528763]\n",
            " [-1282.67249 -1656.01221 -1074.02087 ... -931.076538 -1477.97729 -1314.30615]\n",
            " ...\n",
            " [-255.144638 -564.893188 -1039.21387 ... -839.020569 -858.625183 -605.318359]\n",
            " [-1282.67847 -1656.0155 -1074.02393 ... -931.082 -1477.98303 -1314.31274]\n",
            " [-811.372192 -201.228287 -751.028259 ... -262.694458 -1212.9303 -850.936401]]\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "Training epoch 101/10000, LR=5.00e-04, Loss=-1.46065e+02, channel_BER=0.09, BER=0.308125, duration per call: 0.02s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "llrs [[-20 20 20 ... -20 -20 20]\n",
            " [-20 -20 -20 ... 20 -20 -20]\n",
            " [-20 -20 -20 ... 20 -20 -20]\n",
            " ...\n",
            " [20 -20 20 ... -20 20 20]\n",
            " [-20 20 -20 ... 20 -20 -20]\n",
            " [-20 20 -20 ... -20 -20 -20]] [[-1468.97375 -1332.30652 -978.968567 ... -772.566101 -1646.67944 -1132.55737]\n",
            " [-688.28772 -1217.18469 -1497.2019 ... -527.709 -909.527466 -1102.17358]\n",
            " [-75.9126205 -306.86911 -482.782562 ... 505.034149 42.2593918 -333.453308]\n",
            " ...\n",
            " [-0.785282 268.412537 1012.76483 ... 32.5701332 148.15535 892.598267]\n",
            " [-325.818329 345.178802 -355.686035 ... 60.4309349 -921.491333 -207.229233]\n",
            " [-256.950836 -552.748169 -1010.61682 ... -876.766357 -854.307 -592.081299]]\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "Training epoch 102/10000, LR=5.00e-04, Loss=-1.50473e+02, channel_BER=0.0975, BER=0.30375, duration per call: 0.02s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "llrs [[20 -20 -20 ... -20 20 -20]\n",
            " [-20 -20 20 ... 20 -20 20]\n",
            " [-20 20 -20 ... -20 -20 -20]\n",
            " ...\n",
            " [20 -20 20 ... 20 20 20]\n",
            " [-20 -20 20 ... 20 -20 20]\n",
            " [20 -20 -20 ... 20 20 -20]] [[-1301.95312 -1178.80933 -1061.43311 ... -947.49469 -974.075195 -1375.29626]\n",
            " [-1287.65771 -1661.59766 -1078.42407 ... -935.450745 -1483.42859 -1319.19885]\n",
            " [-1019.35095 -850.310181 -746.775574 ... -981.158813 -821.194763 -688.794]\n",
            " ...\n",
            " [1.40031648 -185.60083 146.103455 ... 268.45755 136.811371 -244.262146]\n",
            " [276.483398 61.9664955 796.733521 ... 291.847687 -74.5697 1076.59631]\n",
            " [611.181091 345.930176 258.611694 ... 257.226166 882.526123 287.315155]]\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "Training epoch 103/10000, LR=5.00e-04, Loss=-1.60483e+02, channel_BER=0.08875, BER=0.29125, duration per call: 0.01s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "llrs [[-20 -20 20 ... -20 -20 20]\n",
            " [20 -20 -20 ... 20 20 -20]\n",
            " [20 -20 -20 ... -20 20 -20]\n",
            " ...\n",
            " [20 20 20 ... -20 20 20]\n",
            " [20 -20 20 ... -20 20 20]\n",
            " [20 20 20 ... -20 20 20]] [[-663.60321 -1161.78516 -47.6861954 ... -620.662354 5.760324 142.440369]\n",
            " [446.006287 -536.830383 -439.601 ... 852.979 593.518066 -47.6971283]\n",
            " [-1289.07532 -1664.12549 -1080.34912 ... -936.027222 -1484.47229 -1320.5614]\n",
            " ...\n",
            " [263.200226 546.351562 816.39032 ... 279.037689 436.345551 1023.82935]\n",
            " [790.046 1019.34882 661.743591 ... 574.209351 910.389038 809.383]\n",
            " [790.195923 1019.49219 661.823669 ... 574.267944 910.435486 809.513794]]\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "Training epoch 104/10000, LR=5.00e-04, Loss=-1.37595e+02, channel_BER=0.08625, BER=0.31875, duration per call: 0.01s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "llrs [[-20 20 -20 ... 20 -20 -20]\n",
            " [20 -20 -20 ... 20 20 -20]\n",
            " [-20 20 20 ... -20 -20 20]\n",
            " ...\n",
            " [-20 -20 20 ... -20 -20 20]\n",
            " [-20 20 20 ... 20 -20 20]\n",
            " [-20 -20 20 ... 20 -20 20]] [[-885.861511 -306.42749 -736.144165 ... -231.355453 -1306.49341 -259.189514]\n",
            " [1153.20825 371.019623 344.657196 ... 234.01355 933.322083 360.786804]\n",
            " [-1441.53967 -1395.62646 -896.529175 ... -786.971 -1366.39331 -1100.82605]\n",
            " ...\n",
            " [136.285126 582.387634 406.359222 ... -385.91568 334.956268 663.065186]\n",
            " [202.219086 -122.935959 -598.260376 ... 683.478149 -267.270874 108.758545]\n",
            " [-1172.85901 -730.69519 -253.087051 ... -328.634247 -1380.62512 -83.3000183]]\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "Training epoch 105/10000, LR=5.00e-04, Loss=-1.26101e+02, channel_BER=0.09125, BER=0.33375, duration per call: 0.01s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "llrs [[-20 -20 -20 ... -20 -20 -20]\n",
            " [20 20 20 ... 20 20 20]\n",
            " [20 20 -20 ... -20 20 -20]\n",
            " ...\n",
            " [20 -20 20 ... 20 20 20]\n",
            " [20 -20 -20 ... 20 20 -20]\n",
            " [-20 20 20 ... 20 -20 20]] [[-1295.16846 -1670.07117 -1084.97949 ... -941.548462 -1491.55017 -1326.52893]\n",
            " [-105.697586 -1141.69971 131.799881 ... 301.363831 -76.7114258 69.9793243]\n",
            " [930.101807 123.891724 226.918655 ... 206.729233 1071.349 193.244278]\n",
            " ...\n",
            " [-496.638855 -112.123764 820.61554 ... -308.418549 58.5148163 482.452545]\n",
            " [79.1161575 -193.286682 -196.63649 ... 194.529404 931.503845 -76.1712189]\n",
            " [792.956604 1022.56384 664.233459 ... 576.470032 913.213318 812.099731]]\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "Training epoch 106/10000, LR=5.00e-04, Loss=-1.34922e+02, channel_BER=0.09375, BER=0.32125, duration per call: 0.01s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "llrs [[-20 20 20 ... -20 -20 20]\n",
            " [20 20 20 ... -20 20 20]\n",
            " [-20 -20 20 ... 20 -20 20]\n",
            " ...\n",
            " [-20 20 -20 ... -20 -20 -20]\n",
            " [20 20 -20 ... 20 20 -20]\n",
            " [-20 20 20 ... -20 -20 20]] [[-939.822388 567.577271 602.894104 ... -545.9 -615.937683 256.835968]\n",
            " [537.536743 563.69751 328.143463 ... 114.431709 411.268951 967.822144]\n",
            " [-601.277405 -416.740021 -261.053406 ... -181.156143 -1008.55615 33.4209404]\n",
            " ...\n",
            " [-760.376587 100.602798 -416.06131 ... -526.837585 206.464859 -900.072266]\n",
            " [233.240189 -334.140747 -323.916962 ... 789.719421 -147.854935 -646.82489]\n",
            " [-629.552856 323.292633 268.664368 ... -1051.35278 -632.263794 444.20755]]\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "Training epoch 107/10000, LR=5.00e-04, Loss=-1.57488e+02, channel_BER=0.094375, BER=0.294375, duration per call: 0.01s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "llrs [[-20 20 -20 ... 20 -20 -20]\n",
            " [20 -20 20 ... -20 20 20]\n",
            " [20 -20 -20 ... -20 20 -20]\n",
            " ...\n",
            " [20 20 20 ... -20 20 20]\n",
            " [20 -20 20 ... -20 20 20]\n",
            " [-20 20 20 ... -20 -20 20]] [[-1300.25073 -1675.8645 -1089.46704 ... -945.183044 -1496.97546 -1331.55164]\n",
            " [464.791931 1015.34924 475.302765 ... 186.217422 937.178101 940.155457]\n",
            " [731.905945 872.124 397.458527 ... 251.755829 604.278137 667.139832]\n",
            " ...\n",
            " [636.596558 532.14917 668.629517 ... 235.56134 486.251923 463.911377]\n",
            " [315.617096 519.103088 603.159668 ... -134.794815 820.783142 668.810303]\n",
            " [-1174.75745 -475.532593 -371.342041 ... -276.154449 -1222.98474 -231.856125]]\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "Training epoch 108/10000, LR=5.00e-04, Loss=-1.37793e+02, channel_BER=0.088125, BER=0.320625, duration per call: 0.01s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "llrs [[-20 20 -20 ... 20 -20 -20]\n",
            " [20 20 20 ... 20 20 20]\n",
            " [20 -20 -20 ... 20 20 -20]\n",
            " ...\n",
            " [-20 -20 20 ... 20 -20 20]\n",
            " [-20 20 20 ... 20 -20 20]\n",
            " [20 -20 -20 ... 20 20 -20]] [[-1302.75586 -1678.75952 -1091.81152 ... -947.01416 -1499.77136 -1334.22253]\n",
            " [796.955322 1027.02539 667.853577 ... 579.291321 917.575684 816.507263]\n",
            " [33.978241 -899.512 -576.138428 ... -58.439003 294.450958 -996.420044]\n",
            " ...\n",
            " [-294.382812 -334.806427 283.197083 ... 524.793701 -937.646606 317.780823]\n",
            " [797.168823 1027.32434 667.981262 ... 579.487732 917.791 816.298218]\n",
            " [-213.632263 -360.580566 -457.341492 ... -666.910278 683.017944 -277.647217]]\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "Training epoch 109/10000, LR=5.00e-04, Loss=-1.47197e+02, channel_BER=0.095625, BER=0.305625, duration per call: 0.01s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "llrs [[-20 20 20 ... 20 -20 20]\n",
            " [20 20 20 ... -20 20 20]\n",
            " [20 -20 20 ... 20 20 20]\n",
            " ...\n",
            " [-20 -20 20 ... 20 -20 20]\n",
            " [20 20 -20 ... -20 20 -20]\n",
            " [20 -20 -20 ... -20 20 -20]] [[798.4599 1028.78137 669.159485 ... 580.358582 919.164612 817.615051]\n",
            " [-190.527664 247.408401 974.042 ... -277.198486 -142.38623 704.655762]\n",
            " [113.939087 215.199188 411.668213 ... -294.122925 316.932037 892.981079]\n",
            " ...\n",
            " [-50.6875076 315.818878 646.126465 ... -270.652252 -142.224869 731.625305]\n",
            " [296.738739 -675.439514 -489.050293 ... -457.539978 517.600342 -670.625427]\n",
            " [-1305.45776 -1681.97083 -1094.18311 ... -948.882263 -1502.68225 -1336.77759]]\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "Training epoch 110/10000, LR=5.00e-04, Loss=-1.46811e+02, channel_BER=0.089375, BER=0.3075, duration per call: 0.01s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "llrs [[20 -20 -20 ... -20 20 -20]\n",
            " [-20 20 20 ... -20 -20 20]\n",
            " [-20 20 -20 ... -20 -20 -20]\n",
            " ...\n",
            " [20 -20 -20 ... -20 20 -20]\n",
            " [-20 -20 20 ... -20 -20 20]\n",
            " [-20 -20 20 ... -20 -20 20]] [[-890.497559 -803.369873 -306.93158 ... -1056.66992 -351.191772 -434.561]\n",
            " [-641.547546 186.168701 -4.54205799 ... -166.390625 -372.555817 292.398285]\n",
            " [-1307.99207 -1684.84937 -1096.46899 ... -950.709229 -1505.35596 -1339.33887]\n",
            " ...\n",
            " [-620.275146 -198.75502 -378.489136 ... -1044.69824 -342.538452 -1067.28162]\n",
            " [-605.765503 -790.006592 -247.277039 ... -680.201294 -284.191681 -23.3857498]\n",
            " [-965.310852 -1108.66174 -516.069458 ... -921.406433 -603.608887 -444.671448]]\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "Training epoch 111/10000, LR=5.00e-04, Loss=-1.32229e+02, channel_BER=0.1, BER=0.325625, duration per call: 0.01s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "llrs [[20 20 20 ... 20 20 20]\n",
            " [-20 20 -20 ... -20 -20 -20]\n",
            " [-20 -20 20 ... -20 -20 20]\n",
            " ...\n",
            " [-20 20 20 ... -20 -20 20]\n",
            " [20 20 20 ... -20 20 20]\n",
            " [-20 -20 -20 ... -20 -20 -20]] [[801.184387 1031.91943 671.762817 ... 582.327698 922.12146 820.478821]\n",
            " [-1310.54211 -1687.52136 -1098.6748 ... -952.569092 -1507.97827 -1341.76135]\n",
            " [78.3959198 -17.1511745 -89.1220703 ... -917.973206 220.1474 414.796753]\n",
            " ...\n",
            " [-1674.20679 -1029.56836 -775.469666 ... -606.756226 -1531.94861 -885.77356]\n",
            " [-128.557114 -811.729614 -38.0030556 ... -34.8580742 -113.205688 -320.607697]\n",
            " [-1310.47778 -1687.802 -1098.89563 ... -952.586121 -1508.14099 -1341.99683]]\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "Training epoch 112/10000, LR=5.00e-04, Loss=-1.42724e+02, channel_BER=0.096875, BER=0.31, duration per call: 0.01s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "llrs [[20 20 -20 ... 20 20 -20]\n",
            " [-20 20 -20 ... 20 -20 -20]\n",
            " [-20 20 -20 ... -20 -20 -20]\n",
            " ...\n",
            " [-20 20 20 ... -20 -20 20]\n",
            " [-20 20 20 ... 20 -20 20]\n",
            " [-20 -20 -20 ... 20 -20 -20]] [[-13.8236132 844.716736 -156.883255 ... 442.851 -444.53717 -399.019562]\n",
            " [-1312.92029 -1690.54529 -1101.23816 ... -954.48114 -1510.78552 -1344.58325]\n",
            " [-975.282654 -1519.12854 -1326.45886 ... -792.97644 -1225.28052 -1258.01575]\n",
            " ...\n",
            " [-1312.87109 -1690.47791 -1101.17236 ... -954.507446 -1510.73474 -1344.51392]\n",
            " [426.538635 1126.42224 738.445679 ... 765.282227 626.614319 484.897614]\n",
            " [-708.921 -1240.45886 -1529.86707 ... -543.122253 -933.321838 -1132.12097]]\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "Training epoch 113/10000, LR=5.00e-04, Loss=-1.32262e+02, channel_BER=0.08875, BER=0.325625, duration per call: 0.01s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "llrs [[-20 20 -20 ... 20 -20 -20]\n",
            " [-20 -20 -20 ... -20 -20 -20]\n",
            " [20 20 -20 ... -20 20 -20]\n",
            " ...\n",
            " [20 -20 -20 ... -20 20 -20]\n",
            " [-20 20 20 ... -20 -20 20]\n",
            " [20 -20 20 ... -20 20 20]] [[-855.66571 -845.784241 -1064.01477 ... -592.613953 -1586.18872 -839.471252]\n",
            " [-1312.73865 -1691.79346 -1105.36597 ... -955.066467 -1511.18 -1346.59778]\n",
            " [739.190735 880.416748 402.01358 ... 255.769989 609.854065 673.325623]\n",
            " ...\n",
            " [-1315.41 -1693.28467 -1103.60461 ... -956.39679 -1513.47156 -1347.1842]\n",
            " [-63.1952477 541.830444 639.137634 ... -112.694122 464.75705 1166.94641]\n",
            " [804.023865 1035.03711 674.535461 ... 584.544556 925.203918 823.480347]]\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "Training epoch 114/10000, LR=5.00e-04, Loss=-1.48622e+02, channel_BER=0.093125, BER=0.305625, duration per call: 0.01s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "llrs [[-20 20 20 ... -20 -20 20]\n",
            " [-20 20 -20 ... 20 -20 -20]\n",
            " [20 -20 -20 ... 20 20 -20]\n",
            " ...\n",
            " [20 -20 -20 ... 20 20 -20]\n",
            " [-20 -20 -20 ... 20 -20 -20]\n",
            " [20 20 20 ... -20 20 20]] [[-298.770386 -337.191833 285.755096 ... 528.503418 -946.006653 320.518768]\n",
            " [-1317.97778 -1696.17261 -1105.98254 ... -958.457642 -1516.27368 -1349.82971]\n",
            " [-20.985281 73.9804535 117.505493 ... 636.316406 451.748596 -411.62558]\n",
            " ...\n",
            " [491.742126 314.998199 370.110077 ... 74.5106049 1002.91162 211.204636]\n",
            " [325.462219 -7.53654575 -308.298676 ... -93.5935593 435.909546 5.45120239]\n",
            " [27.5921745 847.749 442.00177 ... 47.7519913 -302.56427 -311.807861]]\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "Training epoch 115/10000, LR=5.00e-04, Loss=-1.46471e+02, channel_BER=0.09625, BER=0.308125, duration per call: 0.01s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "llrs [[20 -20 20 ... -20 20 20]\n",
            " [-20 20 20 ... 20 -20 20]\n",
            " [20 -20 20 ... 20 20 20]\n",
            " ...\n",
            " [20 20 -20 ... -20 20 -20]\n",
            " [20 -20 -20 ... 20 20 -20]\n",
            " [20 -20 20 ... 20 20 20]] [[468.973907 866.420471 904.110107 ... 423.555603 642.173828 741.079346]\n",
            " [-404.717743 -416.185852 -596.667053 ... 45.7329407 -549.454346 105.620262]\n",
            " [-1211.85583 -585.007263 -364.031982 ... -604.892883 -1046.58862 -614.104797]\n",
            " ...\n",
            " [993.857056 706.521484 577.097351 ... 421.25119 1095.83923 636.627686]\n",
            " [272.559357 -1109.62109 -800.781494 ... 220.924271 37.7568398 -861.006897]\n",
            " [806.611633 1037.59705 676.627686 ... 587.490967 927.973877 825.838684]]\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "Training epoch 116/10000, LR=5.00e-04, Loss=-1.58110e+02, channel_BER=0.085625, BER=0.29, duration per call: 0.01s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "llrs [[20 20 20 ... -20 20 20]\n",
            " [-20 -20 20 ... -20 -20 20]\n",
            " [20 -20 20 ... -20 20 20]\n",
            " ...\n",
            " [20 -20 -20 ... 20 20 -20]\n",
            " [20 20 -20 ... -20 20 -20]\n",
            " [20 -20 20 ... 20 20 20]] [[-245.052368 -299.244446 112.947357 ... -586.842712 -338.75708 6.31499958]\n",
            " [-674.156433 -776.887085 -457.088684 ... -1302.51245 -1005.14209 -215.38562]\n",
            " [657.848877 535.082 805.996216 ... 260.634491 814.130066 553.686]\n",
            " ...\n",
            " [-697.321777 -1232.70544 -808.693115 ... -972.374756 -272.396637 -1104.9613]\n",
            " [963.363098 670.361572 561.017883 ... 419.836731 1120.02795 614.261475]\n",
            " [197.858063 -146.458237 191.183578 ... 583.166504 427.039032 -55.0795746]]\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "Training epoch 117/10000, LR=5.00e-04, Loss=-1.54906e+02, channel_BER=0.089375, BER=0.2975, duration per call: 0.01s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "llrs [[20 -20 20 ... 20 20 20]\n",
            " [-20 20 20 ... -20 -20 20]\n",
            " [-20 20 -20 ... 20 -20 -20]\n",
            " ...\n",
            " [20 20 20 ... 20 20 20]\n",
            " [20 -20 20 ... -20 20 20]\n",
            " [20 -20 -20 ... 20 20 -20]] [[159.087357 505.328613 716.348572 ... 411.367889 825.6073 491.18222]\n",
            " [-1398.07324 -1187.8136 -927.682373 ... -645.92926 -1599.68408 -885.467529]\n",
            " [-1175.22754 -1198.95374 -1240.73938 ... -635.788 -1407.59961 -1083.61548]\n",
            " ...\n",
            " [809.847229 1041.54236 679.778076 ... 589.205444 931.457825 829.215576]\n",
            " [338.634521 -352.783478 172.852783 ... -257.776947 363.499695 -375.888641]\n",
            " [160.585815 -1027.41748 -822.302795 ... -81.7991 261.963501 -973.37854]]\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "Training epoch 118/10000, LR=5.00e-04, Loss=-1.41657e+02, channel_BER=0.089375, BER=0.31125, duration per call: 0.02s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "llrs [[-20 -20 -20 ... 20 -20 -20]\n",
            " [-20 20 20 ... 20 -20 20]\n",
            " [20 -20 -20 ... 20 20 -20]\n",
            " ...\n",
            " [20 20 20 ... -20 20 20]\n",
            " [-20 -20 -20 ... -20 -20 -20]\n",
            " [-20 -20 -20 ... 20 -20 -20]] [[-1328.37976 -1707.94409 -1115.13586 ... -966.673 -1527.49634 -1360.0376]\n",
            " [-299.964386 -1030.46057 -689.166199 ... -45.3554115 -1152.4856 -1015.49457]\n",
            " [290.628845 -823.139709 -728.27594 ... 91.0058 368.350891 -658.96936]\n",
            " ...\n",
            " [-146.455521 202.833237 653.170105 ... -719.181 -59.0831146 282.204651]\n",
            " [-1328.41675 -1707.94104 -1115.23755 ... -966.729797 -1527.54968 -1360.09827]\n",
            " [-22.3425961 -398.318054 -81.8733139 ... -605.838 10.7491169 -29.9846096]]\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "Training epoch 119/10000, LR=5.00e-04, Loss=-1.48821e+02, channel_BER=0.095625, BER=0.3025, duration per call: 0.02s\n",
            "x_nodes TensorShape([160, 15, 1])\n",
            "attn_output TensorShape([160, 15, 128])\n",
            "ffn_output TensorShape([160, 15, 128])\n",
            "x_nodes TensorShape([160, 15, 128])\n",
            "llrs [[20 -20 20 ... -20 20 20]\n",
            " [20 -20 20 ... -20 20 20]\n",
            " [-20 20 -20 ... -20 -20 -20]\n",
            " ...\n",
            " [20 20 -20 ... 20 20 -20]\n",
            " [20 -20 20 ... 20 20 20]\n",
            " [20 -20 20 ... -20 20 20]] [[812.376 1044.04321 682.064758 ... 591.10791 934.192078 832.455139]\n",
            " [613.186096 732.333496 616.558655 ... 450.706055 738.228271 1134.50476]\n",
            " [-185.052856 238.756271 -487.247498 ... -236.932327 -214.910446 -500.703217]\n",
            " ...\n",
            " [812.765 1044.81836 682.06189 ... 591.447571 934.423096 831.78009]\n",
            " [160.625031 521.281921 742.928894 ... 386.235504 836.551392 507.555786]\n",
            " [812.720093 1044.69397 682.296875 ... 591.438293 934.52948 831.985962]]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-38-cf61e6f60142>\u001b[0m in \u001b[0;36m<cell line: 185>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m \u001b[0mtrain_dec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me2e_ltd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ECCT_dims128.h5-1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvisualize_decoder_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-38-cf61e6f60142>\u001b[0m in \u001b[0;36mtrain_dec\u001b[0;34m(model, args, file_name, save_path, visualize_decoder_weights)\u001b[0m\n\u001b[1;32m    160\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Training Model...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m         train_step(model, \n\u001b[0m\u001b[1;32m    163\u001b[0m                    \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m                    \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    831\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 832\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    833\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    866\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    867\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 868\u001b[0;31m       return tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    869\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m       )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1321\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1322\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1325\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1484\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1485\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1486\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1487\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1488\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}