{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMB+sq3kRZV+UxGLuZyzRSV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pollyjuice74/5G-Decoder/blob/main/LTD_model_reg_LDPC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "5q1VAmIeUKIn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "619f235b-e0e3-4c93-b7c4-4450576ba0f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into '5G-Decoder'...\n",
            "remote: Enumerating objects: 1494, done.\u001b[K\n",
            "remote: Counting objects: 100% (1494/1494), done.\u001b[K\n",
            "remote: Compressing objects: 100% (554/554), done.\u001b[K\n",
            "remote: Total 1494 (delta 945), reused 1462 (delta 926), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (1494/1494), 2.06 MiB | 17.76 MiB/s, done.\n",
            "Resolving deltas: 100% (945/945), done.\n",
            "Collecting sionna\n",
            "  Downloading sionna-0.19.1-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting tensorflow<2.16.0,>=2.13.0 (from sionna)\n",
            "  Downloading tensorflow-2.15.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from sionna) (1.26.4)\n",
            "Requirement already satisfied: matplotlib>=3.5.3 in /usr/local/lib/python3.10/dist-packages (from sionna) (3.8.0)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from sionna) (1.13.1)\n",
            "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.10/dist-packages (from sionna) (6.4.5)\n",
            "Collecting mitsuba<3.6.0,>=3.2.0 (from sionna)\n",
            "  Downloading mitsuba-3.5.2-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (5.1 kB)\n",
            "Collecting pythreejs>=2.4.2 (from sionna)\n",
            "  Downloading pythreejs-2.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
            "Collecting ipywidgets>=8.0.4 (from sionna)\n",
            "  Downloading ipywidgets-8.1.5-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting ipydatawidgets==4.3.2 (from sionna)\n",
            "  Downloading ipydatawidgets-4.3.2-py2.py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting jupyterlab-widgets==3.0.5 (from sionna)\n",
            "  Downloading jupyterlab_widgets-3.0.5-py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: traittypes>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from ipydatawidgets==4.3.2->sionna) (0.2.1)\n",
            "Collecting comm>=0.1.3 (from ipywidgets>=8.0.4->sionna)\n",
            "  Downloading comm-0.2.2-py3-none-any.whl.metadata (3.7 kB)\n",
            "Requirement already satisfied: ipython>=6.1.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=8.0.4->sionna) (7.34.0)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=8.0.4->sionna) (5.7.1)\n",
            "Collecting widgetsnbextension~=4.0.12 (from ipywidgets>=8.0.4->sionna)\n",
            "  Downloading widgetsnbextension-4.0.13-py3-none-any.whl.metadata (1.6 kB)\n",
            "INFO: pip is looking at multiple versions of ipywidgets to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting ipywidgets>=8.0.4 (from sionna)\n",
            "  Downloading ipywidgets-8.1.4-py3-none-any.whl.metadata (2.3 kB)\n",
            "  Downloading ipywidgets-8.1.3-py3-none-any.whl.metadata (2.4 kB)\n",
            "  Downloading ipywidgets-8.1.2-py3-none-any.whl.metadata (2.4 kB)\n",
            "  Downloading ipywidgets-8.1.1-py3-none-any.whl.metadata (2.4 kB)\n",
            "  Downloading ipywidgets-8.1.0-py3-none-any.whl.metadata (2.4 kB)\n",
            "  Downloading ipywidgets-8.0.7-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=8.0.4->sionna) (5.5.6)\n",
            "  Downloading ipywidgets-8.0.6-py3-none-any.whl.metadata (2.4 kB)\n",
            "INFO: pip is still looking at multiple versions of ipywidgets to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading ipywidgets-8.0.5-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.3->sionna) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.3->sionna) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.3->sionna) (4.55.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.3->sionna) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.3->sionna) (24.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.3->sionna) (11.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.3->sionna) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.3->sionna) (2.8.2)\n",
            "Collecting drjit==0.4.6 (from mitsuba<3.6.0,>=3.2.0->sionna)\n",
            "  Downloading drjit-0.4.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16.0,>=2.13.0->sionna) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16.0,>=2.13.0->sionna) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16.0,>=2.13.0->sionna) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16.0,>=2.13.0->sionna) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16.0,>=2.13.0->sionna) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16.0,>=2.13.0->sionna) (3.12.1)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16.0,>=2.13.0->sionna) (18.1.1)\n",
            "Collecting ml-dtypes~=0.3.1 (from tensorflow<2.16.0,>=2.13.0->sionna)\n",
            "  Downloading ml_dtypes-0.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16.0,>=2.13.0->sionna) (3.4.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16.0,>=2.13.0->sionna) (4.25.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16.0,>=2.13.0->sionna) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16.0,>=2.13.0->sionna) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16.0,>=2.13.0->sionna) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16.0,>=2.13.0->sionna) (4.12.2)\n",
            "Collecting wrapt<1.15,>=1.11.0 (from tensorflow<2.16.0,>=2.13.0->sionna)\n",
            "  Downloading wrapt-1.14.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16.0,>=2.13.0->sionna) (0.37.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16.0,>=2.13.0->sionna) (1.68.1)\n",
            "Collecting tensorboard<2.16,>=2.15 (from tensorflow<2.16.0,>=2.13.0->sionna)\n",
            "  Downloading tensorboard-2.15.2-py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting tensorflow-estimator<2.16,>=2.15.0 (from tensorflow<2.16.0,>=2.13.0->sionna)\n",
            "  Downloading tensorflow_estimator-2.15.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting keras<2.16,>=2.15.0 (from tensorflow<2.16.0,>=2.13.0->sionna)\n",
            "  Downloading keras-2.15.0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow<2.16.0,>=2.13.0->sionna) (0.45.1)\n",
            "Collecting jedi>=0.16 (from ipython>=6.1.0->ipywidgets>=8.0.4->sionna)\n",
            "  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->sionna) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->sionna) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->sionna) (3.0.48)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->sionna) (2.18.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->sionna) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->sionna) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->sionna) (4.9.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16.0,>=2.13.0->sionna) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16.0,>=2.13.0->sionna) (1.2.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16.0,>=2.13.0->sionna) (3.7)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16.0,>=2.13.0->sionna) (2.32.3)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16.0,>=2.13.0->sionna) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16.0,>=2.13.0->sionna) (3.1.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow<2.16.0,>=2.13.0->sionna) (5.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow<2.16.0,>=2.13.0->sionna) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow<2.16.0,>=2.13.0->sionna) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow<2.16.0,>=2.13.0->sionna) (1.3.1)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets>=8.0.4->sionna) (0.8.4)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets>=8.0.4->sionna) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=6.1.0->ipywidgets>=8.0.4->sionna) (0.2.13)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow<2.16.0,>=2.13.0->sionna) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow<2.16.0,>=2.13.0->sionna) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow<2.16.0,>=2.13.0->sionna) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow<2.16.0,>=2.13.0->sionna) (2024.12.14)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow<2.16.0,>=2.13.0->sionna) (3.0.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow<2.16.0,>=2.13.0->sionna) (0.6.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow<2.16.0,>=2.13.0->sionna) (3.2.2)\n",
            "Downloading sionna-0.19.1-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ipydatawidgets-4.3.2-py2.py3-none-any.whl (271 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m271.6/271.6 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jupyterlab_widgets-3.0.5-py3-none-any.whl (384 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m384.3/384.3 kB\u001b[0m \u001b[31m21.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ipywidgets-8.0.5-py3-none-any.whl (138 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.3/138.3 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mitsuba-3.5.2-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (40.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.4/40.4 MB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading drjit-0.4.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m21.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pythreejs-2.4.2-py3-none-any.whl (3.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m22.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow-2.15.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (475.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m475.2/475.2 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading keras-2.15.0-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m56.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ml_dtypes-0.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboard-2.15.2-py3-none-any.whl (5.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow_estimator-2.15.0-py2.py3-none-any.whl (441 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m442.0/442.0 kB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading widgetsnbextension-4.0.13-py3-none-any.whl (2.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading wrapt-1.14.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (77 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: wrapt, widgetsnbextension, tensorflow-estimator, ml-dtypes, keras, jupyterlab-widgets, jedi, drjit, mitsuba, ipywidgets, tensorboard, ipydatawidgets, tensorflow, pythreejs, sionna\n",
            "  Attempting uninstall: wrapt\n",
            "    Found existing installation: wrapt 1.17.0\n",
            "    Uninstalling wrapt-1.17.0:\n",
            "      Successfully uninstalled wrapt-1.17.0\n",
            "  Attempting uninstall: widgetsnbextension\n",
            "    Found existing installation: widgetsnbextension 3.6.10\n",
            "    Uninstalling widgetsnbextension-3.6.10:\n",
            "      Successfully uninstalled widgetsnbextension-3.6.10\n",
            "  Attempting uninstall: ml-dtypes\n",
            "    Found existing installation: ml-dtypes 0.4.1\n",
            "    Uninstalling ml-dtypes-0.4.1:\n",
            "      Successfully uninstalled ml-dtypes-0.4.1\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 3.5.0\n",
            "    Uninstalling keras-3.5.0:\n",
            "      Successfully uninstalled keras-3.5.0\n",
            "  Attempting uninstall: jupyterlab-widgets\n",
            "    Found existing installation: jupyterlab_widgets 3.0.13\n",
            "    Uninstalling jupyterlab_widgets-3.0.13:\n",
            "      Successfully uninstalled jupyterlab_widgets-3.0.13\n",
            "  Attempting uninstall: ipywidgets\n",
            "    Found existing installation: ipywidgets 7.7.1\n",
            "    Uninstalling ipywidgets-7.7.1:\n",
            "      Successfully uninstalled ipywidgets-7.7.1\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.17.1\n",
            "    Uninstalling tensorboard-2.17.1:\n",
            "      Successfully uninstalled tensorboard-2.17.1\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.17.1\n",
            "    Uninstalling tensorflow-2.17.1:\n",
            "      Successfully uninstalled tensorflow-2.17.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tf-keras 2.17.0 requires tensorflow<2.18,>=2.17, but you have tensorflow 2.15.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed drjit-0.4.6 ipydatawidgets-4.3.2 ipywidgets-8.0.5 jedi-0.19.2 jupyterlab-widgets-3.0.5 keras-2.15.0 mitsuba-3.5.2 ml-dtypes-0.3.2 pythreejs-2.4.2 sionna-0.19.1 tensorboard-2.15.2 tensorflow-2.15.1 tensorflow-estimator-2.15.0 widgetsnbextension-4.0.13 wrapt-1.14.1\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/pollyjuice74/5G-Decoder\n",
        "!pip install sionna"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import tensorflow as tf\n",
        "import random\n",
        "import numpy as np\n",
        "import time\n",
        "from scipy.sparse import issparse, csr_matrix\n",
        "\n",
        "from sionna.fec.utils import generate_reg_ldpc, load_parity_check_examples, LinearEncoder, gm2pcm\n",
        "from sionna.utils.plotting import PlotBER\n",
        "from sionna.fec.ldpc import LDPCBPDecoder\n",
        "\n",
        "import os\n",
        "# os.chdir('../..')\n",
        "if os.path.exists('5G-Decoder'):\n",
        "  os.rename('5G-Decoder', '5G_Decoder')\n",
        "os.chdir('5G_Decoder/adv_nn')\n",
        "\n",
        "from dataset import *\n",
        "from attention import *\n",
        "from channel import *\n",
        "from args import *\n",
        "from model_functs import *\n",
        "from models import *"
      ],
      "metadata": {
        "id": "U5U5qUUVUeRm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Loading LDPC code\")\n",
        "pcm, k, n, coderate = generate_reg_ldpc(v=3,\n",
        "                                        c=5,\n",
        "                                        n=58,\n",
        "                                        allow_flex_len=True,\n",
        "                                        verbose=True)\n",
        "\n",
        "# pcm = tf.cast(pcm, dtype=tf.int32)\n",
        "encoder = LinearEncoder(pcm, is_pcm=True, dtype=tf.int32)\n",
        "\n",
        "batch_size = 2  # For multiple codewords\n",
        "b = tf.random.uniform((batch_size, k), minval=0, maxval=2, dtype=tf.int32)\n",
        "c = encoder(b)\n",
        "print(pcm.shape, c.shape)\n",
        "pcm @ tf.transpose(c) % 2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "6RF7dBDwWg0L",
        "outputId": "b532e0cd-2153-471b-8a38-f750ce1a7080"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading LDPC code\n",
            "Setting n to:  60\n",
            "Number of edges (VN perspective):  180\n",
            "Number of edges (CN perspective):  180\n",
            "Generated regular (3,5) LDPC code of length n=60\n",
            "Code rate is r=0.400.\n",
            "Warning: The alias fec.utils.LinearEncoder will not be included in Sionna 1.0. Please use fec.linear.LinearEncoder instead.\n",
            "(36, 60) (2, 60)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(36, 2), dtype=int32, numpy=\n",
              "array([[0, 0],\n",
              "       [0, 0],\n",
              "       [0, 0],\n",
              "       [0, 0],\n",
              "       [0, 0],\n",
              "       [0, 0],\n",
              "       [0, 0],\n",
              "       [0, 0],\n",
              "       [0, 0],\n",
              "       [0, 0],\n",
              "       [0, 0],\n",
              "       [0, 0],\n",
              "       [0, 0],\n",
              "       [0, 0],\n",
              "       [0, 0],\n",
              "       [0, 0],\n",
              "       [0, 0],\n",
              "       [0, 0],\n",
              "       [0, 0],\n",
              "       [0, 0],\n",
              "       [0, 0],\n",
              "       [0, 0],\n",
              "       [0, 0],\n",
              "       [0, 0],\n",
              "       [0, 0],\n",
              "       [0, 0],\n",
              "       [0, 0],\n",
              "       [0, 0],\n",
              "       [0, 0],\n",
              "       [0, 0],\n",
              "       [0, 0],\n",
              "       [0, 0],\n",
              "       [0, 0],\n",
              "       [0, 0],\n",
              "       [0, 0],\n",
              "       [0, 0]], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# for e2e model\n",
        "from sionna.utils import BinarySource, ebnodb2no\n",
        "from sionna.mapping import Mapper, Demapper\n",
        "from sionna.channel import AWGN\n",
        "# from sionna.fec.ldpc import LDPC5GDecoder, LDPC5GEncoder\n",
        "from tensorflow.keras.layers import Layer, Dense, Dropout\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "class Args():\n",
        "    def __init__(self, model_type, code_type='LDPC', n_look_up=121, k_look_up=80, n=400, k=200,\n",
        "                       n_rings=2, ls_active=True, split_diff=True, sigma=0.1,\n",
        "                       t_layers=2, d_model=64, heads=8, lr=5e-4,\n",
        "                       batch_size=160, batch_size_eval = 150,\n",
        "                       eval_train_iter=50, save_weights_iter=100,\n",
        "                       ebno_db_eval=2.5,\n",
        "                       ebno_db_min=0., ebno_db_max=4., ebno_db_stepsize=0.25,\n",
        "                       traindata_len=500, testdata_len=250,\n",
        "                       mc_batch_size=200, mc_iters=500, epochs=1000000):\n",
        "        assert model_type in ['gen', 'dis'], \"Type must be: 'gen', Generator or 'dis', Discriminator.\"\n",
        "        assert code_type in ['POLAR', 'BCH', 'CCSDS', 'LDPC', 'MACKAY', 'LDPC5G', 'POLAR5G'], \"Invalid linear code type.\"\n",
        "\n",
        "        # model data\n",
        "        self.model_type = model_type\n",
        "\n",
        "        self.split_diff = split_diff\n",
        "        self.n_rings = n_rings # ring connectivity of mask\n",
        "        self.sigma = sigma\n",
        "        self.t_layers = t_layers\n",
        "        self.ls_active = ls_active\n",
        "\n",
        "        self.d_model = d_model\n",
        "        self.heads = heads\n",
        "\n",
        "        # training data\n",
        "        self.lr = lr\n",
        "        self.batch_size = batch_size\n",
        "        self.traindata_len = traindata_len\n",
        "        self.testdata_len = testdata_len\n",
        "        self.epochs = epochs\n",
        "\n",
        "        self.ebno_db_min = ebno_db_min\n",
        "        self.ebno_db_max = ebno_db_max\n",
        "        self.ebno_db_stepsize = ebno_db_stepsize\n",
        "\n",
        "        self.ebno_db_eval = ebno_db_eval\n",
        "        self.eval_train_iter = eval_train_iter\n",
        "        self.save_weights_iter = save_weights_iter\n",
        "        self.batch_size_eval = batch_size_eval\n",
        "\n",
        "        # simulation\n",
        "        self.mc_batch_size = mc_batch_size\n",
        "        self.mc_iters = mc_iters\n",
        "\n",
        "        # code data\n",
        "        self.code_type = code_type\n",
        "        self.code = self.get_code(n_look_up, k_look_up) # n,k look up values in Get_Generator_and_Parity\n",
        "\n",
        "        # if self.code_type not in ['LDPC5G', 'POLAR5G']:\n",
        "        #     self.n, self.m, self.k = self.code.n, self.code.m, self.code.k\n",
        "        # else:\n",
        "        #     self.n, self.m, self.k = n, n-k, k\n",
        "\n",
        "        # self.n_steps = self.m + 5  # Number of diffusion steps\n",
        "\n",
        "    def get_code(self, n_look_up, k_look_up):\n",
        "        code = type('Code', (), {})() # class Code, no base class, no attributes/methods, () instantiate object\n",
        "        # code.n_look_up, code.k_look_up = n_look_up, k_look_up\n",
        "        # code.code_type = self.code_type\n",
        "\n",
        "        # if self.code_type not in ['LDPC5G', 'POLAR5G']:\n",
        "        #     G, H = Get_Generator_and_Parity(code)\n",
        "        #     code.G, code.H = tf.convert_to_tensor(G), csr_matrix( tf.convert_to_tensor(H) )\n",
        "\n",
        "        #     code.m, code.n = code.H.shape\n",
        "        #     code.k = code.n - code.m\n",
        "\n",
        "        return code\n",
        "\n",
        "\n",
        "from tensorflow.keras.layers import MultiHeadAttention, Dense, LayerNormalization, Dropout\n",
        "from tensorflow import einsum, multiply\n",
        "\n",
        "class LinearMHAttention( Layer ):\n",
        "    def __init__(self, num_heads, key_dim, mask_shape, mask_division_shape, dropout=0.1):\n",
        "        super().__init__()\n",
        "        assert (key_dim % num_heads) == 0, 'dimension must be divisible by the number of heads'\n",
        "        self.dims = key_dim\n",
        "        self.heads = num_heads\n",
        "        self.dim_head = self.dims // self.heads\n",
        "\n",
        "        self.k_proj = self.get_k_proj(mask_shape, mask_division_shape) # n+m\n",
        "        self.proj_k = None\n",
        "        self.proj_v = None\n",
        "\n",
        "        self.to_q, self.to_k, self.to_v = [ Dense(self.dims, use_bias=False) for _ in range(3) ]\n",
        "        self.to_out = Dense(self.dims)\n",
        "        self.dropout = Dropout(dropout) # to d-dimentional embeddings\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        n_value = input_shape[1] # (b, n, d)\n",
        "        # Creates shape (n,k_proj) proj matrices for key and value\n",
        "        self.proj_k = self.add_weight(\"proj_k\", shape=[n_value, self.k_proj], initializer=GlorotUniform())\n",
        "        self.proj_v = self.add_weight(\"proj_v\", shape=[n_value, self.k_proj], initializer=GlorotUniform())\n",
        "\n",
        "    def get_k_proj(self, mask_shape, mask_division_shape):\n",
        "        mask_length = mask_shape[1] # mask_shape (b, n+m, n+m)\n",
        "        # gets dimention for linear tranformer vector projection\n",
        "        for k_proj in range(mask_length // mask_division_shape, 0, -1): # starts at half the mask length to 0\n",
        "            if mask_length % k_proj == 0:\n",
        "                return tf.cast(k_proj, tf.int32)\n",
        "\n",
        "    def call(self, query, value, key=None, attention_mask=None, training=False): # O(n)\n",
        "        shape = tf.shape(query) # (b, n, d)\n",
        "        b = tf.cast(shape[0], tf.int32)\n",
        "        n = tf.cast(shape[1], tf.int32)\n",
        "\n",
        "        key = value if key is None else key\n",
        "\n",
        "        assert query.shape[-1] is not None, \"The last dimension of x is undefined.\"\n",
        "\n",
        "        query, key, val = self.to_q(query), self.to_k(key), self.to_v(value)\n",
        "\n",
        "        # Project key and val into k-dimentional space\n",
        "        key = tf.einsum('bnd,nk->bkd', key, self.proj_k)\n",
        "        val = tf.einsum('bnd,nk->bkd', val, self.proj_v)\n",
        "\n",
        "        # Reshape splitting for heads\n",
        "        query = tf.reshape(query, (b, n, self.heads, self.dim_head))\n",
        "        key = tf.reshape(key, (b, self.k_proj, self.heads, self.dim_head))\n",
        "        val = tf.reshape(val, (b, self.k_proj, self.heads, self.dim_head))\n",
        "        query, key, val = [ tf.transpose(x, [0, 2, 1, 3]) for x in [query, key, val] ]\n",
        "\n",
        "        # Low-rank mask (n,k_proj)\n",
        "        mask = tf.expand_dims(attention_mask, axis=-1)\n",
        "        mask = tf.image.resize(mask, [n, self.k_proj], method='nearest')\n",
        "        mask = tf.reshape(mask, (1, 1, n, self.k_proj))\n",
        "\n",
        "        # Main attn logic: sftmx( q@k / d**0.5 ) @ v\n",
        "        scores = tf.einsum('bhnd,bhkd->bhnk', query, key) / (tf.sqrt( tf.cast(self.dim_head, dtype=tf.float32) ))\n",
        "        scores += (mask * -1e9) if mask is not None else 0.\n",
        "        attn = tf.nn.softmax(scores, axis=-1) # (b,h,n,k_proj)\n",
        "        attn = self.dropout(attn) if training else attn\n",
        "        out = tf.einsum('bhnk,bhkd->bhnd', attn, val)\n",
        "\n",
        "        # Reshape and pass through out layer\n",
        "        out = tf.transpose(out, [0, 2, 1, 3])\n",
        "        out = tf.reshape(out, (b, n, -1))\n",
        "        return self.to_out(out)\n",
        "\n",
        "\n",
        "class TransformerEncoderBlock(tf.keras.layers.Layer):\n",
        "    def __init__(self, d_model, num_heads, d_ff, linear, mask_shape, mask_division_shape, dropout_rate=0.1):\n",
        "        super(TransformerEncoderBlock, self).__init__()\n",
        "        self.mha = (\n",
        "            LinearMHAttention(num_heads=num_heads,\n",
        "                              key_dim=d_model,\n",
        "                              mask_shape=mask_shape,\n",
        "                              mask_division_shape=mask_division_shape,\n",
        "                              dropout=dropout_rate)\n",
        "            if linear\n",
        "            else MultiHeadAttention(num_heads=num_heads,\n",
        "                                    key_dim=d_model,\n",
        "                                    dropout=dropout_rate)\n",
        "        )\n",
        "        self.ffn = tf.keras.Sequential([\n",
        "            Dense(d_ff, activation='relu'),\n",
        "            Dense(d_model),\n",
        "        ])\n",
        "\n",
        "        self.layernorm1 = LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm2 = LayerNormalization(epsilon=1e-6)\n",
        "\n",
        "        self.dropout1 = Dropout(dropout_rate)\n",
        "        self.dropout2 = Dropout(dropout_rate)\n",
        "\n",
        "    def call(self, x, mask, training):\n",
        "        # Multi-Head Attention\n",
        "        attn_output = self.mha(x, x, attention_mask=mask, training=training)\n",
        "        attn_output = self.dropout1(attn_output, training=training)\n",
        "        out1 = self.layernorm1(x + attn_output)  # Add & Normalize\n",
        "\n",
        "        # Feedforward Network\n",
        "        ffn_output = self.ffn(out1)\n",
        "        ffn_output = self.dropout2(ffn_output, training=training)\n",
        "        out2 = self.layernorm2(out1 + ffn_output)  # Add & Normalize\n",
        "        return out2\n",
        "\n",
        "\n",
        "class Decoder( Layer ):\n",
        "    def __init__(self,\n",
        "                 args,\n",
        "                 linear=True,\n",
        "                 mask_division_shape=2,\n",
        "                 dropout_rate=0.1):\n",
        "        super().__init__()\n",
        "        code = args.code\n",
        "        self.pcm = tf.cast(code.H, dtype=tf.int32)\n",
        "\n",
        "        # shapes\n",
        "        self._m, self._n = self.pcm.shape\n",
        "        self._k = self._n - self._m\n",
        "        self.dims = args.d_model\n",
        "        self.batch_size = args.batch_size\n",
        "\n",
        "        # mask\n",
        "        self.mask = self.create_mask(self.pcm)\n",
        "        for matrix, title in zip([self.pcm, tf.squeeze(self.mask, axis=0)], [\"PCM Matrix\", \"Mask Matrix\"]):\n",
        "            plt.imshow(matrix, cmap='viridis'); plt.colorbar(); plt.title(title); plt.show()\n",
        "\n",
        "        # layers\n",
        "        self.node_embeddings = Dense(self.dims)\n",
        "        self.encoder_blocks = [\n",
        "            TransformerEncoderBlock(\n",
        "                d_model=args.d_model,\n",
        "                num_heads=args.heads,\n",
        "                d_ff=args.d_model * 4,\n",
        "                linear=linear,\n",
        "                mask_shape=self.mask.shape,\n",
        "                mask_division_shape=mask_division_shape,\n",
        "                dropout_rate=dropout_rate,\n",
        "            )\n",
        "            for _ in range(args.t_layers)\n",
        "        ]\n",
        "        self.forward_channel = Dense(1)\n",
        "        self.dropout = Dropout(dropout_rate)\n",
        "        self.to_n = Dense(self._n)\n",
        "\n",
        "    def create_mask(self, H):\n",
        "        # Initialize diagonal identity mask\n",
        "        mask = tf.eye(2 * self._n - self._k, dtype=tf.float32)\n",
        "\n",
        "        # Get indices where H == 1\n",
        "        indices = tf.where(H == 1)  # Returns (row, col) pairs where H is 1\n",
        "        check_nodes, variable_nodes = indices[:, 0], indices[:, 1]\n",
        "\n",
        "        # Step 1: Update check node to variable node connections\n",
        "        mask = tf.tensor_scatter_nd_update(mask,\n",
        "                                          tf.stack([n + check_nodes, variable_nodes], axis=1),\n",
        "                                          tf.ones_like(check_nodes, dtype=tf.float32))\n",
        "        mask = tf.tensor_scatter_nd_update(mask,\n",
        "                                          tf.stack([variable_nodes, n + check_nodes], axis=1),\n",
        "                                          tf.ones_like(check_nodes, dtype=tf.float32))\n",
        "\n",
        "        # Step 2: Update variable node connections\n",
        "        for cn in tf.unique(check_nodes)[0]:  # Iterate over unique check nodes\n",
        "            related_vns = tf.boolean_mask(variable_nodes, check_nodes == cn)\n",
        "            indices = tf.stack(tf.meshgrid(related_vns, related_vns), axis=-1)\n",
        "            indices = tf.reshape(indices, [-1, 2])  # Flatten indices\n",
        "            mask = tf.tensor_scatter_nd_update(mask, indices, tf.ones_like(indices[:, 0], dtype=tf.float32))\n",
        "\n",
        "        # Expand mask's batch size for tf MHA\n",
        "        mask = tf.expand_dims(mask, axis=0)  # Shape: (1, n+m, n+m)\n",
        "        return mask\n",
        "\n",
        "    def get_syndrome(self, vn_vector, from_llr=True):\n",
        "        \"\"\" Calculate syndrome (pcm @ r = 0) if r is correct in binary \"\"\"\n",
        "        vn_vector = tf.transpose(vn_vector) # (n,b)\n",
        "        bin_vector = llr_to_bin(vn_vector) if from_llr else vn_vector\n",
        "        return tf.cast( (self.pcm @ bin_vector) % 2, dtype=tf.float32) # (m,n)@(n,b)->(m,b)\n",
        "\n",
        "    def call(self, x_nodes, training=False):\n",
        "        # Embed cn/vn nodes vector\n",
        "        x_nodes_embedded = self.node_embeddings( x_nodes ) # (b, n+m, hidden_dims)\n",
        "        # Pass through each encoder block\n",
        "        for block in self.encoder_blocks:\n",
        "            x_nodes = block(x_nodes_embedded,\n",
        "                            mask=self.mask,\n",
        "                            training=training)\n",
        "        x_nodes = tf.squeeze( self.forward_channel(x_nodes), axis=-1 ) # (b, n+m, hidden_dims)->(b, n+m)\n",
        "        x_nodes = self.dropout(x_nodes) if training else x_nodes\n",
        "        llr_hat = self.to_n(x_nodes) # (b, n+m)->(b,n)\n",
        "        return llr_hat\n",
        "\n",
        "\n",
        "class E2EModel(tf.keras.Model):\n",
        "    def __init__(self, encoder, decoder, k, n, return_infobits=False, es_no=False, is_5G=False):\n",
        "        super().__init__()\n",
        "\n",
        "        self._n = n\n",
        "        self._k = k\n",
        "        self._m = n - k\n",
        "        self._is_5G = is_5G\n",
        "\n",
        "        self._binary_source = BinarySource(dtype=tf.int32)\n",
        "        self._num_bits_per_symbol = 2\n",
        "        self._mapper = Mapper(\"qam\", self._num_bits_per_symbol)\n",
        "        self._demapper = Demapper(\"app\", \"qam\", self._num_bits_per_symbol)\n",
        "        self._channel = AWGN()\n",
        "        self._decoder = decoder\n",
        "        self._encoder = encoder\n",
        "        self._return_infobits = return_infobits\n",
        "        self._es_no = es_no\n",
        "\n",
        "    @tf.function(jit_compile=False)\n",
        "    def call(self, batch_size, ebno_db, training=False):\n",
        "\n",
        "        # no rate-adjustment for uncoded transmission or es_no scenario\n",
        "        if self._decoder is not None and self._es_no==False:\n",
        "            no = ebnodb2no(ebno_db, self._num_bits_per_symbol, self._k/self._n)\n",
        "        else: #for uncoded transmissions the rate is 1\n",
        "            no = ebnodb2no(ebno_db, self._num_bits_per_symbol, 1)\n",
        "\n",
        "        b = self._binary_source([batch_size, self._k])\n",
        "        if self._encoder is not None:\n",
        "            c = self._encoder(b)\n",
        "        else:\n",
        "            c = b\n",
        "\n",
        "        # check that rate calculations are correct\n",
        "        assert self._n==c.shape[-1], \"Invalid value of n.\"\n",
        "\n",
        "        # zero padding to support odd codeword lengths\n",
        "        if self._n%2==1:\n",
        "            c_pad = tf.concat([c, tf.zeros([batch_size, 1], dtype=tf.int32)], axis=1)\n",
        "        else: # no padding\n",
        "            c_pad = c\n",
        "        x = self._mapper(c_pad)\n",
        "\n",
        "        y = self._channel([x, no])\n",
        "        llr = self._demapper([y, no])\n",
        "\n",
        "        # remove zero padded bit at the end\n",
        "        if self._n%2==1:\n",
        "            llr = llr[:,:-1]\n",
        "\n",
        "        # decoder input nodes\n",
        "        if not self._is_5G:\n",
        "            syndrome = tf.reshape( self._decoder.get_syndrome(llr),\n",
        "                                  (batch_size, self._m) ) # (m,n)@(n,b)->(m,b) check nodes\n",
        "            x_nodes = tf.concat([llr, syndrome], axis=1)[:, :, tf.newaxis] # (b, n+m, 1)\n",
        "        else:\n",
        "           x_nodes = llr # (b, n, 1)\n",
        "\n",
        "        # and run the decoder\n",
        "        if self._decoder is not None:\n",
        "            ############################\n",
        "            c_hat_logits = self._decoder(x_nodes, training=training)\n",
        "            ############################\n",
        "        c_hat = tf.cast(tf.greater(c_hat_logits, 0.0), tf.int32)\n",
        "\n",
        "        if self._return_infobits:\n",
        "            return b, c_hat, c_hat_logits, llr\n",
        "        else:\n",
        "            return c, c_hat, c_hat_logits, llr\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# args for decoder/discriminator\n",
        "args = Args(model_type='dis')\n",
        "args.code.H = pcm\n",
        "args.n, args.m = pcm.shape\n",
        "args.k = k\n",
        "args.n_steps = args.m + 5\n",
        "\n",
        "ltd_decoder = Decoder(args, linear=False) # Linear Transformer Diffusion (LTD) Decoder\n",
        "\n",
        "e2e_ltd = E2EModel(encoder, ltd_decoder, k, n)"
      ],
      "metadata": {
        "id": "XOILyjSGXMdb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 855
        },
        "outputId": "7aac6889-91fc-4b79-c1b8-4724fd6af3c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "4vZxtXOf4c1k",
        "outputId": "fb5d4119-4359-426c-ea62-96479cd9a9b0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "@staticmethod\n",
        "def bin_to_llr(x):\n",
        "    \"\"\"\n",
        "    Converts binary values (0 or 1) to log-likelihood ratios (LLRs), clipping values to ±20 for numerical stability.\n",
        "    Args:\n",
        "        x (Tensor): Binary input tensor with values 0 or 1.\n",
        "    Returns:\n",
        "        Tensor: Tensor of LLR values with clipped range.\n",
        "    \"\"\"\n",
        "    llr_vector = tf.where(x == 0, -20, 20)\n",
        "    return llr_vector\n",
        "\n",
        "@staticmethod\n",
        "def llr_to_bin(c):\n",
        "    \"\"\"\n",
        "    Converts log-likelihood ratios (LLRs) to binary values based on their sign.\n",
        "    Args:\n",
        "        c (Tensor): Tensor of LLR values.\n",
        "    Returns:\n",
        "        Tensor: Binary tensor with values 0 or 1.\n",
        "    \"\"\"\n",
        "    return tf.cast(tf.greater(c, 0), tf.int32)\n",
        "\n",
        "def load_weights(model, checkpoint_path):\n",
        "    \"\"\"\n",
        "    Loads the model's weights from a specified checkpoint directory.\n",
        "    Args:\n",
        "        model (tf.keras.Model): The model whose weights need to be restored.\n",
        "        checkpoint_path (str): File path where checkpoint files are stored.\n",
        "    \"\"\"\n",
        "    checkpoint = tf.train.Checkpoint(decoder=model._decoder)\n",
        "    try:\n",
        "        checkpoint.restore(checkpoint_path).assert_existing_objects_matched()\n",
        "        print(f\"Successfully restored weights from {checkpoint_path}\")\n",
        "    except AssertionError:\n",
        "        print(\"No checkpoint found. Starting training from scratch.\")\n",
        "\n",
        "def save_weights(model, checkpoint_dir, weight_type='last', ber=None):\n",
        "    \"\"\"\n",
        "    Saves the model's weights to a specified checkpoint directory, optionally including BER in the filename.\n",
        "\n",
        "    Args:\n",
        "        model (tf.keras.Model): The model whose weights need to be saved.\n",
        "        checkpoint_dir (str): Directory path where checkpoint files will be saved.\n",
        "        weight_type (str): Type of weights to save ('best' or 'last').\n",
        "        ber (float, optional): BER value to include in the filename if saving the best weights.\n",
        "    \"\"\"\n",
        "    checkpoint = tf.train.Checkpoint(decoder=model._decoder)\n",
        "    if weight_type == 'best' and ber is not None:\n",
        "        save_path = os.path.join(checkpoint_dir, f'{weight_type}_weights_ber_{ber:.5e}')\n",
        "    else:\n",
        "        save_path = os.path.join(checkpoint_dir, f'{weight_type}_weights')\n",
        "    checkpoint.save(save_path)\n",
        "    print(f\"Saved {weight_type} weights to {save_path}\")\n",
        "\n",
        "def parse_best_ber_from_filename(checkpoint_dir):\n",
        "    \"\"\"\n",
        "    Parses the best BER value from filenames in the checkpoint directory.\n",
        "\n",
        "    Args:\n",
        "        checkpoint_dir (str): Directory path where checkpoint files are stored.\n",
        "\n",
        "    Returns:\n",
        "        float: The best BER value parsed from the filenames.\n",
        "    \"\"\"\n",
        "    import re\n",
        "    import os\n",
        "\n",
        "    best_ber = float('inf')  # Initialize the best BER as infinity\n",
        "    for filename in os.listdir(checkpoint_dir):\n",
        "        match = re.search(r'best_weights_ber_(\\d+\\.\\d+e[+-]?\\d+)', filename)\n",
        "        if match:\n",
        "            ber = float(match.group(1))  # Extract BER from filename\n",
        "            best_ber = min(best_ber, ber)  # Update the best BER if a smaller value is found\n",
        "    print(f\"Best BER found: {best_ber}\")\n",
        "    return best_ber\n",
        "\n",
        "def visualize_weights(model):\n",
        "    \"\"\"\n",
        "    Visualizes the trainable weights of the model as heatmaps, updating them in place during training.\n",
        "    Args:\n",
        "        model (tf.keras.Model): The model whose weights are visualized.\n",
        "    \"\"\"\n",
        "    import seaborn as sns\n",
        "    import matplotlib.pyplot as plt\n",
        "\n",
        "    plt.ion()  # Turn on interactive mode\n",
        "    num_weights = len(model.trainable_weights)\n",
        "    fig, axs = plt.subplots(1, num_weights, figsize=(5 * num_weights, 5))\n",
        "\n",
        "    # Ensure axs is iterable (handles single axis case)\n",
        "    if num_weights == 1:\n",
        "        axs = [axs]\n",
        "\n",
        "    print(model.trainable_weights)\n",
        "    for i, var in enumerate(model.trainable_weights):\n",
        "        var_name = var.name\n",
        "        var_value = var.numpy()\n",
        "\n",
        "        axs[i].clear()  # Clear the axis to avoid overlapping\n",
        "\n",
        "        if len(var_value.shape) == 1:  # 1D tensor (e.g., bias)\n",
        "            axs[i].plot(var_value)\n",
        "            axs[i].set_title(f'{var_name} (1D)')\n",
        "        elif len(var_value.shape) == 2:  # 2D tensor (e.g., weights)\n",
        "            sns.heatmap(var_value, cmap=\"viridis\", ax=axs[i], cbar=True)\n",
        "            axs[i].set_title(f'{var_name} (2D)')\n",
        "        else:  # Higher-dimensional tensors\n",
        "            axs[i].text(0.5, 0.5, f\"{var_name}: Shape {var_value.shape} not visualizable\",\n",
        "                        ha='center', va='center', fontsize=10)\n",
        "            axs[i].set_title(f'{var_name} (Not 1D/2D)')\n",
        "\n",
        "    plt.draw()  # Update the figure with new data\n",
        "    plt.pause(0.5)  # Pause briefly to allow visualization updates\n",
        "\n",
        "    plt.ioff()  # Turn off interactive mode\n",
        "    plt.show()\n",
        "\n",
        "# SGD update iteration\n",
        "@tf.function(jit_compile=False)\n",
        "def train_step(model, loss_fn, optimizer, batch_size):\n",
        "    \"\"\"\n",
        "    Performs one training step with a batch of data, updating weights and saving the best BER weights if applicable.\n",
        "\n",
        "    Args:\n",
        "        model (tf.keras.Model): The model to be trained.\n",
        "        loss_fn (tf.keras.losses.Loss): Loss function to calculate the error.\n",
        "        optimizer (tf.keras.optimizers.Optimizer): Optimizer to update the model weights.\n",
        "        batch_size (int): Number of samples in the training batch.\n",
        "\n",
        "    Returns:\n",
        "        Tuple: Ground truth binary labels, predicted LLR values, and updated best BER.\n",
        "    \"\"\"\n",
        "    # train for random SNRs within a pre-defined interval\n",
        "    ebno_db = tf.random.uniform([batch_size, 1],\n",
        "                                minval=args.ebno_db_min,\n",
        "                                maxval=args.ebno_db_max)\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "        c, c_hat, c_hat_logits, llr_channel = model(batch_size, ebno_db, training=True)\n",
        "\n",
        "        loss_value = loss_fn(c, c_hat_logits)\n",
        "        ber = compute_ber(c, c_hat)\n",
        "\n",
        "    # and apply the SGD updates\n",
        "    weights = model.trainable_weights\n",
        "    grads = tape.gradient(loss_value, weights) # variables\n",
        "    optimizer.apply_gradients(zip(grads, weights))\n",
        "    return c, c_hat_logits, ber\n",
        "\n",
        "def test_step(model, args, loss_fn, learning_rate, epoch):\n",
        "    \"\"\"\n",
        "    Evaluates the model on a batch of data, calculating loss, bit error rate (BER), and timing.\n",
        "    Args:\n",
        "        model (tf.keras.Model): The model to be evaluated.\n",
        "        args (Namespace): Arguments containing evaluation parameters.\n",
        "        loss_fn (tf.keras.losses.Loss): Loss function to calculate the error.\n",
        "        learning_rate (float): Current learning rate of the optimizer.\n",
        "        epoch (int): Current epoch of training.\n",
        "    \"\"\"\n",
        "    ebno_db = tf.random.uniform([args.batch_size, 1],\n",
        "                                 minval=args.ebno_db_eval,\n",
        "                                 maxval=args.ebno_db_eval)\n",
        "    # measure time for call\n",
        "    time_start = time.time()\n",
        "    c, c_hat, c_hat_logits, llr_channel = model(args.batch_size, ebno_db)\n",
        "    duration = time.time() - time_start # in s\n",
        "\n",
        "    # loss\n",
        "    loss_value = loss_fn(c, c_hat_logits)\n",
        "    # ber pred\n",
        "    ber = compute_ber(c, c_hat).numpy()\n",
        "    bler = compute_bler(c, c_hat).numpy()\n",
        "    # ber original\n",
        "    c_channel = llr_to_bin(llr_channel)\n",
        "    channel_ber = compute_ber(c, c_channel).numpy()\n",
        "\n",
        "    print(f'Training epoch {epoch}/{args.epochs}, LR={learning_rate:.2e}, Loss={loss_value.numpy():.5e}, channel_BER={channel_ber}, BER={ber}, BLER={bler} duration per call: {duration:.2f}s')\n",
        "\n",
        "def train_dec(model, args, file_name, save_path='/content/drive/My Drive/ECC_weights/', load_decoder_weights=False, visualize_decoder_weights=False):\n",
        "    \"\"\"\n",
        "    Trains the model using a specified training process, evaluates periodically, and saves weights at intervals.\n",
        "    Args:\n",
        "        model (tf.keras.Model): The model to be trained.\n",
        "        args (Namespace): Training arguments including batch size, epochs, learning rate, etc.\n",
        "        file_name (str): Name of the file to save weights.\n",
        "        save_path (str): Directory path to save model checkpoints.\n",
        "        visualize_decoder_weights (bool): Whether to visualize model weights during training.\n",
        "    \"\"\"\n",
        "    # loss\n",
        "    loss_fn =  tf.keras.losses.BinaryCrossentropy(from_logits=False)\n",
        "    # optimizer\n",
        "    scheduler = tf.keras.optimizers.schedules.CosineDecay(initial_learning_rate=args.lr, decay_steps=args.epochs) # 1000 is size of trainloader\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate=scheduler)\n",
        "\n",
        "    # Load weights if available\n",
        "    weights_path = os.path.join(save_path, file_name)\n",
        "    load_weights(model, weights_path) if load_decoder_weights else None\n",
        "\n",
        "    best_ber = parse_best_ber_from_filename(weights_path) # Retrieve or initialize best BER\n",
        "\n",
        "    print(\"Training Model...\")\n",
        "    for epoch in range(1, args.epochs + 1):\n",
        "        _, _, ber = train_step(model,\n",
        "                              loss_fn,\n",
        "                              optimizer,\n",
        "                              args.batch_size)\n",
        "\n",
        "        # Save the best weights if the current BER is better\n",
        "        if ber < best_ber:\n",
        "            save_weights(model, weights_path, weight_type='best', ber=ber)\n",
        "            best_ber = ber # Update the best BER\n",
        "\n",
        "        # eval train iter\n",
        "        if epoch % args.eval_train_iter == 0:\n",
        "            test_step(model,\n",
        "                      args,\n",
        "                      loss_fn,\n",
        "                      learning_rate=optimizer.learning_rate.numpy(),\n",
        "                      epoch=epoch)\n",
        "            # break\n",
        "\n",
        "        # save weights iter\n",
        "        # if epoch % args.save_weights_iter == 0:\n",
        "            # save_weights(model, weights_path, weight_type='last')\n",
        "\n",
        "        # visualize decoder weights\n",
        "        if visualize_decoder_weights:\n",
        "            visualize_weights(model)\n",
        "\n",
        "\n",
        "train_dec(e2e_ltd, args, file_name='ECCT_pcm_36_60_Tlayers2_dims64/weights', load_decoder_weights=False, visualize_decoder_weights=False)"
      ],
      "metadata": {
        "id": "faokh4umwB2f",
        "outputId": "edf203fe-a007-4d28-8bfc-e6f156580809",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:You are casting an input of type complex64 to an incompatible dtype float32.  This will discard the imaginary part and may not be what you intended.\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['decoder_3/transformer_encoder_block_6/multi_head_attention_6/query/kernel:0', 'decoder_3/transformer_encoder_block_6/multi_head_attention_6/query/bias:0', 'decoder_3/transformer_encoder_block_6/multi_head_attention_6/key/kernel:0', 'decoder_3/transformer_encoder_block_6/multi_head_attention_6/key/bias:0', 'decoder_3/transformer_encoder_block_6/multi_head_attention_6/value/kernel:0', 'decoder_3/transformer_encoder_block_6/multi_head_attention_6/value/bias:0', 'decoder_3/transformer_encoder_block_6/multi_head_attention_6/attention_output/kernel:0', 'decoder_3/transformer_encoder_block_6/multi_head_attention_6/attention_output/bias:0', 'dense_22/kernel:0', 'dense_22/bias:0', 'dense_23/kernel:0', 'dense_23/bias:0', 'decoder_3/transformer_encoder_block_6/layer_normalization_12/gamma:0', 'decoder_3/transformer_encoder_block_6/layer_normalization_12/beta:0', 'decoder_3/transformer_encoder_block_6/layer_normalization_13/gamma:0', 'decoder_3/transformer_encoder_block_6/layer_normalization_13/beta:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['decoder_3/transformer_encoder_block_6/multi_head_attention_6/query/kernel:0', 'decoder_3/transformer_encoder_block_6/multi_head_attention_6/query/bias:0', 'decoder_3/transformer_encoder_block_6/multi_head_attention_6/key/kernel:0', 'decoder_3/transformer_encoder_block_6/multi_head_attention_6/key/bias:0', 'decoder_3/transformer_encoder_block_6/multi_head_attention_6/value/kernel:0', 'decoder_3/transformer_encoder_block_6/multi_head_attention_6/value/bias:0', 'decoder_3/transformer_encoder_block_6/multi_head_attention_6/attention_output/kernel:0', 'decoder_3/transformer_encoder_block_6/multi_head_attention_6/attention_output/bias:0', 'dense_22/kernel:0', 'dense_22/bias:0', 'dense_23/kernel:0', 'dense_23/bias:0', 'decoder_3/transformer_encoder_block_6/layer_normalization_12/gamma:0', 'decoder_3/transformer_encoder_block_6/layer_normalization_12/beta:0', 'decoder_3/transformer_encoder_block_6/layer_normalization_13/gamma:0', 'decoder_3/transformer_encoder_block_6/layer_normalization_13/beta:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['decoder_3/transformer_encoder_block_6/multi_head_attention_6/query/kernel:0', 'decoder_3/transformer_encoder_block_6/multi_head_attention_6/query/bias:0', 'decoder_3/transformer_encoder_block_6/multi_head_attention_6/key/kernel:0', 'decoder_3/transformer_encoder_block_6/multi_head_attention_6/key/bias:0', 'decoder_3/transformer_encoder_block_6/multi_head_attention_6/value/kernel:0', 'decoder_3/transformer_encoder_block_6/multi_head_attention_6/value/bias:0', 'decoder_3/transformer_encoder_block_6/multi_head_attention_6/attention_output/kernel:0', 'decoder_3/transformer_encoder_block_6/multi_head_attention_6/attention_output/bias:0', 'dense_22/kernel:0', 'dense_22/bias:0', 'dense_23/kernel:0', 'dense_23/bias:0', 'decoder_3/transformer_encoder_block_6/layer_normalization_12/gamma:0', 'decoder_3/transformer_encoder_block_6/layer_normalization_12/beta:0', 'decoder_3/transformer_encoder_block_6/layer_normalization_13/gamma:0', 'decoder_3/transformer_encoder_block_6/layer_normalization_13/beta:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['decoder_3/transformer_encoder_block_6/multi_head_attention_6/query/kernel:0', 'decoder_3/transformer_encoder_block_6/multi_head_attention_6/query/bias:0', 'decoder_3/transformer_encoder_block_6/multi_head_attention_6/key/kernel:0', 'decoder_3/transformer_encoder_block_6/multi_head_attention_6/key/bias:0', 'decoder_3/transformer_encoder_block_6/multi_head_attention_6/value/kernel:0', 'decoder_3/transformer_encoder_block_6/multi_head_attention_6/value/bias:0', 'decoder_3/transformer_encoder_block_6/multi_head_attention_6/attention_output/kernel:0', 'decoder_3/transformer_encoder_block_6/multi_head_attention_6/attention_output/bias:0', 'dense_22/kernel:0', 'dense_22/bias:0', 'dense_23/kernel:0', 'dense_23/bias:0', 'decoder_3/transformer_encoder_block_6/layer_normalization_12/gamma:0', 'decoder_3/transformer_encoder_block_6/layer_normalization_12/beta:0', 'decoder_3/transformer_encoder_block_6/layer_normalization_13/gamma:0', 'decoder_3/transformer_encoder_block_6/layer_normalization_13/beta:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch 50/1000000, LR=5.00e-04, Loss=5.20329e+00, channel_BER=0.11802083333333334, BER=0.5055208333333333, BLER=1.0 duration per call: 0.43s\n",
            "Training epoch 100/1000000, LR=5.00e-04, Loss=4.57965e+00, channel_BER=0.11635416666666666, BER=0.5045833333333334, BLER=1.0 duration per call: 0.01s\n",
            "Saved weights to /content/drive/My Drive/ECC_weights/ECCT_pcm_36_60_Tlayers2_dims64/weights\n",
            "Training epoch 150/1000000, LR=5.00e-04, Loss=4.11426e+00, channel_BER=0.1184375, BER=0.4942708333333333, BLER=1.0 duration per call: 0.01s\n",
            "Training epoch 200/1000000, LR=5.00e-04, Loss=7.08225e+00, channel_BER=0.12010416666666666, BER=0.4969791666666667, BLER=1.0 duration per call: 0.01s\n",
            "Saved weights to /content/drive/My Drive/ECC_weights/ECCT_pcm_36_60_Tlayers2_dims64/weights\n",
            "Training epoch 250/1000000, LR=5.00e-04, Loss=7.16293e+00, channel_BER=0.11739583333333334, BER=0.5005208333333333, BLER=1.0 duration per call: 0.01s\n",
            "Training epoch 300/1000000, LR=5.00e-04, Loss=7.12565e+00, channel_BER=0.118125, BER=0.5, BLER=1.0 duration per call: 0.01s\n",
            "Saved weights to /content/drive/My Drive/ECC_weights/ECCT_pcm_36_60_Tlayers2_dims64/weights\n",
            "Training epoch 350/1000000, LR=5.00e-04, Loss=7.11565e+00, channel_BER=0.114375, BER=0.5008333333333334, BLER=1.0 duration per call: 0.01s\n",
            "Training epoch 400/1000000, LR=5.00e-04, Loss=7.00189e+00, channel_BER=0.12177083333333333, BER=0.4946875, BLER=1.0 duration per call: 0.01s\n",
            "Saved weights to /content/drive/My Drive/ECC_weights/ECCT_pcm_36_60_Tlayers2_dims64/weights\n",
            "Training epoch 450/1000000, LR=5.00e-04, Loss=7.02088e+00, channel_BER=0.11604166666666667, BER=0.49802083333333336, BLER=1.0 duration per call: 0.01s\n",
            "Training epoch 500/1000000, LR=5.00e-04, Loss=6.76193e+00, channel_BER=0.11927083333333334, BER=0.4841666666666667, BLER=1.0 duration per call: 0.01s\n",
            "Saved weights to /content/drive/My Drive/ECC_weights/ECCT_pcm_36_60_Tlayers2_dims64/weights\n",
            "Training epoch 550/1000000, LR=5.00e-04, Loss=6.63166e+00, channel_BER=0.1171875, BER=0.4859375, BLER=1.0 duration per call: 0.01s\n",
            "Training epoch 600/1000000, LR=5.00e-04, Loss=6.44593e+00, channel_BER=0.12, BER=0.490625, BLER=1.0 duration per call: 0.01s\n",
            "Saved weights to /content/drive/My Drive/ECC_weights/ECCT_pcm_36_60_Tlayers2_dims64/weights\n",
            "Training epoch 650/1000000, LR=5.00e-04, Loss=6.56534e+00, channel_BER=0.12, BER=0.48364583333333333, BLER=1.0 duration per call: 0.01s\n",
            "Training epoch 700/1000000, LR=5.00e-04, Loss=6.57397e+00, channel_BER=0.11947916666666666, BER=0.48833333333333334, BLER=1.0 duration per call: 0.01s\n",
            "Saved weights to /content/drive/My Drive/ECC_weights/ECCT_pcm_36_60_Tlayers2_dims64/weights\n",
            "Training epoch 750/1000000, LR=5.00e-04, Loss=6.50819e+00, channel_BER=0.12041666666666667, BER=0.48604166666666665, BLER=1.0 duration per call: 0.01s\n",
            "Training epoch 800/1000000, LR=5.00e-04, Loss=6.05945e+00, channel_BER=0.12020833333333333, BER=0.498125, BLER=1.0 duration per call: 0.01s\n",
            "Saved weights to /content/drive/My Drive/ECC_weights/ECCT_pcm_36_60_Tlayers2_dims64/weights\n",
            "Training epoch 850/1000000, LR=5.00e-04, Loss=5.61043e+00, channel_BER=0.11854166666666667, BER=0.5007291666666667, BLER=1.0 duration per call: 0.01s\n",
            "Training epoch 900/1000000, LR=5.00e-04, Loss=7.22399e+00, channel_BER=0.1153125, BER=0.5126041666666666, BLER=1.0 duration per call: 0.01s\n",
            "Saved weights to /content/drive/My Drive/ECC_weights/ECCT_pcm_36_60_Tlayers2_dims64/weights\n",
            "Training epoch 950/1000000, LR=5.00e-04, Loss=7.29166e+00, channel_BER=0.11645833333333333, BER=0.5128125, BLER=1.0 duration per call: 0.01s\n",
            "Training epoch 1000/1000000, LR=5.00e-04, Loss=7.22876e+00, channel_BER=0.1196875, BER=0.5111458333333333, BLER=1.0 duration per call: 0.01s\n",
            "Saved weights to /content/drive/My Drive/ECC_weights/ECCT_pcm_36_60_Tlayers2_dims64/weights\n",
            "Training epoch 1050/1000000, LR=5.00e-04, Loss=7.19502e+00, channel_BER=0.12197916666666667, BER=0.5091666666666667, BLER=1.0 duration per call: 0.01s\n",
            "Training epoch 1100/1000000, LR=5.00e-04, Loss=7.15873e+00, channel_BER=0.11697916666666666, BER=0.5047916666666666, BLER=1.0 duration per call: 0.01s\n",
            "Saved weights to /content/drive/My Drive/ECC_weights/ECCT_pcm_36_60_Tlayers2_dims64/weights\n",
            "Training epoch 1150/1000000, LR=5.00e-04, Loss=7.17421e+00, channel_BER=0.1146875, BER=0.5095833333333334, BLER=1.0 duration per call: 0.01s\n",
            "Training epoch 1200/1000000, LR=5.00e-04, Loss=6.93005e+00, channel_BER=0.11604166666666667, BER=0.4971875, BLER=1.0 duration per call: 0.01s\n",
            "Saved weights to /content/drive/My Drive/ECC_weights/ECCT_pcm_36_60_Tlayers2_dims64/weights\n",
            "Training epoch 1250/1000000, LR=5.00e-04, Loss=7.14195e+00, channel_BER=0.11458333333333333, BER=0.5098958333333333, BLER=1.0 duration per call: 0.01s\n",
            "Training epoch 1300/1000000, LR=5.00e-04, Loss=7.09677e+00, channel_BER=0.12010416666666666, BER=0.505, BLER=1.0 duration per call: 0.01s\n",
            "Saved weights to /content/drive/My Drive/ECC_weights/ECCT_pcm_36_60_Tlayers2_dims64/weights\n",
            "Training epoch 1350/1000000, LR=5.00e-04, Loss=6.95777e+00, channel_BER=0.11489583333333334, BER=0.5027083333333333, BLER=1.0 duration per call: 0.01s\n",
            "Training epoch 1400/1000000, LR=5.00e-04, Loss=6.94605e+00, channel_BER=0.1115625, BER=0.5084375, BLER=1.0 duration per call: 0.01s\n",
            "Saved weights to /content/drive/My Drive/ECC_weights/ECCT_pcm_36_60_Tlayers2_dims64/weights\n",
            "Training epoch 1450/1000000, LR=5.00e-04, Loss=6.78958e+00, channel_BER=0.11229166666666666, BER=0.5110416666666666, BLER=1.0 duration per call: 0.01s\n",
            "Training epoch 1500/1000000, LR=5.00e-04, Loss=6.70784e+00, channel_BER=0.11927083333333334, BER=0.5119791666666667, BLER=1.0 duration per call: 0.01s\n",
            "Saved weights to /content/drive/My Drive/ECC_weights/ECCT_pcm_36_60_Tlayers2_dims64/weights\n",
            "Training epoch 1550/1000000, LR=5.00e-04, Loss=6.31386e+00, channel_BER=0.11572916666666666, BER=0.5010416666666667, BLER=1.0 duration per call: 0.01s\n",
            "Training epoch 1600/1000000, LR=5.00e-04, Loss=6.13762e+00, channel_BER=0.11947916666666666, BER=0.5040625, BLER=1.0 duration per call: 0.01s\n",
            "Saved weights to /content/drive/My Drive/ECC_weights/ECCT_pcm_36_60_Tlayers2_dims64/weights\n",
            "Training epoch 1650/1000000, LR=5.00e-04, Loss=5.16146e+00, channel_BER=0.11447916666666667, BER=0.5058333333333334, BLER=1.0 duration per call: 0.01s\n",
            "Training epoch 1700/1000000, LR=5.00e-04, Loss=5.09048e+00, channel_BER=0.11583333333333333, BER=0.51, BLER=1.0 duration per call: 0.01s\n",
            "Saved weights to /content/drive/My Drive/ECC_weights/ECCT_pcm_36_60_Tlayers2_dims64/weights\n",
            "Training epoch 1750/1000000, LR=5.00e-04, Loss=4.58146e+00, channel_BER=0.1171875, BER=0.5041666666666667, BLER=1.0 duration per call: 0.02s\n",
            "Training epoch 1800/1000000, LR=5.00e-04, Loss=5.99745e+00, channel_BER=0.11635416666666666, BER=0.510625, BLER=1.0 duration per call: 0.02s\n",
            "Saved weights to /content/drive/My Drive/ECC_weights/ECCT_pcm_36_60_Tlayers2_dims64/weights\n",
            "Training epoch 1850/1000000, LR=5.00e-04, Loss=5.62817e+00, channel_BER=0.11177083333333333, BER=0.5016666666666667, BLER=1.0 duration per call: 0.01s\n",
            "Training epoch 1900/1000000, LR=5.00e-04, Loss=4.61059e+00, channel_BER=0.113125, BER=0.505, BLER=1.0 duration per call: 0.01s\n",
            "Saved weights to /content/drive/My Drive/ECC_weights/ECCT_pcm_36_60_Tlayers2_dims64/weights\n",
            "Training epoch 1950/1000000, LR=5.00e-04, Loss=4.35833e+00, channel_BER=0.11479166666666667, BER=0.499375, BLER=1.0 duration per call: 0.01s\n",
            "Training epoch 2000/1000000, LR=5.00e-04, Loss=4.49926e+00, channel_BER=0.11479166666666667, BER=0.500625, BLER=1.0 duration per call: 0.01s\n",
            "Saved weights to /content/drive/My Drive/ECC_weights/ECCT_pcm_36_60_Tlayers2_dims64/weights\n",
            "Training epoch 2050/1000000, LR=5.00e-04, Loss=3.56425e+00, channel_BER=0.12010416666666666, BER=0.5017708333333334, BLER=1.0 duration per call: 0.01s\n",
            "Training epoch 2100/1000000, LR=5.00e-04, Loss=3.11944e+00, channel_BER=0.11833333333333333, BER=0.4965625, BLER=1.0 duration per call: 0.01s\n",
            "Saved weights to /content/drive/My Drive/ECC_weights/ECCT_pcm_36_60_Tlayers2_dims64/weights\n",
            "Training epoch 2150/1000000, LR=5.00e-04, Loss=3.15766e+00, channel_BER=0.11604166666666667, BER=0.5082291666666666, BLER=1.0 duration per call: 0.01s\n",
            "Training epoch 2200/1000000, LR=5.00e-04, Loss=6.68126e+00, channel_BER=0.11416666666666667, BER=0.49583333333333335, BLER=1.0 duration per call: 0.01s\n",
            "Saved weights to /content/drive/My Drive/ECC_weights/ECCT_pcm_36_60_Tlayers2_dims64/weights\n",
            "Training epoch 2250/1000000, LR=5.00e-04, Loss=6.70933e+00, channel_BER=0.11697916666666666, BER=0.4903125, BLER=1.0 duration per call: 0.02s\n",
            "Training epoch 2300/1000000, LR=5.00e-04, Loss=6.61284e+00, channel_BER=0.12354166666666666, BER=0.48760416666666667, BLER=1.0 duration per call: 0.01s\n",
            "Saved weights to /content/drive/My Drive/ECC_weights/ECCT_pcm_36_60_Tlayers2_dims64/weights\n",
            "Training epoch 2350/1000000, LR=5.00e-04, Loss=6.64955e+00, channel_BER=0.12458333333333334, BER=0.4878125, BLER=1.0 duration per call: 0.01s\n",
            "Training epoch 2400/1000000, LR=5.00e-04, Loss=6.53912e+00, channel_BER=0.11052083333333333, BER=0.4822916666666667, BLER=1.0 duration per call: 0.01s\n",
            "Saved weights to /content/drive/My Drive/ECC_weights/ECCT_pcm_36_60_Tlayers2_dims64/weights\n",
            "Training epoch 2450/1000000, LR=5.00e-04, Loss=6.58026e+00, channel_BER=0.11958333333333333, BER=0.48114583333333333, BLER=1.0 duration per call: 0.01s\n",
            "Training epoch 2500/1000000, LR=5.00e-04, Loss=6.46041e+00, channel_BER=0.11270833333333333, BER=0.47541666666666665, BLER=1.0 duration per call: 0.01s\n",
            "Saved weights to /content/drive/My Drive/ECC_weights/ECCT_pcm_36_60_Tlayers2_dims64/weights\n",
            "Training epoch 2550/1000000, LR=5.00e-04, Loss=6.41339e+00, channel_BER=0.113125, BER=0.4739583333333333, BLER=1.0 duration per call: 0.01s\n",
            "Training epoch 2600/1000000, LR=5.00e-04, Loss=6.26185e+00, channel_BER=0.11375, BER=0.4795833333333333, BLER=1.0 duration per call: 0.01s\n",
            "Saved weights to /content/drive/My Drive/ECC_weights/ECCT_pcm_36_60_Tlayers2_dims64/weights\n",
            "Training epoch 2650/1000000, LR=5.00e-04, Loss=6.02854e+00, channel_BER=0.11510416666666666, BER=0.4703125, BLER=1.0 duration per call: 0.01s\n",
            "Training epoch 2700/1000000, LR=5.00e-04, Loss=5.91029e+00, channel_BER=0.11895833333333333, BER=0.47020833333333334, BLER=1.0 duration per call: 0.01s\n",
            "Saved weights to /content/drive/My Drive/ECC_weights/ECCT_pcm_36_60_Tlayers2_dims64/weights\n",
            "Training epoch 2750/1000000, LR=5.00e-04, Loss=5.48137e+00, channel_BER=0.1221875, BER=0.48270833333333335, BLER=1.0 duration per call: 0.01s\n",
            "Training epoch 2800/1000000, LR=5.00e-04, Loss=5.31904e+00, channel_BER=0.11666666666666667, BER=0.5176041666666666, BLER=1.0 duration per call: 0.01s\n",
            "Saved weights to /content/drive/My Drive/ECC_weights/ECCT_pcm_36_60_Tlayers2_dims64/weights\n",
            "Training epoch 2850/1000000, LR=5.00e-04, Loss=4.06291e+00, channel_BER=0.114375, BER=0.5183333333333333, BLER=1.0 duration per call: 0.01s\n",
            "Training epoch 2900/1000000, LR=5.00e-04, Loss=2.75490e+00, channel_BER=0.10927083333333333, BER=0.5066666666666667, BLER=1.0 duration per call: 0.01s\n",
            "Saved weights to /content/drive/My Drive/ECC_weights/ECCT_pcm_36_60_Tlayers2_dims64/weights\n",
            "Training epoch 2950/1000000, LR=5.00e-04, Loss=2.00660e+00, channel_BER=0.1196875, BER=0.4997916666666667, BLER=1.0 duration per call: 0.01s\n",
            "Training epoch 3000/1000000, LR=5.00e-04, Loss=1.60890e+00, channel_BER=0.11885416666666666, BER=0.5008333333333334, BLER=1.0 duration per call: 0.01s\n",
            "Saved weights to /content/drive/My Drive/ECC_weights/ECCT_pcm_36_60_Tlayers2_dims64/weights\n",
            "Training epoch 3050/1000000, LR=5.00e-04, Loss=1.41638e+00, channel_BER=0.11625, BER=0.5057291666666667, BLER=1.0 duration per call: 0.01s\n",
            "Training epoch 3100/1000000, LR=5.00e-04, Loss=2.51534e+00, channel_BER=0.11489583333333334, BER=0.5077083333333333, BLER=1.0 duration per call: 0.01s\n",
            "Saved weights to /content/drive/My Drive/ECC_weights/ECCT_pcm_36_60_Tlayers2_dims64/weights\n",
            "Training epoch 3150/1000000, LR=5.00e-04, Loss=1.09061e+00, channel_BER=0.1140625, BER=0.5101041666666667, BLER=1.0 duration per call: 0.01s\n",
            "Training epoch 3200/1000000, LR=5.00e-04, Loss=6.30726e+00, channel_BER=0.121875, BER=0.49875, BLER=1.0 duration per call: 0.01s\n",
            "Saved weights to /content/drive/My Drive/ECC_weights/ECCT_pcm_36_60_Tlayers2_dims64/weights\n",
            "Training epoch 3250/1000000, LR=5.00e-04, Loss=5.88095e+00, channel_BER=0.11572916666666666, BER=0.4846875, BLER=1.0 duration per call: 0.01s\n",
            "Training epoch 3300/1000000, LR=5.00e-04, Loss=5.68047e+00, channel_BER=0.11927083333333334, BER=0.49052083333333335, BLER=1.0 duration per call: 0.01s\n",
            "Saved weights to /content/drive/My Drive/ECC_weights/ECCT_pcm_36_60_Tlayers2_dims64/weights\n",
            "Training epoch 3350/1000000, LR=5.00e-04, Loss=4.52808e+00, channel_BER=0.119375, BER=0.48864583333333333, BLER=1.0 duration per call: 0.01s\n",
            "Training epoch 3400/1000000, LR=5.00e-04, Loss=1.83814e+00, channel_BER=0.1128125, BER=0.49947916666666664, BLER=1.0 duration per call: 0.01s\n",
            "Saved weights to /content/drive/My Drive/ECC_weights/ECCT_pcm_36_60_Tlayers2_dims64/weights\n",
            "Training epoch 3450/1000000, LR=5.00e-04, Loss=1.73092e+00, channel_BER=0.11729166666666667, BER=0.5008333333333334, BLER=1.0 duration per call: 0.01s\n",
            "Training epoch 3500/1000000, LR=5.00e-04, Loss=5.57700e+00, channel_BER=0.1153125, BER=0.5044791666666667, BLER=1.0 duration per call: 0.01s\n",
            "Saved weights to /content/drive/My Drive/ECC_weights/ECCT_pcm_36_60_Tlayers2_dims64/weights\n",
            "Training epoch 3550/1000000, LR=5.00e-04, Loss=4.75923e+00, channel_BER=0.11760416666666666, BER=0.495, BLER=1.0 duration per call: 0.01s\n",
            "Training epoch 3600/1000000, LR=5.00e-04, Loss=4.99096e+00, channel_BER=0.11385416666666667, BER=0.4791666666666667, BLER=1.0 duration per call: 0.01s\n",
            "Saved weights to /content/drive/My Drive/ECC_weights/ECCT_pcm_36_60_Tlayers2_dims64/weights\n",
            "Training epoch 3650/1000000, LR=5.00e-04, Loss=4.27854e+00, channel_BER=0.11427083333333334, BER=0.479375, BLER=1.0 duration per call: 0.01s\n",
            "Training epoch 3700/1000000, LR=5.00e-04, Loss=5.44879e+00, channel_BER=0.11895833333333333, BER=0.4788541666666667, BLER=1.0 duration per call: 0.01s\n",
            "Saved weights to /content/drive/My Drive/ECC_weights/ECCT_pcm_36_60_Tlayers2_dims64/weights\n",
            "Training epoch 3750/1000000, LR=5.00e-04, Loss=4.88523e+00, channel_BER=0.115625, BER=0.47229166666666667, BLER=1.0 duration per call: 0.01s\n",
            "Training epoch 3800/1000000, LR=5.00e-04, Loss=2.50658e+00, channel_BER=0.11708333333333333, BER=0.495625, BLER=1.0 duration per call: 0.01s\n",
            "Saved weights to /content/drive/My Drive/ECC_weights/ECCT_pcm_36_60_Tlayers2_dims64/weights\n",
            "Training epoch 3850/1000000, LR=5.00e-04, Loss=1.27731e+00, channel_BER=0.1184375, BER=0.49385416666666665, BLER=1.0 duration per call: 0.01s\n",
            "Training epoch 3900/1000000, LR=5.00e-04, Loss=1.23182e+00, channel_BER=0.11572916666666666, BER=0.4925, BLER=1.0 duration per call: 0.01s\n",
            "Saved weights to /content/drive/My Drive/ECC_weights/ECCT_pcm_36_60_Tlayers2_dims64/weights\n",
            "Training epoch 3950/1000000, LR=5.00e-04, Loss=1.16859e+00, channel_BER=0.1184375, BER=0.490625, BLER=1.0 duration per call: 0.01s\n",
            "Training epoch 4000/1000000, LR=5.00e-04, Loss=1.06341e+00, channel_BER=0.118125, BER=0.4970833333333333, BLER=1.0 duration per call: 0.01s\n",
            "Saved weights to /content/drive/My Drive/ECC_weights/ECCT_pcm_36_60_Tlayers2_dims64/weights\n",
            "Training epoch 4050/1000000, LR=5.00e-04, Loss=1.03054e+00, channel_BER=0.11625, BER=0.495, BLER=1.0 duration per call: 0.01s\n",
            "Training epoch 4100/1000000, LR=5.00e-04, Loss=1.05299e+00, channel_BER=0.118125, BER=0.4923958333333333, BLER=1.0 duration per call: 0.01s\n",
            "Saved weights to /content/drive/My Drive/ECC_weights/ECCT_pcm_36_60_Tlayers2_dims64/weights\n",
            "Training epoch 4150/1000000, LR=5.00e-04, Loss=9.07076e-01, channel_BER=0.11520833333333333, BER=0.505, BLER=1.0 duration per call: 0.01s\n",
            "Training epoch 4200/1000000, LR=5.00e-04, Loss=6.21631e+00, channel_BER=0.12197916666666667, BER=0.46677083333333336, BLER=1.0 duration per call: 0.01s\n",
            "Saved weights to /content/drive/My Drive/ECC_weights/ECCT_pcm_36_60_Tlayers2_dims64/weights\n",
            "Training epoch 4250/1000000, LR=5.00e-04, Loss=6.13128e+00, channel_BER=0.11729166666666667, BER=0.455625, BLER=1.0 duration per call: 0.01s\n",
            "Training epoch 4300/1000000, LR=5.00e-04, Loss=6.19512e+00, channel_BER=0.1228125, BER=0.4605208333333333, BLER=1.0 duration per call: 0.01s\n",
            "Saved weights to /content/drive/My Drive/ECC_weights/ECCT_pcm_36_60_Tlayers2_dims64/weights\n",
            "Training epoch 4350/1000000, LR=5.00e-04, Loss=6.22482e+00, channel_BER=0.11479166666666667, BER=0.46677083333333336, BLER=1.0 duration per call: 0.01s\n",
            "Training epoch 4400/1000000, LR=5.00e-04, Loss=6.24564e+00, channel_BER=0.12052083333333333, BER=0.47041666666666665, BLER=1.0 duration per call: 0.01s\n",
            "Saved weights to /content/drive/My Drive/ECC_weights/ECCT_pcm_36_60_Tlayers2_dims64/weights\n",
            "Training epoch 4450/1000000, LR=5.00e-04, Loss=6.29622e+00, channel_BER=0.1184375, BER=0.4753125, BLER=1.0 duration per call: 0.01s\n",
            "Training epoch 4500/1000000, LR=5.00e-04, Loss=6.31891e+00, channel_BER=0.1175, BER=0.4741666666666667, BLER=1.0 duration per call: 0.01s\n",
            "Saved weights to /content/drive/My Drive/ECC_weights/ECCT_pcm_36_60_Tlayers2_dims64/weights\n",
            "Training epoch 4550/1000000, LR=5.00e-04, Loss=6.24428e+00, channel_BER=0.11854166666666667, BER=0.4725, BLER=1.0 duration per call: 0.01s\n",
            "Training epoch 4600/1000000, LR=5.00e-04, Loss=6.12350e+00, channel_BER=0.11927083333333334, BER=0.46791666666666665, BLER=1.0 duration per call: 0.01s\n",
            "Saved weights to /content/drive/My Drive/ECC_weights/ECCT_pcm_36_60_Tlayers2_dims64/weights\n",
            "Training epoch 4650/1000000, LR=5.00e-04, Loss=6.12211e+00, channel_BER=0.1128125, BER=0.4686458333333333, BLER=1.0 duration per call: 0.01s\n",
            "Training epoch 4700/1000000, LR=5.00e-04, Loss=6.03437e+00, channel_BER=0.1178125, BER=0.46697916666666667, BLER=1.0 duration per call: 0.01s\n",
            "Saved weights to /content/drive/My Drive/ECC_weights/ECCT_pcm_36_60_Tlayers2_dims64/weights\n",
            "Training epoch 4750/1000000, LR=5.00e-04, Loss=5.94131e+00, channel_BER=0.12291666666666666, BER=0.47072916666666664, BLER=1.0 duration per call: 0.01s\n",
            "Training epoch 4800/1000000, LR=5.00e-04, Loss=5.90815e+00, channel_BER=0.113125, BER=0.4657291666666667, BLER=1.0 duration per call: 0.01s\n",
            "Saved weights to /content/drive/My Drive/ECC_weights/ECCT_pcm_36_60_Tlayers2_dims64/weights\n",
            "Training epoch 4850/1000000, LR=5.00e-04, Loss=5.76315e+00, channel_BER=0.1203125, BER=0.46166666666666667, BLER=1.0 duration per call: 0.01s\n",
            "Training epoch 4900/1000000, LR=5.00e-04, Loss=5.63518e+00, channel_BER=0.11739583333333334, BER=0.45729166666666665, BLER=1.0 duration per call: 0.01s\n",
            "Saved weights to /content/drive/My Drive/ECC_weights/ECCT_pcm_36_60_Tlayers2_dims64/weights\n",
            "Training epoch 4950/1000000, LR=5.00e-04, Loss=5.67270e+00, channel_BER=0.1146875, BER=0.46239583333333334, BLER=1.0 duration per call: 0.01s\n",
            "Training epoch 5000/1000000, LR=5.00e-04, Loss=5.28041e+00, channel_BER=0.11083333333333334, BER=0.44979166666666665, BLER=1.0 duration per call: 0.02s\n",
            "Saved weights to /content/drive/My Drive/ECC_weights/ECCT_pcm_36_60_Tlayers2_dims64/weights\n",
            "Training epoch 5050/1000000, LR=5.00e-04, Loss=5.18661e+00, channel_BER=0.11895833333333333, BER=0.46177083333333335, BLER=1.0 duration per call: 0.01s\n",
            "Training epoch 5100/1000000, LR=5.00e-04, Loss=4.76952e+00, channel_BER=0.11541666666666667, BER=0.46239583333333334, BLER=1.0 duration per call: 0.01s\n",
            "Saved weights to /content/drive/My Drive/ECC_weights/ECCT_pcm_36_60_Tlayers2_dims64/weights\n",
            "Training epoch 5150/1000000, LR=5.00e-04, Loss=5.14649e+00, channel_BER=0.11229166666666666, BER=0.44729166666666664, BLER=1.0 duration per call: 0.01s\n",
            "Training epoch 5200/1000000, LR=5.00e-04, Loss=4.71483e+00, channel_BER=0.11666666666666667, BER=0.4575, BLER=1.0 duration per call: 0.01s\n",
            "Saved weights to /content/drive/My Drive/ECC_weights/ECCT_pcm_36_60_Tlayers2_dims64/weights\n",
            "Training epoch 5250/1000000, LR=5.00e-04, Loss=5.66763e+00, channel_BER=0.11697916666666666, BER=0.495, BLER=1.0 duration per call: 0.01s\n",
            "Training epoch 5300/1000000, LR=5.00e-04, Loss=4.82712e+00, channel_BER=0.11708333333333333, BER=0.485, BLER=1.0 duration per call: 0.01s\n",
            "Saved weights to /content/drive/My Drive/ECC_weights/ECCT_pcm_36_60_Tlayers2_dims64/weights\n",
            "Training epoch 5350/1000000, LR=5.00e-04, Loss=4.13900e+00, channel_BER=0.11427083333333334, BER=0.47802083333333334, BLER=1.0 duration per call: 0.01s\n",
            "Training epoch 5400/1000000, LR=5.00e-04, Loss=3.44294e+00, channel_BER=0.11458333333333333, BER=0.48104166666666665, BLER=1.0 duration per call: 0.01s\n",
            "Saved weights to /content/drive/My Drive/ECC_weights/ECCT_pcm_36_60_Tlayers2_dims64/weights\n",
            "Training epoch 5450/1000000, LR=5.00e-04, Loss=2.25068e+00, channel_BER=0.11145833333333334, BER=0.49125, BLER=1.0 duration per call: 0.01s\n",
            "Training epoch 5500/1000000, LR=5.00e-04, Loss=1.83068e+00, channel_BER=0.11333333333333333, BER=0.47510416666666666, BLER=1.0 duration per call: 0.01s\n",
            "Saved weights to /content/drive/My Drive/ECC_weights/ECCT_pcm_36_60_Tlayers2_dims64/weights\n",
            "Training epoch 5550/1000000, LR=5.00e-04, Loss=5.27185e+00, channel_BER=0.11239583333333333, BER=0.44416666666666665, BLER=1.0 duration per call: 0.01s\n",
            "Training epoch 5600/1000000, LR=5.00e-04, Loss=5.30968e+00, channel_BER=0.1103125, BER=0.44114583333333335, BLER=1.0 duration per call: 0.01s\n",
            "Saved weights to /content/drive/My Drive/ECC_weights/ECCT_pcm_36_60_Tlayers2_dims64/weights\n",
            "Training epoch 5650/1000000, LR=5.00e-04, Loss=5.10863e+00, channel_BER=0.11708333333333333, BER=0.4425, BLER=1.0 duration per call: 0.01s\n",
            "Training epoch 5700/1000000, LR=5.00e-04, Loss=5.05571e+00, channel_BER=0.11479166666666667, BER=0.44583333333333336, BLER=1.0 duration per call: 0.01s\n",
            "Saved weights to /content/drive/My Drive/ECC_weights/ECCT_pcm_36_60_Tlayers2_dims64/weights\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dir_path = \"/content/drive/My Drive/ECC_weights/\"\n",
        "file_path = \"ECCT_5G_pcm_13_26_Tlayers2_dims64/best_weights_ber_1.17500e-01-1\"\n",
        "best_weights_path = os.path.join(dir_path, file_path)\n",
        "\n",
        "load_weights(e2e_5G, best_weights_path)"
      ],
      "metadata": {
        "id": "IQxdVhThuxXW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ber_plot = PlotBER(f\"Transformer-based Decoding - LDPC, (k,n)=({e2e_ltd._k},{e2e_ltd._n})\")\n",
        "ebno_dbs = np.arange(args.ebno_db_min,\n",
        "                     args.ebno_db_max,\n",
        "                     args.ebno_db_stepsize)"
      ],
      "metadata": {
        "id": "jfyqmvQ0b4zQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# and run the BER simulations\n",
        "ber_plot.simulate(e2e_ltd,\n",
        "                  ebno_dbs=ebno_dbs,\n",
        "                  batch_size=100,#args.mc_batch_size,\n",
        "                  num_target_block_errors=500,\n",
        "                  legend=f\"Transformer dims={e2e_ltd._decoder.dims} n={e2e_ltd._n}\",\n",
        "                  soft_estimates=False,\n",
        "                  max_mc_iter=100,#args.mc_iters,\n",
        "                  forward_keyboard_interrupt=False,\n",
        "                  show_fig=True);"
      ],
      "metadata": {
        "id": "69Jr1CaObMJF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}