{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNKsKdmn7FNJ+p0C+qUzQFX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pollyjuice74/5G-Decoder/blob/main/LTD_model_reg_LDPC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "collapsed": true,
        "id": "5q1VAmIeUKIn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c035ee0-ab20-4fb3-ec13-1fed27f8d07a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into '5G-Decoder'...\n",
            "remote: Enumerating objects: 1482, done.\u001b[K\n",
            "remote: Counting objects: 100% (1482/1482), done.\u001b[K\n",
            "remote: Compressing objects: 100% (542/542), done.\u001b[K\n",
            "remote: Total 1482 (delta 938), reused 1462 (delta 926), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (1482/1482), 1.84 MiB | 8.58 MiB/s, done.\n",
            "Resolving deltas: 100% (938/938), done.\n",
            "Requirement already satisfied: sionna in /usr/local/lib/python3.10/dist-packages (0.19.1)\n",
            "Requirement already satisfied: tensorflow<2.16.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from sionna) (2.15.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from sionna) (1.26.4)\n",
            "Requirement already satisfied: matplotlib>=3.5.3 in /usr/local/lib/python3.10/dist-packages (from sionna) (3.8.0)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from sionna) (1.13.1)\n",
            "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.10/dist-packages (from sionna) (6.4.5)\n",
            "Requirement already satisfied: mitsuba<3.6.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from sionna) (3.5.2)\n",
            "Requirement already satisfied: pythreejs>=2.4.2 in /usr/local/lib/python3.10/dist-packages (from sionna) (2.4.2)\n",
            "Requirement already satisfied: ipywidgets>=8.0.4 in /usr/local/lib/python3.10/dist-packages (from sionna) (8.0.5)\n",
            "Requirement already satisfied: ipydatawidgets==4.3.2 in /usr/local/lib/python3.10/dist-packages (from sionna) (4.3.2)\n",
            "Requirement already satisfied: jupyterlab-widgets==3.0.5 in /usr/local/lib/python3.10/dist-packages (from sionna) (3.0.5)\n",
            "Requirement already satisfied: traittypes>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from ipydatawidgets==4.3.2->sionna) (0.2.1)\n",
            "Requirement already satisfied: ipython>=6.1.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=8.0.4->sionna) (7.34.0)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=8.0.4->sionna) (5.7.1)\n",
            "Requirement already satisfied: widgetsnbextension~=4.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=8.0.4->sionna) (4.0.13)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.3->sionna) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.3->sionna) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.3->sionna) (4.55.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.3->sionna) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.3->sionna) (24.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.3->sionna) (11.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.3->sionna) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.3->sionna) (2.8.2)\n",
            "Requirement already satisfied: drjit==0.4.6 in /usr/local/lib/python3.10/dist-packages (from mitsuba<3.6.0,>=3.2.0->sionna) (0.4.6)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16.0,>=2.13.0->sionna) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16.0,>=2.13.0->sionna) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16.0,>=2.13.0->sionna) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16.0,>=2.13.0->sionna) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16.0,>=2.13.0->sionna) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16.0,>=2.13.0->sionna) (3.12.1)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16.0,>=2.13.0->sionna) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes~=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16.0,>=2.13.0->sionna) (0.3.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16.0,>=2.13.0->sionna) (3.4.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16.0,>=2.13.0->sionna) (4.25.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16.0,>=2.13.0->sionna) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16.0,>=2.13.0->sionna) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16.0,>=2.13.0->sionna) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16.0,>=2.13.0->sionna) (4.12.2)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16.0,>=2.13.0->sionna) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16.0,>=2.13.0->sionna) (0.37.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16.0,>=2.13.0->sionna) (1.68.1)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16.0,>=2.13.0->sionna) (2.15.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16.0,>=2.13.0->sionna) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16.0,>=2.13.0->sionna) (2.15.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow<2.16.0,>=2.13.0->sionna) (0.45.1)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->sionna) (0.19.2)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->sionna) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->sionna) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->sionna) (3.0.48)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->sionna) (2.18.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->sionna) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->sionna) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->sionna) (4.9.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16.0,>=2.13.0->sionna) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16.0,>=2.13.0->sionna) (1.2.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16.0,>=2.13.0->sionna) (3.7)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16.0,>=2.13.0->sionna) (2.32.3)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16.0,>=2.13.0->sionna) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16.0,>=2.13.0->sionna) (3.1.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow<2.16.0,>=2.13.0->sionna) (5.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow<2.16.0,>=2.13.0->sionna) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow<2.16.0,>=2.13.0->sionna) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow<2.16.0,>=2.13.0->sionna) (1.3.1)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets>=8.0.4->sionna) (0.8.4)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets>=8.0.4->sionna) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=6.1.0->ipywidgets>=8.0.4->sionna) (0.2.13)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow<2.16.0,>=2.13.0->sionna) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow<2.16.0,>=2.13.0->sionna) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow<2.16.0,>=2.13.0->sionna) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow<2.16.0,>=2.13.0->sionna) (2024.12.14)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow<2.16.0,>=2.13.0->sionna) (3.0.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow<2.16.0,>=2.13.0->sionna) (0.6.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow<2.16.0,>=2.13.0->sionna) (3.2.2)\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/pollyjuice74/5G-Decoder\n",
        "!pip install sionna"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import tensorflow as tf\n",
        "import random\n",
        "import numpy as np\n",
        "import time\n",
        "from scipy.sparse import issparse, csr_matrix\n",
        "\n",
        "from sionna.fec.utils import generate_reg_ldpc, load_parity_check_examples, LinearEncoder, gm2pcm\n",
        "from sionna.utils.plotting import PlotBER\n",
        "from sionna.fec.ldpc import LDPCBPDecoder\n",
        "\n",
        "import os\n",
        "# os.chdir('../..')\n",
        "if os.path.exists('5G-Decoder'):\n",
        "  os.rename('5G-Decoder', '5G_Decoder')\n",
        "os.chdir('5G_Decoder/adv_nn')\n",
        "\n",
        "from dataset import *\n",
        "from attention import *\n",
        "from channel import *\n",
        "from args import *\n",
        "from model_functs import *\n",
        "from models import *"
      ],
      "metadata": {
        "id": "U5U5qUUVUeRm"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Loading LDPC code\")\n",
        "pcm, k, n, coderate = generate_reg_ldpc(v=1,\n",
        "                                        c=2,\n",
        "                                        n=5,\n",
        "                                        allow_flex_len=True,\n",
        "                                        verbose=True)\n",
        "\n",
        "# pcm = tf.cast(pcm, dtype=tf.int32)\n",
        "encoder = LinearEncoder(pcm, is_pcm=True, dtype=tf.int32)\n",
        "\n",
        "batch_size = 2  # For multiple codewords\n",
        "b = tf.random.uniform((batch_size, k), minval=0, maxval=2, dtype=tf.int32)\n",
        "c = encoder(b)\n",
        "print(pcm.shape, c.shape)\n",
        "pcm @ tf.transpose(c) % 2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 521
        },
        "id": "6RF7dBDwWg0L",
        "outputId": "3f54c68b-215c-4854-84f3-50248af5b871"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading LDPC code\n",
            "Setting n to:  6\n",
            "Number of edges (VN perspective):  6\n",
            "Number of edges (CN perspective):  6\n",
            "Generated regular (1,2) LDPC code of length n=6\n",
            "Code rate is r=0.500.\n",
            "Warning: The alias fec.utils.LinearEncoder will not be included in Sionna 1.0. Please use fec.linear.LinearEncoder instead.\n",
            "(3, 6) (2, 6)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3, 2), dtype=int32, numpy=\n",
              "array([[0, 0],\n",
              "       [0, 0],\n",
              "       [0, 0]], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 54
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# for e2e model\n",
        "from sionna.utils import BinarySource, ebnodb2no\n",
        "from sionna.mapping import Mapper, Demapper\n",
        "from sionna.channel import AWGN\n",
        "# from sionna.fec.ldpc import LDPC5GDecoder, LDPC5GEncoder\n",
        "from tensorflow.keras.layers import Layer, Dense, Dropout\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "class Args():\n",
        "    def __init__(self, model_type, code_type='LDPC', n_look_up=121, k_look_up=80, n=400, k=200,\n",
        "                       n_rings=2, ls_active=True, split_diff=True, sigma=0.1,\n",
        "                       t_layers=2, d_model=32, heads=8, lr=5e-4,\n",
        "                       batch_size=160, batch_size_eval = 150,\n",
        "                       eval_train_iter=50, save_weights_iter=100,\n",
        "                       ebno_db_eval=2.5,\n",
        "                       ebno_db_min=0., ebno_db_max=4., ebno_db_stepsize=0.25,\n",
        "                       traindata_len=500, testdata_len=250,\n",
        "                       mc_batch_size=200, mc_iters=500, epochs=10000):\n",
        "        assert model_type in ['gen', 'dis'], \"Type must be: 'gen', Generator or 'dis', Discriminator.\"\n",
        "        assert code_type in ['POLAR', 'BCH', 'CCSDS', 'LDPC', 'MACKAY', 'LDPC5G', 'POLAR5G'], \"Invalid linear code type.\"\n",
        "\n",
        "        # model data\n",
        "        self.model_type = model_type\n",
        "\n",
        "        self.split_diff = split_diff\n",
        "        self.n_rings = n_rings # ring connectivity of mask\n",
        "        self.sigma = sigma\n",
        "        self.t_layers = t_layers\n",
        "        self.ls_active = ls_active\n",
        "\n",
        "        self.d_model = d_model\n",
        "        self.heads = heads\n",
        "\n",
        "        # training data\n",
        "        self.lr = lr\n",
        "        self.batch_size = batch_size\n",
        "        self.traindata_len = traindata_len\n",
        "        self.testdata_len = testdata_len\n",
        "        self.epochs = epochs\n",
        "\n",
        "        self.ebno_db_min = ebno_db_min\n",
        "        self.ebno_db_max = ebno_db_max\n",
        "        self.ebno_db_stepsize = ebno_db_stepsize\n",
        "\n",
        "        self.ebno_db_eval = ebno_db_eval\n",
        "        self.eval_train_iter = eval_train_iter\n",
        "        self.save_weights_iter = save_weights_iter\n",
        "        self.batch_size_eval = batch_size_eval\n",
        "\n",
        "        # simulation\n",
        "        self.mc_batch_size = mc_batch_size\n",
        "        self.mc_iters = mc_iters\n",
        "\n",
        "        # code data\n",
        "        self.code_type = code_type\n",
        "        self.code = self.get_code(n_look_up, k_look_up) # n,k look up values in Get_Generator_and_Parity\n",
        "\n",
        "        # if self.code_type not in ['LDPC5G', 'POLAR5G']:\n",
        "        #     self.n, self.m, self.k = self.code.n, self.code.m, self.code.k\n",
        "        # else:\n",
        "        #     self.n, self.m, self.k = n, n-k, k\n",
        "\n",
        "        # self.n_steps = self.m + 5  # Number of diffusion steps\n",
        "\n",
        "    def get_code(self, n_look_up, k_look_up):\n",
        "        code = type('Code', (), {})() # class Code, no base class, no attributes/methods, () instantiate object\n",
        "        # code.n_look_up, code.k_look_up = n_look_up, k_look_up\n",
        "        # code.code_type = self.code_type\n",
        "\n",
        "        # if self.code_type not in ['LDPC5G', 'POLAR5G']:\n",
        "        #     G, H = Get_Generator_and_Parity(code)\n",
        "        #     code.G, code.H = tf.convert_to_tensor(G), csr_matrix( tf.convert_to_tensor(H) )\n",
        "\n",
        "        #     code.m, code.n = code.H.shape\n",
        "        #     code.k = code.n - code.m\n",
        "\n",
        "        return code\n",
        "\n",
        "    # def attention(self, x, mask): # O(n^2)\n",
        "    #     shape = tf.shape(x)\n",
        "    #     b = shape[0]\n",
        "    #     n = shape[1]\n",
        "    #     x = x[:, :, tf.newaxis] # (b,n,1)\n",
        "\n",
        "    #     query, key, val = self.to_q(x), self.to_k(x), self.to_v(x) # (b, n, d)\n",
        "    #     query, key, val = [ tf.reshape(x, (b, n, self.heads, self.dim_head)) for x in [query, key, val] ]\n",
        "    #     query, key, val = [ tf.cast( tf.transpose(x, [0, 2, 1, 3]), tf.float32 )\n",
        "    #                                                                         for x in [query, key, val] ]\n",
        "\n",
        "    #     scores = tf.einsum('bhqd,bhkd->bhqk', query, key) / (tf.sqrt( tf.cast(self.dim_head, tf.float32) ))\n",
        "    #     scores += (mask * -1e9) if mask is not None else 0. # apply mask non-edge connections\n",
        "    #     attn = tf.nn.softmax(scores, axis=-1) #-1\n",
        "    #     attn = self.dropout(attn)\n",
        "    #     out = tf.einsum('bhqk,bhkd->bhqd', attn, val)\n",
        "\n",
        "    #     out = tf.transpose(out, [0, 2, 1, 3])\n",
        "    #     out = tf.reshape(out, (b, n, -1))\n",
        "    #     return self.to_out(out)\n",
        "\n",
        "\n",
        "# class Decoder( TransformerDiffusion ):\n",
        "#     def __init__(self, args):\n",
        "#         super().__init__(args)\n",
        "#         self.transformer =\n",
        "\n",
        "#     # 'test' function\n",
        "#     def call(self, r_t):\n",
        "#         i = tf.constant(0)  # Initialize loop counter\n",
        "\n",
        "#         def condition(r_t, i):\n",
        "#             # Loop while i < self.m and syndrome sum is not zero\n",
        "#             return tf.logical_and(i < 5, tf.reduce_sum(self.get_syndrome(r_t)) != 0) # CHANGE 5 TO SELF.M\n",
        "\n",
        "#         def body(r_t, i):\n",
        "#             # Perform reverse or split diffusion\n",
        "#             r_t = tf.cond(\n",
        "#                 tf.logical_not(self.split_diff),\n",
        "#                 lambda: self.split_rdiff_call(r_t),\n",
        "#                 lambda: self.rev_diff_call(r_t),\n",
        "#             )\n",
        "#             return r_t, tf.add(i, 1)\n",
        "\n",
        "#         # Run tf.while_loop with the loop variables\n",
        "#         llr_hat, _ = tf.while_loop(\n",
        "#             condition,\n",
        "#             body,\n",
        "#             loop_vars=[r_t, i],\n",
        "#             maximum_iterations=self.m,\n",
        "#             shape_invariants=[tf.TensorShape([self.batch_size, self.n]), i.get_shape()]\n",
        "#         )\n",
        "\n",
        "#         # llr_hat, _ = self.tran_call(r_t)\n",
        "#         tf.print(\"llr_hat\", llr_hat)\n",
        "\n",
        "#         return llr_hat\n",
        "\n",
        "#     # Refines recieved codeword r at time t\n",
        "#     def rev_diff_call(self, r_t):\n",
        "#         tf.print(\"Rev def call with line-search...\")\n",
        "\n",
        "#         # Transformer error prediction\n",
        "#         z_hat_crude, t = self.tran_call(r_t) # (b,n)\n",
        "#         r_t1 = r_t - z_hat_crude*self.get_sigma(t)[:, tf.newaxis] # (b,n)\n",
        "#         # tf.print(r_t1)\n",
        "\n",
        "#         # # Refined estimate of the codeword for the ls diffusion step\n",
        "#         # r_t1, z_hat = self.line_search(r_t, sigma, err_hat) if self.ls_active else 1.\n",
        "#         # tf.print(\"After linesearch: \", r_t1)\n",
        "\n",
        "#         print(\"r_t1\", r_t1.shape, r_t1.dtype)\n",
        "#         return r_t1 # r at t-1, both (b,n)\n",
        "\n",
        "#     def split_rdiff_call(self, r_t):\n",
        "#         tf.print(\"Rev diff call with split diffusion...\")\n",
        "#         # First half-step condition subproblem\n",
        "#         z_hat_crude, t = self.tran_call(r_t)\n",
        "#         # tf.print(\"fc input: \", (z_hat_crude * self.get_sigma(t)[:, tf.newaxis]))\n",
        "#         r_t_half = r_t - 0.5 * self.fc( z_hat_crude * self.get_sigma(t)[:, tf.newaxis] )\n",
        "#         # tf.print(\"r_t_half\", r_t_half)\n",
        "\n",
        "#         # Full-step diffusion subproblem\n",
        "#         r_t1 = r_t_half + tf.random.normal(r_t_half.shape) * tf.sqrt(self.get_sigma(t)[:, tf.newaxis])\n",
        "\n",
        "#         # Second half-step condition subproblem\n",
        "#         z_hat_crude_half, t = self.tran_call(r_t1)  # Reuse the second `tran_call`\n",
        "#         r_t1 = r_t1 - 0.5 * self.fc(z_hat_crude_half * self.get_sigma(t)[:, tf.newaxis])\n",
        "#         print(\"r_t1\", r_t1.shape, r_t1.dtype)\n",
        "#         return r_t1  # r at t-1, both (b,n)\n",
        "\n",
        "from tensorflow.keras.layers import MultiHeadAttention, Dense, LayerNormalization, Dropout\n",
        "\n",
        "class LinearMHAttention( MultiHeadAttention ):\n",
        "    def __init__(self, num_heads, key_dim, mask_shape, dropout, **kwargs):\n",
        "        super().__init__(num_heads, key_dim, mask_shape, dropout, **kwargs)\n",
        "        # self.num_heads = num_heads\n",
        "        # self.key_dim = key_dim\n",
        "        # self._dropout = dropout\n",
        "\n",
        "        self.k_proj = self.get_k_proj(mask_shape) # mask_shape: (1, n+m, n+m)\n",
        "        self.proj_k = None\n",
        "        self.proj_v = None\n",
        "\n",
        "    def build(self, input_shape, **kwargs):\n",
        "        super().build(**kwargs)\n",
        "        # Creates shape (n,k_proj) proj matrices for key and\n",
        "        n_value = input_shape[1]\n",
        "        self.proj_k = self.add_weight(\"proj_k\", shape=[n_value, self.k_proj], initializer=GlorotUniform())\n",
        "        self.proj_v = self.add_weight(\"proj_v\", shape=[n_value, self.k_proj], initializer=GlorotUniform())\n",
        "\n",
        "    def call(\n",
        "        self,\n",
        "        query,\n",
        "        value,\n",
        "        key=None,\n",
        "        query_mask=None,\n",
        "        value_mask=None,\n",
        "        key_mask=None,\n",
        "        attention_mask=None,\n",
        "        return_attention_scores=False,\n",
        "        training=None,\n",
        "        use_causal_mask=False,\n",
        "    ):\n",
        "        if key is None:\n",
        "            key = value\n",
        "\n",
        "        attention_mask = self._compute_attention_mask(\n",
        "            query,\n",
        "            value,\n",
        "            query_mask=query_mask,\n",
        "            value_mask=value_mask,\n",
        "            key_mask=key_mask,\n",
        "            attention_mask=attention_mask,\n",
        "            use_causal_mask=use_causal_mask,\n",
        "        )\n",
        "\n",
        "        #   N = `num_attention_heads`\n",
        "        #   H = `size_per_head`\n",
        "        query = self._query_dense(query) # `query` = [B, T, N ,H]\n",
        "        key = self._key_dense(key) # `key` = [B, S, N, H]\n",
        "        value = self._value_dense(value) # `value` = [B, S, N, H]\n",
        "\n",
        "        attention_output, attention_scores = self._compute_lin_attention(\n",
        "            query, key, value, attention_mask, training\n",
        "        )\n",
        "        attention_output = self._output_dense(attention_output)\n",
        "\n",
        "        if return_attention_scores:\n",
        "            return attention_output, attention_scores\n",
        "        return attention_output\n",
        "\n",
        "    def _compute_lin_attention(self, x, mask): # O(n)\n",
        "        shape = tf.shape(x) # (b, n, d)\n",
        "        b = tf.cast(shape[0], tf.int32)\n",
        "        n = tf.cast(shape[1], tf.int32)\n",
        "\n",
        "        # # Reshape splitting for heads\n",
        "        # query = tf.reshape(query, (b, n, self.heads, self.dim_head))\n",
        "        # key = tf.reshape(key, (b, self.k_proj, self.heads, self.dim_head))\n",
        "        # val = tf.reshape(val, (b, self.k_proj, self.heads, self.dim_head))\n",
        "        # query, key, val = [ tf.transpose(x, [0, 2, 1, 3]) for x in [query, key, val] ]\n",
        "\n",
        "        # Low-rank mask (n,k_proj)\n",
        "        mask = tf.expand_dims(mask, axis=-1)\n",
        "        mask = tf.image.resize(mask, [n, self.k_proj], method='nearest')\n",
        "        mask = tf.reshape(mask, (1, 1, n, self.k_proj))\n",
        "\n",
        "        # # Main attn logic: sftmx( q@k / d**0.5 ) @ v\n",
        "        # scores = tf.einsum('bhnd,bhkd->bhnk', query, key) / (tf.sqrt( tf.cast(self.dim_head, dtype=tf.float32) ))\n",
        "        # scores += (mask * -1e9) if mask is not None else 0.\n",
        "        # attn = tf.nn.softmax(scores, axis=-1) # (b,h,n,k_proj)\n",
        "        # attn = self.dropout(attn)\n",
        "        # out = tf.einsum('bhnk,bhkd->bhnd', attn, val)\n",
        "\n",
        "        key = tf.einsum('bnd,nk->bkd', self._key_dense(x), self.proj_k)\n",
        "        value = tf.einsum('bnd,nk->bkd', self._value_dense(x), self.proj_v)\n",
        "\n",
        "        # Custom low-rank mask preprocessing\n",
        "        processed_mask = self.preprocess_mask(mask, tf.shape(x)[1], self.k_proj)\n",
        "\n",
        "        # Compute attention\n",
        "        return self._compute_attention(query=self._query_dense(x),\n",
        "                                       key=key,\n",
        "                                       value=value,\n",
        "                                       attention_mask=processed_mask)\n",
        "\n",
        "    def get_k_proj(self, mask_shape):\n",
        "        mask_length = mask_shape[1] # (b, n+m, n+m)\n",
        "        # gets dimention for linear tranformer vector projection\n",
        "        for k_proj in range(mask_length // 2, 0, -1): # starts at half the mask length TO 0\n",
        "            if mask_length % k_proj == 0:\n",
        "                return tf.cast(k_proj, tf.int32) # common mask_length divisor\n",
        "\n",
        "    def SVD_k_proj():\n",
        "        pass\n",
        "\n",
        "class TransformerEncoderBlock(tf.keras.layers.Layer):\n",
        "    def __init__(self, d_model, num_heads, d_ff, linear, mask_shape, dropout_rate=0.1):\n",
        "        super(TransformerEncoderBlock, self).__init__()\n",
        "        self.mha = (\n",
        "            LinearMHAttention(num_heads=num_heads, key_dim=d_model, mask_shape=mask_shape, dropout=dropout_rate)\n",
        "            if linear\n",
        "            else MultiHeadAttention(num_heads=num_heads, key_dim=d_model, dropout=dropout_rate)\n",
        "        )\n",
        "        self.ffn = tf.keras.Sequential([\n",
        "            Dense(d_ff, activation='relu'),\n",
        "            Dense(d_model),\n",
        "        ])\n",
        "\n",
        "        self.layernorm1 = LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm2 = LayerNormalization(epsilon=1e-6)\n",
        "\n",
        "        self.dropout1 = Dropout(dropout_rate)\n",
        "        self.dropout2 = Dropout(dropout_rate)\n",
        "\n",
        "    def call(self, x, mask, training):\n",
        "        # Multi-Head Attention\n",
        "        attn_output = self.mha(x, x, attention_mask=mask)\n",
        "        # tf.print(\"attn_output\", attn_output.shape)\n",
        "        attn_output = self.dropout1(attn_output, training=training)\n",
        "        out1 = self.layernorm1(x + attn_output)  # Add & Normalize\n",
        "\n",
        "        # Feedforward Network\n",
        "        ffn_output = self.ffn(out1)\n",
        "        # tf.print(\"ffn_output\", ffn_output.shape)\n",
        "        ffn_output = self.dropout2(ffn_output, training=training)\n",
        "        out2 = self.layernorm2(out1 + ffn_output)  # Add & Normalize\n",
        "        return out2\n",
        "\n",
        "\n",
        "class Decoder( Layer ):\n",
        "    def __init__(self, args, linear=True):\n",
        "        super().__init__()\n",
        "        code = args.code\n",
        "        self.pcm = tf.cast(code.H, dtype=tf.int32)\n",
        "\n",
        "        # shapes\n",
        "        self._m, self._n = self.pcm.shape\n",
        "        self._k = self._n - self._m\n",
        "        self.dims = args.d_model\n",
        "        self.batch_size = args.batch_size\n",
        "\n",
        "        # mask\n",
        "        self.mask = self.create_mask(self.pcm)\n",
        "        for matrix, title in zip([self.pcm, tf.squeeze(self.mask, axis=0)], [\"PCM Matrix\", \"Mask Matrix\"]):\n",
        "            plt.imshow(matrix, cmap='viridis'); plt.colorbar(); plt.title(title); plt.show()\n",
        "        # print(\"mask, pcm: \", self.mask, self.pcm)\n",
        "\n",
        "        # layers\n",
        "        self.node_embeddings = Dense(self.dims)\n",
        "        self.encoder_blocks = [\n",
        "            TransformerEncoderBlock(\n",
        "                d_model=args.d_model,\n",
        "                num_heads=args.heads,\n",
        "                d_ff=args.d_model * 4,\n",
        "                linear=linear,\n",
        "                mask_shape=self.mask.shape,\n",
        "                dropout_rate=0.1,\n",
        "            )\n",
        "            for _ in range(args.t_layers)\n",
        "        ]\n",
        "        self.forward_channel = Dense(1)\n",
        "        self.to_n = Dense(self._n)\n",
        "\n",
        "    def create_mask(self, H):\n",
        "        # Initialize diagonal identity mask\n",
        "        mask = tf.eye(2 * self._n - self._k, dtype=tf.float32)\n",
        "\n",
        "        # Get indices where H == 1\n",
        "        indices = tf.where(H == 1)  # Returns (row, col) pairs where H is 1\n",
        "        check_nodes, variable_nodes = indices[:, 0], indices[:, 1]\n",
        "\n",
        "        # Step 1: Update check node to variable node connections\n",
        "        mask = tf.tensor_scatter_nd_update(mask,\n",
        "                                          tf.stack([n + check_nodes, variable_nodes], axis=1),\n",
        "                                          tf.ones_like(check_nodes, dtype=tf.float32))\n",
        "        mask = tf.tensor_scatter_nd_update(mask,\n",
        "                                          tf.stack([variable_nodes, n + check_nodes], axis=1),\n",
        "                                          tf.ones_like(check_nodes, dtype=tf.float32))\n",
        "\n",
        "        # Step 2: Update variable node connections\n",
        "        for cn in tf.unique(check_nodes)[0]:  # Iterate over unique check nodes\n",
        "            related_vns = tf.boolean_mask(variable_nodes, check_nodes == cn)\n",
        "            indices = tf.stack(tf.meshgrid(related_vns, related_vns), axis=-1)\n",
        "            indices = tf.reshape(indices, [-1, 2])  # Flatten indices\n",
        "            mask = tf.tensor_scatter_nd_update(mask, indices, tf.ones_like(indices[:, 0], dtype=tf.float32))\n",
        "\n",
        "        # Tile mask across batch size for tf MHA\n",
        "        mask = tf.expand_dims(mask, axis=0)  # Shape: (1, n+m, n+m)\n",
        "        # mask = tf.tile(mask, [self.batch_size, 1, 1])  # Shape: (b, n+m, n+m)\n",
        "        return mask\n",
        "\n",
        "    def get_syndrome(self, vn_vector, from_llr=True):\n",
        "        \"\"\" Calculate syndrome (pcm @ r = 0) if r is correct in binary \"\"\"\n",
        "        vn_vector = tf.transpose(vn_vector) # (n,b)\n",
        "        bin_vector = llr_to_bin(vn_vector) if from_llr else vn_vector\n",
        "        return tf.cast( (self.pcm @ bin_vector) % 2, dtype=tf.float32) # (m,n)@(n,b)->(m,b)\n",
        "\n",
        "    def call(self, x_nodes, training=False):\n",
        "        # tf.print(\"DECODER CALL\")\n",
        "        # tf.print(\"x_nodes\", x_nodes.shape)\n",
        "        # Embed cn/vn nodes vector\n",
        "        x_nodes_embedded = self.node_embeddings( x_nodes ) # (b, n+m, hidden_dims)\n",
        "        # Pass through each encoder block\n",
        "        for block in self.encoder_blocks:\n",
        "            x_nodes = block(x_nodes_embedded,\n",
        "                            mask=self.mask,\n",
        "                            training=training)\n",
        "            # tf.print(\"x_nodes\", x_nodes.shape)\n",
        "        x_nodes = tf.squeeze( self.forward_channel(x_nodes), axis=-1 ) # (b, n+m, hidden_dims)->(b, n+m)\n",
        "        # tf.print(\"x_nodes\", x_nodes, x_nodes.shape)\n",
        "        llr_hat = self.to_n(x_nodes) # (b, n+m)->(b,n)\n",
        "        # tf.print(\"Decoded output (llr_hat):\", llr_hat)\n",
        "        return llr_hat\n",
        "\n",
        "\n",
        "class E2EModel(tf.keras.Model):\n",
        "    def __init__(self, encoder, decoder, k, n, return_infobits=False, es_no=False):\n",
        "        super().__init__()\n",
        "\n",
        "        self._n = n\n",
        "        self._k = k\n",
        "        self._m = n - k\n",
        "\n",
        "        self._binary_source = BinarySource(dtype=tf.int32)\n",
        "        self._num_bits_per_symbol = 2\n",
        "        self._mapper = Mapper(\"qam\", self._num_bits_per_symbol)\n",
        "        self._demapper = Demapper(\"app\", \"qam\", self._num_bits_per_symbol)\n",
        "        self._channel = AWGN()\n",
        "        self._decoder = decoder\n",
        "        self._encoder = encoder\n",
        "        self._return_infobits = return_infobits\n",
        "        self._es_no = es_no\n",
        "\n",
        "    @tf.function(jit_compile=False)\n",
        "    def call(self, batch_size, ebno_db):\n",
        "\n",
        "        # no rate-adjustment for uncoded transmission or es_no scenario\n",
        "        if self._decoder is not None and self._es_no==False:\n",
        "            no = ebnodb2no(ebno_db, self._num_bits_per_symbol, self._k/self._n)\n",
        "        else: #for uncoded transmissions the rate is 1\n",
        "            no = ebnodb2no(ebno_db, self._num_bits_per_symbol, 1)\n",
        "\n",
        "        b = self._binary_source([batch_size, self._k])\n",
        "        if self._encoder is not None:\n",
        "            c = self._encoder(b)\n",
        "        else:\n",
        "            c = b\n",
        "\n",
        "        # check that rate calculations are correct\n",
        "        assert self._n==c.shape[-1], \"Invalid value of n.\"\n",
        "\n",
        "        # zero padding to support odd codeword lengths\n",
        "        if self._n%2==1:\n",
        "            c_pad = tf.concat([c, tf.zeros([batch_size, 1])], axis=1)\n",
        "        else: # no padding\n",
        "            c_pad = c\n",
        "        x = self._mapper(c_pad)\n",
        "\n",
        "        y = self._channel([x, no])\n",
        "        llr = self._demapper([y, no])\n",
        "\n",
        "        # remove zero padded bit at the end\n",
        "        if self._n%2==1:\n",
        "            llr = llr[:,:-1]\n",
        "        # tf.print('PCM @ CW: ', self._decoder.pcm @\n",
        "                #  tf.transpose(tf.cast(c, dtype=tf.int32)) % 2)\n",
        "\n",
        "        # decoder input nodes\n",
        "        syndrome = tf.reshape( self._decoder.get_syndrome(llr),\n",
        "                               (batch_size, self._m) ) # (m,n)@(n,b)->(m,b) check nodes\n",
        "        # tf.print(\"SYNDROME_CHECK\", self._decoder.get_syndrome(bin_to_llr(c)))\n",
        "        # tf.print(\"syndrome_sum\", tf.reduce_sum(syndrome))\n",
        "        x_nodes = tf.concat([llr, syndrome], axis=1)[:, :, tf.newaxis] # (b, n+m, 1)\n",
        "        # tf.print(\"syndrome, x_nodes.dtype\", syndrome, x_nodes.dtype)\n",
        "\n",
        "        # and run the decoder\n",
        "        if self._decoder is not None:\n",
        "            # tf.print('x_nodes input: ', x_nodes)\n",
        "            ############################\n",
        "            c_hat_logits = self._decoder(x_nodes)\n",
        "            ############################\n",
        "            # tf.print(llr_hat)\n",
        "            # c_check = llr_to_bin(bin_to_llr(c))\n",
        "            # tf.print(\"CHECK: \", c.dtype, c_check.dtype, c==c_check)\n",
        "        c_hat = tf.cast(tf.greater(c_hat_logits, 0.0), tf.int32)\n",
        "\n",
        "        if self._return_infobits:\n",
        "            return b, c_hat, c_hat_logits, llr\n",
        "        else:\n",
        "            return c, c_hat, c_hat_logits, llr\n",
        "\n",
        "\n",
        "# args for decoder/discriminator\n",
        "args = Args(model_type='dis')\n",
        "args.code.H = pcm\n",
        "args.n, args.m = pcm.shape\n",
        "args.k = k\n",
        "args.n_steps = args.m + 5\n",
        "\n",
        "ltd_decoder = Decoder(args) # Linear Transformer Diffusion (LTD) Decoder\n",
        "\n",
        "e2e_ltd = E2EModel(encoder, ltd_decoder, k, n)"
      ],
      "metadata": {
        "id": "XOILyjSGXMdb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 855
        },
        "outputId": "46e82785-1a44-4714-872a-87660181d071"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhcAAAGTCAYAAACbEDAbAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAz10lEQVR4nO3df1hVZbr/8c8GEzQFf/JDpTTL34mJSmglTiSZWfStjqGFedSyIx2VqdTGxLTCmdLs5A+yMmamSM1JbdIwBkOPiWNizMlO2rFMzQQ1R1BKsL339w/GnVtA2ey112a736/req4rFs+z1s2+NG/u+1lrWex2u10AAAAGCfB2AAAA4PJCcgEAAAxFcgEAAAxFcgEAAAxFcgEAAAxFcgEAAAxFcgEAAAxFcgEAAAxFcgEAAAxFcgEAAAxFcgEAwGVqy5YtGjFihNq1ayeLxaK1a9deck1+fr769u2roKAgXXvttcrKynL5uiQXAABcpsrLyxUdHa3FixfXaf7+/fs1fPhwDRkyREVFRZoyZYrGjx+vjRs3unRdCy8uAwDg8mexWLRmzRolJSXVOmfatGlav369du/e7Tj2wAMP6OTJk8rJyanztRq5EygAALi0M2fOqLKy0u3z2O12WSwWp2NBQUEKCgpy+9ySVFBQoISEBKdjiYmJmjJlikvnIbkAAMCDzpw5o05XN1PxUavb52rWrJlOnz7tdCw9PV2zZ892+9ySVFxcrPDwcKdj4eHhKisr088//6wmTZrU6TwkFwAAeFBlZaWKj1q1v/BqhTSv/1bHslM2dYo5oEOHDikkJMRx3KiqhZFILgAAMEFI8wC3kgvHeUJCnJILI0VERKikpMTpWElJiUJCQupctZBILgAAMIXVbpPVjVsorHabccHUIi4uThs2bHA6lpubq7i4OJfOw62oAACYwCa728NVp0+fVlFRkYqKiiRV3WpaVFSkgwcPSpJmzJihlJQUx/yJEyfq22+/1VNPPaU9e/ZoyZIlWrVqlaZOnerSdUkuAAC4TO3cuVM33HCDbrjhBklSWlqabrjhBs2aNUuSdOTIEUeiIUmdOnXS+vXrlZubq+joaM2fP19vvPGGEhMTXbouz7kAAMCDysrKFBoaqh/2dnB7Q2e7rt+rtLTUY3sujMKeCwAATGC122V14/d5d9aajbYIAAAwFJULAABMUN9Nmeev9xUkFwAAmMAmu6wkFwAAwCj+VLlgzwUAADAUlQsAAEzgT3eLkFwAAGAC27+GO+t9BW0RAABgKCoXAACYwOrm3SLurDUbyQUAACaw2uXmW1GNi8XTaIsAAABDUbkAAMAE/rShk+QCAAAT2GSRVRa31vsK2iIAAMBQVC4AADCBzV413FnvK0guAAAwgdXNtog7a81GcgEAgAn8KblgzwUAADAUlQsAAExgs1tks7txt4gba81GcgEAgAloiwAAANQTlQsAAExgVYCsbvxObzUwFk8juQAAwAR2N/dc2H1ozwVtEQAAYCgqFwAAmMCfNnSSXAAAYAKrPUBWuxt7Lnzo8d+0RQAAgKGoXAAAYAKbLLK58Tu9Tb5TuiC5AADABOy5AAAAhnJ/z4XvVC7YcwEAAAxF5QIAABNU7blw48VltEUAAMD5bG4+/tuXNnTSFgEAAIaicgEAgAn8aUMnyQUAACawKcBvnnNBWwQAABiKygUAACaw2i2yuvHadHfWmo3kAgAAE1jdvFvESlsEAAD4KyoXAACYwGYPkM2Nu0Vs3C0CAADO509tEZILAABMYJN7mzJtxoXicey5AAAAhqJyAQCACdx/iJbv1ANILgAAMIH7j//2neTCdyIFAAA+gcoFAAAmsMkim9zZ0MkTOgEAwHloiwAAANQTlQsAAEzg/kO0fKceQHIBAIAJbHaLbO48RMuH3orqO2kQAADwCVQuAAAwgc3NtggP0QIAAE7cfysqyQUAADiPVRZZ3XhWhTtrzeY7aRCAy0J+fr4sFovy8/O9HQoADyG5AOohKytLFovFMYKDg9WlSxelpqaqpKSk2vySkhI98cQT6tatm5o2baorr7xSMTExeu6553Ty5EnHvPj4eFksFl133XU1Xjc3N9dxzdWrV180xu+++84x97nnnqtxzujRo2WxWNSsWbO6//Dnyc7O1sKFC+u1FvA359oi7gxfQVsEcMOcOXPUqVMnnTlzRlu3btXSpUu1YcMG7d69W02bNpUkffbZZ7rjjjt0+vRpPfjgg4qJiZEk7dy5U/PmzdOWLVv08ccfO84ZHBysffv2aceOHRowYIDT9d555x0FBwfrzJkzdY4xODhY7777rmbOnOl0vLy8XOvWrVNwcHB9f3xlZ2dr9+7dmjJlSp3X3HLLLfr555/VuHHjel8X8EVWudfasBoXiseRXABuGDZsmPr16ydJGj9+vFq3bq0FCxZo3bp1Sk5O1smTJ3XPPfcoMDBQn3/+ubp16+a0/vnnn9frr7/udKxz58765Zdf9O677zolF2fOnNGaNWs0fPhw/eUvf6lzjHfccYfef/99/eMf/1B0dLTj+Lp161RZWanbb79dmzZtqs+P75IzZ86ocePGCggIcCuhAdDw+U6NBfABv/nNbyRJ+/fvlyS99tprOnz4sBYsWFAtsZCk8PDwahUFSUpOTtbKlStls9kcx/7617/qp59+0r/927+5FFNcXJw6deqk7Oxsp+PvvPOObr/9drVq1aramnXr1mn48OFq166dgoKC1LlzZ82dO1dW66+/O8XHx2v9+vU6cOCAo/3SsWNHSb/uq1ixYoVmzpyp9u3bq2nTpiorK6u25+Krr75SkyZNlJKS4hTD1q1bFRgYqGnTprn08wINFW0RAPXyzTffSJJat24tSfrggw/UpEkT3XfffS6dZ9SoUZo9e7by8/MdCUt2drZuvfVWhYWFuRxXcnKy3n77bc2bN08Wi0XHjx/Xxx9/rD//+c/KycmpNj8rK0vNmjVTWlqamjVrpk2bNmnWrFkqKyvTiy++KEn63e9+p9LSUn3//fd6+eWXJana3o25c+eqcePGeuKJJ1RRUVFjK6R79+6aO3eunnzySd1333266667VF5erocffljdunXTnDlzXP55gYaIF5cBqJPS0lIdP35c33//vVauXKk5c+aoSZMmuvPOOyVV/VbepUsXl/cXXHfdderXr5+j2nDy5Elt2LBBo0aNqleco0aN0sGDB/Xpp59KklatWqXg4GDdddddNc7Pzs7WypUr9cQTT2jixIlatWqVHn30US1ZskQVFRWSpNtuu03t27fXlVdeqQcffFAPPvigkpKSnM5z5swZbdu2TVOnTtX06dMd+1AulJaWpptuukmPPPKIfvzxR02bNk0HDhzQH//4RwUFBdXrZwZQZfHixerYsaOCg4MVGxurHTt2XHT+woUL1bVrVzVp0kRRUVGaOnWqS/u8JJILwC0JCQlq27atoqKi9MADD6hZs2Zas2aN2rdvL0kqKytT8+bN63XuUaNG6f3331dlZaVWr16twMBA3XPPPfU6V8+ePdW7d2+9++67kqqSh7vvvrvWf+ybNGni+O9Tp07p+PHjuvnmm/XTTz9pz549db7umDFjnM5Vm4CAAGVlZen06dMaNmyYlixZohkzZjj2swCXA7sssrkx7PXYDLpy5UqlpaUpPT1du3btUnR0tBITE3X06NEa52dnZ2v69OlKT0/XV199pTfffFMrV67U008/7dJ1SS4ANyxevFi5ubn65JNP9L//+7/69ttvlZiY6Ph+SEiITp06Va9zP/DAAyotLdVHH32kd955R3feeWe9ExWpKll57733tG/fPm3btu2iVZAvv/xS99xzj0JDQxUSEqK2bdvqwQcflFRVramrTp061Xlu586dNXv2bH322Wfq2bOnnnnmmTqvBXzBubaIO8NVCxYs0IQJEzR27Fj16NFDmZmZatq0qZYvX17j/G3btmnQoEEaNWqUOnbsqKFDhyo5OfmS1Y4LkVwAbhgwYIASEhIUHx+v7t27KyDA+a9Ut27d9PXXX6uystLlc0dGRio+Pl7z58/Xli1b6t0SOSc5OVnHjx/XhAkT1Lp1aw0dOrTGeSdPntTgwYP1j3/8Q3PmzNFf//pX5ebm6ve//70kOW0yvZS6VC3Od+6W3B9++EE//vijS2sBf1FWVuY0zrUqL1RZWanCwkIlJCQ4jgUEBCghIUEFBQU1rhk4cKAKCwsdycS3336rDRs26I477nApRpILwINGjBihn3/+2aVbR883atQo/fd//7dCQkJc/st9oauuukqDBg1Sfn6+7r//fjVqVPN+7vz8fP3444/KysrS5MmTdeeddyohIUEtW7asNtdiMe5xxJmZmcrNzdXzzz+vyspKPfroo4adG2gIzr1y3Z0hSVFRUQoNDXWMjIyMGq93/PhxWa1WhYeHOx0PDw9XcXFxjWtGjRqlOXPm6KabbtIVV1yhzp07Kz4+3uW2CHeLAB40ceJEvfrqq/rtb3+rmJgYdenSxen7R48e1bJly2q8HVWS7rvvPh06dEhdu3Y15KFTzz33nD755BONHDmy1jmBgYGSJLvd7jhWWVmpJUuWVJt75ZVXutQmqc3+/fv15JNP6t5779XTTz+t1q1ba+LEifrTn/5U7RZVwFdZ3Xwr6rm1hw4dUkhIiOO4kZue8/Pz9cILL2jJkiWKjY3Vvn37NHnyZM2dO9elViXJBeBBLVu21Jo1a3THHXeoT58+Tk/o3LVrl959913FxcXVuj40NFSzZ882LJ7Bgwdr8ODBF50zcOBAtWzZUmPGjNF//ud/ymKx6M9//rNTsnFOTEyMY8NY//791axZM40YMcKlmOx2u/793/9dTZo00dKlSyVJjz76qP7yl79o8uTJSkhIULt27Vw6J9AQnV99qO96qWov1/nJRW3atGmjwMDAaq8kKCkpUURERI1rnnnmGT300EMaP368JOn6669XeXm5HnnkEf3ud7+r1vqtDW0RwMNiY2O1e/duTZw4UZs3b9aUKVOUlpamwsJCTZ8+Xe+99563Q3TSunVrffjhh4qMjNTMmTP10ksv6bbbbtMf/vCHanP/4z/+Q6NGjdJbb72lUaNG6fHHH3f5eq+++qry8/OVmZmptm3bOo6/+eabstlsmjBhgls/D+CvGjdurJiYGOXl5TmO2Ww25eXl1fpLzU8//VQtgaipmnkpFrsrswEAgEvKysoUGhqq1K33KKjZFfU+T8Xps1p00xqVlpbWqXIhVd2KOmbMGL322msaMGCAFi5cqFWrVmnPnj0KDw9XSkqK2rdv79i3MXv2bC1YsEDLli1ztEUee+wxR5WyrmiLAABgAqvdIqsbbZH6rB05cqSOHTumWbNmqbi4WH369FFOTo5jk+fBgwedKhUzZ86UxWLRzJkzdfjwYbVt21YjRozQ888/79J1qVwAAOBB5yoXj/33/3O7crH05vddqlx4C5ULAABMYNSGTl/gsQ2dJ06c0OjRoxUSEqIWLVpo3LhxOn369EXXxMfHO96ueG5MnDjRUyECAGAau5tvRLX70IvLPFa5GD16tI4cOaLc3FydPXtWY8eO1SOPPFLttc8XmjBhgtNbEGt79wEAAGiYPJJcfPXVV8rJydFnn33mePHQq6++qjvuuEMvvfTSRe9Zb9q0aa333wIA4Kussshaj5ePnb/eV3gkuSgoKFCLFi2c3miYkJCggIAA/f3vf7/omx3feecdvf3224qIiNCIESP0zDPPXLR6UVFR4fRcdZvNphMnTqh169aGPpoYAHD5sdvtOnXqlNq1a1fnB0TVl83u3r4Jmw/dfuGR5KK4uFhhYWHOF2rUSK1atar1eeZS1TPNr776arVr107/8z//o2nTpmnv3r16//33a12TkZGhZ5991rDYAQD+59ChQ+rQoYO3w7hsuJRcTJ8+3fFmxNp89dVX9Q7mkUcecfz39ddfr8jISN1666365ptv1Llz5xrXzJgxQ2lpaY6vS0tLddVVV+km3aFGqv8tP7h8rPn6C2+H0CDc0+V6b4fQIPDn4Vf8mZB+0Vlt1QY1b97c49c6tzHTnfW+wqXk4re//a0efvjhi8655pprFBERoaNHjzod/+WXX3TixAmX9lPExsZKkvbt21drchEUFFTjS1sa6Qo1spBcQApp7jt/IT2Jvw9V+PPwK/5MSPpXq8GMNrpNFtnc2DfhzlqzuZRctG3b1unZ/7WJi4vTyZMnVVhY6HhJ06ZNm2Sz2RwJQ10UFRVJkiIjI10JEwCABscbT+j0Fo+k8N27d9ftt9+uCRMmaMeOHfr000+VmpqqBx54wHGnyOHDh9WtWzft2LFDkvTNN99o7ty5Kiws1HfffacPPvhAKSkpuuWWW9S7d29PhAkAADzAY8+5eOedd5Samqpbb71VAQEBuvfee/Vf//Vfju+fPXtWe/fu1U8//SSp6u1tf/vb37Rw4UKVl5crKipK9957r2bOnOmpEAEAMA17LgzQqlWriz4wq2PHjk6vb42KitLmzZs9FQ4AAF5lk5uP//ahPRe+kwYBAACfwIvLAAAwgd3Nu0XsPlS5ILkAAMAEvBUVAACgnqhcAABgAu4WAQAAhqItAgAAUE9ULgAAMAHvFgEAAIbyp7YIyQUAACbwp+SCPRcAAMBQVC4AADCBP1UuSC4AADCBPyUXtEUAAIChqFwAAGACu9y7ndRuXCgeR3IBAIAJaIsAAADUE5ULAABM4E+VC5ILAABM4E/JBW0RAABgKCoXAACYwJ8qFyQXAACYwG63yO5GguDOWrOZ0hZZvHixOnbsqODgYMXGxmrHjh0Xnf/ee++pW7duCg4O1vXXX68NGzaYESYAAB5z7pXr7gxf4fHkYuXKlUpLS1N6erp27dql6OhoJSYm6ujRozXO37Ztm5KTkzVu3Dh9/vnnSkpKUlJSknbv3u3pUAEAgAE8nlwsWLBAEyZM0NixY9WjRw9lZmaqadOmWr58eY3zX3nlFd1+++168skn1b17d82dO1d9+/bVokWLPB0qAAAec27PhTvDV3g0uaisrFRhYaESEhJ+vWBAgBISElRQUFDjmoKCAqf5kpSYmFjr/IqKCpWVlTkNAAAamnN7LtwZvsKjycXx48dltVoVHh7udDw8PFzFxcU1rikuLnZpfkZGhkJDQx0jKirKmOABAEC9+PxzLmbMmKHS0lLHOHTokLdDAgCgGn9qi3j0VtQ2bdooMDBQJSUlTsdLSkoUERFR45qIiAiX5gcFBSkoKMiYgAEA8BBuRTVI48aNFRMTo7y8PMcxm82mvLw8xcXF1bgmLi7Oab4k5ebm1jofAAA0LB5/iFZaWprGjBmjfv36acCAAVq4cKHKy8s1duxYSVJKSorat2+vjIwMSdLkyZM1ePBgzZ8/X8OHD9eKFSu0c+dOLVu2zNOhAgDgMXY3Wxu+VLnweHIxcuRIHTt2TLNmzVJxcbH69OmjnJwcx6bNgwcPKiDg1wLKwIEDlZ2drZkzZ+rpp5/Wddddp7Vr16pXr16eDhUAAI+xS7Lb3VvvK0x5/HdqaqpSU1Nr/F5+fn61Y/fff7/uv/9+D0cFAAA8gXeLAABgApsssrjxCG9fevw3yQUAACbwp7tFSC4AADCBzW6RxU9eue7zD9ECAAANC5ULAABMYLe7ebeID90uQnIBAIAJ/GnPBW0RAABgKCoXAACYwJ8qFyQXAACYgLtFAAAA6onKBQAAJuBuEQAAYKiq5MKdPRcGBuNhtEUAAIChqFwAAGAC7hYBAACGsv9ruLPeV5BcAABgAn+qXLDnAgAAGIrKBQAAZvCjvgiVCwAAzPCvtkh9h+rZFlm8eLE6duyo4OBgxcbGaseOHRedf/LkSU2aNEmRkZEKCgpSly5dtGHDBpeuSeUCAIDL1MqVK5WWlqbMzEzFxsZq4cKFSkxM1N69exUWFlZtfmVlpW677TaFhYVp9erVat++vQ4cOKAWLVq4dF2SCwAATOCNJ3QuWLBAEyZM0NixYyVJmZmZWr9+vZYvX67p06dXm798+XKdOHFC27Zt0xVXXCFJ6tixo8vXpS0CAIAJ3GmJnH+nSVlZmdOoqKio8XqVlZUqLCxUQkKC41hAQIASEhJUUFBQ45oPPvhAcXFxmjRpksLDw9WrVy+98MILslqtLv2spiQXrvR7srKyZLFYnEZwcLAZYQIA0OBFRUUpNDTUMTIyMmqcd/z4cVmtVoWHhzsdDw8PV3FxcY1rvv32W61evVpWq1UbNmzQM888o/nz5+u5555zKUaPt0Vc7fdIUkhIiPbu3ev42mLxnXt7AQCokRubMh3rJR06dEghISGOw0FBQe5G5mCz2RQWFqZly5YpMDBQMTExOnz4sF588UWlp6fX+Twer1yc3+/p0aOHMjMz1bRpUy1fvrzWNRaLRREREY5xYdYFAICvObfnwp0hVf0Cfv6oLblo06aNAgMDVVJS4nS8pKREERERNa6JjIxUly5dFBgY6DjWvXt3FRcXq7Kyss4/q0crF+f6PTNmzHAcu1S/R5JOnz6tq6++WjabTX379tULL7ygnj171ji3oqLCqd9UVlYmSVrz9RcKae7fW0oS2/XxdggNAp9DlY0/FHk7hAaBPw/wGpOfc9G4cWPFxMQoLy9PSUlJkqoqE3l5eUpNTa1xzaBBg5SdnS2bzaaAgKp/Q7/++mtFRkaqcePGdb62R//1rU+/p2vXrlq+fLnWrVunt99+WzabTQMHDtT3339f4/yMjAyn3lNUVJThPwcAAL4oLS1Nr7/+uv74xz/qq6++0mOPPaby8nLH3SMpKSlOBYDHHntMJ06c0OTJk/X1119r/fr1euGFFzRp0iSXrtvgbkWNi4tTXFyc4+uBAweqe/fueu211zR37txq82fMmKG0tDTH12VlZSQYAIAGxxvvFhk5cqSOHTumWbNmqbi4WH369FFOTo7jl/6DBw86KhRS1WbRjRs3aurUqerdu7fat2+vyZMna9q0aS5d16PJRX36PRe64oordMMNN2jfvn01fj8oKMjQzSwAAHiMFx7hnZqaWmsbJD8/v9qxuLg4bd++3a1rerQtcn6/55xz/Z7zqxMXY7Va9cUXXygyMtJTYQIAAAN5vC2SlpamMWPGqF+/fhowYIAWLlxYrd/Tvn17x326c+bM0Y033qhrr71WJ0+e1IsvvqgDBw5o/Pjxng4VAACP8adXrns8uXC13/PPf/5TEyZMUHFxsVq2bKmYmBht27ZNPXr08HSoAAB4jh+9FdWUDZ2u9HtefvllvfzyyyZEBQAAPKHB3S0CAMDlyfKv4c5630ByAQCAGfyoLeLfj7AEAACGo3IBAIAZ/KhyQXIBAIAZDHorqi8guQAAwATnv9m0vut9BXsuAACAoahcAABgBvZcAAAAQ/nRngvaIgAAwFBULgAAMIHFXjXcWe8rSC4AADCDH+25oC0CAAAMReUCAAAz+NGGTpILAADMQFsEAACgfqhcAABgBj+qXJBcAABgBpILAABgKD/a0MmeCwAAYCgqFwAAmIAndAIAAGP50Z4Lj7ZFtmzZohEjRqhdu3ayWCxau3btJdfk5+erb9++CgoK0rXXXqusrCxPhggAAAzm0eSivLxc0dHRWrx4cZ3m79+/X8OHD9eQIUNUVFSkKVOmaPz48dq4caMnwwQAAAbyaFtk2LBhGjZsWJ3nZ2ZmqlOnTpo/f74kqXv37tq6datefvllJSYmeipMAAA8ziI391wYFonnNai7RQoKCpSQkOB0LDExUQUFBbWuqaioUFlZmdMAAADe06CSi+LiYoWHhzsdCw8PV1lZmX7++eca12RkZCg0NNQxoqKizAgVAADXnHvOhTvDRzSo5KI+ZsyYodLSUsc4dOiQt0MCAKA6uwHDRzSoW1EjIiJUUlLidKykpEQhISFq0qRJjWuCgoIUFBRkRngAAKAOGlTlIi4uTnl5eU7HcnNzFRcX56WIAAAwiB9VLjyaXJw+fVpFRUUqKiqSVHWraVFRkQ4ePCipqqWRkpLimD9x4kR9++23euqpp7Rnzx4tWbJEq1at0tSpUz0ZJgAAHnfuCZ3uDF/h0bbIzp07NWTIEMfXaWlpkqQxY8YoKytLR44ccSQaktSpUyetX79eU6dO1SuvvKIOHTrojTfe4DZUAIDv86MndHo0uYiPj5fdXvunUdPTN+Pj4/X55597MCoAAOBJDWpDJwAAly0qFwAAwEj+9FbUBnW3CAAA8H1ULgAAMIO7T9n0oSd0klwAAGAGP9pzQVsEAAAYisoFAAAm8KcNnSQXAACYgbYIAABA/VC5AADADO6+H8SHKhckFwAAmMGP2iIkFwAAmMGPkgv2XAAAAENRuQAAwAT+dCsqlQsAAGAokgsAAGAo2iIAAJjBjzZ0klwAAGAC9lwAAADUE5ULAADM4kPVB3eQXAAAYAY/2nNBWwQAABjKo8nFli1bNGLECLVr104Wi0Vr16696Pz8/HxZLJZqo7i42JNhAgDgcec2dLozfIVHk4vy8nJFR0dr8eLFLq3bu3evjhw54hhhYWEeihAAAJPYDRg+wqN7LoYNG6Zhw4a5vC4sLEwtWrQwPiAAALyEW1G9rE+fPoqMjNRtt92mTz/99KJzKyoqVFZW5jQAAID3NKi7RSIjI5WZmal+/fqpoqJCb7zxhuLj4/X3v/9dffv2rXFNRkaGnn322WrH7+lyvRpZrvB0yA3axh+KvB1Cg5DYro+3Q2gQ+BxwIf4fIZWdsqllF5Mu5qW7RRYvXqwXX3xRxcXFio6O1quvvqoBAwZcct2KFSuUnJysu++++5J7Ji/UoCoXXbt21aOPPqqYmBgNHDhQy5cv18CBA/Xyyy/XumbGjBkqLS11jEOHDpkYMQAAdeSFPRcrV65UWlqa0tPTtWvXLkVHRysxMVFHjx696LrvvvtOTzzxhG6++WbXL6oGllzUZMCAAdq3b1+t3w8KClJISIjTAAAA0oIFCzRhwgSNHTtWPXr0UGZmppo2barly5fXusZqtWr06NF69tlndc0119Trug0+uSgqKlJkZKS3wwAAwC1G3Yp64T7DioqKGq9XWVmpwsJCJSQkOI4FBAQoISFBBQUFtcY5Z84chYWFady4cfX+WT265+L06dNOVYf9+/erqKhIrVq10lVXXaUZM2bo8OHD+tOf/iRJWrhwoTp16qSePXvqzJkzeuONN7Rp0yZ9/PHHngwTAADPM2jPRVRUlNPh9PR0zZ49u9r048ePy2q1Kjw83Ol4eHi49uzZU+Mltm7dqjfffFNFRUVuBOrh5GLnzp0aMmSI4+u0tDRJ0pgxY5SVlaUjR47o4MGDju9XVlbqt7/9rQ4fPqymTZuqd+/e+tvf/uZ0DgAA/NmhQ4ectgAEBQUZct5Tp07poYce0uuvv642bdq4dS6PJhfx8fGy22tP07Kyspy+fuqpp/TUU095MiQAALzDoMpFXfcXtmnTRoGBgSopKXE6XlJSooiIiGrzv/nmG3333XcaMWKE45jNZpMkNWrUSHv37lXnzp3rFGqD33MBAMDlwOzHfzdu3FgxMTHKy8tzHLPZbMrLy1NcXFy1+d26ddMXX3yhoqIix7jrrrs0ZMgQFRUVVWvHXEyDes4FAAAwTlpamsaMGaN+/fppwIABWrhwocrLyzV27FhJUkpKitq3b6+MjAwFBwerV69eTuvPPS37wuOXQnIBAIAZvPAQrZEjR+rYsWOaNWuWiouL1adPH+Xk5Dg2eR48eFABAcY3MUguAAAwgbfeLZKamqrU1NQav5efn3/RtRfujawrkgsAAMzgpcd/ewMbOgEAgKGoXAAAYAY/qlyQXAAAYALLv4Y7630FbREAAGAoKhcAAJiBtggAADCSt25F9QbaIgAAwFBULgAAMANtEQAAYDgfShDcQVsEAAAYisoFAAAm8KcNnSQXAACYgT0XAADASP5UuWDPBQAAMBSVCwAAzEBbBAAAGIm2CAAAQD15NLnIyMhQ//791bx5c4WFhSkpKUl79+695Lr33ntP3bp1U3BwsK6//npt2LDBk2ECAOB5dgOGj/BocrF582ZNmjRJ27dvV25urs6ePauhQ4eqvLy81jXbtm1TcnKyxo0bp88//1xJSUlKSkrS7t27PRkqAACe5UfJhUf3XOTk5Dh9nZWVpbCwMBUWFuqWW26pcc0rr7yi22+/XU8++aQkae7cucrNzdWiRYuUmZnpyXABAIABTN1zUVpaKklq1apVrXMKCgqUkJDgdCwxMVEFBQU1zq+oqFBZWZnTAACgoTm3odOd4StMSy5sNpumTJmiQYMGqVevXrXOKy4uVnh4uNOx8PBwFRcX1zg/IyNDoaGhjhEVFWVo3AAAGMKP2iKmJReTJk3S7t27tWLFCkPPO2PGDJWWljrGoUOHDD0/AABwjSnPuUhNTdWHH36oLVu2qEOHDhedGxERoZKSEqdjJSUlioiIqHF+UFCQgoKCDIsVAABPsNjtstjrX35wZ63ZPFq5sNvtSk1N1Zo1a7Rp0yZ16tTpkmvi4uKUl5fndCw3N1dxcXGeChMAAM/zo7aIRysXkyZNUnZ2ttatW6fmzZs79k2EhoaqSZMmkqSUlBS1b99eGRkZkqTJkydr8ODBmj9/voYPH64VK1Zo586dWrZsmSdDBQDAo3hCp0GWLl2q0tJSxcfHKzIy0jFWrlzpmHPw4EEdOXLE8fXAgQOVnZ2tZcuWKTo6WqtXr9batWsvugkUAAA0HB6tXNjr0B/Kz8+vduz+++/X/fff74GIAADwEl5cBgAAjERbBAAAoJ6oXAAAYAbaIgAAwEi0RQAAAOqJygUAAGagLQIAAIzmS60Nd9AWAQAAhqJyAQCAGez2quHOeh9BcgEAgAn86W4RkgsAAMzgRxs62XMBAAAMReUCAAATWGxVw531voLkAgAAM9AWAQAAqB8qFwAAmIC7RQAAgLH86DkXtEUAAIChqFwAAGAC2iIAAMBY3C0CAABQP1QuAAAwgT+1RTxaucjIyFD//v3VvHlzhYWFKSkpSXv37r3omqysLFksFqcRHBzsyTABAPC8c3eLuDN8hEeTi82bN2vSpEnavn27cnNzdfbsWQ0dOlTl5eUXXRcSEqIjR444xoEDBzwZJgAAHneucuHO8BUebYvk5OQ4fZ2VlaWwsDAVFhbqlltuqXWdxWJRRESEJ0MDAAAeYuqei9LSUklSq1atLjrv9OnTuvrqq2Wz2dS3b1+98MIL6tmzZ41zKyoqVFFRUe0av+isT+2s9YSyUz70lhsP+sV+1tshAA0S/4+Qyk5XfQZ2M1oOfnS3iGnJhc1m05QpUzRo0CD16tWr1nldu3bV8uXL1bt3b5WWluqll17SwIED9eWXX6pDhw7V5mdkZOjZZ5+tdnyrNhgavy9q2cXbETQU33o7AKBB4v8Rvzp16pRCQ0M9eg1/2tBpsZuSrkmPPfaYPvroI23durXGJKE2Z8+eVffu3ZWcnKy5c+dW+/6FlQubzaYTJ06odevWslgshsTuqrKyMkVFRenQoUMKCQnxSgwNAZ/Dr/gsqvA5VOFzqNIQPge73a5Tp06pXbt2CgjwzDbEsrIyhYaGamDiHDW6ov43KPxy9oy2bZyl0tLSBv/nxpTKRWpqqj788ENt2bLFpcRCkq644grdcMMN2rdvX43fDwoKUlBQkNOxFi1a1DdUQ4WEhDT4PwBm4HP4FZ9FFT6HKnwOVbz9OXi6YuFgs1cNd9b7CI/eLWK325Wamqo1a9Zo06ZN6tSpk8vnsFqt+uKLLxQZGemBCAEAMIndgOEjPFq5mDRpkrKzs7Vu3To1b95cxcXFkqqyxCZNmkiSUlJS1L59e2VkZEiS5syZoxtvvFHXXnutTp48qRdffFEHDhzQ+PHjPRkqAAAwiEeTi6VLl0qS4uPjnY6/9dZbevjhhyVJBw8edOpz/fOf/9SECRNUXFysli1bKiYmRtu2bVOPHj08GaqhgoKClJ6eXq1d42/4HH7FZ1GFz6EKn0MVf/scLHJzQ6dhkXieaRs6AQDwR+c2dA66dbYaNXJjQ+cvZ/Rp3myf2NDJi8sAAIChSC4AADCBtx7/vXjxYnXs2FHBwcGKjY3Vjh07ap37+uuv6+abb1bLli3VsmVLJSQkXHR+bUguAAAwgxfuFlm5cqXS0tKUnp6uXbt2KTo6WomJiTp69GiN8/Pz85WcnKxPPvlEBQUFioqK0tChQ3X48GGXrsueCwAAPOjcnoub49Pd3nPx3/nPurTnIjY2Vv3799eiRYskVT1oMioqSo8//rimT59+yfVWq1UtW7bUokWLlJKSUudYqVx4gCslqMvVli1bNGLECLVr104Wi0Vr1671dkimy8jIUP/+/dW8eXOFhYUpKSlJe/fu9XZYplu6dKl69+7teFBSXFycPvroI2+H5XXz5s2TxWLRlClTvB2K6WbPni2LxeI0unXr5u2wfEZZWZnTOP8p1eerrKxUYWGhEhISHMcCAgKUkJCggoKCOl3rp59+0tmzZy/5TrALkVwYzNUS1OWqvLxc0dHRWrx4sbdD8ZrNmzdr0qRJ2r59u3Jzc3X27FkNHTpU5eXl3g7NVB06dNC8efNUWFionTt36je/+Y3uvvtuffnll94OzWs+++wzvfbaa+rdu7e3Q/Ganj176siRI46xdetWb4fkeTYDhqSoqCiFhoY6xrnnRF3o+PHjslqtCg8PdzoeHh7ueO7UpUybNk3t2rVzSlDqwtS3ovqDBQsWaMKECRo7dqwkKTMzU+vXr9fy5cvrVIK6XAwbNkzDhg3zdhhelZOT4/R1VlaWwsLCVFhYqFtuucVLUZlvxIgRTl8///zzWrp0qbZv317r244vZ6dPn9bo0aP1+uuv67nnnvN2OF7TqFEjRUREeDsMU1nsdlnc2Ilwbu2F72Lx1HNC5s2bpxUrVig/P1/Bwa61c6hcGMiIEhQuX6WlpZLkcnnxcmK1WrVixQqVl5crLi7O2+F4xaRJkzR8+HCXfxO83Pzf//2f2rVrp2uuuUajR4/WwYMHvR2SzzjXYjw3aksu2rRpo8DAQJWUlDgdLykpuWRi99JLL2nevHn6+OOP61VhI7kwkBElKFyebDabpkyZokGDBqlXr17eDsd0X3zxhZo1a6agoCBNnDhRa9as8amn7hplxYoV2rVrV61lbH8RGxurrKws5eTkaOnSpdq/f79uvvlmnTp1ytuheZbJd4s0btxYMTExysvLcxyz2WzKy8u7aHL/hz/8QXPnzlVOTo769evn2kX/hbYIYIJJkyZp9+7d/tFXrkHXrl1VVFSk0tJSrV69WmPGjNHmzZv9KsE4dOiQJk+erNzcXJdLzJeb81umvXv3VmxsrK6++mqtWrVK48aN82JkHma3Vw131rsoLS1NY8aMUb9+/TRgwAAtXLhQ5eXljtb9he/3+v3vf69Zs2YpOztbHTt2dPxi3KxZMzVr1qzO1yW5MJA7JShcvlJTU/Xhhx9qy5Yt6tChg7fD8YrGjRvr2muvlSTFxMTos88+0yuvvKLXXnvNy5GZp7CwUEePHlXfvn0dx6xWq7Zs2aJFixapoqJCgYGBXozQe1q0aKEuXbpo37593g7lsjNy5EgdO3ZMs2bNUnFxsfr06aOcnBxHhf3C93stXbpUlZWVuu+++5zOk56ertmzZ9f5uiQXBjq/BJWUlCTp1xJUamqqd4OD6ex2ux5//HGtWbNG+fn56tSpk7dDajBsNlutt89drm699VZ98cUXTsfGjh2rbt26adq0aX6bWEhVm1y/+eYbPfTQQ94OxaPcecrmufX1kZqaWuu/Qfn5+U5ff/fdd/W7yAVILgx2qRKUvzh9+rTTbyH79+9XUVGRWrVqpauuusqLkZln0qRJys7O1rp169S8eXNHeTE0NFRNmjTxcnTmmTFjhoYNG6arrrpKp06dUnZ2tvLz87Vx40Zvh2aq5s2bV9tvc+WVV6p169Z+tw/niSee0IgRI3T11Vfrhx9+UHp6ugIDA5WcnOzt0DzLC20RbyG5MNilSlD+YufOnRoyZIjj67S0NEnSmDFjlJWV5aWozLV06VJJUnx8vNPxt956Sw8//LD5AXnJ0aNHlZKSoiNHjig0NFS9e/fWxo0bddttt3k7NHjJ999/r+TkZP34449q27atbrrpJm3fvl1t27b1dmgwCI//BgDAg849/js+dqbbj//O//tzPvHKdSoXAACYgbYIAAAwVD3fbOq03kfwEC0AAGAoKhcAAJjAqHeL+AKSCwAAzOBHey5oiwAAAENRuQAAwAx2STY31/sIkgsAAEzgT3suaIsAAABDUbkAAMAMdrm5odOwSDyO5AIAADNwtwgAAED9ULkAAMAMNkkWN9f7CJILAABM4E93i5BcAABgBvZcAAAA1A+VCwAAzOBHlQuSCwAAzOBHyQVtEQAAYCgqFwAAmIFbUQEAgJH86VZU2iIAAMBQVC4AADCDH23oJLkAAMAMNrtkcSNBsPlOckFbBAAAGIrKBQAAZqAtAgAAjOVmciGSCwAAcD4/qlyw5wIAABiKygUAAGaw2eVWa8OH7hYhuQAAwAx2W9VwZ72PoC0CAAAMReUCAAAz+NGGTpILAADM4Ed7LmiLAAAAQ1G5AADADLRFAACAoexyM7kwLBKPoy0CAAAMReUCAAAz0BYBAACGstkkufEgLJvvPESL5AIAADP4UeWCPRcAAMBQVC4AADCDH1UuSC4AADADT+gEAACoHyoXAACYwG63ye7Ga9PdWWs2kgsAAMxgt7vX2vChPRe0RQAAgKGoXAAAYAa7mxs6fahyQXIBAIAZbDbJ4sa+CR/ac0FbBAAAGIrKBQAAZqAtAgAAjGS32WR3oy3CragAAMCZH1Uu2HMBAAAMReUCAAAz2OySxT8qFyQXAACYwW6X5M6tqL6TXNAWAQAAhqJyAQCACew2u+xutEXsPlS5ILkAAMAMdpvca4v4zq2otEUAALiMLV68WB07dlRwcLBiY2O1Y8eOi85/77331K1bNwUHB+v666/Xhg0bXL4myQUAACaw2+xuD1etXLlSaWlpSk9P165duxQdHa3ExEQdPXq0xvnbtm1TcnKyxo0bp88//1xJSUlKSkrS7t27Xbquxe5LTRwAAHxMWVmZQkNDFa+71chyRb3P84v9rPK1TqWlpQoJCanTmtjYWPXv31+LFi2SJNlsNkVFRenxxx/X9OnTq80fOXKkysvL9eGHHzqO3XjjjerTp48yMzPrHCuVCwAATPCLzuoXuxtDZyVVJSvnj4qKihqvV1lZqcLCQiUkJDiOBQQEKCEhQQUFBTWuKSgocJovSYmJibXOrw0bOgEA8KDGjRsrIiJCW4td37twoWbNmikqKsrpWHp6umbPnl1t7vHjx2W1WhUeHu50PDw8XHv27Knx/MXFxTXOLy4udilOkgsAADwoODhY+/fvV2VlpdvnstvtslgsTseCgoLcPq/RSC4AAPCw4OBgBQcHm3rNNm3aKDAwUCUlJU7HS0pKFBERUeOaiIgIl+bXhj0XAABchho3bqyYmBjl5eU5jtlsNuXl5SkuLq7GNXFxcU7zJSk3N7fW+bWhcgEAwGUqLS1NY8aMUb9+/TRgwAAtXLhQ5eXlGjt2rCQpJSVF7du3V0ZGhiRp8uTJGjx4sObPn6/hw4drxYoV2rlzp5YtW+bSdUkuAAC4TI0cOVLHjh3TrFmzVFxcrD59+ignJ8exafPgwYMKCPi1iTFw4EBlZ2dr5syZevrpp3Xddddp7dq16tWrl0vX5TkXAADAUOy5AAAAhiK5AAAAhiK5AAAAhiK5AAAAhiK5AAAAhiK5AAAAhiK5AAAAhiK5AAAAhiK5AAAAhiK5AAAAhiK5AAAAhvr/MARDCnp9XZsAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "4vZxtXOf4c1k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@staticmethod\n",
        "def bin_to_llr(x):\n",
        "    \"\"\"\n",
        "    Converts binary values (0 or 1) to log-likelihood ratios (LLRs), clipping values to ±20 for numerical stability.\n",
        "    Args:\n",
        "        x (Tensor): Binary input tensor with values 0 or 1.\n",
        "    Returns:\n",
        "        Tensor: Tensor of LLR values with clipped range.\n",
        "    \"\"\"\n",
        "    llr_vector = tf.where(x == 0, -20, 20)\n",
        "    return llr_vector\n",
        "\n",
        "@staticmethod\n",
        "def llr_to_bin(c):\n",
        "    \"\"\"\n",
        "    Converts log-likelihood ratios (LLRs) to binary values based on their sign.\n",
        "    Args:\n",
        "        c (Tensor): Tensor of LLR values.\n",
        "    Returns:\n",
        "        Tensor: Binary tensor with values 0 or 1.\n",
        "    \"\"\"\n",
        "    return tf.cast(tf.greater(c, 0), tf.int32)\n",
        "\n",
        "def load_weights(model, checkpoint_path):\n",
        "    \"\"\"\n",
        "    Loads the model's weights from a specified checkpoint directory.\n",
        "    Args:\n",
        "        model (tf.keras.Model): The model whose weights need to be restored.\n",
        "        checkpoint_path (str): File path where checkpoint files are stored.\n",
        "    \"\"\"\n",
        "    checkpoint = tf.train.Checkpoint(decoder=model._decoder)\n",
        "    try:\n",
        "        checkpoint.restore(checkpoint_path).assert_existing_objects_matched()\n",
        "        print(f\"Successfully restored weights from {checkpoint_path}\")\n",
        "    except AssertionError:\n",
        "        print(\"No checkpoint found. Starting training from scratch.\")\n",
        "\n",
        "def save_weights(model, checkpoint_dir):\n",
        "    \"\"\"\n",
        "    Saves the model's current weights to a specified checkpoint directory.\n",
        "    Args:\n",
        "        model (tf.keras.Model): The model whose weights need to be saved.\n",
        "        checkpoint_dir (str): Directory path where checkpoint files will be saved.\n",
        "    \"\"\"\n",
        "    checkpoint = tf.train.Checkpoint(decoder=model._decoder)\n",
        "    checkpoint.save(checkpoint_dir)\n",
        "    print(f\"Saved weights to {checkpoint_dir}\")\n",
        "\n",
        "def visualize_weights(model):\n",
        "    \"\"\"\n",
        "    Visualizes the trainable weights of the model as heatmaps, updating them in place during training.\n",
        "    Args:\n",
        "        model (tf.keras.Model): The model whose weights are visualized.\n",
        "    \"\"\"\n",
        "    import seaborn as sns\n",
        "    import matplotlib.pyplot as plt\n",
        "\n",
        "    plt.ion()  # Turn on interactive mode\n",
        "    num_weights = len(model.trainable_weights)\n",
        "    fig, axs = plt.subplots(1, num_weights, figsize=(5 * num_weights, 5))\n",
        "\n",
        "    # Ensure axs is iterable (handles single axis case)\n",
        "    if num_weights == 1:\n",
        "        axs = [axs]\n",
        "\n",
        "    print(model.trainable_weights)\n",
        "    for i, var in enumerate(model.trainable_weights):\n",
        "        var_name = var.name\n",
        "        var_value = var.numpy()\n",
        "\n",
        "        axs[i].clear()  # Clear the axis to avoid overlapping\n",
        "\n",
        "        if len(var_value.shape) == 1:  # 1D tensor (e.g., bias)\n",
        "            axs[i].plot(var_value)\n",
        "            axs[i].set_title(f'{var_name} (1D)')\n",
        "        elif len(var_value.shape) == 2:  # 2D tensor (e.g., weights)\n",
        "            sns.heatmap(var_value, cmap=\"viridis\", ax=axs[i], cbar=True)\n",
        "            axs[i].set_title(f'{var_name} (2D)')\n",
        "        else:  # Higher-dimensional tensors\n",
        "            axs[i].text(0.5, 0.5, f\"{var_name}: Shape {var_value.shape} not visualizable\",\n",
        "                        ha='center', va='center', fontsize=10)\n",
        "            axs[i].set_title(f'{var_name} (Not 1D/2D)')\n",
        "\n",
        "    plt.draw()  # Update the figure with new data\n",
        "    plt.pause(0.5)  # Pause briefly to allow visualization updates\n",
        "\n",
        "    plt.ioff()  # Turn off interactive mode\n",
        "    plt.show()\n",
        "\n",
        "# SGD update iteration\n",
        "@tf.function(jit_compile=False)\n",
        "def train_step(model, loss_fn, optimizer, batch_size):\n",
        "    \"\"\"\n",
        "    Performs one training step with a batch of data, applying SGD updates to the model.\n",
        "    Args:\n",
        "        model (tf.keras.Model): The model to be trained.\n",
        "        loss_fn (tf.keras.losses.Loss): Loss function to calculate the error.\n",
        "        optimizer (tf.keras.optimizers.Optimizer): Optimizer to update the model weights.\n",
        "        batch_size (int): Number of samples in the training batch.\n",
        "    Returns:\n",
        "        Tuple: Ground truth binary labels and predicted LLR values.\n",
        "    \"\"\"\n",
        "    # train for random SNRs within a pre-defined interval\n",
        "    ebno_db = tf.random.uniform([batch_size, 1],\n",
        "                                minval=args.ebno_db_min,\n",
        "                                maxval=args.ebno_db_max)\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "        c, c_hat, c_hat_logits, llr_channel = model(batch_size, ebno_db)\n",
        "        # tf.print(c, c_hat)\n",
        "\n",
        "        # tf.print(\"c/c_hat\", c, c_hat_logits)\n",
        "        loss_value = loss_fn(c, c_hat_logits)\n",
        "\n",
        "    # and apply the SGD updates\n",
        "    weights = model.trainable_weights\n",
        "    grads = tape.gradient(loss_value, weights) # variables\n",
        "    optimizer.apply_gradients(zip(grads, weights))\n",
        "    return c, c_hat_logits\n",
        "\n",
        "def test_step(model, args, loss_fn, learning_rate, epoch):\n",
        "    \"\"\"\n",
        "    Evaluates the model on a batch of data, calculating loss, bit error rate (BER), and timing.\n",
        "    Args:\n",
        "        model (tf.keras.Model): The model to be evaluated.\n",
        "        args (Namespace): Arguments containing evaluation parameters.\n",
        "        loss_fn (tf.keras.losses.Loss): Loss function to calculate the error.\n",
        "        learning_rate (float): Current learning rate of the optimizer.\n",
        "        epoch (int): Current epoch of training.\n",
        "    \"\"\"\n",
        "    ebno_db = tf.random.uniform([args.batch_size, 1],\n",
        "                                 minval=args.ebno_db_eval,\n",
        "                                 maxval=args.ebno_db_eval)\n",
        "    # measure time for call\n",
        "    time_start = time.time()\n",
        "    c, c_hat, c_hat_logits, llr_channel = model(args.batch_size, ebno_db)\n",
        "    duration = time.time() - time_start # in s\n",
        "\n",
        "    # loss\n",
        "    loss_value = loss_fn(c, c_hat_logits)\n",
        "    # ber pred\n",
        "    ber = compute_ber(c, c_hat).numpy()\n",
        "    bler = compute_bler(c, c_hat).numpy()\n",
        "    # ber original\n",
        "    c_channel = llr_to_bin(llr_channel)\n",
        "    channel_ber = compute_ber(c, c_channel).numpy()\n",
        "\n",
        "    print(f'Training epoch {epoch}/{args.epochs}, LR={learning_rate:.2e}, Loss={loss_value.numpy():.5e}, channel_BER={channel_ber}, BER={ber}, BLER={bler} duration per call: {duration:.2f}s')\n",
        "\n",
        "def train_dec(model, args, file_name, save_path='/content/drive/My Drive/ECC_weights/', load_decoder_weights=False, visualize_decoder_weights=False):\n",
        "    \"\"\"\n",
        "    Trains the model using a specified training process, evaluates periodically, and saves weights at intervals.\n",
        "    Args:\n",
        "        model (tf.keras.Model): The model to be trained.\n",
        "        args (Namespace): Training arguments including batch size, epochs, learning rate, etc.\n",
        "        file_name (str): Name of the file to save weights.\n",
        "        save_path (str): Directory path to save model checkpoints.\n",
        "        visualize_decoder_weights (bool): Whether to visualize model weights during training.\n",
        "    \"\"\"\n",
        "    # loss\n",
        "    loss_fn =  tf.keras.losses.BinaryCrossentropy(from_logits=False)\n",
        "    # optimizer\n",
        "    scheduler = tf.keras.optimizers.schedules.CosineDecay(initial_learning_rate=args.lr, decay_steps=args.epochs) # 1000 is size of trainloader\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate=scheduler)\n",
        "\n",
        "    # Load weights if available\n",
        "    weights_path = os.path.join(save_path, file_name)\n",
        "    load_weights(model, weights_path) if load_decoder_weights else None\n",
        "\n",
        "    print(\"Training Model...\")\n",
        "    for epoch in range(1, args.epochs + 1):\n",
        "        train_step(model,\n",
        "                   loss_fn,\n",
        "                   optimizer,\n",
        "                   args.batch_size)\n",
        "\n",
        "        # eval train iter\n",
        "        if epoch % args.eval_train_iter == 0:\n",
        "            test_step(model,\n",
        "                      args,\n",
        "                      loss_fn,\n",
        "                      learning_rate=optimizer.learning_rate.numpy(),\n",
        "                      epoch=epoch)\n",
        "            # break\n",
        "\n",
        "        # save weights iter\n",
        "        if epoch % args.save_weights_iter == 0:\n",
        "            save_weights(model, weights_path)\n",
        "\n",
        "        # visualize decoder weights\n",
        "        if visualize_decoder_weights:\n",
        "            visualize_weights(model)\n",
        "\n",
        "\n",
        "train_dec(e2e_ltd, args, file_name='ECCT_pcm_3_5_Tlayers2_dims32/weights-1-1', load_decoder_weights=True, visualize_decoder_weights=False)"
      ],
      "metadata": {
        "id": "oHhDtIq64gjg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ber_plot = PlotBER(f\"Transformer-based Decoding - LDPC, (k,n)=({e2e_ltd._k},{e2e_ltd._n})\")\n",
        "ebno_dbs = np.arange(args.ebno_db_min,\n",
        "                     args.ebno_db_max,\n",
        "                     args.ebno_db_stepsize)"
      ],
      "metadata": {
        "id": "jfyqmvQ0b4zQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# and run the BER simulations\n",
        "ber_plot.simulate(e2e_ltd,\n",
        "                  ebno_dbs=ebno_dbs,\n",
        "                  batch_size=100,#args.mc_batch_size,\n",
        "                  num_target_block_errors=500,\n",
        "                  legend=f\"Transformer dims={e2e_ltd._decoder.dims} n={e2e_ltd._n}\",\n",
        "                  soft_estimates=False,\n",
        "                  max_mc_iter=100,#args.mc_iters,\n",
        "                  forward_keyboard_interrupt=False,\n",
        "                  show_fig=True);"
      ],
      "metadata": {
        "id": "69Jr1CaObMJF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}